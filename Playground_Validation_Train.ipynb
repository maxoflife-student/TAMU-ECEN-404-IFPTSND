{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ignore cuDDa warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enable GPU\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# # Expands the Jupyter Notebook Output Size to fit your window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# Load in tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "from tensorflow_models import TF_Models, Ein_Multiply, leaky_relu, rank_loss_func\n",
    "from graph_predictions import Graph_Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.3045 - val_loss: 0.0564\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2423 - val_loss: 0.0504\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2398 - val_loss: 0.0417\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2415 - val_loss: 0.0338\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1914 - val_loss: 0.0278\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1743 - val_loss: 0.0223\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1320 - val_loss: 0.0116\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1007 - val_loss: 0.0039\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0609 - val_loss: 0.0046\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0346 - val_loss: 0.0050\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0312 - val_loss: 0.0050\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0292 - val_loss: 0.0046\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0302 - val_loss: 0.0042\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0291 - val_loss: 0.0038\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0305 - val_loss: 0.0036\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0308 - val_loss: 0.0034\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0329 - val_loss: 0.0031\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0311 - val_loss: 0.0031\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0279 - val_loss: 0.0030\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0260 - val_loss: 0.0030\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0313 - val_loss: 0.0029\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0290 - val_loss: 0.0030\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0285 - val_loss: 0.0029\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0265 - val_loss: 0.0029\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0223 - val_loss: 0.0029\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0241 - val_loss: 0.0029\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0231 - val_loss: 0.0028\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0224 - val_loss: 0.0028\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0223 - val_loss: 0.0027\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0188 - val_loss: 0.0026\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0173 - val_loss: 0.0024\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0191 - val_loss: 0.0022\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0176 - val_loss: 0.0020\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0181 - val_loss: 0.0019\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0134 - val_loss: 0.0017\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0127 - val_loss: 0.0015\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0157 - val_loss: 0.0014\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0119 - val_loss: 0.0014\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0166 - val_loss: 0.0014\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0129 - val_loss: 0.0015\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0112 - val_loss: 0.0014\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0113 - val_loss: 0.0014\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0116 - val_loss: 0.0013\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - val_loss: 0.0013\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0105 - val_loss: 0.0013\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0092 - val_loss: 0.0013\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0100 - val_loss: 0.0014\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0093 - val_loss: 0.0016\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0097 - val_loss: 0.0019\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0080 - val_loss: 0.0022\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0084 - val_loss: 0.0025\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0075 - val_loss: 0.0026\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0084 - val_loss: 0.0027\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0070 - val_loss: 0.0028\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0072 - val_loss: 0.0029\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0075 - val_loss: 0.0029\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0072 - val_loss: 0.0028\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0068 - val_loss: 0.0028\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0058 - val_loss: 0.0026\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0052 - val_loss: 0.0023\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0054 - val_loss: 0.0021\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0057 - val_loss: 0.0019\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0056 - val_loss: 0.0014\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0046 - val_loss: 9.8752e-04\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0049 - val_loss: 9.5455e-04\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0046 - val_loss: 9.8100e-04\n",
      "Epoch 71/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0046 - val_loss: 9.4000e-04\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0050 - val_loss: 8.4169e-04\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0041 - val_loss: 7.7418e-04\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0048 - val_loss: 6.6122e-04\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0039 - val_loss: 6.8140e-04\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0040 - val_loss: 7.6771e-04\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 8.3442e-04\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 8.9048e-04\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0036 - val_loss: 9.3945e-04\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0037 - val_loss: 9.8983e-04\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0036 - val_loss: 0.0010\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0010\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 9.6525e-04\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0035 - val_loss: 8.5239e-04\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0030 - val_loss: 7.4154e-04\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0027 - val_loss: 6.3376e-04\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0032 - val_loss: 5.3055e-04\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - val_loss: 4.4854e-04\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0029 - val_loss: 3.7674e-04\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0028 - val_loss: 3.1923e-04\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0024 - val_loss: 2.7285e-04\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0028 - val_loss: 2.4753e-04\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0029 - val_loss: 2.3114e-04\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - val_loss: 2.2222e-04\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0026 - val_loss: 2.1618e-04\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0029 - val_loss: 2.2511e-04\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0024 - val_loss: 2.5262e-04\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 2.7458e-04\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - val_loss: 2.9673e-04\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0026 - val_loss: 3.1978e-04\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - val_loss: 3.4120e-04\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 3.5950e-04\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0022 - val_loss: 3.9041e-04\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0024 - val_loss: 4.4117e-04\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0024 - val_loss: 5.2724e-04\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0023 - val_loss: 5.8979e-04\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0023 - val_loss: 6.3284e-04\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 6.2986e-04\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0021 - val_loss: 6.1553e-04\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 5.9248e-04\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0023 - val_loss: 5.5043e-04\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0020 - val_loss: 5.1130e-04\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - val_loss: 5.0825e-04\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0021 - val_loss: 4.9117e-04\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0023 - val_loss: 4.4446e-04\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0022 - val_loss: 4.0227e-04\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0024 - val_loss: 4.5522e-04\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0019 - val_loss: 5.0019e-04\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0023 - val_loss: 5.3175e-04\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0023 - val_loss: 5.7394e-04\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0021 - val_loss: 6.1478e-04\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0022 - val_loss: 6.2622e-04\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0021 - val_loss: 6.0239e-04\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0023 - val_loss: 5.5361e-04\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - val_loss: 4.9903e-04\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0019 - val_loss: 4.2831e-04\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 3.6354e-04\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0021 - val_loss: 3.0612e-04\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 2.5665e-04\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0019 - val_loss: 2.2789e-04\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0020 - val_loss: 2.4207e-04\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0017 - val_loss: 2.5527e-04\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0019 - val_loss: 2.5301e-04\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0019 - val_loss: 3.2966e-04\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0020 - val_loss: 3.9133e-04\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 4.5121e-04\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0021 - val_loss: 5.0465e-04\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0020 - val_loss: 5.4333e-04\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0019 - val_loss: 5.6609e-04\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0018 - val_loss: 5.7760e-04\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0019 - val_loss: 5.6952e-04\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0019 - val_loss: 5.4454e-04\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0024 - val_loss: 4.9367e-04\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0024 - val_loss: 4.0276e-04\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - val_loss: 3.1474e-04\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 2.3296e-04\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - val_loss: 1.6679e-04\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0019 - val_loss: 1.2507e-04\n",
      "Epoch 149/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0017 - val_loss: 1.1348e-04\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 1.1355e-04\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0016 - val_loss: 1.1687e-04\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0018 - val_loss: 1.1596e-04\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0019 - val_loss: 1.1325e-04\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - val_loss: 1.2172e-04\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0024 - val_loss: 1.2281e-04\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0020 - val_loss: 1.3814e-04\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - val_loss: 1.6247e-04\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 1.9105e-04\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - val_loss: 2.1446e-04\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0020 - val_loss: 2.1751e-04\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0017 - val_loss: 2.1397e-04\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0019 - val_loss: 2.1508e-04\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0019 - val_loss: 2.1529e-04\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - val_loss: 2.2205e-04\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 2.3090e-04\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0019 - val_loss: 2.2116e-04\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 2.0840e-04\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 1.9033e-04\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 1.7573e-04\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 1.5834e-04\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 1.6068e-04\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 1.6509e-04\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 1.6970e-04\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0016 - val_loss: 1.7616e-04\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0018 - val_loss: 1.9018e-04\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0019 - val_loss: 1.9612e-04\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 1.9909e-04\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0016 - val_loss: 2.0282e-04\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0017 - val_loss: 2.1740e-04\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0018 - val_loss: 2.1394e-04\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0022 - val_loss: 4.6397e-04\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 6.8997e-04\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - val_loss: 8.7764e-04\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0019 - val_loss: 9.9667e-04\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0018 - val_loss: 9.9389e-04\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - val_loss: 9.0111e-04\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - val_loss: 7.9625e-04\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 6.5042e-04\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 5.0365e-04\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0017 - val_loss: 3.6480e-04\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0017 - val_loss: 2.1905e-04\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0016 - val_loss: 1.2465e-04\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0018 - val_loss: 1.2233e-04\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 1.4540e-04\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 1.3720e-04\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0020 - val_loss: 1.1751e-04\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 1.7054e-04\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0019 - val_loss: 2.6578e-04\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 3.7757e-04\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0015 - val_loss: 4.7379e-04\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0017 - val_loss: 5.3338e-04\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 5.7475e-04\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0014 - val_loss: 5.9785e-04\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 5.7495e-04\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - val_loss: 5.0739e-04\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 4.2016e-04\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0017 - val_loss: 3.3871e-04\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0017 - val_loss: 2.5043e-04\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - val_loss: 1.8814e-04\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0018 - val_loss: 1.4858e-04\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0017 - val_loss: 1.3804e-04\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 1.3360e-04\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - val_loss: 1.2974e-04\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0017 - val_loss: 1.5499e-04\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 2.7210e-04\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 3.5494e-04\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0014 - val_loss: 4.2780e-04\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - val_loss: 4.6472e-04\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0015 - val_loss: 4.8205e-04\n",
      "\n",
      "Loading Model: '02-07-2021--03--15-E2E_LSTM_ValSet_1000.0-ALPHA0.0001-BETA_SD17-223Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 0.006627147427626585\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.3051 - val_loss: 0.0571\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.2430 - val_loss: 0.0511\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2405 - val_loss: 0.0425\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2422 - val_loss: 0.0346\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1922 - val_loss: 0.0287\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1753 - val_loss: 0.0232\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1332 - val_loss: 0.0128\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1022 - val_loss: 0.0048\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0625 - val_loss: 0.0054\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0356 - val_loss: 0.0058\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0321 - val_loss: 0.0058\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0300 - val_loss: 0.0054\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0310 - val_loss: 0.0050\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0299 - val_loss: 0.0046\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0312 - val_loss: 0.0044\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0316 - val_loss: 0.0042\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0335 - val_loss: 0.0040\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0318 - val_loss: 0.0039\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0285 - val_loss: 0.0039\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0267 - val_loss: 0.0039\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0318 - val_loss: 0.0039\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0296 - val_loss: 0.0039\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0291 - val_loss: 0.0039\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0270 - val_loss: 0.0039\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0229 - val_loss: 0.0039\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0246 - val_loss: 0.0038\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0237 - val_loss: 0.0038\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0229 - val_loss: 0.0037\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0228 - val_loss: 0.0036\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0193 - val_loss: 0.0035\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0178 - val_loss: 0.0033\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0197 - val_loss: 0.0031\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0181 - val_loss: 0.0029\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0186 - val_loss: 0.0027\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0140 - val_loss: 0.0025\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0133 - val_loss: 0.0023\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0163 - val_loss: 0.0023\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0125 - val_loss: 0.0023\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0172 - val_loss: 0.0023\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0135 - val_loss: 0.0024\n",
      "Epoch 41/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0118 - val_loss: 0.0024\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0119 - val_loss: 0.0023\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0122 - val_loss: 0.0023\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0105 - val_loss: 0.0023\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0112 - val_loss: 0.0023\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0100 - val_loss: 0.0024\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0108 - val_loss: 0.0025\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0101 - val_loss: 0.0026\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0107 - val_loss: 0.0029\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0087 - val_loss: 0.0032\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0093 - val_loss: 0.0035\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0083 - val_loss: 0.0037\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0092 - val_loss: 0.0039\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0079 - val_loss: 0.0040\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0080 - val_loss: 0.0040\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0081 - val_loss: 0.0040\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0077 - val_loss: 0.0039\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0067 - val_loss: 0.0037\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0060 - val_loss: 0.0034\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0070 - val_loss: 0.0030\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0059 - val_loss: 0.0028\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0066 - val_loss: 0.0026\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0058 - val_loss: 0.0019\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0053 - val_loss: 0.0017\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057 - val_loss: 0.0014\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0055 - val_loss: 0.0015\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0047 - val_loss: 0.0015\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0050 - val_loss: 0.0014\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046 - val_loss: 0.0014\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - val_loss: 0.0021\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0046 - val_loss: 0.0021\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - val_loss: 0.0010\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.0010\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - val_loss: 0.0010\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - val_loss: 0.0010\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 204/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "\n",
      "Loading Model: '02-07-2021--03--27-E2E_LSTM_ValSet_1000.0-ALPHA0.001-BETA_SD17-218Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 0.01168744299173145\n",
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.3113 - val_loss: 0.0640\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.2496 - val_loss: 0.0587\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2475 - val_loss: 0.0506\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2501 - val_loss: 0.0431\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2004 - val_loss: 0.0378\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1856 - val_loss: 0.0332\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1486 - val_loss: 0.0264\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1269 - val_loss: 0.0149\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0974 - val_loss: 0.0132\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0556 - val_loss: 0.0135\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0405 - val_loss: 0.0136\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0373 - val_loss: 0.0134\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0377 - val_loss: 0.0133\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0367 - val_loss: 0.0131\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0383 - val_loss: 0.0131\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0388 - val_loss: 0.0130\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0405 - val_loss: 0.0130\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0390 - val_loss: 0.0130\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0360 - val_loss: 0.0131\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0343 - val_loss: 0.0132\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0393 - val_loss: 0.0133\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0373 - val_loss: 0.0133\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0369 - val_loss: 0.0133\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0351 - val_loss: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0312 - val_loss: 0.0132\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0326 - val_loss: 0.0131\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0318 - val_loss: 0.0131\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0311 - val_loss: 0.0130\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0310 - val_loss: 0.0128\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0277 - val_loss: 0.0127\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0263 - val_loss: 0.0125\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0281 - val_loss: 0.0123\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0265 - val_loss: 0.0121\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0271 - val_loss: 0.0119\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0226 - val_loss: 0.0116\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0220 - val_loss: 0.0115\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0248 - val_loss: 0.0114\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0212 - val_loss: 0.0114\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0257 - val_loss: 0.0114\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0222 - val_loss: 0.0114\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0206 - val_loss: 0.0113\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0207 - val_loss: 0.0113\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0210 - val_loss: 0.0113\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0194 - val_loss: 0.0114\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0200 - val_loss: 0.0116\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0189 - val_loss: 0.0117\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0197 - val_loss: 0.0117\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0189 - val_loss: 0.0118\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0197 - val_loss: 0.0121\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0176 - val_loss: 0.0123\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0180 - val_loss: 0.0126\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0172 - val_loss: 0.0127\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0182 - val_loss: 0.0129\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0168 - val_loss: 0.0130\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0170 - val_loss: 0.0130\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0173 - val_loss: 0.0130\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0171 - val_loss: 0.0130\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0166 - val_loss: 0.0129\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0158 - val_loss: 0.0128\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0156 - val_loss: 0.0126\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0155 - val_loss: 0.0125\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0149 - val_loss: 0.0123\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0152 - val_loss: 0.0121\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0159 - val_loss: 0.0119\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0148 - val_loss: 0.0117\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0155 - val_loss: 0.0114\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0149 - val_loss: 0.0112\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0146 - val_loss: 0.0110\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0147 - val_loss: 0.0108\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0143 - val_loss: 0.0106\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0139 - val_loss: 0.0105\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0147 - val_loss: 0.0105\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0139 - val_loss: 0.0106\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0144 - val_loss: 0.0105\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0137 - val_loss: 0.0105\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0138 - val_loss: 0.0103\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0141 - val_loss: 0.0106\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0134 - val_loss: 0.0108\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0136 - val_loss: 0.0109\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0135 - val_loss: 0.0110\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0136 - val_loss: 0.0111\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0131 - val_loss: 0.0109\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0129 - val_loss: 0.0108\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0126 - val_loss: 0.0108\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0128 - val_loss: 0.0104\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0129 - val_loss: 0.0103\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0127 - val_loss: 0.0101\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0123 - val_loss: 0.0100\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0128 - val_loss: 0.0100\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0122 - val_loss: 0.0101\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0124 - val_loss: 0.0103\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0126 - val_loss: 0.0101\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0126 - val_loss: 0.0101\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0123 - val_loss: 0.0102\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0122 - val_loss: 0.0107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0124 - val_loss: 0.0109\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0124 - val_loss: 0.0106\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0119 - val_loss: 0.0104\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0118 - val_loss: 0.0103\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0121 - val_loss: 0.0102\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0120 - val_loss: 0.0101\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0120 - val_loss: 0.0101\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0121 - val_loss: 0.0100\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0118 - val_loss: 0.0100\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0118 - val_loss: 0.0103\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0118 - val_loss: 0.0104\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0118 - val_loss: 0.0104\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0121 - val_loss: 0.0102\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0118 - val_loss: 0.0100\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0117 - val_loss: 0.0099\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0115 - val_loss: 0.0099\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0126 - val_loss: 0.0101\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0118 - val_loss: 0.0100\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0113 - val_loss: 0.0101\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0102\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0114 - val_loss: 0.0102\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 188/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0102\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0101\n",
      "\n",
      "Loading Model: '02-07-2021--03--39-E2E_LSTM_ValSet_1000.0-ALPHA0.01-BETA_SD17-219Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 0.013909704545112736\n",
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.3731 - val_loss: 0.1303\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.3163 - val_loss: 0.1290\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3137 - val_loss: 0.1256\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3225 - val_loss: 0.1257\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2721 - val_loss: 0.1239\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2666 - val_loss: 0.1239\n",
      "Epoch 7/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2367 - val_loss: 0.1249\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2301 - val_loss: 0.1247\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2269 - val_loss: 0.1261\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2055 - val_loss: 0.1257\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2106 - val_loss: 0.1250\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2015 - val_loss: 0.1242\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1783 - val_loss: 0.1227\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1760 - val_loss: 0.1210\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1860 - val_loss: 0.1194\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1773 - val_loss: 0.1162\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1592 - val_loss: 0.1132\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1660 - val_loss: 0.1108\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1512 - val_loss: 0.1085\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1504 - val_loss: 0.1060\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1447 - val_loss: 0.1043\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1392 - val_loss: 0.1044\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1386 - val_loss: 0.1047\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1309 - val_loss: 0.1049\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1342 - val_loss: 0.1053\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1332 - val_loss: 0.1058\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1312 - val_loss: 0.1069\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1280 - val_loss: 0.1079\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1290 - val_loss: 0.1087\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1229 - val_loss: 0.1093\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1221 - val_loss: 0.1092\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1231 - val_loss: 0.1086\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1196 - val_loss: 0.1075\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1199 - val_loss: 0.1065\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1162 - val_loss: 0.1056\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1145 - val_loss: 0.1045\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1170 - val_loss: 0.1041\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1146 - val_loss: 0.1040\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1151 - val_loss: 0.1041\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1155 - val_loss: 0.1044\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1125 - val_loss: 0.1046\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1146 - val_loss: 0.1048\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1128 - val_loss: 0.1048\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1134 - val_loss: 0.1046\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1115 - val_loss: 0.1046\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1125 - val_loss: 0.1046\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1103 - val_loss: 0.1045\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1124 - val_loss: 0.1041\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1106 - val_loss: 0.1037\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1101 - val_loss: 0.1035\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1080 - val_loss: 0.1035\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1095 - val_loss: 0.1034\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1096 - val_loss: 0.1034\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1090 - val_loss: 0.1035\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1078 - val_loss: 0.1036\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1089 - val_loss: 0.1036\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1077 - val_loss: 0.1037\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1075 - val_loss: 0.1037\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1067 - val_loss: 0.1036\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1072 - val_loss: 0.1033\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1087 - val_loss: 0.1031\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1074 - val_loss: 0.1028\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1057 - val_loss: 0.1027\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1073 - val_loss: 0.1027\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1065 - val_loss: 0.1028\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1087 - val_loss: 0.1030\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1061 - val_loss: 0.1033\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1073 - val_loss: 0.1034\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1077 - val_loss: 0.1035\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1059 - val_loss: 0.1035\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1070 - val_loss: 0.1033\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1075 - val_loss: 0.1032\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1057 - val_loss: 0.1031\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1070 - val_loss: 0.1027\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1061 - val_loss: 0.1023\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1056 - val_loss: 0.1020\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1064 - val_loss: 0.1019\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1067 - val_loss: 0.1018\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1059 - val_loss: 0.1018\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1059 - val_loss: 0.1021\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1062 - val_loss: 0.1024\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1064 - val_loss: 0.1025\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1065 - val_loss: 0.1029\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1066 - val_loss: 0.1037\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1061 - val_loss: 0.1042\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1060 - val_loss: 0.1047\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1070 - val_loss: 0.1047\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1065 - val_loss: 0.1045\n",
      "Epoch 89/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1070 - val_loss: 0.1034\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1077 - val_loss: 0.1022\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1046 - val_loss: 0.1014\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1054 - val_loss: 0.1011\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1068 - val_loss: 0.1011\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1071 - val_loss: 0.1011\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1063 - val_loss: 0.1012\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1069 - val_loss: 0.1012\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1059 - val_loss: 0.1011\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1066 - val_loss: 0.1009\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1052 - val_loss: 0.1010\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1055 - val_loss: 0.1011\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1058 - val_loss: 0.1013\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1045 - val_loss: 0.1015\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1043 - val_loss: 0.1017\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1055 - val_loss: 0.1019\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1049 - val_loss: 0.1019\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1045 - val_loss: 0.1020\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1052 - val_loss: 0.1018\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1052 - val_loss: 0.1017\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1052 - val_loss: 0.1016\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1044 - val_loss: 0.1015\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1041 - val_loss: 0.1015\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1044 - val_loss: 0.1015\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1052 - val_loss: 0.1013\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1041 - val_loss: 0.1012\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1045 - val_loss: 0.1012\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1052 - val_loss: 0.1012\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1045 - val_loss: 0.1012\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1044 - val_loss: 0.1013\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1048 - val_loss: 0.1014\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1050 - val_loss: 0.1016\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1044 - val_loss: 0.1017\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1046 - val_loss: 0.1018\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1051 - val_loss: 0.1018\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1049 - val_loss: 0.1019\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1041 - val_loss: 0.1019\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1037 - val_loss: 0.1020\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1039 - val_loss: 0.1020\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1038 - val_loss: 0.1020\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1039 - val_loss: 0.1019\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1048 - val_loss: 0.1018\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1048 - val_loss: 0.1017\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1045 - val_loss: 0.1015\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1040 - val_loss: 0.1015\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1041 - val_loss: 0.1015\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1048 - val_loss: 0.1015\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1037 - val_loss: 0.1015\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1051 - val_loss: 0.1015\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1043 - val_loss: 0.1015\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1039 - val_loss: 0.1015\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1034 - val_loss: 0.1015\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1043 - val_loss: 0.1015\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1040 - val_loss: 0.1015\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1051 - val_loss: 0.1015\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1048 - val_loss: 0.1016\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1043 - val_loss: 0.1015\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1044 - val_loss: 0.1015\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1041 - val_loss: 0.1014\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1038 - val_loss: 0.1014\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1034 - val_loss: 0.1014\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1033 - val_loss: 0.1014\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1036 - val_loss: 0.1013\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1035 - val_loss: 0.1013\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1038 - val_loss: 0.1012\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1042 - val_loss: 0.1012\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1050 - val_loss: 0.1011\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1043 - val_loss: 0.1011\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1033 - val_loss: 0.1011\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1032 - val_loss: 0.1012\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1029 - val_loss: 0.1012\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1041 - val_loss: 0.1013\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1036 - val_loss: 0.1013\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1039 - val_loss: 0.1013\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1040 - val_loss: 0.1013\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1043 - val_loss: 0.1014\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1034 - val_loss: 0.1015\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1045 - val_loss: 0.1013\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1033 - val_loss: 0.1012\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1035 - val_loss: 0.1011\n",
      "\n",
      "Loading Model: '02-07-2021--03--51-E2E_LSTM_ValSet_1000.0-ALPHA0.1-BETA_SD17-168Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 0.0019858717358929366\n",
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.3044 - val_loss: 0.0563\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.2422 - val_loss: 0.0503\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2397 - val_loss: 0.0416\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2414 - val_loss: 0.0337\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1913 - val_loss: 0.0278\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1742 - val_loss: 0.0222\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1318 - val_loss: 0.0115\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1005 - val_loss: 0.0038\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0607 - val_loss: 0.0045\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0345 - val_loss: 0.0049\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0311 - val_loss: 0.0049\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0291 - val_loss: 0.0045\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0301 - val_loss: 0.0041\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0290 - val_loss: 0.0037\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0304 - val_loss: 0.0035\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0307 - val_loss: 0.0033\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0328 - val_loss: 0.0030\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0310 - val_loss: 0.0030\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0277 - val_loss: 0.0029\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0259 - val_loss: 0.0028\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0312 - val_loss: 0.0028\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0289 - val_loss: 0.0028\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0284 - val_loss: 0.0028\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0264 - val_loss: 0.0028\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0222 - val_loss: 0.0028\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0239 - val_loss: 0.0028\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0230 - val_loss: 0.0027\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0223 - val_loss: 0.0027\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0222 - val_loss: 0.0026\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0187 - val_loss: 0.0025\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0172 - val_loss: 0.0023\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0190 - val_loss: 0.0021\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0175 - val_loss: 0.0019\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0180 - val_loss: 0.0018\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0133 - val_loss: 0.0016\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0126 - val_loss: 0.0014\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0156 - val_loss: 0.0013\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0118 - val_loss: 0.0013\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0165 - val_loss: 0.0013\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0128 - val_loss: 0.0014\n",
      "Epoch 41/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0111 - val_loss: 0.0013\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0112 - val_loss: 0.0013\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0115 - val_loss: 0.0012\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - val_loss: 0.0012\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0104 - val_loss: 0.0012\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - val_loss: 0.0012\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0099 - val_loss: 0.0013\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0092 - val_loss: 0.0015\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0096 - val_loss: 0.0018\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0079 - val_loss: 0.0021\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0083 - val_loss: 0.0024\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0074 - val_loss: 0.0025\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0069 - val_loss: 0.0027\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0071 - val_loss: 0.0028\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0074 - val_loss: 0.0028\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0071 - val_loss: 0.0027\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0056 - val_loss: 0.0024\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0051 - val_loss: 0.0022\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0055 - val_loss: 0.0013\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050 - val_loss: 0.0011\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0045 - val_loss: 9.0944e-04\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0048 - val_loss: 8.8613e-04\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0045 - val_loss: 8.9878e-04\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0046 - val_loss: 8.5438e-04\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0049 - val_loss: 7.5251e-04\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0040 - val_loss: 6.6145e-04\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0047 - val_loss: 5.5014e-04\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 5.8958e-04\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 6.7762e-04\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 7.4329e-04\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 7.9811e-04\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - val_loss: 8.4473e-04\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - val_loss: 8.8898e-04\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - val_loss: 9.1464e-04\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 9.1602e-04\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 8.5191e-04\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - val_loss: 7.3579e-04\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 6.2595e-04\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0026 - val_loss: 5.1936e-04\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - val_loss: 4.1772e-04\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - val_loss: 3.3866e-04\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0028 - val_loss: 2.6975e-04\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0027 - val_loss: 2.1514e-04\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - val_loss: 1.8120e-04\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0027 - val_loss: 1.5855e-04\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0028 - val_loss: 1.4279e-04\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0029 - val_loss: 1.3365e-04\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - val_loss: 1.2847e-04\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 1.3803e-04\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0023 - val_loss: 1.6116e-04\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 1.7733e-04\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - val_loss: 1.9412e-04\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 2.1197e-04\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 2.2950e-04\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 2.4972e-04\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0021 - val_loss: 2.8380e-04\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0023 - val_loss: 3.3756e-04\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0023 - val_loss: 4.2658e-04\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 4.9134e-04\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 5.3641e-04\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0024 - val_loss: 5.3502e-04\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 5.2140e-04\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0022 - val_loss: 4.9842e-04\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 4.5608e-04\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - val_loss: 4.1600e-04\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 4.0448e-04\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 3.7956e-04\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 3.2612e-04\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0021 - val_loss: 2.7860e-04\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - val_loss: 3.2676e-04\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 3.6810e-04\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 3.9743e-04\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0023 - val_loss: 4.3881e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - val_loss: 4.7990e-04\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0021 - val_loss: 4.9264e-04\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 4.7083e-04\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 4.2859e-04\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 3.8090e-04\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 3.1657e-04\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 2.5769e-04\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - val_loss: 2.0524e-04\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 1.5602e-04\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0018 - val_loss: 1.2545e-04\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 1.3802e-04\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - val_loss: 1.4960e-04\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0018 - val_loss: 1.5738e-04\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 1.8051e-04\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0019 - val_loss: 1.9935e-04\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0018 - val_loss: 2.2556e-04\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0021 - val_loss: 2.9061e-04\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - val_loss: 3.4515e-04\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 3.8531e-04\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 4.1660e-04\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 4.3030e-04\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 4.2615e-04\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0023 - val_loss: 3.9362e-04\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0023 - val_loss: 3.1816e-04\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 2.4867e-04\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 1.7784e-04\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0019 - val_loss: 1.1362e-04\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - val_loss: 4.9963e-05\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0016 - val_loss: 2.1955e-05\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0017 - val_loss: 1.6091e-05\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0015 - val_loss: 1.4292e-05\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 1.4394e-05\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0018 - val_loss: 1.5255e-05\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 2.6653e-05\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 2.6287e-05\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 4.0560e-05\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 6.2526e-05\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 8.8155e-05\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 1.1328e-04\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 1.1232e-04\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0016 - val_loss: 1.1148e-04\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 1.1487e-04\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 1.1874e-04\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - val_loss: 1.2982e-04\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 1.5384e-04\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 1.6757e-04\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 1.7425e-04\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0017 - val_loss: 1.5721e-04\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 1.3782e-04\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 1.0710e-04\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 1.0539e-04\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 1.0222e-04\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 9.8441e-05\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0015 - val_loss: 9.5974e-05\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 9.9140e-05\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0018 - val_loss: 1.1139e-04\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0017 - val_loss: 1.1690e-04\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 1.3215e-04\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 1.4960e-04\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 1.4536e-04\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0021 - val_loss: 3.9810e-04\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 6.2324e-04\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 8.0782e-04\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 9.2237e-04\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 9.9715e-04\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 9.7566e-04\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 8.9097e-04\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 7.8966e-04\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 6.7309e-04\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 5.0932e-04\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 3.5949e-04\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 2.1970e-04\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 1.2851e-04\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0015 - val_loss: 8.5763e-05\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 7.7448e-05\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 5.6573e-05\n",
      "Epoch 199/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 9.9897e-05\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 2.7258e-04\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0014 - val_loss: 4.3255e-04\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 5.4684e-04\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 6.1964e-04\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 6.6472e-04\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 6.6719e-04\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 6.4840e-04\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 6.1363e-04\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 5.3464e-04\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 4.1181e-04\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 2.7761e-04\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 1.6507e-04\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 7.1692e-05\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 2.6792e-05\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 1.5183e-05\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 1.5259e-05\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 2.0350e-05\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0016 - val_loss: 2.8740e-05\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 9.2122e-05\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 2.5803e-04\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 3.6809e-04\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 4.6097e-04\n",
      "\n",
      "Loading Model: '02-07-2021--04--03-E2E_LSTM_ValSet_1000.0-ALPHA0-BETA_SD17-221Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 0.005392774761501238\n",
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.9917 - val_loss: 0.6828\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8763 - val_loss: 0.6158\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.8147 - val_loss: 0.5592\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.8004 - val_loss: 0.5177\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7178 - val_loss: 0.4846\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7115 - val_loss: 0.4567\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6456 - val_loss: 0.4346\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6106 - val_loss: 0.4155\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6541 - val_loss: 0.4039\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5710 - val_loss: 0.3947\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6026 - val_loss: 0.3897\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6198 - val_loss: 0.3856\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5330 - val_loss: 0.3818\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5529 - val_loss: 0.3779\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6308 - val_loss: 0.3754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5897 - val_loss: 0.3740\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5356 - val_loss: 0.3736\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5975 - val_loss: 0.3743\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5400 - val_loss: 0.3747\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5670 - val_loss: 0.3754\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5001 - val_loss: 0.3752\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5189 - val_loss: 0.3748\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5268 - val_loss: 0.3744\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5226 - val_loss: 0.3739\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5305 - val_loss: 0.3742\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5218 - val_loss: 0.3758\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5331 - val_loss: 0.3772\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5002 - val_loss: 0.3791\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5534 - val_loss: 0.3810\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5009 - val_loss: 0.3805\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5181 - val_loss: 0.3798\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4917 - val_loss: 0.3780\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5021 - val_loss: 0.3776\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5181 - val_loss: 0.3775\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4786 - val_loss: 0.3778\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4501 - val_loss: 0.3772\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5406 - val_loss: 0.3755\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4818 - val_loss: 0.3742\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4810 - val_loss: 0.3725\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4679 - val_loss: 0.3686\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4963 - val_loss: 0.3653\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4747 - val_loss: 0.3623\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4620 - val_loss: 0.3593\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4834 - val_loss: 0.3560\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4399 - val_loss: 0.3538\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4601 - val_loss: 0.3500\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4929 - val_loss: 0.3472\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4971 - val_loss: 0.3461\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4713 - val_loss: 0.3464\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4408 - val_loss: 0.3485\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4778 - val_loss: 0.3490\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4333 - val_loss: 0.3477\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4628 - val_loss: 0.3458\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4205 - val_loss: 0.3437\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4217 - val_loss: 0.3409\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4280 - val_loss: 0.3375\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4629 - val_loss: 0.3357\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4510 - val_loss: 0.3363\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4004 - val_loss: 0.3383\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4440 - val_loss: 0.3424\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4161 - val_loss: 0.3472\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4511 - val_loss: 0.3530\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4161 - val_loss: 0.3596\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4397 - val_loss: 0.3635\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4024 - val_loss: 0.3655\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4391 - val_loss: 0.3629\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3965 - val_loss: 0.3609\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3919 - val_loss: 0.3577\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4316 - val_loss: 0.3520\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4520 - val_loss: 0.3467\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4239 - val_loss: 0.3443\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4268 - val_loss: 0.3388\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4288 - val_loss: 0.3330\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3847 - val_loss: 0.3285\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3884 - val_loss: 0.3238\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4276 - val_loss: 0.3203\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4326 - val_loss: 0.3186\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4378 - val_loss: 0.3189\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4172 - val_loss: 0.3211\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4431 - val_loss: 0.3261\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3983 - val_loss: 0.3327\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4186 - val_loss: 0.3400\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3799 - val_loss: 0.3477\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3827 - val_loss: 0.3469\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4277 - val_loss: 0.3460\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4189 - val_loss: 0.3457\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4593 - val_loss: 0.3432\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4192 - val_loss: 0.3394\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3922 - val_loss: 0.3369\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4058 - val_loss: 0.3346\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4080 - val_loss: 0.3335\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3809 - val_loss: 0.3342\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3742 - val_loss: 0.3371\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3750 - val_loss: 0.3395\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4030 - val_loss: 0.3441\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3823 - val_loss: 0.3489\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3970 - val_loss: 0.3571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3988 - val_loss: 0.3619\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3569 - val_loss: 0.3627\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4173 - val_loss: 0.3607\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3564 - val_loss: 0.3590\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4261 - val_loss: 0.3576\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3604 - val_loss: 0.3532\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3789 - val_loss: 0.3520\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3878 - val_loss: 0.3511\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4001 - val_loss: 0.3458\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4222 - val_loss: 0.3390\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3692 - val_loss: 0.3323\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3932 - val_loss: 0.3292\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3700 - val_loss: 0.3287\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3825 - val_loss: 0.3309\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3992 - val_loss: 0.3366\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3569 - val_loss: 0.3407\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3698 - val_loss: 0.3459\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3608 - val_loss: 0.3458\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3630 - val_loss: 0.3465\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3924 - val_loss: 0.3509\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3880 - val_loss: 0.3550\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3613 - val_loss: 0.3559\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3498 - val_loss: 0.3566\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3334 - val_loss: 0.3617\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3879 - val_loss: 0.3594\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3746 - val_loss: 0.3519\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3786 - val_loss: 0.3426\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3799 - val_loss: 0.3363\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3877 - val_loss: 0.3315\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3656 - val_loss: 0.3277\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4097 - val_loss: 0.3278\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3819 - val_loss: 0.3299\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3711 - val_loss: 0.3361\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3847 - val_loss: 0.3403\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4343 - val_loss: 0.3430\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3769 - val_loss: 0.3422\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3809 - val_loss: 0.3409\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3945 - val_loss: 0.3394\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3829 - val_loss: 0.3376\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3630 - val_loss: 0.3367\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3692 - val_loss: 0.3380\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3381 - val_loss: 0.3411\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3523 - val_loss: 0.3461\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3387 - val_loss: 0.3561\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3465 - val_loss: 0.3602\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3392 - val_loss: 0.3547\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3567 - val_loss: 0.3469\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3376 - val_loss: 0.3423\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3587 - val_loss: 0.3390\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3255 - val_loss: 0.3353\n",
      "\n",
      "Loading Model: '02-07-2021--04--14-E2E_LSTM_ValSet_1000.0-ALPHA1.0-BETA_SD17-147Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.00818082313448629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 69.0365 - val_loss: 58.0744\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 57.6744 - val_loss: 47.3694\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 46.7613 - val_loss: 37.3128\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 36.8141 - val_loss: 28.0381\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 27.6196 - val_loss: 19.8834\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 19.7456 - val_loss: 12.7153\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 13.1404 - val_loss: 6.6995\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.5385 - val_loss: 2.7894\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.2267 - val_loss: 2.2533\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 6.0656 - val_loss: 4.5760\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3581 - val_loss: 5.8989\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 12.0764 - val_loss: 5.4519\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 11.1679 - val_loss: 4.0972\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0515 - val_loss: 2.7407\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 7.2648 - val_loss: 1.8654\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.4527 - val_loss: 1.5821\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.8850 - val_loss: 1.7903\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4916 - val_loss: 2.3226\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.1818 - val_loss: 2.9972\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.7186 - val_loss: 3.6613\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.7847 - val_loss: 4.2222\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.3962 - val_loss: 4.6324\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.2644 - val_loss: 4.8517\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.9231 - val_loss: 4.8772\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.5805 - val_loss: 4.7362\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4229 - val_loss: 4.4587\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.3905 - val_loss: 4.0771\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.1951 - val_loss: 3.6334\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.1083 - val_loss: 3.1685\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2197 - val_loss: 2.7097\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 4.1545 - val_loss: 2.2839\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.8586 - val_loss: 1.9226\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.0052 - val_loss: 1.6414\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.2623 - val_loss: 1.4430\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.7541 - val_loss: 1.3149\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.8091 - val_loss: 1.2408\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.3853 - val_loss: 1.1969\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.8655 - val_loss: 1.1705\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.9199 - val_loss: 1.1551\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.9066 - val_loss: 1.1487\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.0657 - val_loss: 1.1552\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2594 - val_loss: 1.1871\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1425 - val_loss: 1.2574\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.7824 - val_loss: 1.3521\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.5887 - val_loss: 1.4703\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6634 - val_loss: 1.5821\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6974 - val_loss: 1.6799\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7502 - val_loss: 1.7436\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.7207 - val_loss: 1.7820\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6748 - val_loss: 1.7808\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5919 - val_loss: 1.7572\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6355 - val_loss: 1.7104\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4426 - val_loss: 1.6410\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6177 - val_loss: 1.5733\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.3506 - val_loss: 1.4857\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.3725 - val_loss: 1.3846\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4496 - val_loss: 1.2869\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4566 - val_loss: 1.2048\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.1472 - val_loss: 1.1413\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.1591 - val_loss: 1.0962\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.9871 - val_loss: 1.0582\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.2360 - val_loss: 1.0341\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.1581 - val_loss: 1.0255\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0386 - val_loss: 1.0352\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0631 - val_loss: 1.0577\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1223 - val_loss: 1.0793\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.9876 - val_loss: 1.1092\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9970 - val_loss: 1.1568\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0635 - val_loss: 1.2076\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2260 - val_loss: 1.2583\n",
      "Epoch 71/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7650 - val_loss: 1.2980\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0374 - val_loss: 1.3119\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.1841 - val_loss: 1.2986\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.8462 - val_loss: 1.2746\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7899 - val_loss: 1.2333\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.8585 - val_loss: 1.1812\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9677 - val_loss: 1.1271\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9529 - val_loss: 1.0897\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6209 - val_loss: 1.0543\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.8676 - val_loss: 1.0316\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.8083 - val_loss: 1.0189\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.7042 - val_loss: 1.0155\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6925 - val_loss: 1.0330\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.6985 - val_loss: 1.0532\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.8371 - val_loss: 1.0726\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.6732 - val_loss: 1.0951\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.5794 - val_loss: 1.1215\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8392 - val_loss: 1.1397\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6093 - val_loss: 1.1478\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.8544 - val_loss: 1.1519\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7538 - val_loss: 1.1347\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.5171 - val_loss: 1.1229\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7306 - val_loss: 1.1206\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.6681 - val_loss: 1.0920\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6353 - val_loss: 1.0449\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.3698 - val_loss: 1.0120\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.4927 - val_loss: 0.9759\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.4086 - val_loss: 0.9529\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.2188 - val_loss: 0.9407\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4843 - val_loss: 0.9448\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.2206 - val_loss: 0.9964\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5041 - val_loss: 1.0568\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4558 - val_loss: 1.1306\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.3508 - val_loss: 1.1869\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3844 - val_loss: 1.1649\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3912 - val_loss: 1.0954\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.4351 - val_loss: 0.9934\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.4409 - val_loss: 0.9275\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.2514 - val_loss: 0.8949\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2553 - val_loss: 0.8982\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.2591 - val_loss: 0.9223\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.3823 - val_loss: 0.9447\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2250 - val_loss: 0.9705\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2502 - val_loss: 1.0000\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.1828 - val_loss: 1.0321\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2024 - val_loss: 1.0345\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2064 - val_loss: 1.0033\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3375 - val_loss: 0.9587\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.1540 - val_loss: 0.9386\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1427 - val_loss: 0.9210\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0289 - val_loss: 0.9366\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1270 - val_loss: 0.9860\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2040 - val_loss: 1.0333\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1739 - val_loss: 1.0294\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2278 - val_loss: 0.9253\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.1913 - val_loss: 0.7955\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1625 - val_loss: 0.7611\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2448 - val_loss: 0.7924\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0816 - val_loss: 0.8680\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0383 - val_loss: 1.0017\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.1633 - val_loss: 1.0172\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.1881 - val_loss: 0.9219\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2404 - val_loss: 0.8163\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1983 - val_loss: 0.7855\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.1537 - val_loss: 0.7961\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1325 - val_loss: 0.8158\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0566 - val_loss: 0.8752\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9949 - val_loss: 0.9105\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9069 - val_loss: 0.9070\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9920 - val_loss: 0.8683\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7840 - val_loss: 0.8255\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9998 - val_loss: 0.8679\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9732 - val_loss: 0.9692\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8606 - val_loss: 0.9918\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8509 - val_loss: 0.8603\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9006 - val_loss: 0.7634\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9938 - val_loss: 0.7367\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.9475 - val_loss: 0.8057\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9644 - val_loss: 0.9920\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0085 - val_loss: 1.0768\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9006 - val_loss: 1.0007\n",
      "Epoch 152/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9788 - val_loss: 0.8439\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9961 - val_loss: 0.7348\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0028 - val_loss: 0.7108\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9094 - val_loss: 0.7847\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0367 - val_loss: 0.9144\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9533 - val_loss: 0.9851\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8925 - val_loss: 0.9121\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9149 - val_loss: 0.7876\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9118 - val_loss: 0.7132\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8595 - val_loss: 0.7001\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9336 - val_loss: 0.7008\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8915 - val_loss: 0.7773\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7985 - val_loss: 0.8963\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7528 - val_loss: 0.9571\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8430 - val_loss: 0.8740\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9111 - val_loss: 0.7588\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.8937 - val_loss: 0.6892\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9267 - val_loss: 0.6982\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8541 - val_loss: 0.7753\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8209 - val_loss: 0.8861\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6952 - val_loss: 0.9085\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7999 - val_loss: 0.7948\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8284 - val_loss: 0.6974\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.7425 - val_loss: 0.6469\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.8969 - val_loss: 0.6548\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6930 - val_loss: 0.6830\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7265 - val_loss: 0.7384\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0464 - val_loss: 0.7542\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9207 - val_loss: 0.7727\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7517 - val_loss: 0.7592\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7273 - val_loss: 0.7581\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8005 - val_loss: 0.7058\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8130 - val_loss: 0.7040\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7161 - val_loss: 0.7135\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8695 - val_loss: 0.7224\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6888 - val_loss: 0.7461\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8125 - val_loss: 0.7641\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8292 - val_loss: 0.7557\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.7802 - val_loss: 0.7265\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8052 - val_loss: 0.7333\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7451 - val_loss: 0.7174\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.8002 - val_loss: 0.7560\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7686 - val_loss: 0.7324\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8537 - val_loss: 0.6683\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.6803 - val_loss: 0.6370\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7470 - val_loss: 0.7170\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0021 - val_loss: 0.8223\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7804 - val_loss: 0.8497\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7702 - val_loss: 0.7362\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6962 - val_loss: 0.6519\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8170 - val_loss: 0.6419\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6820 - val_loss: 0.7337\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.6793 - val_loss: 0.8719\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.7911 - val_loss: 0.9067\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8142 - val_loss: 0.7055\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.6749 - val_loss: 0.5878\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7068 - val_loss: 0.5993\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7046 - val_loss: 0.7018\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7373 - val_loss: 0.8084\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.7603 - val_loss: 0.8975\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7080 - val_loss: 0.7863\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5925 - val_loss: 0.6711\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6603 - val_loss: 0.6305\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7839 - val_loss: 0.6649\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6882 - val_loss: 0.7402\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.6772 - val_loss: 0.8104\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6407 - val_loss: 0.7977\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5917 - val_loss: 0.7088\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7187 - val_loss: 0.6283\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5339 - val_loss: 0.6380\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6642 - val_loss: 0.7119\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6482 - val_loss: 0.7814\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6208 - val_loss: 0.7662\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7011 - val_loss: 0.6893\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5712 - val_loss: 0.6179\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6615 - val_loss: 0.6292\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6213 - val_loss: 0.7170\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.6195 - val_loss: 0.7824\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6727 - val_loss: 0.6883\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6675 - val_loss: 0.6294\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6245 - val_loss: 0.6641\n",
      "Epoch 233/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4526 - val_loss: 0.7163\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.6196 - val_loss: 0.6907\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5784 - val_loss: 0.6836\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6841 - val_loss: 0.6727\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4162 - val_loss: 0.6944\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6899 - val_loss: 0.6426\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5790 - val_loss: 0.6175\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6530 - val_loss: 0.6320\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5348 - val_loss: 0.6498\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7351 - val_loss: 0.6825\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5873 - val_loss: 0.6860\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5556 - val_loss: 0.6550\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6768 - val_loss: 0.6439\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5569 - val_loss: 0.6683\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6518 - val_loss: 0.7147\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6587 - val_loss: 0.6636\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5251 - val_loss: 0.6468\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5771 - val_loss: 0.7063\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6753 - val_loss: 0.7062\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6058 - val_loss: 0.7133\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6413 - val_loss: 0.7563\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5901 - val_loss: 0.6836\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6274 - val_loss: 0.6520\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5191 - val_loss: 0.6229\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5594 - val_loss: 0.6336\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5241 - val_loss: 0.6959\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5289 - val_loss: 0.7126\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5458 - val_loss: 0.7058\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5346 - val_loss: 0.6727\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4858 - val_loss: 0.6375\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6322 - val_loss: 0.6278\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6192 - val_loss: 0.6705\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5617 - val_loss: 0.7309\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5748 - val_loss: 0.6869\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5088 - val_loss: 0.6384\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4872 - val_loss: 0.6391\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5428 - val_loss: 0.5989\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3925 - val_loss: 0.6285\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5127 - val_loss: 0.6762\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.6219 - val_loss: 0.7172\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4778 - val_loss: 0.6540\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6060 - val_loss: 0.5938\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.4730 - val_loss: 0.6166\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3729 - val_loss: 0.6775\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5384 - val_loss: 0.6904\n",
      "\n",
      "Loading Model: '02-07-2021--04--27-E2E_LSTM_ValSet_1000.0-ALPHA100.0-BETA_SD17-277Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.011754628832511533\n",
      "Model: \"functional_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 687.6253 - val_loss: 579.1910\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 573.4418 - val_loss: 471.4766\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 463.2179 - val_loss: 370.0913\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 362.3191 - val_loss: 275.7377\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 269.7374 - val_loss: 193.2566\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 189.9204 - val_loss: 121.1828\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 123.8285 - val_loss: 60.8146\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 67.8528 - val_loss: 21.7756\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 44.1371 - val_loss: 17.1653\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 55.4571 - val_loss: 40.9758\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 88.9028 - val_loss: 53.8354\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 114.3331 - val_loss: 48.8973\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 105.8558 - val_loss: 35.1794\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 84.1874 - val_loss: 21.7908\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 64.9287 - val_loss: 13.4112\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 47.0644 - val_loss: 10.9923\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 41.8667 - val_loss: 13.4489\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 37.5717 - val_loss: 19.0603\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 35.4936 - val_loss: 25.9922\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 40.4564 - val_loss: 32.7324\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 42.1418 - val_loss: 38.3646\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 47.5335 - val_loss: 42.4446\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 46.1092 - val_loss: 44.5995\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 52.8408 - val_loss: 44.8030\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 49.2625 - val_loss: 43.3291\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 47.8694 - val_loss: 40.4712\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 47.2986 - val_loss: 36.5366\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 45.5267 - val_loss: 31.9590\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 43.7301 - val_loss: 27.2232\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 35.8830 - val_loss: 22.6342\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 35.0941 - val_loss: 18.4009\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 32.7377 - val_loss: 14.8335\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 32.8319 - val_loss: 12.0760\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 36.4951 - val_loss: 10.1514\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 31.6544 - val_loss: 8.9265\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 32.0493 - val_loss: 8.2328\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 36.2206 - val_loss: 7.8302\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 32.7000 - val_loss: 7.5998\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 32.9641 - val_loss: 7.4871\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 32.9526 - val_loss: 7.4809\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 34.2181 - val_loss: 7.6185\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 36.1551 - val_loss: 8.0223\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 35.2965 - val_loss: 8.8180\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 31.5267 - val_loss: 9.8519\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.1842 - val_loss: 11.1097\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 31.1016 - val_loss: 12.2792\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.6271 - val_loss: 13.2573\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 31.4787 - val_loss: 13.8155\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.7457 - val_loss: 14.0512\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 31.1794 - val_loss: 13.8101\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 29.7652 - val_loss: 13.3153\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.7281 - val_loss: 12.6036\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 28.1852 - val_loss: 11.7243\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 29.9165 - val_loss: 10.9529\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 27.7264 - val_loss: 10.1090\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 27.8875 - val_loss: 9.2722\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 28.5215 - val_loss: 8.5457\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 28.5792 - val_loss: 7.9637\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 25.9787 - val_loss: 7.5232\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 25.9578 - val_loss: 7.2226\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 24.8934 - val_loss: 6.9657\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 26.4681 - val_loss: 6.8172\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 26.1368 - val_loss: 6.7993\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 24.4385 - val_loss: 6.9400\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 25.1015 - val_loss: 7.1863\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 25.6484 - val_loss: 7.3771\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 24.4267 - val_loss: 7.6130\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 25.0827 - val_loss: 7.9902\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 25.4143 - val_loss: 8.3538\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 26.4103 - val_loss: 8.6726\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.6927 - val_loss: 8.8814\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 24.8748 - val_loss: 8.8965\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 25.9789 - val_loss: 8.6963\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 23.7893 - val_loss: 8.4508\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.7003 - val_loss: 8.0969\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 23.2440 - val_loss: 7.6643\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 24.8482 - val_loss: 7.2287\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 23.4759 - val_loss: 6.9387\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 21.2831 - val_loss: 6.6599\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 23.3449 - val_loss: 6.4723\n",
      "Epoch 81/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step - loss: 23.0564 - val_loss: 6.3584\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 21.9779 - val_loss: 6.3157\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 21.8817 - val_loss: 6.4557\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.4784 - val_loss: 6.6202\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 23.2905 - val_loss: 6.7527\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 21.5266 - val_loss: 6.8992\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 20.4924 - val_loss: 7.0783\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 23.0525 - val_loss: 7.2086\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 21.5415 - val_loss: 7.3016\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 23.1848 - val_loss: 7.3935\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 21.8627 - val_loss: 7.3293\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 20.7043 - val_loss: 7.2879\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.5890 - val_loss: 7.3175\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 22.0061 - val_loss: 7.1665\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 21.7824 - val_loss: 6.8522\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.5430 - val_loss: 6.5937\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 20.2241 - val_loss: 6.2687\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.6740 - val_loss: 5.9977\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 18.1494 - val_loss: 5.7589\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 20.1650 - val_loss: 5.6357\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 18.6982 - val_loss: 5.8832\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 20.2536 - val_loss: 6.2392\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 20.2595 - val_loss: 6.7746\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 19.3210 - val_loss: 7.3346\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 19.3879 - val_loss: 7.5326\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.8915 - val_loss: 7.4727\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 20.1605 - val_loss: 7.0373\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 20.0762 - val_loss: 6.5834\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 18.1774 - val_loss: 6.1411\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 18.0662 - val_loss: 5.7815\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 18.3954 - val_loss: 5.5002\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.6207 - val_loss: 5.2372\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 18.7776 - val_loss: 5.1187\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 18.3656 - val_loss: 5.2514\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.9391 - val_loss: 5.7153\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.8025 - val_loss: 6.2578\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.3618 - val_loss: 6.6946\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 18.6073 - val_loss: 6.8352\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 17.6887 - val_loss: 6.7634\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.5914 - val_loss: 6.2827\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 16.5020 - val_loss: 5.8073\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.8140 - val_loss: 5.5680\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 17.6219 - val_loss: 5.6116\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.7923 - val_loss: 5.8661\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 17.9753 - val_loss: 5.8084\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.7872 - val_loss: 5.3668\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.1175 - val_loss: 5.1502\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 17.6967 - val_loss: 5.0846\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.1774 - val_loss: 5.1797\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.4219 - val_loss: 5.7429\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 17.1936 - val_loss: 5.8815\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.2117 - val_loss: 5.5625\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 18.1076 - val_loss: 5.1901\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.2797 - val_loss: 5.2112\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.2832 - val_loss: 5.3026\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 16.8040 - val_loss: 5.0575\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 16.5455 - val_loss: 5.0486\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.8912 - val_loss: 5.0605\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.2695 - val_loss: 5.1651\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.9723 - val_loss: 5.2428\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.1058 - val_loss: 5.2216\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.3151 - val_loss: 5.7274\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.0658 - val_loss: 6.4005\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.9169 - val_loss: 5.9298\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 14.7428 - val_loss: 4.4441\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 14.8227 - val_loss: 3.6687\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.3635 - val_loss: 3.7301\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.7985 - val_loss: 4.6942\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.8447 - val_loss: 6.7112\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.0894 - val_loss: 7.5180\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.1709 - val_loss: 6.6939\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 15.9828 - val_loss: 5.1444\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 15.7119 - val_loss: 3.9939\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 16.0755 - val_loss: 3.6532\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 15.5414 - val_loss: 4.2192\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 16.2304 - val_loss: 5.3734\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.2645 - val_loss: 6.3302\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.9403 - val_loss: 6.3078\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 15.2547 - val_loss: 5.5594\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.4500 - val_loss: 4.7265\n",
      "Epoch 161/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step - loss: 14.8486 - val_loss: 4.1171\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 15.7450 - val_loss: 3.6026\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 14.8711 - val_loss: 3.7836\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.7115 - val_loss: 4.5986\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.6168 - val_loss: 5.8325\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.6179 - val_loss: 6.5754\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.4696 - val_loss: 6.1993\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.1152 - val_loss: 4.9795\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.0931 - val_loss: 3.8964\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 14.7149 - val_loss: 3.4723\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.4826 - val_loss: 3.8459\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2493 - val_loss: 4.8459\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.7101 - val_loss: 5.6352\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 14.2240 - val_loss: 5.7478\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.6351 - val_loss: 4.8866\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 14.8143 - val_loss: 3.8242\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 13.1608 - val_loss: 3.0678\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 13.6392 - val_loss: 3.0178\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.1066 - val_loss: 3.4516\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.0737 - val_loss: 4.6294\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.7207 - val_loss: 5.7333\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.4074 - val_loss: 5.8957\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.1996 - val_loss: 4.4775\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.2179 - val_loss: 3.3765\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 13.1505 - val_loss: 2.8793\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.2157 - val_loss: 2.9883\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 13.1449 - val_loss: 3.8322\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.9319 - val_loss: 5.0815\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.0934 - val_loss: 5.6786\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.0483 - val_loss: 5.0653\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 14.0057 - val_loss: 4.1474\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.6042 - val_loss: 3.2496\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.8115 - val_loss: 3.1624\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.6821 - val_loss: 3.3479\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.4440 - val_loss: 3.6155\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.9801 - val_loss: 3.8217\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.5124 - val_loss: 4.3896\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.0770 - val_loss: 4.4935\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.6406 - val_loss: 4.1657\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.5584 - val_loss: 3.4743\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.0784 - val_loss: 3.2075\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 14.4242 - val_loss: 3.4285\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.0699 - val_loss: 4.3458\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.9187 - val_loss: 5.1792\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.6548 - val_loss: 5.0442\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.3458 - val_loss: 3.3334\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 12.4572 - val_loss: 2.5122\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.2632 - val_loss: 2.7693\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.9664 - val_loss: 3.8004\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.0490 - val_loss: 4.6964\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.7195 - val_loss: 5.2731\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.3731 - val_loss: 4.2693\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.3123 - val_loss: 3.3185\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.9803 - val_loss: 2.9454\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.6823 - val_loss: 3.1285\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.7630 - val_loss: 3.6434\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.1436 - val_loss: 4.2927\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.5274 - val_loss: 4.5528\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.6427 - val_loss: 4.0665\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.1138 - val_loss: 3.2047\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.5238 - val_loss: 2.8907\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.2241 - val_loss: 3.1266\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.7929 - val_loss: 3.7688\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.0247 - val_loss: 4.3573\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.4558 - val_loss: 4.3060\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.2017 - val_loss: 3.4838\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 12.8046 - val_loss: 2.9910\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.3497 - val_loss: 3.1774\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.1706 - val_loss: 3.7582\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.5381 - val_loss: 3.6862\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.6350 - val_loss: 3.5754\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.2927 - val_loss: 3.7889\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.5134 - val_loss: 3.6862\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.7053 - val_loss: 3.0968\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 11.8767 - val_loss: 3.1082\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.1923 - val_loss: 3.5153\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 10.9882 - val_loss: 4.2414\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.8668 - val_loss: 3.5592\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.2129 - val_loss: 2.8718\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 12.7072 - val_loss: 2.7505\n",
      "Epoch 241/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 11.7201 - val_loss: 2.9950\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.3806 - val_loss: 3.6385\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.3510 - val_loss: 3.9838\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.2213 - val_loss: 3.6196\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.9211 - val_loss: 3.1989\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.0703 - val_loss: 3.1699\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.8858 - val_loss: 3.6406\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.3140 - val_loss: 3.5056\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.0125 - val_loss: 3.5346\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.8617 - val_loss: 3.8023\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.8220 - val_loss: 3.5214\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.6223 - val_loss: 3.5988\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 12.2497 - val_loss: 4.0799\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.1309 - val_loss: 3.7350\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.3605 - val_loss: 3.4722\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.5321 - val_loss: 3.0573\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.2519 - val_loss: 2.9853\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.9831 - val_loss: 3.6848\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.6811 - val_loss: 4.1439\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4245 - val_loss: 4.2421\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.8807 - val_loss: 3.7861\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.3755 - val_loss: 3.1727\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.5050 - val_loss: 2.9667\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 12.7768 - val_loss: 3.4662\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.8882 - val_loss: 4.2135\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.1863 - val_loss: 4.0072\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.7390 - val_loss: 3.4540\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.3304 - val_loss: 3.2767\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.9190 - val_loss: 2.8628\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10.5508 - val_loss: 3.2759\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.5530 - val_loss: 3.9599\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.1858 - val_loss: 4.3957\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.4278 - val_loss: 3.5782\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.3121 - val_loss: 2.7202\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.6446 - val_loss: 2.9546\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 10.6505 - val_loss: 3.8149\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.0873 - val_loss: 4.1201\n",
      "\n",
      "Loading Model: '02-07-2021--04--40-E2E_LSTM_ValSet_1000.0-ALPHA1000.0-BETA_SD17-277Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.01103129164689844\n",
      "Model: \"functional_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_34 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.0305 - val_loss: 0.0057\n",
      "Epoch 2/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0243 - val_loss: 0.0051\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0241 - val_loss: 0.0043\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0243 - val_loss: 0.0035\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0193 - val_loss: 0.0029\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0176 - val_loss: 0.0023\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0135 - val_loss: 0.0013\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0104 - val_loss: 4.6386e-04\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0065 - val_loss: 5.2504e-04\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - val_loss: 5.5913e-04\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - val_loss: 5.5907e-04\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 5.1910e-04\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 4.8068e-04\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - val_loss: 4.5132e-04\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0031 - val_loss: 4.2921e-04\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0032 - val_loss: 4.0671e-04\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - val_loss: 3.9275e-04\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - val_loss: 3.8904e-04\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029 - val_loss: 3.8832e-04\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0027 - val_loss: 3.8687e-04\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - val_loss: 3.8985e-04\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 3.9267e-04\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0029 - val_loss: 3.9411e-04\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0027 - val_loss: 3.9565e-04\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - val_loss: 3.9494e-04\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 3.9203e-04\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - val_loss: 3.8762e-04\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - val_loss: 3.8211e-04\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - val_loss: 3.7199e-04\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0020 - val_loss: 3.5800e-04\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0018 - val_loss: 3.3973e-04\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0020 - val_loss: 3.1844e-04\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - val_loss: 2.9669e-04\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0019 - val_loss: 2.7675e-04\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0014 - val_loss: 2.5308e-04\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0014 - val_loss: 2.3448e-04\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0017 - val_loss: 2.2654e-04\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0013 - val_loss: 2.2577e-04\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0018 - val_loss: 2.2653e-04\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 2.2913e-04\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 2.3412e-04\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 2.3848e-04\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 2.3604e-04\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 2.3217e-04\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0011 - val_loss: 2.3035e-04\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 2.3550e-04\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 2.4550e-04\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 2.6464e-04\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 2.9905e-04\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.8700e-04 - val_loss: 3.2943e-04\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.3294e-04 - val_loss: 3.5307e-04\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.3686e-04 - val_loss: 3.6520e-04\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3075e-04 - val_loss: 3.7262e-04\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.9373e-04 - val_loss: 3.7820e-04\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.1433e-04 - val_loss: 3.8057e-04\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.4017e-04 - val_loss: 3.7987e-04\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.1827e-04 - val_loss: 3.7729e-04\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.6910e-04 - val_loss: 3.7315e-04\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.8484e-04 - val_loss: 3.6644e-04\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.7414e-04 - val_loss: 3.5639e-04\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.6180e-04 - val_loss: 3.4278e-04\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.0594e-04 - val_loss: 3.2701e-04\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.3071e-04 - val_loss: 3.0995e-04\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.7944e-04 - val_loss: 2.8863e-04\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.9435e-04 - val_loss: 2.6864e-04\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.6192e-04 - val_loss: 2.4882e-04\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.9759e-04 - val_loss: 2.3011e-04\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.6580e-04 - val_loss: 2.1536e-04\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.0313e-04 - val_loss: 2.1231e-04\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.4722e-04 - val_loss: 2.0632e-04\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.2688e-04 - val_loss: 1.9486e-04\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.7849e-04 - val_loss: 1.8434e-04\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.0479e-04 - val_loss: 1.7578e-04\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 5.3502e-04 - val_loss: 1.6535e-04\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 4.7967e-04 - val_loss: 1.6523e-04\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9310e-04 - val_loss: 1.6632e-04\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.6844e-04 - val_loss: 1.6616e-04\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.8493e-04 - val_loss: 1.6608e-04\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5664e-04 - val_loss: 1.6524e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.5467e-04 - val_loss: 1.6393e-04\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.5350e-04 - val_loss: 1.6191e-04\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.6636e-04 - val_loss: 1.5897e-04\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.4698e-04 - val_loss: 1.5110e-04\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.2837e-04 - val_loss: 1.4044e-04\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.9596e-04 - val_loss: 1.3179e-04\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.6070e-04 - val_loss: 1.2473e-04\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.1540e-04 - val_loss: 1.2161e-04\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.0663e-04 - val_loss: 1.1985e-04\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.8552e-04 - val_loss: 1.1852e-04\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.6423e-04 - val_loss: 1.1778e-04\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.3409e-04 - val_loss: 1.1719e-04\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.6784e-04 - val_loss: 1.1694e-04\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.7784e-04 - val_loss: 1.1643e-04\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.9050e-04 - val_loss: 1.1611e-04\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.5458e-04 - val_loss: 1.1542e-04\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.7942e-04 - val_loss: 1.1558e-04\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3229e-04 - val_loss: 1.1600e-04\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.8445e-04 - val_loss: 1.1561e-04\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 3.2836e-04 - val_loss: 1.1508e-04\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.4862e-04 - val_loss: 1.1484e-04\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.4658e-04 - val_loss: 1.1458e-04\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.1841e-04 - val_loss: 1.1488e-04\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3321e-04 - val_loss: 1.2149e-04\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.3314e-04 - val_loss: 1.3071e-04\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.3895e-04 - val_loss: 1.4367e-04\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.2731e-04 - val_loss: 1.5304e-04\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2072e-04 - val_loss: 1.5974e-04\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.4234e-04 - val_loss: 1.6124e-04\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.0765e-04 - val_loss: 1.6108e-04\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.1771e-04 - val_loss: 1.5912e-04\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2245e-04 - val_loss: 1.5472e-04\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9709e-04 - val_loss: 1.5008e-04\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2507e-04 - val_loss: 1.4752e-04\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9977e-04 - val_loss: 1.4334e-04\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2563e-04 - val_loss: 1.3604e-04\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.1438e-04 - val_loss: 1.2924e-04\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4986e-04 - val_loss: 1.3251e-04\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8764e-04 - val_loss: 1.3521e-04\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1827e-04 - val_loss: 1.3678e-04\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2849e-04 - val_loss: 1.3982e-04\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0397e-04 - val_loss: 1.4298e-04\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.0789e-04 - val_loss: 1.4354e-04\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0354e-04 - val_loss: 1.4093e-04\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2077e-04 - val_loss: 1.3652e-04\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9131e-04 - val_loss: 1.3217e-04\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8119e-04 - val_loss: 1.2639e-04\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.7364e-04 - val_loss: 1.2126e-04\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9811e-04 - val_loss: 1.1699e-04\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.7573e-04 - val_loss: 1.1279e-04\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.8399e-04 - val_loss: 1.1003e-04\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.9201e-04 - val_loss: 1.0898e-04\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.6361e-04 - val_loss: 1.0828e-04\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.8277e-04 - val_loss: 1.0761e-04\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.8137e-04 - val_loss: 1.1476e-04\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.8963e-04 - val_loss: 1.2223e-04\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.7280e-04 - val_loss: 1.2978e-04\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0487e-04 - val_loss: 1.3684e-04\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9216e-04 - val_loss: 1.4237e-04\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7559e-04 - val_loss: 1.4617e-04\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6756e-04 - val_loss: 1.4874e-04\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7583e-04 - val_loss: 1.4913e-04\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7738e-04 - val_loss: 1.4756e-04\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2991e-04 - val_loss: 1.4313e-04\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2889e-04 - val_loss: 1.3440e-04\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7936e-04 - val_loss: 1.2568e-04\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.7966e-04 - val_loss: 1.1755e-04\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9299e-04 - val_loss: 1.1028e-04\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.8148e-04 - val_loss: 1.0387e-04\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.6194e-04 - val_loss: 1.0098e-04\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.7156e-04 - val_loss: 1.0056e-04\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5147e-04 - val_loss: 1.0066e-04\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6906e-04 - val_loss: 1.0060e-04\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7952e-04 - val_loss: 1.0066e-04\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7585e-04 - val_loss: 1.0208e-04\n",
      "Epoch 155/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2777e-04 - val_loss: 1.0215e-04\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9067e-04 - val_loss: 1.0411e-04\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5803e-04 - val_loss: 1.0678e-04\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.6583e-04 - val_loss: 1.1005e-04\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4897e-04 - val_loss: 1.1229e-04\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9367e-04 - val_loss: 1.1185e-04\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5914e-04 - val_loss: 1.1081e-04\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8283e-04 - val_loss: 1.1095e-04\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.7669e-04 - val_loss: 1.1106e-04\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6459e-04 - val_loss: 1.1197e-04\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6569e-04 - val_loss: 1.1329e-04\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8041e-04 - val_loss: 1.1275e-04\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6568e-04 - val_loss: 1.1178e-04\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.6920e-04 - val_loss: 1.0932e-04\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5000e-04 - val_loss: 1.0714e-04\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.6234e-04 - val_loss: 1.0486e-04\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7233e-04 - val_loss: 1.0485e-04\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5905e-04 - val_loss: 1.0507e-04\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3307e-04 - val_loss: 1.0536e-04\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4981e-04 - val_loss: 1.0589e-04\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7023e-04 - val_loss: 1.0731e-04\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.8156e-04 - val_loss: 1.0806e-04\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7042e-04 - val_loss: 1.0879e-04\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5346e-04 - val_loss: 1.0958e-04\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6273e-04 - val_loss: 1.1068e-04\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6648e-04 - val_loss: 1.0998e-04\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0770e-04 - val_loss: 1.3527e-04\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7045e-04 - val_loss: 1.5833e-04\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5799e-04 - val_loss: 1.7752e-04\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8298e-04 - val_loss: 1.8965e-04\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6190e-04 - val_loss: 1.9777e-04\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5074e-04 - val_loss: 2.0306e-04\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9498e-04 - val_loss: 2.0227e-04\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6362e-04 - val_loss: 1.9701e-04\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7442e-04 - val_loss: 1.8869e-04\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5934e-04 - val_loss: 1.7902e-04\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5931e-04 - val_loss: 1.6812e-04\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6636e-04 - val_loss: 1.5311e-04\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4096e-04 - val_loss: 1.3807e-04\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5752e-04 - val_loss: 1.2402e-04\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6278e-04 - val_loss: 1.0941e-04\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5198e-04 - val_loss: 1.0083e-04\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7649e-04 - val_loss: 1.0065e-04\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3976e-04 - val_loss: 1.0151e-04\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.6448e-04 - val_loss: 1.0045e-04\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8795e-04 - val_loss: 1.0404e-04\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4109e-04 - val_loss: 1.1550e-04\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8245e-04 - val_loss: 1.2631e-04\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.6599e-04 - val_loss: 1.3492e-04\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3816e-04 - val_loss: 1.4160e-04\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5664e-04 - val_loss: 1.4462e-04\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3976e-04 - val_loss: 1.4595e-04\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.3344e-04 - val_loss: 1.4578e-04\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6385e-04 - val_loss: 1.4136e-04\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5643e-04 - val_loss: 1.3298e-04\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5324e-04 - val_loss: 1.2322e-04\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6169e-04 - val_loss: 1.1504e-04\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5495e-04 - val_loss: 1.0703e-04\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6228e-04 - val_loss: 1.0568e-04\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7035e-04 - val_loss: 1.0519e-04\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5522e-04 - val_loss: 1.0669e-04\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.4188e-04 - val_loss: 1.0873e-04\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6188e-04 - val_loss: 1.1032e-04\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5887e-04 - val_loss: 1.1767e-04\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5610e-04 - val_loss: 1.2920e-04\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7123e-04 - val_loss: 1.3480e-04\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3193e-04 - val_loss: 1.3909e-04\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5414e-04 - val_loss: 1.3971e-04\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4618e-04 - val_loss: 1.3857e-04\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6578e-04 - val_loss: 1.3531e-04\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4542e-04 - val_loss: 1.3115e-04\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4342e-04 - val_loss: 1.2574e-04\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4326e-04 - val_loss: 1.1913e-04\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5574e-04 - val_loss: 1.1942e-04\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2435e-04 - val_loss: 1.1827e-04\n",
      "Epoch 230/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2641e-04 - val_loss: 1.1656e-04\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4420e-04 - val_loss: 1.1377e-04\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3857e-04 - val_loss: 1.1076e-04\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5056e-04 - val_loss: 1.1032e-04\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5806e-04 - val_loss: 1.1023e-04\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3175e-04 - val_loss: 1.0998e-04\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4433e-04 - val_loss: 1.0835e-04\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.5614e-04 - val_loss: 1.0855e-04\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6975e-04 - val_loss: 1.0533e-04\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4130e-04 - val_loss: 1.0372e-04\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.4689e-04 - val_loss: 1.0191e-04\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2560e-04 - val_loss: 1.0096e-04\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.4721e-04 - val_loss: 1.0121e-04\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5472e-04 - val_loss: 1.0151e-04\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.3622e-04 - val_loss: 1.0246e-04\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4616e-04 - val_loss: 1.0523e-04\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3356e-04 - val_loss: 1.0982e-04\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5374e-04 - val_loss: 1.2136e-04\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4122e-04 - val_loss: 1.2928e-04\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4558e-04 - val_loss: 1.3407e-04\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4417e-04 - val_loss: 1.3448e-04\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5289e-04 - val_loss: 1.3607e-04\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4904e-04 - val_loss: 1.3746e-04\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8561e-04 - val_loss: 1.5405e-04\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.3626e-04 - val_loss: 1.6809e-04\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4238e-04 - val_loss: 1.7648e-04\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6620e-04 - val_loss: 1.7950e-04\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5077e-04 - val_loss: 1.7815e-04\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4004e-04 - val_loss: 1.7461e-04\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5668e-04 - val_loss: 1.6816e-04\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5177e-04 - val_loss: 1.5921e-04\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5204e-04 - val_loss: 1.4720e-04\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.3665e-04 - val_loss: 1.3392e-04\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4223e-04 - val_loss: 1.2293e-04\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2752e-04 - val_loss: 1.1219e-04\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2439e-04 - val_loss: 1.0319e-04\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3308e-04 - val_loss: 1.0071e-04\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3984e-04 - val_loss: 1.0051e-04\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6079e-04 - val_loss: 1.0394e-04\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6825e-04 - val_loss: 1.2472e-04\n",
      "\n",
      "Loading Model: '02-07-2021--04--53-E2E_LSTM_ValSet_100.0-ALPHA0.0001-BETA_SD17-269Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 0.0028715777954697935\n",
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_38 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.0311 - val_loss: 0.0064\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0250 - val_loss: 0.0059\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0248 - val_loss: 0.0051\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0251 - val_loss: 0.0043\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0201 - val_loss: 0.0038\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0186 - val_loss: 0.0033\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0149 - val_loss: 0.0026\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0127 - val_loss: 0.0014\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - val_loss: 0.0013\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0056 - val_loss: 0.0013\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0042 - val_loss: 0.0014\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0012 - val_loss: 9.9912e-04\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0012 - val_loss: 9.9767e-04\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0012 - val_loss: 9.9862e-04\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0012 - val_loss: 9.9488e-04\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 9.9656e-04\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 9.9794e-04\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 9.9886e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 9.9818e-04\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 9.9768e-04\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 9.9649e-04\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 9.9565e-04\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0012 - val_loss: 9.9481e-04\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0011 - val_loss: 9.9434e-04\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0012 - val_loss: 9.9389e-04\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 9.9453e-04\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 9.9563e-04\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 9.9745e-04\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 9.9670e-04\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 9.9927e-04\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 9.9707e-04\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 9.9444e-04\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 9.9515e-04\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 9.9733e-04\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 9.9978e-04\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 9.9638e-04\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "\n",
      "Loading Model: '02-07-2021--05--05-E2E_LSTM_ValSet_100.0-ALPHA0.001-BETA_SD17-240Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 0.012661512213549993\n",
      "Model: \"functional_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_42 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_43 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.0373 - val_loss: 0.0130\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0316 - val_loss: 0.0129\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0314 - val_loss: 0.0126\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0323 - val_loss: 0.0126\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0273 - val_loss: 0.0124\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0267 - val_loss: 0.0124\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0237 - val_loss: 0.0125\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0231 - val_loss: 0.0125\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0227 - val_loss: 0.0126\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0206 - val_loss: 0.0126\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0211 - val_loss: 0.0125\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0202 - val_loss: 0.0125\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0179 - val_loss: 0.0123\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0176 - val_loss: 0.0121\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0186 - val_loss: 0.0120\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0178 - val_loss: 0.0117\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0160 - val_loss: 0.0114\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0167 - val_loss: 0.0111\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0152 - val_loss: 0.0109\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0145 - val_loss: 0.0104\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0139 - val_loss: 0.0105\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0134 - val_loss: 0.0105\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0133 - val_loss: 0.0106\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0131 - val_loss: 0.0107\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0129 - val_loss: 0.0109\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0120 - val_loss: 0.0108\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 41/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0108 - val_loss: 0.0103\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0108 - val_loss: 0.0103\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0105 - val_loss: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "\n",
      "Loading Model: '02-07-2021--05--17-E2E_LSTM_ValSet_100.0-ALPHA0.01-BETA_SD17-186Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 0.00034745793618936417\n",
      "Model: \"functional_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_46 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_47 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.0992 - val_loss: 0.0683\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0877 - val_loss: 0.0616\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0815 - val_loss: 0.0560\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0801 - val_loss: 0.0518\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0718 - val_loss: 0.0485\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0712 - val_loss: 0.0457\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0646 - val_loss: 0.0435\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0611 - val_loss: 0.0416\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0654 - val_loss: 0.0404\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0572 - val_loss: 0.0395\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0603 - val_loss: 0.0390\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0620 - val_loss: 0.0385\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0533 - val_loss: 0.0382\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0554 - val_loss: 0.0378\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0631 - val_loss: 0.0375\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0591 - val_loss: 0.0374\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0537 - val_loss: 0.0373\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0598 - val_loss: 0.0374\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0542 - val_loss: 0.0374\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0570 - val_loss: 0.0375\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0502 - val_loss: 0.0375\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0521 - val_loss: 0.0375\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0529 - val_loss: 0.0374\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0524 - val_loss: 0.0374\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0532 - val_loss: 0.0374\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0523 - val_loss: 0.0375\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0533 - val_loss: 0.0376\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0502 - val_loss: 0.0378\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0555 - val_loss: 0.0381\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0502 - val_loss: 0.0381\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0518 - val_loss: 0.0381\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0492 - val_loss: 0.0379\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0504 - val_loss: 0.0379\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0519 - val_loss: 0.0379\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0480 - val_loss: 0.0379\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0451 - val_loss: 0.0379\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0542 - val_loss: 0.0377\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0483 - val_loss: 0.0375\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0482 - val_loss: 0.0374\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0469 - val_loss: 0.0369\n",
      "Epoch 41/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0498 - val_loss: 0.0366\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0477 - val_loss: 0.0363\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0463 - val_loss: 0.0360\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0485 - val_loss: 0.0356\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0441 - val_loss: 0.0354\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0461 - val_loss: 0.0351\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0494 - val_loss: 0.0348\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0498 - val_loss: 0.0347\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0473 - val_loss: 0.0348\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0442 - val_loss: 0.0350\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0479 - val_loss: 0.0351\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0435 - val_loss: 0.0349\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0463 - val_loss: 0.0347\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0421 - val_loss: 0.0345\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0422 - val_loss: 0.0342\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0429 - val_loss: 0.0339\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0464 - val_loss: 0.0337\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0452 - val_loss: 0.0337\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0401 - val_loss: 0.0339\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0444 - val_loss: 0.0344\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0417 - val_loss: 0.0348\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0452 - val_loss: 0.0354\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0417 - val_loss: 0.0360\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0441 - val_loss: 0.0364\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0403 - val_loss: 0.0366\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0439 - val_loss: 0.0364\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0398 - val_loss: 0.0361\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0393 - val_loss: 0.0358\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0433 - val_loss: 0.0352\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0453 - val_loss: 0.0347\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0425 - val_loss: 0.0345\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0428 - val_loss: 0.0339\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0430 - val_loss: 0.0334\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0386 - val_loss: 0.0330\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0390 - val_loss: 0.0326\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0429 - val_loss: 0.0324\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0434 - val_loss: 0.0322\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0440 - val_loss: 0.0323\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0419 - val_loss: 0.0325\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0446 - val_loss: 0.0331\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0400 - val_loss: 0.0338\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0421 - val_loss: 0.0343\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0381 - val_loss: 0.0349\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0384 - val_loss: 0.0347\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0429 - val_loss: 0.0345\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0421 - val_loss: 0.0345\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0460 - val_loss: 0.0343\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0421 - val_loss: 0.0339\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0399 - val_loss: 0.0336\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0408 - val_loss: 0.0334\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0411 - val_loss: 0.0334\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0383 - val_loss: 0.0335\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0375 - val_loss: 0.0339\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0377 - val_loss: 0.0342\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0405 - val_loss: 0.0347\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0384 - val_loss: 0.0352\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0399 - val_loss: 0.0361\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0401 - val_loss: 0.0367\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0359 - val_loss: 0.0369\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0419 - val_loss: 0.0367\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0359 - val_loss: 0.0366\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0431 - val_loss: 0.0363\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0364 - val_loss: 0.0356\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0380 - val_loss: 0.0354\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0390 - val_loss: 0.0351\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0405 - val_loss: 0.0345\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0425 - val_loss: 0.0338\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0372 - val_loss: 0.0333\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0397 - val_loss: 0.0330\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0372 - val_loss: 0.0330\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0385 - val_loss: 0.0331\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0404 - val_loss: 0.0336\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0359 - val_loss: 0.0340\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0373 - val_loss: 0.0346\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0363 - val_loss: 0.0347\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0365 - val_loss: 0.0348\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0395 - val_loss: 0.0353\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0392 - val_loss: 0.0357\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0366 - val_loss: 0.0356\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0351 - val_loss: 0.0355\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0338 - val_loss: 0.0358\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0388 - val_loss: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0376 - val_loss: 0.0349\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0380 - val_loss: 0.0342\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0384 - val_loss: 0.0338\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0390 - val_loss: 0.0336\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0369 - val_loss: 0.0334\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0415 - val_loss: 0.0335\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0387 - val_loss: 0.0339\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0372 - val_loss: 0.0345\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0386 - val_loss: 0.0349\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0436 - val_loss: 0.0352\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0379 - val_loss: 0.0352\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0385 - val_loss: 0.0351\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0400 - val_loss: 0.0349\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0385 - val_loss: 0.0346\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0365 - val_loss: 0.0344\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0369 - val_loss: 0.0345\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0341 - val_loss: 0.0348\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0355 - val_loss: 0.0352\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0342 - val_loss: 0.0356\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0347 - val_loss: 0.0358\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0342 - val_loss: 0.0352\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0357 - val_loss: 0.0346\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0340 - val_loss: 0.0341\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0361 - val_loss: 0.0335\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0326 - val_loss: 0.0331\n",
      "\n",
      "Loading Model: '02-07-2021--05--29-E2E_LSTM_ValSet_100.0-ALPHA0.1-BETA_SD17-147Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.007388058309865633\n",
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_50 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_51 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.0304 - val_loss: 0.0057\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0242 - val_loss: 0.0051\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0240 - val_loss: 0.0042\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0242 - val_loss: 0.0034\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0192 - val_loss: 0.0028\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0175 - val_loss: 0.0022\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0133 - val_loss: 0.0012\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0102 - val_loss: 3.7724e-04\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0062 - val_loss: 4.3954e-04\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0035 - val_loss: 4.7429e-04\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - val_loss: 4.7264e-04\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0029 - val_loss: 4.3052e-04\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 3.8994e-04\n",
      "Epoch 14/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0029 - val_loss: 3.5586e-04\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0030 - val_loss: 3.3173e-04\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0031 - val_loss: 3.0639e-04\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - val_loss: 2.8923e-04\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - val_loss: 2.8321e-04\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0027 - val_loss: 2.8110e-04\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0026 - val_loss: 2.7861e-04\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0031 - val_loss: 2.8075e-04\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0029 - val_loss: 2.8340e-04\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 2.8512e-04\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0026 - val_loss: 2.8737e-04\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0022 - val_loss: 2.8746e-04\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0024 - val_loss: 2.8515e-04\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0023 - val_loss: 2.8142e-04\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0022 - val_loss: 2.7707e-04\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0022 - val_loss: 2.6752e-04\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0018 - val_loss: 2.5362e-04\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0017 - val_loss: 2.3631e-04\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0019 - val_loss: 2.1652e-04\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0017 - val_loss: 1.9824e-04\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0018 - val_loss: 1.8033e-04\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0013 - val_loss: 1.5616e-04\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0012 - val_loss: 1.4041e-04\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0015 - val_loss: 1.3371e-04\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 1.3438e-04\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 1.3598e-04\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 1.3974e-04\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 1.4496e-04\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 1.4927e-04\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 1.4994e-04\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5897e-04 - val_loss: 1.4338e-04\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0010 - val_loss: 1.3993e-04\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0010e-04 - val_loss: 1.4212e-04\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.6870e-04 - val_loss: 1.4856e-04\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0647e-04 - val_loss: 1.6386e-04\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5916e-04 - val_loss: 1.9312e-04\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.7782e-04 - val_loss: 2.2125e-04\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.2828e-04 - val_loss: 2.4819e-04\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.2832e-04 - val_loss: 2.6243e-04\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.2390e-04 - val_loss: 2.7158e-04\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.8903e-04 - val_loss: 2.7791e-04\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.0940e-04 - val_loss: 2.8081e-04\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.3743e-04 - val_loss: 2.8138e-04\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.1594e-04 - val_loss: 2.7979e-04\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.6787e-04 - val_loss: 2.7619e-04\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8336e-04 - val_loss: 2.6965e-04\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7615e-04 - val_loss: 2.6001e-04\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6083e-04 - val_loss: 2.4699e-04\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0369e-04 - val_loss: 2.3191e-04\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.2838e-04 - val_loss: 2.1545e-04\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.9753e-04 - val_loss: 1.9473e-04\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.9567e-04 - val_loss: 1.7524e-04\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6195e-04 - val_loss: 1.5571e-04\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9878e-04 - val_loss: 1.3709e-04\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 4.7404e-04 - val_loss: 1.1782e-04\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.8628e-04 - val_loss: 9.9631e-05\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.3862e-04 - val_loss: 8.3152e-05\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.9425e-04 - val_loss: 6.9944e-05\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.7529e-04 - val_loss: 5.9901e-05\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.0429e-04 - val_loss: 5.7077e-05\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.2990e-04 - val_loss: 4.7799e-05\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.7662e-04 - val_loss: 4.3865e-05\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.9360e-04 - val_loss: 4.3477e-05\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6521e-04 - val_loss: 4.4712e-05\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8407e-04 - val_loss: 4.6732e-05\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5424e-04 - val_loss: 4.8444e-05\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5559e-04 - val_loss: 5.1811e-05\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.5063e-04 - val_loss: 5.4628e-05\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6252e-04 - val_loss: 5.6531e-05\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3491e-04 - val_loss: 5.3244e-05\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2639e-04 - val_loss: 4.6318e-05\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.9313e-04 - val_loss: 4.0173e-05\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.6128e-04 - val_loss: 3.3747e-05\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.0532e-04 - val_loss: 2.7458e-05\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.0352e-04 - val_loss: 2.2977e-05\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.8336e-04 - val_loss: 1.8950e-05\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.6312e-04 - val_loss: 1.6922e-05\n",
      "Epoch 91/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step - loss: 2.3267e-04 - val_loss: 1.6424e-05\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.6676e-04 - val_loss: 1.6248e-05\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7878e-04 - val_loss: 1.6275e-05\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9051e-04 - val_loss: 1.6336e-05\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5456e-04 - val_loss: 1.6682e-05\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9090e-04 - val_loss: 2.1534e-05\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3112e-04 - val_loss: 3.1314e-05\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8871e-04 - val_loss: 3.9334e-05\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3065e-04 - val_loss: 4.5845e-05\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5091e-04 - val_loss: 5.0747e-05\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5009e-04 - val_loss: 5.3834e-05\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2176e-04 - val_loss: 5.5220e-05\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1540e-04 - val_loss: 5.5693e-05\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2315e-04 - val_loss: 5.7415e-05\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.3553e-04 - val_loss: 5.8518e-05\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3065e-04 - val_loss: 5.6818e-05\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2145e-04 - val_loss: 5.3454e-05\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4050e-04 - val_loss: 4.6289e-05\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0742e-04 - val_loss: 3.9013e-05\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1656e-04 - val_loss: 3.2647e-05\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1663e-04 - val_loss: 2.5700e-05\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9853e-04 - val_loss: 2.0146e-05\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.3036e-04 - val_loss: 1.9107e-05\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.9531e-04 - val_loss: 1.7817e-05\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.1889e-04 - val_loss: 1.4728e-05\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1925e-04 - val_loss: 1.3162e-05\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7078e-04 - val_loss: 2.0558e-05\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8760e-04 - val_loss: 2.8022e-05\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1854e-04 - val_loss: 3.4594e-05\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2676e-04 - val_loss: 4.1500e-05\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0534e-04 - val_loss: 4.8311e-05\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0913e-04 - val_loss: 5.2062e-05\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0474e-04 - val_loss: 5.2165e-05\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2198e-04 - val_loss: 4.9436e-05\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9124e-04 - val_loss: 4.5245e-05\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8453e-04 - val_loss: 3.8846e-05\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7464e-04 - val_loss: 3.2681e-05\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9811e-04 - val_loss: 2.6948e-05\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7748e-04 - val_loss: 2.1007e-05\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8255e-04 - val_loss: 1.5938e-05\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.9161e-04 - val_loss: 1.1812e-05\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.6370e-04 - val_loss: 8.5391e-06\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.8438e-04 - val_loss: 6.1536e-06\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.8757e-04 - val_loss: 1.0155e-05\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.9219e-04 - val_loss: 1.8852e-05\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7363e-04 - val_loss: 2.8268e-05\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0487e-04 - val_loss: 3.7059e-05\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9312e-04 - val_loss: 4.4194e-05\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7638e-04 - val_loss: 4.9434e-05\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6930e-04 - val_loss: 5.3234e-05\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7883e-04 - val_loss: 5.4554e-05\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7786e-04 - val_loss: 5.3737e-05\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3250e-04 - val_loss: 4.8578e-05\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3153e-04 - val_loss: 3.9134e-05\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8039e-04 - val_loss: 2.9683e-05\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8042e-04 - val_loss: 2.0582e-05\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9505e-04 - val_loss: 1.2375e-05\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8342e-04 - val_loss: 4.9143e-06\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.6378e-04 - val_loss: 1.7057e-06\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.7137e-04 - val_loss: 1.3056e-06\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5247e-04 - val_loss: 1.7746e-06\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6987e-04 - val_loss: 1.8991e-06\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8190e-04 - val_loss: 1.3682e-06\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7808e-04 - val_loss: 1.8468e-06\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1746e-04 - val_loss: 1.9322e-06\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9110e-04 - val_loss: 3.3777e-06\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5871e-04 - val_loss: 5.9163e-06\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6550e-04 - val_loss: 8.7464e-06\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5002e-04 - val_loss: 1.1373e-05\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9425e-04 - val_loss: 1.2087e-05\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6008e-04 - val_loss: 1.2165e-05\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8398e-04 - val_loss: 1.3372e-05\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7695e-04 - val_loss: 1.4370e-05\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6583e-04 - val_loss: 1.5972e-05\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6663e-04 - val_loss: 1.7630e-05\n",
      "Epoch 166/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8188e-04 - val_loss: 1.7158e-05\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6681e-04 - val_loss: 1.6154e-05\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7050e-04 - val_loss: 1.3509e-05\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5049e-04 - val_loss: 1.1011e-05\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6400e-04 - val_loss: 7.8193e-06\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.6966e-04 - val_loss: 7.5082e-06\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5958e-04 - val_loss: 7.5365e-06\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3382e-04 - val_loss: 7.6594e-06\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4995e-04 - val_loss: 8.0354e-06\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7175e-04 - val_loss: 9.3327e-06\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8220e-04 - val_loss: 9.7618e-06\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7117e-04 - val_loss: 1.0412e-05\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5429e-04 - val_loss: 1.1548e-05\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6307e-04 - val_loss: 1.2447e-05\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6731e-04 - val_loss: 1.1557e-05\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9697e-04 - val_loss: 3.6541e-05\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7159e-04 - val_loss: 5.9266e-05\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5863e-04 - val_loss: 7.8227e-05\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8270e-04 - val_loss: 9.0266e-05\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6165e-04 - val_loss: 9.8408e-05\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5062e-04 - val_loss: 1.0379e-04\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9497e-04 - val_loss: 1.0322e-04\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6335e-04 - val_loss: 9.8294e-05\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7496e-04 - val_loss: 9.0369e-05\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5993e-04 - val_loss: 8.1101e-05\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6022e-04 - val_loss: 7.0649e-05\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6592e-04 - val_loss: 5.6092e-05\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4188e-04 - val_loss: 4.1460e-05\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5796e-04 - val_loss: 2.7732e-05\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6295e-04 - val_loss: 1.3464e-05\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5266e-04 - val_loss: 2.5842e-06\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7396e-04 - val_loss: 1.8664e-06\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4042e-04 - val_loss: 4.8600e-06\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6763e-04 - val_loss: 3.3849e-06\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9657e-04 - val_loss: 1.9326e-06\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4299e-04 - val_loss: 9.2525e-06\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8338e-04 - val_loss: 1.9802e-05\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6603e-04 - val_loss: 2.9320e-05\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3927e-04 - val_loss: 3.7715e-05\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5568e-04 - val_loss: 4.2607e-05\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4046e-04 - val_loss: 4.5894e-05\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3470e-04 - val_loss: 4.7608e-05\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6475e-04 - val_loss: 4.4964e-05\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5700e-04 - val_loss: 3.8105e-05\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5352e-04 - val_loss: 2.9500e-05\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6200e-04 - val_loss: 2.1923e-05\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5597e-04 - val_loss: 1.3832e-05\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6117e-04 - val_loss: 1.2300e-05\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7049e-04 - val_loss: 1.0738e-05\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5487e-04 - val_loss: 1.2368e-05\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4163e-04 - val_loss: 1.3976e-05\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6274e-04 - val_loss: 1.4904e-05\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6203e-04 - val_loss: 2.1564e-05\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5758e-04 - val_loss: 3.2324e-05\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.7122e-04 - val_loss: 3.7091e-05\n",
      "\n",
      "Loading Model: '02-07-2021--05--41-E2E_LSTM_ValSet_100.0-ALPHA0-BETA_SD17-220Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 0.008216391761593084\n",
      "Model: \"functional_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_54 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_55 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.7178 - val_loss: 0.5901\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6044 - val_loss: 0.4868\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5007 - val_loss: 0.3907\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4105 - val_loss: 0.3038\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3204 - val_loss: 0.2281\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2511 - val_loss: 0.1623\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1864 - val_loss: 0.1090\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1357 - val_loss: 0.0782\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1297 - val_loss: 0.0788\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1266 - val_loss: 0.0927\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1467 - val_loss: 0.1012\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1794 - val_loss: 0.0964\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1582 - val_loss: 0.0845\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1423 - val_loss: 0.0724\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1387 - val_loss: 0.0640\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1214 - val_loss: 0.0603\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1134 - val_loss: 0.0608\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1149 - val_loss: 0.0644\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1031 - val_loss: 0.0694\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1126 - val_loss: 0.0745\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1021 - val_loss: 0.0789\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1144 - val_loss: 0.0822\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1139 - val_loss: 0.0838\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1180 - val_loss: 0.0838\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1153 - val_loss: 0.0823\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1113 - val_loss: 0.0796\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1131 - val_loss: 0.0759\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1090 - val_loss: 0.0716\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1172 - val_loss: 0.0672\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0988 - val_loss: 0.0628\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0999 - val_loss: 0.0588\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0919 - val_loss: 0.0554\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1064 - val_loss: 0.0527\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0984 - val_loss: 0.0507\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0934 - val_loss: 0.0493\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0931 - val_loss: 0.0485\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1122 - val_loss: 0.0480\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0933 - val_loss: 0.0477\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0957 - val_loss: 0.0477\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0919 - val_loss: 0.0479\n",
      "Epoch 41/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0974 - val_loss: 0.0484\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0979 - val_loss: 0.0493\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0921 - val_loss: 0.0507\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0935 - val_loss: 0.0521\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0859 - val_loss: 0.0534\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0883 - val_loss: 0.0541\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0956 - val_loss: 0.0542\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0938 - val_loss: 0.0536\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0953 - val_loss: 0.0526\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0844 - val_loss: 0.0510\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0905 - val_loss: 0.0495\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0848 - val_loss: 0.0481\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0878 - val_loss: 0.0470\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0888 - val_loss: 0.0464\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0816 - val_loss: 0.0459\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0824 - val_loss: 0.0455\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0865 - val_loss: 0.0454\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0841 - val_loss: 0.0455\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0789 - val_loss: 0.0458\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0802 - val_loss: 0.0463\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0741 - val_loss: 0.0467\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0810 - val_loss: 0.0471\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0791 - val_loss: 0.0474\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0813 - val_loss: 0.0477\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0750 - val_loss: 0.0477\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0797 - val_loss: 0.0471\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0766 - val_loss: 0.0467\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0714 - val_loss: 0.0465\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0755 - val_loss: 0.0463\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0831 - val_loss: 0.0464\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0708 - val_loss: 0.0467\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0758 - val_loss: 0.0465\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0803 - val_loss: 0.0463\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0662 - val_loss: 0.0460\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0692 - val_loss: 0.0455\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0745 - val_loss: 0.0450\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0712 - val_loss: 0.0446\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0807 - val_loss: 0.0447\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0695 - val_loss: 0.0449\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0744 - val_loss: 0.0455\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0705 - val_loss: 0.0460\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0707 - val_loss: 0.0462\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0669 - val_loss: 0.0460\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0629 - val_loss: 0.0451\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0698 - val_loss: 0.0444\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0732 - val_loss: 0.0442\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0731 - val_loss: 0.0446\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0723 - val_loss: 0.0453\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0658 - val_loss: 0.0462\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0713 - val_loss: 0.0468\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0706 - val_loss: 0.0467\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0641 - val_loss: 0.0463\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0649 - val_loss: 0.0455\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0650 - val_loss: 0.0442\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0664 - val_loss: 0.0435\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0603 - val_loss: 0.0436\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0662 - val_loss: 0.0441\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0642 - val_loss: 0.0450\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0591 - val_loss: 0.0460\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0668 - val_loss: 0.0468\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0563 - val_loss: 0.0464\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0672 - val_loss: 0.0455\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0622 - val_loss: 0.0451\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0629 - val_loss: 0.0452\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0648 - val_loss: 0.0453\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0626 - val_loss: 0.0451\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0665 - val_loss: 0.0443\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0606 - val_loss: 0.0433\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0620 - val_loss: 0.0423\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0617 - val_loss: 0.0417\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0617 - val_loss: 0.0410\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0646 - val_loss: 0.0403\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0575 - val_loss: 0.0400\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0641 - val_loss: 0.0399\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0621 - val_loss: 0.0402\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0604 - val_loss: 0.0406\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0639 - val_loss: 0.0407\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0649 - val_loss: 0.0406\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0590 - val_loss: 0.0408\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0590 - val_loss: 0.0412\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0562 - val_loss: 0.0417\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0643 - val_loss: 0.0427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0623 - val_loss: 0.0437\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0609 - val_loss: 0.0438\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0630 - val_loss: 0.0426\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0625 - val_loss: 0.0412\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0615 - val_loss: 0.0409\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0665 - val_loss: 0.0414\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0638 - val_loss: 0.0424\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0594 - val_loss: 0.0439\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0635 - val_loss: 0.0433\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0680 - val_loss: 0.0416\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0625 - val_loss: 0.0403\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0659 - val_loss: 0.0404\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0636 - val_loss: 0.0412\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0658 - val_loss: 0.0423\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0602 - val_loss: 0.0432\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0593 - val_loss: 0.0428\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0572 - val_loss: 0.0418\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0584 - val_loss: 0.0414\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0540 - val_loss: 0.0414\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0568 - val_loss: 0.0422\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0562 - val_loss: 0.0435\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0558 - val_loss: 0.0443\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0562 - val_loss: 0.0435\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0588 - val_loss: 0.0423\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0556 - val_loss: 0.0412\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0569 - val_loss: 0.0406\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0582 - val_loss: 0.0410\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0589 - val_loss: 0.0417\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0577 - val_loss: 0.0418\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0598 - val_loss: 0.0409\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0607 - val_loss: 0.0399\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0597 - val_loss: 0.0394\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0543 - val_loss: 0.0393\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0624 - val_loss: 0.0399\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0606 - val_loss: 0.0403\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0572 - val_loss: 0.0398\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0589 - val_loss: 0.0396\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0560 - val_loss: 0.0400\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0557 - val_loss: 0.0407\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0565 - val_loss: 0.0407\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0598 - val_loss: 0.0409\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0605 - val_loss: 0.0412\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0556 - val_loss: 0.0415\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0540 - val_loss: 0.0414\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0551 - val_loss: 0.0412\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0561 - val_loss: 0.0406\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0570 - val_loss: 0.0402\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0571 - val_loss: 0.0400\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0559 - val_loss: 0.0399\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0537 - val_loss: 0.0398\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0558 - val_loss: 0.0395\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0564 - val_loss: 0.0390\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0539 - val_loss: 0.0381\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0569 - val_loss: 0.0373\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0524 - val_loss: 0.0366\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0509 - val_loss: 0.0369\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0613 - val_loss: 0.0379\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0585 - val_loss: 0.0393\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0537 - val_loss: 0.0397\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0547 - val_loss: 0.0395\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0563 - val_loss: 0.0390\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0553 - val_loss: 0.0390\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0546 - val_loss: 0.0393\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0615 - val_loss: 0.0405\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0529 - val_loss: 0.0409\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0540 - val_loss: 0.0405\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0582 - val_loss: 0.0400\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0545 - val_loss: 0.0399\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0548 - val_loss: 0.0405\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0516 - val_loss: 0.0412\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0566 - val_loss: 0.0424\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0548 - val_loss: 0.0425\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0551 - val_loss: 0.0412\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0522 - val_loss: 0.0399\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0513 - val_loss: 0.0392\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0637 - val_loss: 0.0396\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0549 - val_loss: 0.0401\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0540 - val_loss: 0.0390\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0516 - val_loss: 0.0373\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0507 - val_loss: 0.0365\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0479 - val_loss: 0.0367\n",
      "Epoch 204/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0513 - val_loss: 0.0380\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0562 - val_loss: 0.0401\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0593 - val_loss: 0.0394\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0557 - val_loss: 0.0381\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0531 - val_loss: 0.0376\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0547 - val_loss: 0.0377\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0541 - val_loss: 0.0382\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0532 - val_loss: 0.0394\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0503 - val_loss: 0.0392\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0489 - val_loss: 0.0389\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0486 - val_loss: 0.0390\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0543 - val_loss: 0.0394\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0534 - val_loss: 0.0400\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0500 - val_loss: 0.0409\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0497 - val_loss: 0.0410\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0469 - val_loss: 0.0405\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0531 - val_loss: 0.0397\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0482 - val_loss: 0.0392\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0500 - val_loss: 0.0389\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0510 - val_loss: 0.0384\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0514 - val_loss: 0.0379\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0486 - val_loss: 0.0375\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0495 - val_loss: 0.0374\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0499 - val_loss: 0.0380\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0510 - val_loss: 0.0387\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0516 - val_loss: 0.0389\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0502 - val_loss: 0.0383\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0529 - val_loss: 0.0384\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0495 - val_loss: 0.0388\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0424 - val_loss: 0.0385\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0484 - val_loss: 0.0378\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0521 - val_loss: 0.0378\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0516 - val_loss: 0.0381\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0461 - val_loss: 0.0384\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0531 - val_loss: 0.0380\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0490 - val_loss: 0.0373\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0488 - val_loss: 0.0370\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0494 - val_loss: 0.0370\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0534 - val_loss: 0.0379\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0489 - val_loss: 0.0386\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0474 - val_loss: 0.0382\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0511 - val_loss: 0.0377\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0480 - val_loss: 0.0378\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0517 - val_loss: 0.0386\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0534 - val_loss: 0.0394\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0443 - val_loss: 0.0399\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0503 - val_loss: 0.0399\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0508 - val_loss: 0.0394\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0473 - val_loss: 0.0392\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0527 - val_loss: 0.0397\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0493 - val_loss: 0.0398\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0495 - val_loss: 0.0392\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0495 - val_loss: 0.0382\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0464 - val_loss: 0.0375\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0458 - val_loss: 0.0373\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0490 - val_loss: 0.0378\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0446 - val_loss: 0.0390\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0481 - val_loss: 0.0398\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0463 - val_loss: 0.0396\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0524 - val_loss: 0.0393\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0464 - val_loss: 0.0394\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0522 - val_loss: 0.0395\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0487 - val_loss: 0.0399\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0474 - val_loss: 0.0402\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0484 - val_loss: 0.0394\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0486 - val_loss: 0.0380\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0451 - val_loss: 0.0373\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0469 - val_loss: 0.0375\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0534 - val_loss: 0.0394\n",
      "\n",
      "Loading Model: '02-07-2021--05--54-E2E_LSTM_ValSet_100.0-ALPHA1.0-BETA_SD17-272Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.012762842866497688\n",
      "Model: \"functional_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_58 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_59 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 68.7625 - val_loss: 57.9192\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 57.3443 - val_loss: 47.1478\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 46.3220 - val_loss: 37.0094\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 36.2322 - val_loss: 27.5742\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 26.9741 - val_loss: 19.3261\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 18.9925 - val_loss: 12.1188\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 12.3833 - val_loss: 6.0819\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.7856 - val_loss: 2.1778\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.4138 - val_loss: 1.7163\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.5452 - val_loss: 4.0972\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.8897 - val_loss: 5.3834\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.4330 - val_loss: 4.8899\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 10.5857 - val_loss: 3.5182\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.4191 - val_loss: 2.1793\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.4932 - val_loss: 1.3412\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 4.7067 - val_loss: 1.0992\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1868 - val_loss: 1.3448\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7572 - val_loss: 1.9058\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.5493 - val_loss: 2.5990\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0456 - val_loss: 3.2731\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.2141 - val_loss: 3.8363\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 4.7533 - val_loss: 4.2444\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.6109 - val_loss: 4.4599\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.2841 - val_loss: 4.4803\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.9263 - val_loss: 4.3329\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.7870 - val_loss: 4.0472\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.7299 - val_loss: 3.6538\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5528 - val_loss: 3.1960\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.3731 - val_loss: 2.7224\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5884 - val_loss: 2.2636\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5096 - val_loss: 1.8402\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2739 - val_loss: 1.4835\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2833 - val_loss: 1.2077\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.6496 - val_loss: 1.0152\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.1655 - val_loss: 0.8927\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.2050 - val_loss: 0.8233\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.6222 - val_loss: 0.7831\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.2700 - val_loss: 0.7600\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.2966 - val_loss: 0.7487\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.2954 - val_loss: 0.7479\n",
      "Epoch 41/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 3.4220 - val_loss: 0.7617\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.6158 - val_loss: 0.8019\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.5300 - val_loss: 0.8814\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1526 - val_loss: 0.9847\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.0185 - val_loss: 1.1104\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1098 - val_loss: 1.2274\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0625 - val_loss: 1.3253\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1475 - val_loss: 1.3813\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0743 - val_loss: 1.4051\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1179 - val_loss: 1.3812\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9765 - val_loss: 1.3319\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.0728 - val_loss: 1.2609\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8186 - val_loss: 1.1731\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9915 - val_loss: 1.0959\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.7727 - val_loss: 1.0116\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7886 - val_loss: 0.9282\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8519 - val_loss: 0.8556\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8577 - val_loss: 0.7972\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5976 - val_loss: 0.7530\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.5956 - val_loss: 0.7226\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.4893 - val_loss: 0.6967\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.6468 - val_loss: 0.6816\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.6138 - val_loss: 0.6796\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4441 - val_loss: 0.6934\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5104 - val_loss: 0.7179\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.5649 - val_loss: 0.7369\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.4428 - val_loss: 0.7606\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5085 - val_loss: 0.7984\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5416 - val_loss: 0.8350\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.6412 - val_loss: 0.8673\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2693 - val_loss: 0.8884\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.4877 - val_loss: 0.8901\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5981 - val_loss: 0.8702\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3791 - val_loss: 0.8458\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2703 - val_loss: 0.8105\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.3246 - val_loss: 0.7672\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4851 - val_loss: 0.7236\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.3477 - val_loss: 0.6945\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1285 - val_loss: 0.6665\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.3347 - val_loss: 0.6476\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.3059 - val_loss: 0.6361\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1980 - val_loss: 0.6317\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1886 - val_loss: 0.6456\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2482 - val_loss: 0.6619\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.3294 - val_loss: 0.6751\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1530 - val_loss: 0.6898\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0496 - val_loss: 0.7078\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3056 - val_loss: 0.7209\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1546 - val_loss: 0.7304\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3189 - val_loss: 0.7397\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1866 - val_loss: 0.7335\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0709 - val_loss: 0.7294\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2592 - val_loss: 0.7324\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2011 - val_loss: 0.7173\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1789 - val_loss: 0.6858\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9547 - val_loss: 0.6599\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0229 - val_loss: 0.6273\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9680 - val_loss: 0.6001\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8152 - val_loss: 0.5761\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0173 - val_loss: 0.5637\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.8703 - val_loss: 0.5883\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.0259 - val_loss: 0.6238\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0264 - val_loss: 0.6772\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9328 - val_loss: 0.7332\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9391 - val_loss: 0.7532\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9897 - val_loss: 0.7475\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0164 - val_loss: 0.7044\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0083 - val_loss: 0.6592\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8182 - val_loss: 0.6150\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8071 - val_loss: 0.5789\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.8401 - val_loss: 0.5505\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.9625 - val_loss: 0.5239\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.8782 - val_loss: 0.5118\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8371 - val_loss: 0.5248\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7945 - val_loss: 0.5710\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7805 - val_loss: 0.6253\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.7365 - val_loss: 0.6693\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8611 - val_loss: 0.6840\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7693 - val_loss: 0.6774\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7596 - val_loss: 0.6296\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6507 - val_loss: 0.5821\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6816 - val_loss: 0.5580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.7625 - val_loss: 0.5621\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7794 - val_loss: 0.5873\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7976 - val_loss: 0.5815\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7785 - val_loss: 0.5374\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.7120 - val_loss: 0.5161\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.7696 - val_loss: 0.5100\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6176 - val_loss: 0.5195\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6422 - val_loss: 0.5755\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7194 - val_loss: 0.5886\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.7212 - val_loss: 0.5560\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.8106 - val_loss: 0.5184\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7280 - val_loss: 0.5207\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7280 - val_loss: 0.5305\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.6802 - val_loss: 0.5064\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.6545 - val_loss: 0.5057\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5894 - val_loss: 0.5067\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5269 - val_loss: 0.5168\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5973 - val_loss: 0.5244\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4105 - val_loss: 0.5223\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6312 - val_loss: 0.5731\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6063 - val_loss: 0.6411\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4914 - val_loss: 0.5944\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4743 - val_loss: 0.4454\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.4823 - val_loss: 0.3674\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6365 - val_loss: 0.3733\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5801 - val_loss: 0.4696\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5847 - val_loss: 0.6715\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6089 - val_loss: 0.7527\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5172 - val_loss: 0.6706\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5985 - val_loss: 0.5154\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5716 - val_loss: 0.3998\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.6079 - val_loss: 0.3653\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5546 - val_loss: 0.4214\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6237 - val_loss: 0.5364\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5266 - val_loss: 0.6324\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4938 - val_loss: 0.6313\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5257 - val_loss: 0.5574\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5452 - val_loss: 0.4744\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4852 - val_loss: 0.4132\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.5748 - val_loss: 0.3612\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.4872 - val_loss: 0.3786\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3715 - val_loss: 0.4595\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3620 - val_loss: 0.5828\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4619 - val_loss: 0.6580\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5472 - val_loss: 0.6219\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5121 - val_loss: 0.5003\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5097 - val_loss: 0.3913\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4717 - val_loss: 0.3478\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4486 - val_loss: 0.3844\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3254 - val_loss: 0.4839\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3711 - val_loss: 0.5633\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4225 - val_loss: 0.5761\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3638 - val_loss: 0.4907\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4819 - val_loss: 0.3841\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.3164 - val_loss: 0.3076\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.3641 - val_loss: 0.3019\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6111 - val_loss: 0.3446\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5083 - val_loss: 0.4625\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3724 - val_loss: 0.5740\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3410 - val_loss: 0.5920\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4209 - val_loss: 0.4504\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4223 - val_loss: 0.3392\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.3153 - val_loss: 0.2883\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4220 - val_loss: 0.2984\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3154 - val_loss: 0.3825\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3937 - val_loss: 0.5080\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4095 - val_loss: 0.5697\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4053 - val_loss: 0.5097\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4011 - val_loss: 0.4176\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3611 - val_loss: 0.3263\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3813 - val_loss: 0.3161\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3685 - val_loss: 0.3337\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4449 - val_loss: 0.3607\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2980 - val_loss: 0.3827\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3515 - val_loss: 0.4413\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5081 - val_loss: 0.4522\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3645 - val_loss: 0.4184\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3562 - val_loss: 0.3478\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3083 - val_loss: 0.3204\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4430 - val_loss: 0.3424\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3077 - val_loss: 0.4348\n",
      "Epoch 204/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2921 - val_loss: 0.5197\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3660 - val_loss: 0.5074\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3356 - val_loss: 0.3356\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.2458 - val_loss: 0.2520\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3264 - val_loss: 0.2763\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2974 - val_loss: 0.3781\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3049 - val_loss: 0.4692\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3721 - val_loss: 0.5301\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3381 - val_loss: 0.4314\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2317 - val_loss: 0.3348\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2979 - val_loss: 0.2951\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3686 - val_loss: 0.3114\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2772 - val_loss: 0.3622\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3148 - val_loss: 0.4289\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2528 - val_loss: 0.4582\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2649 - val_loss: 0.4112\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3122 - val_loss: 0.3235\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1523 - val_loss: 0.2898\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3228 - val_loss: 0.3115\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2800 - val_loss: 0.3752\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2027 - val_loss: 0.4363\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3459 - val_loss: 0.4344\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2210 - val_loss: 0.3523\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2808 - val_loss: 0.3009\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2350 - val_loss: 0.3171\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2178 - val_loss: 0.3739\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2537 - val_loss: 0.3685\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2638 - val_loss: 0.3599\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2295 - val_loss: 0.3821\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1519 - val_loss: 0.3704\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2709 - val_loss: 0.3096\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1882 - val_loss: 0.3100\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3199 - val_loss: 0.3514\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0992 - val_loss: 0.4258\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2872 - val_loss: 0.3586\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2217 - val_loss: 0.2888\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2708 - val_loss: 0.2751\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1725 - val_loss: 0.2984\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3389 - val_loss: 0.3631\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2355 - val_loss: 0.3999\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2228 - val_loss: 0.3648\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2927 - val_loss: 0.3218\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2074 - val_loss: 0.3171\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2892 - val_loss: 0.3626\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2314 - val_loss: 0.3500\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2018 - val_loss: 0.3549\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1865 - val_loss: 0.3827\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2829 - val_loss: 0.3538\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2627 - val_loss: 0.3597\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2256 - val_loss: 0.4065\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2132 - val_loss: 0.3734\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2366 - val_loss: 0.3488\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1538 - val_loss: 0.3074\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2256 - val_loss: 0.2989\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1988 - val_loss: 0.3672\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1686 - val_loss: 0.4133\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2428 - val_loss: 0.4252\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1886 - val_loss: 0.3809\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1381 - val_loss: 0.3185\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2511 - val_loss: 0.2960\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2783 - val_loss: 0.3447\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1894 - val_loss: 0.4207\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2190 - val_loss: 0.4027\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1748 - val_loss: 0.3474\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1334 - val_loss: 0.3277\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1925 - val_loss: 0.2849\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0560 - val_loss: 0.3261\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1561 - val_loss: 0.3960\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2190 - val_loss: 0.4417\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1439 - val_loss: 0.3595\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2323 - val_loss: 0.2719\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1650 - val_loss: 0.2936\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0660 - val_loss: 0.3794\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2091 - val_loss: 0.4127\n",
      "\n",
      "Loading Model: '02-07-2021--06--07-E2E_LSTM_ValSet_100.0-ALPHA100.0-BETA_SD17-277Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.01103129164689844\n",
      "Model: \"functional_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_62 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_63 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 687.3513 - val_loss: 579.0989\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 573.1647 - val_loss: 471.3477\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 462.8871 - val_loss: 369.9203\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 361.8965 - val_loss: 275.5151\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 269.3006 - val_loss: 192.9736\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 189.3869 - val_loss: 120.8360\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 123.2786 - val_loss: 60.3928\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 67.2428 - val_loss: 21.2552\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 43.3343 - val_loss: 16.5504\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 54.7467 - val_loss: 40.3760\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 88.2540 - val_loss: 53.2916\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 113.6116 - val_loss: 48.3864\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 105.3123 - val_loss: 34.6752\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 83.6254 - val_loss: 21.2867\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 64.2308 - val_loss: 12.9114\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 46.3622 - val_loss: 10.5018\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 41.1834 - val_loss: 12.9713\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 36.8338 - val_loss: 18.5979\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 34.8441 - val_loss: 25.5449\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 39.7575 - val_loss: 32.2984\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 41.5524 - val_loss: 37.9432\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 46.8743 - val_loss: 42.0334\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 45.4396 - val_loss: 44.1963\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 52.1938 - val_loss: 44.4056\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 48.6116 - val_loss: 42.9356\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 47.2415 - val_loss: 40.0794\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 46.6451 - val_loss: 36.1432\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 44.8970 - val_loss: 31.5607\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 43.0043 - val_loss: 26.8163\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 35.2599 - val_loss: 22.2227\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 34.4548 - val_loss: 17.9872\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 32.1584 - val_loss: 14.4187\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 32.1087 - val_loss: 11.6609\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 35.8797 - val_loss: 9.7372\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 31.0570 - val_loss: 8.5139\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 31.4378 - val_loss: 7.8220\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 35.4561 - val_loss: 7.4212\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 32.1012 - val_loss: 7.1927\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 32.3381 - val_loss: 7.0815\n",
      "Epoch 40/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 32.3432 - val_loss: 7.0766\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 33.5788 - val_loss: 7.2147\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 35.5223 - val_loss: 7.6195\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 34.6987 - val_loss: 8.4164\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.8905 - val_loss: 9.4516\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 29.6121 - val_loss: 10.7113\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 30.5281 - val_loss: 11.8838\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 29.9732 - val_loss: 12.8649\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 30.8456 - val_loss: 13.4254\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.0736 - val_loss: 13.6616\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 30.5998 - val_loss: 13.4202\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 29.1369 - val_loss: 12.9235\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.1640 - val_loss: 12.2094\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 27.5603 - val_loss: 11.3276\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 29.2737 - val_loss: 10.5543\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 27.1586 - val_loss: 9.7091\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 27.3049 - val_loss: 8.8693\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 27.9223 - val_loss: 8.1410\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 27.9641 - val_loss: 7.5685\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 25.4134 - val_loss: 7.1379\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 25.3828 - val_loss: 6.8425\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 24.3880 - val_loss: 6.5874\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 25.8700 - val_loss: 6.4398\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 25.5879 - val_loss: 6.4221\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 23.8472 - val_loss: 6.5623\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 24.5420 - val_loss: 6.8077\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 25.0730 - val_loss: 6.9965\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 23.8647 - val_loss: 7.2294\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 24.5805 - val_loss: 7.6046\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 24.8804 - val_loss: 7.9698\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 25.8123 - val_loss: 8.2936\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 22.1813 - val_loss: 8.5038\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 24.3094 - val_loss: 8.5228\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 25.3796 - val_loss: 8.3268\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 23.2992 - val_loss: 8.0852\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.1684 - val_loss: 7.7352\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.7028 - val_loss: 7.3051\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 24.3550 - val_loss: 6.8710\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.8458 - val_loss: 6.5795\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 20.7793 - val_loss: 6.2974\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 22.7887 - val_loss: 6.1047\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 22.5468 - val_loss: 5.9845\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 21.4622 - val_loss: 5.9357\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 21.3737 - val_loss: 6.0702\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 22.0374 - val_loss: 6.2313\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 22.7776 - val_loss: 6.3627\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 21.0001 - val_loss: 6.5102\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 19.9624 - val_loss: 6.6919\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 22.5133 - val_loss: 6.8270\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 21.0858 - val_loss: 6.9271\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 22.6414 - val_loss: 7.0268\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 21.2794 - val_loss: 6.9694\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 20.2466 - val_loss: 6.9313\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 22.0856 - val_loss: 6.9616\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 21.5323 - val_loss: 6.8118\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 21.3225 - val_loss: 6.4983\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 19.1092 - val_loss: 6.2377\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7375 - val_loss: 5.9089\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.2155 - val_loss: 5.6330\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 17.7366 - val_loss: 5.3884\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.6941 - val_loss: 5.2581\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 18.3255 - val_loss: 5.4979\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.7572 - val_loss: 5.8484\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 19.8042 - val_loss: 6.3802\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 18.8793 - val_loss: 6.9406\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 18.9266 - val_loss: 7.1478\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.4845 - val_loss: 7.1077\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.7015 - val_loss: 6.6964\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 19.5915 - val_loss: 6.2582\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.7282 - val_loss: 5.8200\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.6138 - val_loss: 5.4536\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 17.9594 - val_loss: 5.1583\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.1679 - val_loss: 4.8771\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 18.3816 - val_loss: 4.7409\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.9139 - val_loss: 4.8536\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.5123 - val_loss: 5.2948\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 17.3744 - val_loss: 5.8374\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.8646 - val_loss: 6.2960\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 18.1008 - val_loss: 6.4825\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 17.2731 - val_loss: 6.4545\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.1691 - val_loss: 5.9995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.0938 - val_loss: 5.5229\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.3286 - val_loss: 5.2567\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.1482 - val_loss: 5.2586\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 17.3491 - val_loss: 5.4744\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 17.4904 - val_loss: 5.4078\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.2931 - val_loss: 4.9920\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.6365 - val_loss: 4.8221\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.2002 - val_loss: 4.7958\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.6697 - val_loss: 4.9087\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 15.9796 - val_loss: 5.4649\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.7184 - val_loss: 5.5644\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.7036 - val_loss: 5.2060\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.6296 - val_loss: 4.8156\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.8063 - val_loss: 4.8459\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.7985 - val_loss: 4.9680\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.2957 - val_loss: 4.7526\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.0909 - val_loss: 4.7577\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 15.4600 - val_loss: 4.7633\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.8514 - val_loss: 4.8469\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.5502 - val_loss: 4.9012\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.7029 - val_loss: 4.8683\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.9159 - val_loss: 5.3818\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.6659 - val_loss: 6.0803\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 14.5006 - val_loss: 5.6429\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 14.3518 - val_loss: 4.1638\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 14.3631 - val_loss: 3.3566\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 15.9584 - val_loss: 3.3869\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.4022 - val_loss: 4.3176\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.4337 - val_loss: 6.2932\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 15.6158 - val_loss: 7.1692\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.7082 - val_loss: 6.4490\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.5612 - val_loss: 4.9271\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 15.2598 - val_loss: 3.7329\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 15.6248 - val_loss: 3.3328\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.1523 - val_loss: 3.8441\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.7804 - val_loss: 4.9470\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.7987 - val_loss: 5.9000\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.4808 - val_loss: 5.9444\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.7984 - val_loss: 5.2748\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 15.0454 - val_loss: 4.4850\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.4498 - val_loss: 3.8739\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 15.3472 - val_loss: 3.3243\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.4268 - val_loss: 3.4666\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.2528 - val_loss: 4.2416\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2266 - val_loss: 5.4551\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 14.2248 - val_loss: 6.2238\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.0595 - val_loss: 5.8900\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.7075 - val_loss: 4.6962\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 14.6795 - val_loss: 3.6132\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 14.3096 - val_loss: 3.1754\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.0711 - val_loss: 3.5388\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.8616 - val_loss: 4.5274\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2708 - val_loss: 5.3125\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.8124 - val_loss: 5.4440\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.2248 - val_loss: 4.6124\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.3911 - val_loss: 3.5650\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 12.7946 - val_loss: 2.7993\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 13.2710 - val_loss: 2.7367\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.6925 - val_loss: 3.1417\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.6851 - val_loss: 4.2873\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 13.3346 - val_loss: 5.4422\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.0169 - val_loss: 5.7082\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.8209 - val_loss: 4.3247\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.8478 - val_loss: 3.1731\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 12.7554 - val_loss: 2.5992\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.7365 - val_loss: 2.6374\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.7878 - val_loss: 3.4295\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.5183 - val_loss: 4.6985\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.6397 - val_loss: 5.3973\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.6544 - val_loss: 4.8690\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 13.6061 - val_loss: 3.9478\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.2472 - val_loss: 2.9817\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.3509 - val_loss: 2.8189\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2839 - val_loss: 2.9473\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.0399 - val_loss: 3.2100\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.5836 - val_loss: 3.4783\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.1412 - val_loss: 4.1364\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.5847 - val_loss: 4.2787\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.2170 - val_loss: 3.9068\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.1477 - val_loss: 3.1455\n",
      "Epoch 201/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 12.6739 - val_loss: 2.8390\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.0663 - val_loss: 3.0574\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.7184 - val_loss: 4.0048\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.5233 - val_loss: 4.9256\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.2452 - val_loss: 4.8347\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.9290 - val_loss: 3.0862\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 11.9980 - val_loss: 2.2061\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.8506 - val_loss: 2.4011\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.5879 - val_loss: 3.3626\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.6290 - val_loss: 4.3286\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 13.3081 - val_loss: 5.0823\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.0388 - val_loss: 4.2053\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.9669 - val_loss: 3.1687\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.5919 - val_loss: 2.6443\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.2647 - val_loss: 2.6929\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 12.3816 - val_loss: 3.1397\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.7851 - val_loss: 3.8721\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 12.1307 - val_loss: 4.3386\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.3207 - val_loss: 3.9739\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.7610 - val_loss: 3.0333\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.1298 - val_loss: 2.5738\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.8617 - val_loss: 2.6799\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.4246 - val_loss: 3.2684\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.6032 - val_loss: 3.9809\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.0772 - val_loss: 4.1388\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.8681 - val_loss: 3.3480\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4281 - val_loss: 2.7407\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.9481 - val_loss: 2.7792\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.7764 - val_loss: 3.2592\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 12.1119 - val_loss: 3.2768\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.2244 - val_loss: 3.3238\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.9179 - val_loss: 3.6203\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.2233 - val_loss: 3.4500\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.3791 - val_loss: 2.7439\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.4715 - val_loss: 2.6855\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.8201 - val_loss: 3.1050\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 10.6745 - val_loss: 3.9420\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4497 - val_loss: 3.3655\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.8440 - val_loss: 2.6374\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.2892 - val_loss: 2.4142\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.3572 - val_loss: 2.5667\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.0009 - val_loss: 3.1991\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.9826 - val_loss: 3.6928\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.8860 - val_loss: 3.4631\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.5412 - val_loss: 3.0046\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.7073 - val_loss: 2.8340\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.5186 - val_loss: 3.1687\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.9026 - val_loss: 3.0829\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.6865 - val_loss: 3.2511\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.4763 - val_loss: 3.6118\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4512 - val_loss: 3.2844\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.2673 - val_loss: 3.2297\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.8542 - val_loss: 3.5975\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.7291 - val_loss: 3.3329\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.9788 - val_loss: 3.2034\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.1708 - val_loss: 2.8323\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.9017 - val_loss: 2.6930\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.6274 - val_loss: 3.2767\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.3368 - val_loss: 3.7075\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.0955 - val_loss: 3.9255\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.5163 - val_loss: 3.5904\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.0442 - val_loss: 2.9416\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.1200 - val_loss: 2.6179\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.4504 - val_loss: 3.0253\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.5106 - val_loss: 3.8091\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.8297 - val_loss: 3.7696\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.3957 - val_loss: 3.2530\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10.9882 - val_loss: 2.9791\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.5845 - val_loss: 2.4762\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10.2442 - val_loss: 2.8635\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.2130 - val_loss: 3.6245\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.7821 - val_loss: 4.1786\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.1172 - val_loss: 3.3571\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.9710 - val_loss: 2.4010\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.3365 - val_loss: 2.5364\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 10.3645 - val_loss: 3.3698\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.7399 - val_loss: 3.8251\n",
      "\n",
      "Loading Model: '02-07-2021--06--20-E2E_LSTM_ValSet_100.0-ALPHA1000.0-BETA_SD17-277Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.010997811916933838\n",
      "Model: \"functional_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_66 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_67 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 3.7313e-04 - val_loss: 1.3258e-04\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.2205e-04 - val_loss: 1.3264e-04\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.2466e-04 - val_loss: 1.2957e-04\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.4010e-04 - val_loss: 1.2829e-04\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.9445e-04 - val_loss: 1.2652e-04\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.8983e-04 - val_loss: 1.2549e-04\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.5921e-04 - val_loss: 1.2492e-04\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.5045e-04 - val_loss: 1.2604e-04\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4908e-04 - val_loss: 1.2582e-04\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.2135e-04 - val_loss: 1.2630e-04\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2872e-04 - val_loss: 1.2897e-04\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1917e-04 - val_loss: 1.2837e-04\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9117e-04 - val_loss: 1.2691e-04\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8965e-04 - val_loss: 1.2529e-04\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0259e-04 - val_loss: 1.2473e-04\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9343e-04 - val_loss: 1.2393e-04\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.7322e-04 - val_loss: 1.2279e-04\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.8247e-04 - val_loss: 1.2111e-04\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.6440e-04 - val_loss: 1.1937e-04\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6341e-04 - val_loss: 1.1729e-04\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.5676e-04 - val_loss: 1.1458e-04\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.5307e-04 - val_loss: 1.1162e-04\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.4864e-04 - val_loss: 1.0880e-04\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4061e-04 - val_loss: 1.0635e-04\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.4451e-04 - val_loss: 1.0526e-04\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4206e-04 - val_loss: 1.0509e-04\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3967e-04 - val_loss: 1.0534e-04\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3539e-04 - val_loss: 1.0579e-04\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3773e-04 - val_loss: 1.0612e-04\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2819e-04 - val_loss: 1.0658e-04\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2802e-04 - val_loss: 1.0709e-04\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3009e-04 - val_loss: 1.0766e-04\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2795e-04 - val_loss: 1.0814e-04\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2724e-04 - val_loss: 1.0821e-04\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1970e-04 - val_loss: 1.0773e-04\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1962e-04 - val_loss: 1.0694e-04\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2453e-04 - val_loss: 1.0613e-04\n",
      "Epoch 38/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2088e-04 - val_loss: 1.0522e-04\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.2109e-04 - val_loss: 1.0455e-04\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.2103e-04 - val_loss: 1.0432e-04\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.1688e-04 - val_loss: 1.0417e-04\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1932e-04 - val_loss: 1.0424e-04\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1737e-04 - val_loss: 1.0438e-04\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1708e-04 - val_loss: 1.0453e-04\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1579e-04 - val_loss: 1.0497e-04\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1559e-04 - val_loss: 1.0528e-04\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1384e-04 - val_loss: 1.0548e-04\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1614e-04 - val_loss: 1.0542e-04\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1496e-04 - val_loss: 1.0504e-04\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1294e-04 - val_loss: 1.0468e-04\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1041e-04 - val_loss: 1.0444e-04\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1236e-04 - val_loss: 1.0427e-04\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1174e-04 - val_loss: 1.0428e-04\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1076e-04 - val_loss: 1.0427e-04\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0954e-04 - val_loss: 1.0425e-04\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.1164e-04 - val_loss: 1.0414e-04\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.0970e-04 - val_loss: 1.0410e-04\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.1010e-04 - val_loss: 1.0403e-04\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.0835e-04 - val_loss: 1.0393e-04\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.0906e-04 - val_loss: 1.0367e-04\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.1016e-04 - val_loss: 1.0350e-04\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0895e-04 - val_loss: 1.0334e-04\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0742e-04 - val_loss: 1.0326e-04\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0871e-04 - val_loss: 1.0339e-04\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0774e-04 - val_loss: 1.0356e-04\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1018e-04 - val_loss: 1.0377e-04\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0692e-04 - val_loss: 1.0397e-04\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0856e-04 - val_loss: 1.0428e-04\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0914e-04 - val_loss: 1.0454e-04\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0768e-04 - val_loss: 1.0452e-04\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0748e-04 - val_loss: 1.0437e-04\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0924e-04 - val_loss: 1.0427e-04\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0646e-04 - val_loss: 1.0398e-04\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0766e-04 - val_loss: 1.0368e-04\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0721e-04 - val_loss: 1.0340e-04\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.0675e-04 - val_loss: 1.0318e-04\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.0716e-04 - val_loss: 1.0297e-04\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0786e-04 - val_loss: 1.0278e-04\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.0673e-04 - val_loss: 1.0264e-04\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0666e-04 - val_loss: 1.0262e-04\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0678e-04 - val_loss: 1.0267e-04\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0698e-04 - val_loss: 1.0279e-04\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0729e-04 - val_loss: 1.0300e-04\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0809e-04 - val_loss: 1.0328e-04\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0586e-04 - val_loss: 1.0335e-04\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0627e-04 - val_loss: 1.0336e-04\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0637e-04 - val_loss: 1.0330e-04\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0684e-04 - val_loss: 1.0322e-04\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0642e-04 - val_loss: 1.0309e-04\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0732e-04 - val_loss: 1.0261e-04\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0504e-04 - val_loss: 1.0226e-04\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.0607e-04 - val_loss: 1.0200e-04\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0795e-04 - val_loss: 1.0183e-04\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0743e-04 - val_loss: 1.0173e-04\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0663e-04 - val_loss: 1.0172e-04\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0719e-04 - val_loss: 1.0173e-04\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0589e-04 - val_loss: 1.0179e-04\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0655e-04 - val_loss: 1.0190e-04\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0530e-04 - val_loss: 1.0207e-04\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0597e-04 - val_loss: 1.0224e-04\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0673e-04 - val_loss: 1.0234e-04\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0533e-04 - val_loss: 1.0235e-04\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0499e-04 - val_loss: 1.0228e-04\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0580e-04 - val_loss: 1.0217e-04\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0559e-04 - val_loss: 1.0212e-04\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0506e-04 - val_loss: 1.0217e-04\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0542e-04 - val_loss: 1.0222e-04\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0624e-04 - val_loss: 1.0230e-04\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0558e-04 - val_loss: 1.0234e-04\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0487e-04 - val_loss: 1.0239e-04\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0499e-04 - val_loss: 1.0230e-04\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0531e-04 - val_loss: 1.0209e-04\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0559e-04 - val_loss: 1.0190e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0476e-04 - val_loss: 1.0164e-04\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.0501e-04 - val_loss: 1.0154e-04\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0586e-04 - val_loss: 1.0148e-04\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0500e-04 - val_loss: 1.0143e-04\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0494e-04 - val_loss: 1.0152e-04\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0531e-04 - val_loss: 1.0163e-04\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0569e-04 - val_loss: 1.0180e-04\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0503e-04 - val_loss: 1.0195e-04\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0522e-04 - val_loss: 1.0221e-04\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0565e-04 - val_loss: 1.0241e-04\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0534e-04 - val_loss: 1.0248e-04\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0472e-04 - val_loss: 1.0252e-04\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0408e-04 - val_loss: 1.0256e-04\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0438e-04 - val_loss: 1.0255e-04\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0437e-04 - val_loss: 1.0247e-04\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0427e-04 - val_loss: 1.0232e-04\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0540e-04 - val_loss: 1.0184e-04\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0516e-04 - val_loss: 1.0154e-04\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.0497e-04 - val_loss: 1.0139e-04\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.0481e-04 - val_loss: 1.0134e-04\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0456e-04 - val_loss: 1.0135e-04\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0543e-04 - val_loss: 1.0144e-04\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0430e-04 - val_loss: 1.0161e-04\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0547e-04 - val_loss: 1.0179e-04\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0477e-04 - val_loss: 1.0201e-04\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0452e-04 - val_loss: 1.0207e-04\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0392e-04 - val_loss: 1.0210e-04\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0478e-04 - val_loss: 1.0211e-04\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0460e-04 - val_loss: 1.0206e-04\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0564e-04 - val_loss: 1.0204e-04\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0535e-04 - val_loss: 1.0203e-04\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0470e-04 - val_loss: 1.0198e-04\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0456e-04 - val_loss: 1.0188e-04\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0459e-04 - val_loss: 1.0180e-04\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0460e-04 - val_loss: 1.0181e-04\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0373e-04 - val_loss: 1.0186e-04\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0388e-04 - val_loss: 1.0189e-04\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0417e-04 - val_loss: 1.0193e-04\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0384e-04 - val_loss: 1.0194e-04\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0446e-04 - val_loss: 1.0190e-04\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0467e-04 - val_loss: 1.0183e-04\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0545e-04 - val_loss: 1.0174e-04\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0490e-04 - val_loss: 1.0166e-04\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0375e-04 - val_loss: 1.0162e-04\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0375e-04 - val_loss: 1.0161e-04\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0329e-04 - val_loss: 1.0159e-04\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0451e-04 - val_loss: 1.0161e-04\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0410e-04 - val_loss: 1.0161e-04\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0439e-04 - val_loss: 1.0162e-04\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0442e-04 - val_loss: 1.0163e-04\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0474e-04 - val_loss: 1.0162e-04\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0385e-04 - val_loss: 1.0158e-04\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0490e-04 - val_loss: 1.0161e-04\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0395e-04 - val_loss: 1.0160e-04\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0377e-04 - val_loss: 1.0169e-04\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0321e-04 - val_loss: 1.0176e-04\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0466e-04 - val_loss: 1.0173e-04\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0403e-04 - val_loss: 1.0177e-04\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0369e-04 - val_loss: 1.0191e-04\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0291e-04 - val_loss: 1.0212e-04\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0403e-04 - val_loss: 1.0224e-04\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0438e-04 - val_loss: 1.0232e-04\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0446e-04 - val_loss: 1.0236e-04\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0398e-04 - val_loss: 1.0237e-04\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0334e-04 - val_loss: 1.0233e-04\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0418e-04 - val_loss: 1.0218e-04\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0372e-04 - val_loss: 1.0203e-04\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0664e-04 - val_loss: 1.0159e-04\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0452e-04 - val_loss: 1.0136e-04\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.0389e-04 - val_loss: 1.0116e-04\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.0458e-04 - val_loss: 1.0112e-04\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0386e-04 - val_loss: 1.0120e-04\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0349e-04 - val_loss: 1.0135e-04\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0457e-04 - val_loss: 1.0150e-04\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0373e-04 - val_loss: 1.0176e-04\n",
      "Epoch 189/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0365e-04 - val_loss: 1.0208e-04\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0431e-04 - val_loss: 1.0212e-04\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0386e-04 - val_loss: 1.0210e-04\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0348e-04 - val_loss: 1.0205e-04\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0363e-04 - val_loss: 1.0186e-04\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0360e-04 - val_loss: 1.0166e-04\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0326e-04 - val_loss: 1.0159e-04\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0370e-04 - val_loss: 1.0164e-04\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0387e-04 - val_loss: 1.0169e-04\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0303e-04 - val_loss: 1.0172e-04\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0352e-04 - val_loss: 1.0176e-04\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0315e-04 - val_loss: 1.0180e-04\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0364e-04 - val_loss: 1.0181e-04\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0433e-04 - val_loss: 1.0180e-04\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0348e-04 - val_loss: 1.0174e-04\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0295e-04 - val_loss: 1.0162e-04\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0311e-04 - val_loss: 1.0155e-04\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0345e-04 - val_loss: 1.0147e-04\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0283e-04 - val_loss: 1.0139e-04\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0327e-04 - val_loss: 1.0135e-04\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0322e-04 - val_loss: 1.0133e-04\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0307e-04 - val_loss: 1.0135e-04\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0387e-04 - val_loss: 1.0131e-04\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0425e-04 - val_loss: 1.0125e-04\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0354e-04 - val_loss: 1.0125e-04\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0386e-04 - val_loss: 1.0119e-04\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0345e-04 - val_loss: 1.0114e-04\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0285e-04 - val_loss: 1.0113e-04\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0378e-04 - val_loss: 1.0119e-04\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0387e-04 - val_loss: 1.0133e-04\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0291e-04 - val_loss: 1.0155e-04\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0297e-04 - val_loss: 1.0168e-04\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0275e-04 - val_loss: 1.0175e-04\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0320e-04 - val_loss: 1.0178e-04\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0348e-04 - val_loss: 1.0170e-04\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0337e-04 - val_loss: 1.0158e-04\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0304e-04 - val_loss: 1.0144e-04\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0328e-04 - val_loss: 1.0131e-04\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0290e-04 - val_loss: 1.0120e-04\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0322e-04 - val_loss: 1.0113e-04\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.0265e-04 - val_loss: 1.0108e-04\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0271e-04 - val_loss: 1.0098e-04\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.0303e-04 - val_loss: 1.0096e-04\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0285e-04 - val_loss: 1.0097e-04\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.0280e-04 - val_loss: 1.0090e-04\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0324e-04 - val_loss: 1.0086e-04\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0293e-04 - val_loss: 1.0090e-04\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0327e-04 - val_loss: 1.0098e-04\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0339e-04 - val_loss: 1.0107e-04\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0330e-04 - val_loss: 1.0118e-04\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.0311e-04 - val_loss: 1.0128e-04\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0243e-04 - val_loss: 1.0135e-04\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0259e-04 - val_loss: 1.0142e-04\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0279e-04 - val_loss: 1.0150e-04\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0340e-04 - val_loss: 1.0155e-04\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0233e-04 - val_loss: 1.0154e-04\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0266e-04 - val_loss: 1.0157e-04\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0236e-04 - val_loss: 1.0158e-04\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0246e-04 - val_loss: 1.0161e-04\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0264e-04 - val_loss: 1.0164e-04\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0295e-04 - val_loss: 1.0166e-04\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0312e-04 - val_loss: 1.0165e-04\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0389e-04 - val_loss: 1.0156e-04\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0311e-04 - val_loss: 1.0146e-04\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0399e-04 - val_loss: 1.0135e-04\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0290e-04 - val_loss: 1.0115e-04\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0256e-04 - val_loss: 1.0114e-04\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0318e-04 - val_loss: 1.0122e-04\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0245e-04 - val_loss: 1.0141e-04\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0243e-04 - val_loss: 1.0165e-04\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0312e-04 - val_loss: 1.0182e-04\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0284e-04 - val_loss: 1.0187e-04\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0258e-04 - val_loss: 1.0190e-04\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0264e-04 - val_loss: 1.0187e-04\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0264e-04 - val_loss: 1.0175e-04\n",
      "Epoch 264/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0200e-04 - val_loss: 1.0152e-04\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0283e-04 - val_loss: 1.0128e-04\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0261e-04 - val_loss: 1.0112e-04\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0313e-04 - val_loss: 1.0109e-04\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0256e-04 - val_loss: 1.0112e-04\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0286e-04 - val_loss: 1.0111e-04\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0223e-04 - val_loss: 1.0127e-04\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0292e-04 - val_loss: 1.0127e-04\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0219e-04 - val_loss: 1.0142e-04\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0255e-04 - val_loss: 1.0155e-04\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0279e-04 - val_loss: 1.0156e-04\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0193e-04 - val_loss: 1.0157e-04\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0311e-04 - val_loss: 1.0153e-04\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0268e-04 - val_loss: 1.0141e-04\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0263e-04 - val_loss: 1.0126e-04\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0296e-04 - val_loss: 1.0138e-04\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0242e-04 - val_loss: 1.0146e-04\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0234e-04 - val_loss: 1.0145e-04\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0256e-04 - val_loss: 1.0126e-04\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0264e-04 - val_loss: 1.0088e-04\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0214e-04 - val_loss: 1.0045e-04\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0292e-04 - val_loss: 1.0030e-04\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0203e-04 - val_loss: 1.0042e-04\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0256e-04 - val_loss: 1.0055e-04\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0219e-04 - val_loss: 1.0063e-04\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0251e-04 - val_loss: 1.0075e-04\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0185e-04 - val_loss: 1.0096e-04\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0270e-04 - val_loss: 1.0118e-04\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0195e-04 - val_loss: 1.0152e-04\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0232e-04 - val_loss: 1.0132e-04\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0266e-04 - val_loss: 1.0133e-04\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0291e-04 - val_loss: 1.0151e-04\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0245e-04 - val_loss: 1.0146e-04\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0211e-04 - val_loss: 1.0148e-04\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0248e-04 - val_loss: 1.0155e-04\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0243e-04 - val_loss: 1.0163e-04\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0251e-04 - val_loss: 1.0173e-04\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0244e-04 - val_loss: 1.0181e-04\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0160e-04 - val_loss: 1.0182e-04\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0238e-04 - val_loss: 1.0179e-04\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0246e-04 - val_loss: 1.0158e-04\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0222e-04 - val_loss: 1.0136e-04\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0230e-04 - val_loss: 1.0123e-04\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0183e-04 - val_loss: 1.0118e-04\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0235e-04 - val_loss: 1.0115e-04\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0288e-04 - val_loss: 1.0117e-04\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0215e-04 - val_loss: 1.0119e-04\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0269e-04 - val_loss: 1.0128e-04\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0224e-04 - val_loss: 1.0121e-04\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0210e-04 - val_loss: 1.0121e-04\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0152e-04 - val_loss: 1.0121e-04\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0211e-04 - val_loss: 1.0117e-04\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0152e-04 - val_loss: 1.0105e-04\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0230e-04 - val_loss: 1.0088e-04\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0172e-04 - val_loss: 1.0076e-04\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0173e-04 - val_loss: 1.0077e-04\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0219e-04 - val_loss: 1.0078e-04\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0189e-04 - val_loss: 1.0080e-04\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0247e-04 - val_loss: 1.0090e-04\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0203e-04 - val_loss: 1.0117e-04\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0181e-04 - val_loss: 1.0140e-04\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0168e-04 - val_loss: 1.0161e-04\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0219e-04 - val_loss: 1.0168e-04\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0186e-04 - val_loss: 1.0173e-04\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0187e-04 - val_loss: 1.0166e-04\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0154e-04 - val_loss: 1.0152e-04\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0185e-04 - val_loss: 1.0130e-04\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0313e-04 - val_loss: 1.0117e-04\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0213e-04 - val_loss: 1.0114e-04\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0201e-04 - val_loss: 1.0110e-04\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0176e-04 - val_loss: 1.0115e-04\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0212e-04 - val_loss: 1.0131e-04\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0140e-04 - val_loss: 1.0153e-04\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0170e-04 - val_loss: 1.0174e-04\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0229e-04 - val_loss: 1.0149e-04\n",
      "Epoch 339/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0263e-04 - val_loss: 1.0112e-04\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0226e-04 - val_loss: 1.0091e-04\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0142e-04 - val_loss: 1.0091e-04\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0237e-04 - val_loss: 1.0093e-04\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0175e-04 - val_loss: 1.0102e-04\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0178e-04 - val_loss: 1.0118e-04\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0204e-04 - val_loss: 1.0137e-04\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0185e-04 - val_loss: 1.0159e-04\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0203e-04 - val_loss: 1.0174e-04\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.0211e-04 - val_loss: 1.0167e-04\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0157e-04 - val_loss: 1.0171e-04\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0168e-04 - val_loss: 1.0175e-04\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0192e-04 - val_loss: 1.0181e-04\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0202e-04 - val_loss: 1.0190e-04\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0170e-04 - val_loss: 1.0197e-04\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0173e-04 - val_loss: 1.0201e-04\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0169e-04 - val_loss: 1.0204e-04\n",
      "\n",
      "Loading Model: '02-07-2021--06--34-E2E_LSTM_ValSet_1.0-ALPHA0.0001-BETA_SD17-355Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 0.0021623023594034715\n",
      "Model: \"functional_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_70 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_71 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 9.9171e-04 - val_loss: 6.9080e-04\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 8.8870e-04 - val_loss: 6.2770e-04\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 8.3443e-04 - val_loss: 5.8343e-04\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 8.3308e-04 - val_loss: 5.4468e-04\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.5628e-04 - val_loss: 5.1562e-04\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.5056e-04 - val_loss: 4.9267e-04\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.9332e-04 - val_loss: 4.7067e-04\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.5226e-04 - val_loss: 4.5154e-04\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.8647e-04 - val_loss: 4.3609e-04\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.0593e-04 - val_loss: 4.2156e-04\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.3342e-04 - val_loss: 4.1071e-04\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.4931e-04 - val_loss: 4.0280e-04\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.6133e-04 - val_loss: 3.9661e-04\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.8447e-04 - val_loss: 3.9165e-04\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 6.4548e-04 - val_loss: 3.8773e-04\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.1572e-04 - val_loss: 3.8504e-04\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.8143e-04 - val_loss: 3.8291e-04\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.3457e-04 - val_loss: 3.8123e-04\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.6886e-04 - val_loss: 3.7985e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.0809e-04 - val_loss: 3.7910e-04\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.2826e-04 - val_loss: 3.7824e-04\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.5538e-04 - val_loss: 3.7775e-04\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.6307e-04 - val_loss: 3.7768e-04\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5528e-04 - val_loss: 3.7776e-04\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6189e-04 - val_loss: 3.7799e-04\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.4134e-04 - val_loss: 3.7815e-04\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.6192e-04 - val_loss: 3.7769e-04\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.3079e-04 - val_loss: 3.7674e-04\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.9317e-04 - val_loss: 3.7650e-04\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.2481e-04 - val_loss: 3.7565e-04\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.4299e-04 - val_loss: 3.7514e-04\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.1287e-04 - val_loss: 3.7458e-04\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4382e-04 - val_loss: 3.7464e-04\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3403e-04 - val_loss: 3.7527e-04\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.0146e-04 - val_loss: 3.7611e-04\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.8764e-04 - val_loss: 3.7679e-04\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7216e-04 - val_loss: 3.7779e-04\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0336e-04 - val_loss: 3.7994e-04\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0738e-04 - val_loss: 3.8298e-04\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.9699e-04 - val_loss: 3.8430e-04\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.2079e-04 - val_loss: 3.8500e-04\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.1127e-04 - val_loss: 3.8467e-04\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9051e-04 - val_loss: 3.8419e-04\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.0838e-04 - val_loss: 3.8258e-04\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.7480e-04 - val_loss: 3.8097e-04\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.9340e-04 - val_loss: 3.7739e-04\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.3348e-04 - val_loss: 3.7392e-04\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.3487e-04 - val_loss: 3.7131e-04\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.2064e-04 - val_loss: 3.6987e-04\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.6096e-04 - val_loss: 3.7010e-04\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.0855e-04 - val_loss: 3.6907e-04\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.7450e-04 - val_loss: 3.6688e-04\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.9814e-04 - val_loss: 3.6406e-04\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.7027e-04 - val_loss: 3.6074e-04\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 4.4688e-04 - val_loss: 3.5737e-04\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.7221e-04 - val_loss: 3.5396e-04\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.9443e-04 - val_loss: 3.5166e-04\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.7281e-04 - val_loss: 3.5017e-04\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.4261e-04 - val_loss: 3.4896e-04\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.7035e-04 - val_loss: 3.4824e-04\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.4720e-04 - val_loss: 3.4754e-04\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.7254e-04 - val_loss: 3.4774e-04\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5533e-04 - val_loss: 3.4982e-04\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.8673e-04 - val_loss: 3.5239e-04\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.3902e-04 - val_loss: 3.5556e-04\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.6358e-04 - val_loss: 3.5652e-04\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 4.4843e-04 - val_loss: 3.5848e-04\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.2316e-04 - val_loss: 3.6027e-04\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.5147e-04 - val_loss: 3.6002e-04\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.9749e-04 - val_loss: 3.6020e-04\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.4383e-04 - val_loss: 3.6185e-04\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.6676e-04 - val_loss: 3.5887e-04\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 4.7484e-04 - val_loss: 3.5484e-04\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0687e-04 - val_loss: 3.5112e-04\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 4.1601e-04 - val_loss: 3.4639e-04\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 4.6461e-04 - val_loss: 3.4236e-04\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.4025e-04 - val_loss: 3.3972e-04\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 4.8062e-04 - val_loss: 3.3905e-04\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.3511e-04 - val_loss: 3.3935e-04\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.6412e-04 - val_loss: 3.4150e-04\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2493e-04 - val_loss: 3.4387e-04\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.3505e-04 - val_loss: 3.4710e-04\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0686e-04 - val_loss: 3.5012e-04\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.9447e-04 - val_loss: 3.4904e-04\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.4764e-04 - val_loss: 3.4892e-04\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 4.4753e-04 - val_loss: 3.5011e-04\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 4.8247e-04 - val_loss: 3.5100e-04\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4667e-04 - val_loss: 3.5124e-04\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.3568e-04 - val_loss: 3.5195e-04\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.3623e-04 - val_loss: 3.5248e-04\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.4342e-04 - val_loss: 3.5348e-04\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0292e-04 - val_loss: 3.5571e-04\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9552e-04 - val_loss: 3.5848e-04\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.0024e-04 - val_loss: 3.5924e-04\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.2348e-04 - val_loss: 3.5977e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0330e-04 - val_loss: 3.5953e-04\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1911e-04 - val_loss: 3.6042e-04\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1472e-04 - val_loss: 3.6109e-04\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.7665e-04 - val_loss: 3.6191e-04\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.3538e-04 - val_loss: 3.6331e-04\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7436e-04 - val_loss: 3.6467e-04\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.5306e-04 - val_loss: 3.6555e-04\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.9885e-04 - val_loss: 3.6343e-04\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0054e-04 - val_loss: 3.6185e-04\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1647e-04 - val_loss: 3.5960e-04\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.2590e-04 - val_loss: 3.5383e-04\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.4138e-04 - val_loss: 3.4666e-04\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 3.9709e-04 - val_loss: 3.3887e-04\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 4.2235e-04 - val_loss: 3.3315e-04\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.8951e-04 - val_loss: 3.2919e-04\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.0681e-04 - val_loss: 3.2687e-04\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.2105e-04 - val_loss: 3.2683e-04\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.7794e-04 - val_loss: 3.2642e-04\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.9731e-04 - val_loss: 3.2742e-04\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8357e-04 - val_loss: 3.2799e-04\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.9101e-04 - val_loss: 3.2989e-04\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.3360e-04 - val_loss: 3.3505e-04\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.2939e-04 - val_loss: 3.4105e-04\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8646e-04 - val_loss: 3.4567e-04\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6931e-04 - val_loss: 3.5085e-04\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6627e-04 - val_loss: 3.5785e-04\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1421e-04 - val_loss: 3.6136e-04\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9776e-04 - val_loss: 3.6129e-04\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.0735e-04 - val_loss: 3.5865e-04\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1145e-04 - val_loss: 3.5569e-04\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0511e-04 - val_loss: 3.5235e-04\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0391e-04 - val_loss: 3.4869e-04\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4247e-04 - val_loss: 3.4721e-04\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.1295e-04 - val_loss: 3.4536e-04\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.9403e-04 - val_loss: 3.4482e-04\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0599e-04 - val_loss: 3.4429e-04\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.5853e-04 - val_loss: 3.4560e-04\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.0645e-04 - val_loss: 3.4667e-04\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1390e-04 - val_loss: 3.4742e-04\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.2405e-04 - val_loss: 3.4839e-04\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2239e-04 - val_loss: 3.4799e-04\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8812e-04 - val_loss: 3.4736e-04\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0971e-04 - val_loss: 3.4600e-04\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7625e-04 - val_loss: 3.4493e-04\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8648e-04 - val_loss: 3.4583e-04\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8850e-04 - val_loss: 3.4574e-04\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7002e-04 - val_loss: 3.4611e-04\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5359e-04 - val_loss: 3.4419e-04\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7722e-04 - val_loss: 3.4051e-04\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.6757e-04 - val_loss: 3.3726e-04\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8103e-04 - val_loss: 3.3473e-04\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5563e-04 - val_loss: 3.3194e-04\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7292e-04 - val_loss: 3.2803e-04\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 3.9156e-04 - val_loss: 3.2587e-04\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.0081e-04 - val_loss: 3.2525e-04\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8039e-04 - val_loss: 3.2529e-04\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.9792e-04 - val_loss: 3.2682e-04\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 4.1907e-04 - val_loss: 3.2967e-04\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.8364e-04 - val_loss: 3.3503e-04\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6512e-04 - val_loss: 3.3799e-04\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0822e-04 - val_loss: 3.4181e-04\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1221e-04 - val_loss: 3.4292e-04\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8861e-04 - val_loss: 3.4307e-04\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9419e-04 - val_loss: 3.4415e-04\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5898e-04 - val_loss: 3.4537e-04\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7261e-04 - val_loss: 3.4511e-04\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7720e-04 - val_loss: 3.4321e-04\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.9256e-04 - val_loss: 3.4278e-04\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.0940e-04 - val_loss: 3.4202e-04\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7245e-04 - val_loss: 3.4323e-04\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.5865e-04 - val_loss: 3.4212e-04\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.7604e-04 - val_loss: 3.4180e-04\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7543e-04 - val_loss: 3.3916e-04\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7569e-04 - val_loss: 3.3904e-04\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8422e-04 - val_loss: 3.3967e-04\n",
      "Epoch 171/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7867e-04 - val_loss: 3.3984e-04\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9139e-04 - val_loss: 3.4002e-04\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7511e-04 - val_loss: 3.3774e-04\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7923e-04 - val_loss: 3.3625e-04\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6787e-04 - val_loss: 3.3457e-04\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.0510e-04 - val_loss: 3.3196e-04\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6332e-04 - val_loss: 3.2964e-04\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5602e-04 - val_loss: 3.2957e-04\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9976e-04 - val_loss: 3.3097e-04\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8492e-04 - val_loss: 3.3104e-04\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.1309e-04 - val_loss: 3.3217e-04\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0108e-04 - val_loss: 3.3476e-04\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9419e-04 - val_loss: 3.3825e-04\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8658e-04 - val_loss: 3.4009e-04\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.8033e-04 - val_loss: 3.4082e-04\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.3883e-04 - val_loss: 3.4472e-04\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5499e-04 - val_loss: 3.4570e-04\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.8232e-04 - val_loss: 3.4419e-04\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.9828e-04 - val_loss: 3.4256e-04\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8452e-04 - val_loss: 3.4236e-04\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8057e-04 - val_loss: 3.4435e-04\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.4491e-04 - val_loss: 3.4471e-04\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8843e-04 - val_loss: 3.4711e-04\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7975e-04 - val_loss: 3.4848e-04\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6582e-04 - val_loss: 3.4577e-04\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5436e-04 - val_loss: 3.3890e-04\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5584e-04 - val_loss: 3.3063e-04\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 4.1827e-04 - val_loss: 3.2383e-04\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.7788e-04 - val_loss: 3.1781e-04\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.7563e-04 - val_loss: 3.1414e-04\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.6246e-04 - val_loss: 3.1314e-04\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5617e-04 - val_loss: 3.1338e-04\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4336e-04 - val_loss: 3.1429e-04\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4148e-04 - val_loss: 3.1694e-04\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8715e-04 - val_loss: 3.1929e-04\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.3571e-04 - val_loss: 3.2443e-04\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.1023e-04 - val_loss: 3.3013e-04\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.8156e-04 - val_loss: 3.2985e-04\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.7996e-04 - val_loss: 3.2781e-04\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7731e-04 - val_loss: 3.2474e-04\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.7153e-04 - val_loss: 3.2418e-04\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.6223e-04 - val_loss: 3.2488e-04\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5881e-04 - val_loss: 3.2666e-04\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.5161e-04 - val_loss: 3.2957e-04\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6250e-04 - val_loss: 3.3252e-04\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7942e-04 - val_loss: 3.3669e-04\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9000e-04 - val_loss: 3.4171e-04\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6760e-04 - val_loss: 3.4211e-04\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2143e-04 - val_loss: 3.4113e-04\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.6505e-04 - val_loss: 3.3451e-04\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.5602e-04 - val_loss: 3.2990e-04\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5735e-04 - val_loss: 3.2538e-04\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7324e-04 - val_loss: 3.2305e-04\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7970e-04 - val_loss: 3.2206e-04\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3737e-04 - val_loss: 3.2170e-04\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7749e-04 - val_loss: 3.2218e-04\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6403e-04 - val_loss: 3.2338e-04\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5933e-04 - val_loss: 3.2259e-04\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7527e-04 - val_loss: 3.2329e-04\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.7523e-04 - val_loss: 3.2433e-04\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.7912e-04 - val_loss: 3.2677e-04\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6765e-04 - val_loss: 3.2940e-04\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1794e-04 - val_loss: 3.2922e-04\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3858e-04 - val_loss: 3.2816e-04\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.8882e-04 - val_loss: 3.2696e-04\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6194e-04 - val_loss: 3.2468e-04\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.2986e-04 - val_loss: 3.2236e-04\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7263e-04 - val_loss: 3.1930e-04\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6689e-04 - val_loss: 3.1838e-04\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5111e-04 - val_loss: 3.1807e-04\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.5018e-04 - val_loss: 3.1728e-04\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.7480e-04 - val_loss: 3.1725e-04\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5019e-04 - val_loss: 3.1741e-04\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.5260e-04 - val_loss: 3.1779e-04\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.6766e-04 - val_loss: 3.2031e-04\n",
      "Epoch 246/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step - loss: 3.2830e-04 - val_loss: 3.2304e-04\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.8328e-04 - val_loss: 3.2694e-04\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.9218e-04 - val_loss: 3.3244e-04\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.3088e-04 - val_loss: 3.3898e-04\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6991e-04 - val_loss: 3.4139e-04\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6630e-04 - val_loss: 3.4428e-04\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5313e-04 - val_loss: 3.4584e-04\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0956e-04 - val_loss: 3.4046e-04\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6221e-04 - val_loss: 3.3568e-04\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7676e-04 - val_loss: 3.2937e-04\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5048e-04 - val_loss: 3.2251e-04\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4857e-04 - val_loss: 3.1815e-04\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.6880e-04 - val_loss: 3.1638e-04\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.3757e-04 - val_loss: 3.1538e-04\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2395e-04 - val_loss: 3.1573e-04\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5040e-04 - val_loss: 3.1766e-04\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3114e-04 - val_loss: 3.2063e-04\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.0001e-04 - val_loss: 3.2634e-04\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3257e-04 - val_loss: 3.3328e-04\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7749e-04 - val_loss: 3.3364e-04\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5617e-04 - val_loss: 3.2850e-04\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7390e-04 - val_loss: 3.2250e-04\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5836e-04 - val_loss: 3.1862e-04\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.5971e-04 - val_loss: 3.1574e-04\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.2125e-04 - val_loss: 3.1433e-04\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2991e-04 - val_loss: 3.1574e-04\n",
      "\n",
      "Loading Model: '02-07-2021--06--47-E2E_LSTM_ValSet_1.0-ALPHA0.001-BETA_SD17-271Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 0.0005509337406278041\n",
      "Model: \"functional_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_74 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_75 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0014 - val_loss: 8.0854e-04\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0013 - val_loss: 7.3324e-04\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 8.4415e-04\n",
      "Epoch 11/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 9.6206e-04\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 9.6579e-04\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0016 - val_loss: 8.7870e-04\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 7.6224e-04\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0015 - val_loss: 6.6387e-04\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0013 - val_loss: 6.0695e-04\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0012 - val_loss: 5.9265e-04\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 6.1317e-04\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 6.5542e-04\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 7.0613e-04\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0010 - val_loss: 7.5414e-04\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 7.9440e-04\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 8.2166e-04\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 8.3361e-04\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 8.3083e-04\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 8.1429e-04\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 7.8591e-04\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 7.4888e-04\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 7.0773e-04\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 6.6450e-04\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 6.2212e-04\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 9.3903e-04 - val_loss: 5.8360e-04\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0011 - val_loss: 5.5168e-04\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 9.9806e-04 - val_loss: 5.2710e-04\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 9.3901e-04 - val_loss: 5.0966e-04\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 9.4101e-04 - val_loss: 4.9827e-04\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0011 - val_loss: 4.9092e-04\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 9.3969e-04 - val_loss: 4.8589e-04\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 9.7734e-04 - val_loss: 4.8210e-04\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 9.4251e-04 - val_loss: 4.7940e-04\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 9.9754e-04 - val_loss: 4.7875e-04\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 4.8080e-04\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5904e-04 - val_loss: 4.8650e-04\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5198e-04 - val_loss: 4.9408e-04\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8606e-04 - val_loss: 5.0368e-04\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8188e-04 - val_loss: 5.1269e-04\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6589e-04 - val_loss: 5.2099e-04\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4993e-04 - val_loss: 5.2644e-04\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.7523e-04 - val_loss: 5.3035e-04\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8025e-04 - val_loss: 5.2895e-04\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2827e-04 - val_loss: 5.2471e-04\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8082e-04 - val_loss: 5.1747e-04\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9826e-04 - val_loss: 5.0808e-04\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 9.1470e-04 - val_loss: 4.9923e-04\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.3639e-04 - val_loss: 4.8974e-04\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.4882e-04 - val_loss: 4.8068e-04\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 8.8298e-04 - val_loss: 4.7341e-04\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 8.6049e-04 - val_loss: 4.6780e-04\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 8.1499e-04 - val_loss: 4.6461e-04\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 8.2823e-04 - val_loss: 4.6368e-04\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 7.5672e-04 - val_loss: 4.6330e-04\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.3553e-04 - val_loss: 4.6422e-04\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.1088e-04 - val_loss: 4.6788e-04\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.3847e-04 - val_loss: 4.7413e-04\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.7925e-04 - val_loss: 4.8088e-04\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.2130e-04 - val_loss: 4.8507e-04\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.9633e-04 - val_loss: 4.8849e-04\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.4132e-04 - val_loss: 4.9077e-04\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.7852e-04 - val_loss: 4.8942e-04\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6030e-04 - val_loss: 4.8651e-04\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.3427e-04 - val_loss: 4.8243e-04\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.9033e-04 - val_loss: 4.7431e-04\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.4550e-04 - val_loss: 4.6553e-04\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.9186e-04 - val_loss: 4.5795e-04\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 7.2317e-04 - val_loss: 4.5052e-04\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 7.7874e-04 - val_loss: 4.4503e-04\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 7.3880e-04 - val_loss: 4.4195e-04\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.4957e-04 - val_loss: 4.4449e-04\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.1740e-04 - val_loss: 4.4881e-04\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.7970e-04 - val_loss: 4.5584e-04\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.3303e-04 - val_loss: 4.6175e-04\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.3493e-04 - val_loss: 4.6477e-04\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.0868e-04 - val_loss: 4.6431e-04\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.6018e-04 - val_loss: 4.5716e-04\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.2685e-04 - val_loss: 4.4707e-04\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.5912e-04 - val_loss: 4.3939e-04\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 7.5584e-04 - val_loss: 4.3656e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.6528e-04 - val_loss: 4.3699e-04\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.8206e-04 - val_loss: 4.3988e-04\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.5339e-04 - val_loss: 4.4647e-04\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.5939e-04 - val_loss: 4.5387e-04\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.6268e-04 - val_loss: 4.6359e-04\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.8798e-04 - val_loss: 4.7037e-04\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.7790e-04 - val_loss: 4.6469e-04\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.9959e-04 - val_loss: 4.5392e-04\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.1806e-04 - val_loss: 4.4587e-04\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.8116e-04 - val_loss: 4.3968e-04\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.6538e-04 - val_loss: 4.3986e-04\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.0493e-04 - val_loss: 4.4586e-04\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.8106e-04 - val_loss: 4.5784e-04\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6917e-04 - val_loss: 4.7409e-04\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.0208e-04 - val_loss: 4.8813e-04\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.4306e-04 - val_loss: 4.9363e-04\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.4851e-04 - val_loss: 4.8849e-04\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.7042e-04 - val_loss: 4.7216e-04\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.4894e-04 - val_loss: 4.5187e-04\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.8490e-04 - val_loss: 4.3403e-04\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 6.4320e-04 - val_loss: 4.2378e-04\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.3807e-04 - val_loss: 4.2053e-04\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.3450e-04 - val_loss: 4.2311e-04\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.3433e-04 - val_loss: 4.2800e-04\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5346e-04 - val_loss: 4.2995e-04\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.9152e-04 - val_loss: 4.2832e-04\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.5609e-04 - val_loss: 4.2396e-04\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.3837e-04 - val_loss: 4.1790e-04\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.1791e-04 - val_loss: 4.1323e-04\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 6.5470e-04 - val_loss: 4.1295e-04\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.6544e-04 - val_loss: 4.1470e-04\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.0541e-04 - val_loss: 4.1897e-04\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.0025e-04 - val_loss: 4.2340e-04\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7789e-04 - val_loss: 4.2904e-04\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.6031e-04 - val_loss: 4.3566e-04\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.3436e-04 - val_loss: 4.4136e-04\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2172e-04 - val_loss: 4.4287e-04\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.4509e-04 - val_loss: 4.3634e-04\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.3421e-04 - val_loss: 4.2555e-04\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.3106e-04 - val_loss: 4.1838e-04\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.7749e-04 - val_loss: 4.1719e-04\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.5991e-04 - val_loss: 4.1983e-04\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.1134e-04 - val_loss: 4.2987e-04\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.4805e-04 - val_loss: 4.3574e-04\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.9154e-04 - val_loss: 4.3410e-04\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.4376e-04 - val_loss: 4.2470e-04\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.6940e-04 - val_loss: 4.1799e-04\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.4564e-04 - val_loss: 4.1449e-04\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.7624e-04 - val_loss: 4.1316e-04\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1875e-04 - val_loss: 4.1588e-04\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.0407e-04 - val_loss: 4.1796e-04\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8151e-04 - val_loss: 4.1974e-04\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.9429e-04 - val_loss: 4.2196e-04\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.5646e-04 - val_loss: 4.1979e-04\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7758e-04 - val_loss: 4.2104e-04\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.7636e-04 - val_loss: 4.2279e-04\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7113e-04 - val_loss: 4.2311e-04\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7242e-04 - val_loss: 4.1775e-04\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.0075e-04 - val_loss: 4.1433e-04\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.6625e-04 - val_loss: 4.1120e-04\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.8335e-04 - val_loss: 4.0961e-04\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.0094e-04 - val_loss: 4.1504e-04\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.0631e-04 - val_loss: 4.1564e-04\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.9113e-04 - val_loss: 4.0780e-04\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.0968e-04 - val_loss: 3.9670e-04\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.2354e-04 - val_loss: 3.9001e-04\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.1222e-04 - val_loss: 3.9050e-04\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.6111e-04 - val_loss: 3.9385e-04\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.4408e-04 - val_loss: 4.0262e-04\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.2736e-04 - val_loss: 4.0361e-04\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.9649e-04 - val_loss: 3.9441e-04\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.1030e-04 - val_loss: 3.8789e-04\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7431e-04 - val_loss: 3.8796e-04\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7782e-04 - val_loss: 3.9351e-04\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.8037e-04 - val_loss: 3.9708e-04\n",
      "Epoch 163/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 6.1567e-04 - val_loss: 4.0611e-04\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2507e-04 - val_loss: 4.1294e-04\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7140e-04 - val_loss: 4.1497e-04\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5573e-04 - val_loss: 4.1136e-04\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7195e-04 - val_loss: 4.0946e-04\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.8122e-04 - val_loss: 4.0828e-04\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.9173e-04 - val_loss: 4.1078e-04\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.9295e-04 - val_loss: 4.1579e-04\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8628e-04 - val_loss: 4.1809e-04\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4966e-04 - val_loss: 4.1454e-04\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8396e-04 - val_loss: 4.0527e-04\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8327e-04 - val_loss: 3.9902e-04\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5802e-04 - val_loss: 3.9153e-04\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.9368e-04 - val_loss: 3.8489e-04\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.5021e-04 - val_loss: 3.7941e-04\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.3316e-04 - val_loss: 3.8045e-04\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.3313e-04 - val_loss: 3.8403e-04\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.0636e-04 - val_loss: 3.8870e-04\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6334e-04 - val_loss: 3.8817e-04\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.6948e-04 - val_loss: 3.8855e-04\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.9893e-04 - val_loss: 3.8566e-04\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7447e-04 - val_loss: 3.8679e-04\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.6352e-04 - val_loss: 3.8889e-04\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.4113e-04 - val_loss: 3.9606e-04\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.5251e-04 - val_loss: 3.9842e-04\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7259e-04 - val_loss: 3.9958e-04\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.1214e-04 - val_loss: 4.0075e-04\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7578e-04 - val_loss: 4.0281e-04\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7055e-04 - val_loss: 4.1060e-04\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4632e-04 - val_loss: 4.1482e-04\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.0270e-04 - val_loss: 4.2424e-04\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.6647e-04 - val_loss: 4.2374e-04\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8615e-04 - val_loss: 4.1447e-04\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.4971e-04 - val_loss: 4.0315e-04\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4524e-04 - val_loss: 3.9807e-04\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.8010e-04 - val_loss: 4.0337e-04\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8526e-04 - val_loss: 4.0728e-04\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.7533e-04 - val_loss: 3.9508e-04\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.4537e-04 - val_loss: 3.7891e-04\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.4120e-04 - val_loss: 3.6893e-04\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.2511e-04 - val_loss: 3.6770e-04\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4380e-04 - val_loss: 3.7590e-04\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.9651e-04 - val_loss: 3.8846e-04\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.1721e-04 - val_loss: 3.8168e-04\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.9449e-04 - val_loss: 3.7244e-04\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6598e-04 - val_loss: 3.6964e-04\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.6691e-04 - val_loss: 3.7343e-04\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7062e-04 - val_loss: 3.7963e-04\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.6774e-04 - val_loss: 3.9304e-04\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.1382e-04 - val_loss: 3.9007e-04\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.1635e-04 - val_loss: 3.8610e-04\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.2355e-04 - val_loss: 3.8586e-04\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6863e-04 - val_loss: 3.8967e-04\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6867e-04 - val_loss: 3.9636e-04\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3723e-04 - val_loss: 4.0357e-04\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4004e-04 - val_loss: 4.0300e-04\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.8529e-04 - val_loss: 3.9481e-04\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5308e-04 - val_loss: 3.8828e-04\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.0205e-04 - val_loss: 3.8591e-04\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3827e-04 - val_loss: 3.8715e-04\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.4432e-04 - val_loss: 3.8786e-04\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5606e-04 - val_loss: 3.8494e-04\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.1955e-04 - val_loss: 3.7699e-04\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3492e-04 - val_loss: 3.6927e-04\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3377e-04 - val_loss: 3.6809e-04\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3433e-04 - val_loss: 3.7274e-04\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.5849e-04 - val_loss: 3.7956e-04\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4093e-04 - val_loss: 3.7663e-04\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.5441e-04 - val_loss: 3.7582e-04\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.1920e-04 - val_loss: 3.7868e-04\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4876e-04 - val_loss: 3.7760e-04\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0472e-04 - val_loss: 3.7536e-04\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.5629e-04 - val_loss: 3.8097e-04\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4638e-04 - val_loss: 3.8835e-04\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.7129e-04 - val_loss: 3.8959e-04\n",
      "Epoch 238/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6519e-04 - val_loss: 3.8026e-04\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.2555e-04 - val_loss: 3.7395e-04\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.4153e-04 - val_loss: 3.7295e-04\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.1541e-04 - val_loss: 3.7476e-04\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.6682e-04 - val_loss: 3.8087e-04\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.1680e-04 - val_loss: 3.8228e-04\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.0878e-04 - val_loss: 3.7526e-04\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.4378e-04 - val_loss: 3.7102e-04\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.9730e-04 - val_loss: 3.7184e-04\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4212e-04 - val_loss: 3.7861e-04\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.6752e-04 - val_loss: 3.8519e-04\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.7764e-04 - val_loss: 3.8958e-04\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4060e-04 - val_loss: 3.9259e-04\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.3844e-04 - val_loss: 3.9269e-04\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0745e-04 - val_loss: 3.9601e-04\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.6152e-04 - val_loss: 4.0357e-04\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3205e-04 - val_loss: 4.0244e-04\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.4094e-04 - val_loss: 3.9512e-04\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.1926e-04 - val_loss: 3.8346e-04\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9557e-04 - val_loss: 3.7657e-04\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.0914e-04 - val_loss: 3.7857e-04\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.0581e-04 - val_loss: 3.8308e-04\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.7183e-04 - val_loss: 3.8568e-04\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.1637e-04 - val_loss: 3.8429e-04\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.8769e-04 - val_loss: 3.8091e-04\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.5134e-04 - val_loss: 3.8334e-04\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.8731e-04 - val_loss: 3.8870e-04\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4071e-04 - val_loss: 3.9600e-04\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.1089e-04 - val_loss: 3.9652e-04\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0987e-04 - val_loss: 3.9153e-04\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0356e-04 - val_loss: 3.8423e-04\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.0785e-04 - val_loss: 3.7648e-04\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.7199e-04 - val_loss: 3.7619e-04\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.8422e-04 - val_loss: 3.8356e-04\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5688e-04 - val_loss: 3.9873e-04\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9475e-04 - val_loss: 3.9730e-04\n",
      "\n",
      "Loading Model: '02-07-2021--07--00-E2E_LSTM_ValSet_1.0-ALPHA0.01-BETA_SD17-273Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.013246123523840829\n",
      "Model: \"functional_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_78 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_79 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.0690 - val_loss: 0.0581\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0577 - val_loss: 0.0474\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0468 - val_loss: 0.0374\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0277 - val_loss: 0.0200\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0199 - val_loss: 0.0128\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0133 - val_loss: 0.0068\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0076 - val_loss: 0.0029\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0053 - val_loss: 0.0022\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0120 - val_loss: 0.0055\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0112 - val_loss: 0.0042\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0092 - val_loss: 0.0028\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - val_loss: 0.0019\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - val_loss: 0.0012\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - val_loss: 0.0010\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0027 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0025 - val_loss: 9.8097e-04\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0024 - val_loss: 9.4996e-04\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - val_loss: 9.2949e-04\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0025 - val_loss: 9.2583e-04\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0023 - val_loss: 9.6758e-04\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 9.6458e-04\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0023 - val_loss: 9.1595e-04\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0023 - val_loss: 8.9347e-04\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023 - val_loss: 8.8932e-04\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - val_loss: 8.9172e-04\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - val_loss: 9.0796e-04\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0023 - val_loss: 9.4450e-04\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 9.8404e-04\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 9.3530e-04\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0021 - val_loss: 9.1068e-04\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 9.2295e-04\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 9.5991e-04\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 9.9843e-04\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0023 - val_loss: 9.6438e-04\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0023 - val_loss: 8.7637e-04\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - val_loss: 8.2776e-04\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0023 - val_loss: 8.1721e-04\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0021 - val_loss: 8.3789e-04\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0021 - val_loss: 9.2139e-04\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0022 - val_loss: 9.6255e-04\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 9.4187e-04\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0023 - val_loss: 8.9109e-04\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0022 - val_loss: 8.7115e-04\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 8.5720e-04\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 8.2672e-04\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0021 - val_loss: 8.4046e-04\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0020 - val_loss: 8.6428e-04\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - val_loss: 8.8910e-04\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0020 - val_loss: 8.9420e-04\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 8.6460e-04\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 8.9805e-04\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - val_loss: 9.6490e-04\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0019 - val_loss: 9.2371e-04\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0019 - val_loss: 7.7964e-04\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0019 - val_loss: 7.1789e-04\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - val_loss: 7.3618e-04\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 8.4831e-04\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0019 - val_loss: 9.5569e-04\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 7.8672e-04\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0020 - val_loss: 6.9997e-04\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0021 - val_loss: 7.0481e-04\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - val_loss: 8.0914e-04\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0021 - val_loss: 9.6775e-04\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0019 - val_loss: 9.5326e-04\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - val_loss: 8.0326e-04\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0019 - val_loss: 7.0676e-04\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0019 - val_loss: 6.8173e-04\n",
      "Epoch 162/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - val_loss: 6.8398e-04\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - val_loss: 7.7096e-04\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 9.2361e-04\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - val_loss: 9.3056e-04\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - val_loss: 7.8524e-04\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 6.8738e-04\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0019 - val_loss: 6.7402e-04\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 7.3835e-04\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 8.7322e-04\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 9.6246e-04\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 8.8652e-04\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0019 - val_loss: 7.6341e-04\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0018 - val_loss: 6.6402e-04\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0019 - val_loss: 6.3149e-04\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 6.4272e-04\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 7.1298e-04\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0021 - val_loss: 7.9016e-04\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0019 - val_loss: 8.5323e-04\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 8.3591e-04\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 7.8519e-04\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 6.9536e-04\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 6.7030e-04\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 6.8359e-04\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - val_loss: 7.2721e-04\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 7.8934e-04\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0018 - val_loss: 8.2362e-04\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 7.9362e-04\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 7.3286e-04\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 7.1211e-04\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 6.9791e-04\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 7.4941e-04\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 7.6001e-04\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - val_loss: 7.1381e-04\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 6.6539e-04\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 6.9774e-04\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - val_loss: 7.6213e-04\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 8.1517e-04\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 7.7171e-04\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 7.0911e-04\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0018 - val_loss: 6.7591e-04\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 7.1280e-04\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 7.9430e-04\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0018 - val_loss: 8.4557e-04\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 7.2316e-04\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0017 - val_loss: 6.2748e-04\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0017 - val_loss: 6.2269e-04\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 6.8185e-04\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 7.4909e-04\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0018 - val_loss: 8.4323e-04\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 7.8623e-04\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 6.9905e-04\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 6.4545e-04\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 6.5464e-04\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 7.0184e-04\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 7.6979e-04\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 7.9172e-04\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 7.2991e-04\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 6.4214e-04\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 6.2756e-04\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 6.7545e-04\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 7.4795e-04\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 7.7297e-04\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 7.2572e-04\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 6.4190e-04\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 6.2866e-04\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 6.9354e-04\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 7.6530e-04\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 6.9905e-04\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 6.4758e-04\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 6.7626e-04\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 7.0840e-04\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - val_loss: 6.7357e-04\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 6.7452e-04\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 6.8505e-04\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 7.1841e-04\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 6.5356e-04\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0016 - val_loss: 6.1352e-04\n",
      "Epoch 240/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 6.2151e-04\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 6.4374e-04\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 6.8901e-04\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 7.0476e-04\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 6.6903e-04\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 6.4646e-04\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 6.5596e-04\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 6.9741e-04\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 6.6060e-04\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 6.5311e-04\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 7.0310e-04\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 6.8948e-04\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - val_loss: 6.9334e-04\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 7.4054e-04\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 6.8024e-04\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 6.5593e-04\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 6.2225e-04\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 6.2622e-04\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 6.9770e-04\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 7.2272e-04\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 7.0833e-04\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 6.6725e-04\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 6.2518e-04\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 6.1752e-04\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 6.6114e-04\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - val_loss: 7.1050e-04\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 6.7005e-04\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 6.2121e-04\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 6.2615e-04\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0016 - val_loss: 5.9370e-04\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 6.2608e-04\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0016 - val_loss: 6.6975e-04\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 7.1318e-04\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 6.4550e-04\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0017 - val_loss: 5.7250e-04\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0015 - val_loss: 5.9022e-04\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 6.5984e-04\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0016 - val_loss: 6.9152e-04\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 7.0814e-04\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 5.9337e-04\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 5.8025e-04\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0016 - val_loss: 6.1797e-04\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0016 - val_loss: 6.7794e-04\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 6.8290e-04\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0015 - val_loss: 6.3577e-04\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 5.8457e-04\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0014 - val_loss: 5.8091e-04\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0014 - val_loss: 6.7623e-04\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 7.1153e-04\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 6.2892e-04\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 5.7598e-04\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 5.9522e-04\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 6.1996e-04\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 6.4010e-04\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 6.1587e-04\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 6.2297e-04\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 6.2333e-04\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0014 - val_loss: 6.4424e-04\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0017 - val_loss: 5.9615e-04\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 6.3196e-04\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 6.9502e-04\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 7.2064e-04\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0016 - val_loss: 5.4709e-04\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0014 - val_loss: 5.0996e-04\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 5.7412e-04\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0015 - val_loss: 6.6221e-04\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 7.0362e-04\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 5.8678e-04\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 5.3323e-04\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0014 - val_loss: 6.3395e-04\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 6.9565e-04\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 6.3711e-04\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 5.5289e-04\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 5.6893e-04\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 6.6000e-04\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0014 - val_loss: 7.1224e-04\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 6.5900e-04\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 5.8576e-04\n",
      "Epoch 318/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 5.6237e-04\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 5.9922e-04\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 6.7030e-04\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 6.5076e-04\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 5.9672e-04\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 5.8401e-04\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0015 - val_loss: 6.4229e-04\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 7.0049e-04\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 6.2247e-04\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 5.4797e-04\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 5.9803e-04\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 6.6036e-04\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 5.8323e-04\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 5.4637e-04\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 5.9206e-04\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0013 - val_loss: 6.6418e-04\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 6.4360e-04\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 5.8588e-04\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 5.5540e-04\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0015 - val_loss: 6.5667e-04\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0012 - val_loss: 7.1108e-04\n",
      "Epoch 339/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 6.4774e-04\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 5.5608e-04\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 6.0038e-04\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 6.6327e-04\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 6.6403e-04\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 5.5916e-04\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 5.5218e-04\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 6.2948e-04\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 6.5365e-04\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 6.1464e-04\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 6.4160e-04\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 6.2097e-04\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 5.8622e-04\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 5.7556e-04\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0013 - val_loss: 6.0956e-04\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 6.4812e-04\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 6.5705e-04\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 5.5478e-04\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 5.6539e-04\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 6.1267e-04\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 6.0405e-04\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 6.4094e-04\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 6.2444e-04\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 6.2797e-04\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 6.1432e-04\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 5.7129e-04\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 5.7953e-04\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 5.8728e-04\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 7.1233e-04\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 6.3970e-04\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - val_loss: 5.5172e-04\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - val_loss: 5.9180e-04\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 6.4905e-04\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 6.2093e-04\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 5.4619e-04\n",
      "\n",
      "Loading Model: '02-07-2021--07--14-E2E_LSTM_ValSet_1.0-ALPHA0.1-BETA_SD17-373Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.012919346459468914\n",
      "Model: \"functional_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_82 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_83 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 3.0439e-04 - val_loss: 6.0024e-05\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.4853e-04 - val_loss: 5.6791e-05\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.5161e-04 - val_loss: 5.0052e-05\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.6161e-04 - val_loss: 4.4490e-05\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 2.1681e-04 - val_loss: 3.7146e-05\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0673e-04 - val_loss: 3.2142e-05\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.7276e-04 - val_loss: 2.7465e-05\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.6366e-04 - val_loss: 2.1954e-05\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5748e-04 - val_loss: 1.5519e-05\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.2053e-04 - val_loss: 7.1620e-06\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 9.9404e-05 - val_loss: 2.7304e-06\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1564e-05 - val_loss: 3.0026e-06\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7693e-05 - val_loss: 3.2779e-06\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9313e-05 - val_loss: 3.3815e-06\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0448e-05 - val_loss: 3.3179e-06\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0344e-05 - val_loss: 3.0995e-06\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.2257e-05 - val_loss: 2.7872e-06\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.2791e-05 - val_loss: 2.6079e-06\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.8419e-05 - val_loss: 2.5308e-06\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.6729e-05 - val_loss: 2.4885e-06\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.3014e-05 - val_loss: 2.4530e-06\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.1466e-05 - val_loss: 2.4335e-06\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.0803e-05 - val_loss: 2.4117e-06\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.9923e-05 - val_loss: 2.4036e-06\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5467e-05 - val_loss: 2.4197e-06\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9027e-05 - val_loss: 2.4638e-06\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8142e-05 - val_loss: 2.5277e-06\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8118e-05 - val_loss: 2.5918e-06\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8781e-05 - val_loss: 2.6341e-06\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3856e-05 - val_loss: 2.7087e-06\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.2291e-05 - val_loss: 2.7926e-06\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5210e-05 - val_loss: 2.8691e-06\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4632e-05 - val_loss: 2.9328e-06\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4853e-05 - val_loss: 2.9648e-06\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8616e-05 - val_loss: 2.9994e-06\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7669e-05 - val_loss: 3.0071e-06\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1663e-05 - val_loss: 3.0250e-06\n",
      "Epoch 38/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7465e-05 - val_loss: 3.0342e-06\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2761e-05 - val_loss: 3.0149e-06\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8343e-05 - val_loss: 2.9764e-06\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6803e-05 - val_loss: 2.8936e-06\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5777e-05 - val_loss: 2.7678e-06\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6806e-05 - val_loss: 2.5613e-06\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.4680e-05 - val_loss: 2.3400e-06\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.5580e-05 - val_loss: 2.1606e-06\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.3828e-05 - val_loss: 1.9679e-06\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.4600e-05 - val_loss: 1.8080e-06\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.4486e-05 - val_loss: 1.7113e-06\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3483e-05 - val_loss: 1.8529e-06\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1802e-05 - val_loss: 2.0211e-06\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1880e-05 - val_loss: 2.1856e-06\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0835e-05 - val_loss: 2.3077e-06\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1800e-05 - val_loss: 2.3803e-06\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0388e-05 - val_loss: 2.4214e-06\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0654e-05 - val_loss: 2.4268e-06\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0708e-05 - val_loss: 2.4438e-06\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0416e-05 - val_loss: 2.4392e-06\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0559e-05 - val_loss: 2.4156e-06\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6231e-06 - val_loss: 2.3960e-06\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8892e-06 - val_loss: 2.3884e-06\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.4522e-06 - val_loss: 2.3983e-06\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.3174e-06 - val_loss: 2.4078e-06\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.0565e-06 - val_loss: 2.4075e-06\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.9275e-06 - val_loss: 2.3212e-06\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.3353e-06 - val_loss: 2.2461e-06\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.9577e-06 - val_loss: 2.1693e-06\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.4166e-06 - val_loss: 2.1414e-06\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5704e-06 - val_loss: 2.0777e-06\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.4911e-06 - val_loss: 2.0357e-06\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.9357e-06 - val_loss: 2.0051e-06\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2768e-06 - val_loss: 1.9815e-06\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.5476e-06 - val_loss: 1.9372e-06\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.6778e-06 - val_loss: 1.8742e-06\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5126e-06 - val_loss: 1.8077e-06\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.9765e-06 - val_loss: 1.7427e-06\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 6.0459e-06 - val_loss: 1.6833e-06\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.3438e-06 - val_loss: 1.6049e-06\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.2615e-06 - val_loss: 1.6695e-06\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.5540e-06 - val_loss: 1.7140e-06\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.3934e-06 - val_loss: 1.7614e-06\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.5049e-06 - val_loss: 1.7930e-06\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8907e-06 - val_loss: 1.8064e-06\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.9455e-06 - val_loss: 1.7383e-06\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6317e-06 - val_loss: 1.6059e-06\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.8056e-06 - val_loss: 1.4676e-06\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.4056e-06 - val_loss: 1.3188e-06\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.8702e-06 - val_loss: 1.1744e-06\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.8852e-06 - val_loss: 1.0372e-06\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.6074e-06 - val_loss: 9.1514e-07\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.2182e-06 - val_loss: 8.0966e-07\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.9242e-06 - val_loss: 7.1224e-07\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.1803e-06 - val_loss: 6.2785e-07\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 4.1344e-06 - val_loss: 5.2316e-07\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.2448e-06 - val_loss: 4.3396e-07\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.8786e-06 - val_loss: 3.5590e-07\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 4.7468e-06 - val_loss: 3.9299e-07\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8908e-06 - val_loss: 4.4306e-07\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.5605e-06 - val_loss: 4.8959e-07\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.4061e-06 - val_loss: 5.3920e-07\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.1400e-06 - val_loss: 5.8982e-07\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.8946e-06 - val_loss: 6.3949e-07\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.6712e-06 - val_loss: 6.8377e-07\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.3356e-06 - val_loss: 7.3354e-07\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.4256e-06 - val_loss: 7.9702e-07\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4362e-06 - val_loss: 8.4539e-07\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6388e-06 - val_loss: 8.7222e-07\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5136e-06 - val_loss: 8.7944e-07\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2901e-06 - val_loss: 8.4949e-07\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1368e-06 - val_loss: 8.1184e-07\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3805e-06 - val_loss: 7.7164e-07\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.5159e-06 - val_loss: 7.1929e-07\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8011e-06 - val_loss: 6.6604e-07\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3283e-06 - val_loss: 6.3858e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1170e-06 - val_loss: 6.0035e-07\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5968e-06 - val_loss: 5.3396e-07\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1249e-06 - val_loss: 4.7642e-07\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.4170e-06 - val_loss: 5.1582e-07\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9410e-06 - val_loss: 5.7260e-07\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0370e-06 - val_loss: 6.1828e-07\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0594e-06 - val_loss: 6.5242e-07\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0021e-06 - val_loss: 6.8886e-07\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8954e-06 - val_loss: 7.0029e-07\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7574e-06 - val_loss: 6.9587e-07\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9387e-06 - val_loss: 6.7423e-07\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6110e-06 - val_loss: 6.4149e-07\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6784e-06 - val_loss: 5.9364e-07\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3853e-06 - val_loss: 5.4509e-07\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6756e-06 - val_loss: 4.9682e-07\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3281e-06 - val_loss: 4.4810e-07\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5845e-06 - val_loss: 4.0486e-07\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6967e-06 - val_loss: 3.7000e-07\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.4226e-06 - val_loss: 3.4278e-07\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.4711e-06 - val_loss: 3.1682e-07\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.3566e-06 - val_loss: 3.0825e-07\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6842e-06 - val_loss: 3.3862e-07\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2189e-06 - val_loss: 3.7681e-07\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7191e-06 - val_loss: 4.2871e-07\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.4557e-06 - val_loss: 4.7542e-07\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3082e-06 - val_loss: 5.1153e-07\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.3500e-06 - val_loss: 5.4241e-07\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2652e-06 - val_loss: 5.6446e-07\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1979e-06 - val_loss: 5.7267e-07\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7546e-06 - val_loss: 5.6064e-07\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8623e-06 - val_loss: 5.1427e-07\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2885e-06 - val_loss: 4.6458e-07\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1775e-06 - val_loss: 4.0870e-07\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.4637e-06 - val_loss: 3.5581e-07\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.2268e-06 - val_loss: 2.9772e-07\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.9939e-06 - val_loss: 2.4533e-07\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1355e-06 - val_loss: 2.6395e-07\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9871e-06 - val_loss: 2.6688e-07\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1049e-06 - val_loss: 2.8763e-07\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1304e-06 - val_loss: 3.2547e-07\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1267e-06 - val_loss: 3.7903e-07\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.0352e-06 - val_loss: 3.6708e-07\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2558e-06 - val_loss: 3.7986e-07\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8281e-06 - val_loss: 3.8406e-07\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0534e-06 - val_loss: 3.7787e-07\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7566e-06 - val_loss: 3.5622e-07\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2013e-06 - val_loss: 3.0980e-07\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9282e-06 - val_loss: 2.7134e-07\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1449e-06 - val_loss: 2.3955e-07\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1358e-06 - val_loss: 2.2110e-07\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0233e-06 - val_loss: 2.0479e-07\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9584e-06 - val_loss: 2.0486e-07\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1157e-06 - val_loss: 1.9743e-07\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.9428e-06 - val_loss: 1.9112e-07\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0956e-06 - val_loss: 1.7784e-07\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.7497e-06 - val_loss: 1.6732e-07\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9295e-06 - val_loss: 1.5440e-07\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2477e-06 - val_loss: 1.5967e-07\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8932e-06 - val_loss: 1.6163e-07\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5882e-06 - val_loss: 1.6489e-07\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7380e-06 - val_loss: 1.6931e-07\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9450e-06 - val_loss: 1.7830e-07\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1685e-06 - val_loss: 1.8756e-07\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0358e-06 - val_loss: 2.0636e-07\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7158e-06 - val_loss: 2.3699e-07\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8469e-06 - val_loss: 2.8214e-07\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9937e-06 - val_loss: 3.0487e-07\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4401e-06 - val_loss: 5.4760e-07\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0427e-06 - val_loss: 7.6866e-07\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8134e-06 - val_loss: 9.5566e-07\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2052e-06 - val_loss: 1.0731e-06\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7915e-06 - val_loss: 1.1497e-06\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7696e-06 - val_loss: 1.1985e-06\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2135e-06 - val_loss: 1.1833e-06\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.9293e-06 - val_loss: 1.1240e-06\n",
      "Epoch 189/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0742e-06 - val_loss: 1.0361e-06\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7821e-06 - val_loss: 9.3896e-07\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.9029e-06 - val_loss: 8.3503e-07\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9493e-06 - val_loss: 6.8903e-07\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6773e-06 - val_loss: 5.4695e-07\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.7860e-06 - val_loss: 4.0794e-07\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8931e-06 - val_loss: 3.1039e-07\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8119e-06 - val_loss: 2.1813e-07\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9435e-06 - val_loss: 1.8469e-07\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6871e-06 - val_loss: 1.8837e-07\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9447e-06 - val_loss: 2.2039e-07\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7369e-06 - val_loss: 2.5359e-07\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6818e-06 - val_loss: 2.8337e-07\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9608e-06 - val_loss: 3.1334e-07\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9124e-06 - val_loss: 3.4582e-07\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6726e-06 - val_loss: 3.7122e-07\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7467e-06 - val_loss: 3.7092e-07\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6584e-06 - val_loss: 4.0454e-07\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5722e-06 - val_loss: 4.2702e-07\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7737e-06 - val_loss: 4.1199e-07\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6839e-06 - val_loss: 3.8959e-07\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7381e-06 - val_loss: 3.4938e-07\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8007e-06 - val_loss: 3.1553e-07\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8018e-06 - val_loss: 2.9682e-07\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7775e-06 - val_loss: 2.7916e-07\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8992e-06 - val_loss: 2.6137e-07\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7916e-06 - val_loss: 2.5887e-07\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5930e-06 - val_loss: 2.5833e-07\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8198e-06 - val_loss: 2.5353e-07\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6552e-06 - val_loss: 2.4809e-07\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.7862e-06 - val_loss: 2.8291e-07\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9416e-06 - val_loss: 2.7444e-07\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4606e-06 - val_loss: 2.6589e-07\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7832e-06 - val_loss: 2.4151e-07\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6020e-06 - val_loss: 2.1386e-07\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8663e-06 - val_loss: 1.8978e-07\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5980e-06 - val_loss: 1.6773e-07\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7980e-06 - val_loss: 2.0308e-07\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6512e-06 - val_loss: 2.2451e-07\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8210e-06 - val_loss: 3.2406e-07\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4326e-06 - val_loss: 3.9915e-07\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4257e-06 - val_loss: 4.5831e-07\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6188e-06 - val_loss: 4.9023e-07\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5755e-06 - val_loss: 5.0572e-07\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7168e-06 - val_loss: 5.0114e-07\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8243e-06 - val_loss: 4.9048e-07\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5306e-06 - val_loss: 4.6991e-07\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.6840e-06 - val_loss: 4.2057e-07\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8073e-06 - val_loss: 3.5785e-07\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3774e-06 - val_loss: 2.3323e-07\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.5572e-06 - val_loss: 1.4789e-07\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.6205e-06 - val_loss: 6.5695e-08\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4579e-06 - val_loss: 4.7362e-08\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6743e-06 - val_loss: 5.2440e-08\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.8396e-06 - val_loss: 5.4860e-08\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5555e-06 - val_loss: 4.9015e-08\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7160e-06 - val_loss: 4.7510e-08\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5317e-06 - val_loss: 9.4466e-08\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5773e-06 - val_loss: 2.5722e-07\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7247e-06 - val_loss: 4.0663e-07\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6645e-06 - val_loss: 5.2284e-07\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6919e-06 - val_loss: 5.8588e-07\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.7562e-06 - val_loss: 6.3566e-07\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6377e-06 - val_loss: 6.6355e-07\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6455e-06 - val_loss: 6.5977e-07\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5872e-06 - val_loss: 6.4486e-07\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5533e-06 - val_loss: 6.0082e-07\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7076e-06 - val_loss: 5.2440e-07\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6289e-06 - val_loss: 4.3224e-07\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4811e-06 - val_loss: 3.4835e-07\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6700e-06 - val_loss: 2.7256e-07\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6513e-06 - val_loss: 2.0395e-07\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6612e-06 - val_loss: 1.3513e-07\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5547e-06 - val_loss: 8.9005e-08\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5458e-06 - val_loss: 5.8849e-08\n",
      "Epoch 264/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step - loss: 1.4106e-06 - val_loss: 4.0519e-08\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.3770e-06 - val_loss: 3.3554e-08\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4963e-06 - val_loss: 3.2242e-08\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5512e-06 - val_loss: 3.7796e-08\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9033e-06 - val_loss: 1.0590e-07\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6506e-06 - val_loss: 2.7394e-07\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3902e-06 - val_loss: 4.1850e-07\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5159e-06 - val_loss: 5.4191e-07\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5857e-06 - val_loss: 6.2525e-07\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7283e-06 - val_loss: 6.7874e-07\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6728e-06 - val_loss: 7.0926e-07\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4568e-06 - val_loss: 7.0989e-07\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7214e-06 - val_loss: 6.7392e-07\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5957e-06 - val_loss: 6.1432e-07\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6135e-06 - val_loss: 5.2996e-07\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7534e-06 - val_loss: 4.1186e-07\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5678e-06 - val_loss: 2.7361e-07\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4798e-06 - val_loss: 1.5094e-07\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6800e-06 - val_loss: 5.5500e-08\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6076e-06 - val_loss: 4.0873e-08\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6097e-06 - val_loss: 3.8011e-08\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6684e-06 - val_loss: 4.4291e-08\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5477e-06 - val_loss: 2.1636e-07\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4551e-06 - val_loss: 4.0597e-07\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3390e-06 - val_loss: 5.7507e-07\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7637e-06 - val_loss: 7.0697e-07\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8437e-06 - val_loss: 7.4165e-07\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5689e-06 - val_loss: 7.3736e-07\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6078e-06 - val_loss: 6.8093e-07\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6084e-06 - val_loss: 6.0924e-07\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3909e-06 - val_loss: 5.3907e-07\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6200e-06 - val_loss: 4.4079e-07\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4142e-06 - val_loss: 3.2434e-07\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4224e-06 - val_loss: 2.2179e-07\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4079e-06 - val_loss: 1.3019e-07\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5233e-06 - val_loss: 8.1349e-08\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5090e-06 - val_loss: 5.8988e-08\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7822e-06 - val_loss: 5.3994e-08\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2934e-06 - val_loss: 5.6958e-08\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5327e-06 - val_loss: 1.0582e-07\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3705e-06 - val_loss: 1.8343e-07\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4090e-06 - val_loss: 2.6865e-07\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5425e-06 - val_loss: 3.4334e-07\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2894e-06 - val_loss: 4.0885e-07\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4922e-06 - val_loss: 4.4530e-07\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6210e-06 - val_loss: 4.8964e-07\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3871e-06 - val_loss: 4.9850e-07\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6561e-06 - val_loss: 4.9216e-07\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5818e-06 - val_loss: 4.6031e-07\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4608e-06 - val_loss: 4.0359e-07\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4346e-06 - val_loss: 3.3375e-07\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5386e-06 - val_loss: 2.5324e-07\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3889e-06 - val_loss: 1.7471e-07\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5249e-06 - val_loss: 1.0628e-07\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4568e-06 - val_loss: 7.0923e-08\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2919e-06 - val_loss: 4.4412e-08\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4804e-06 - val_loss: 6.0188e-08\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3976e-06 - val_loss: 1.3285e-07\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6710e-06 - val_loss: 2.0610e-07\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.4593e-06 - val_loss: 2.8012e-07\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3078e-06 - val_loss: 3.4405e-07\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4477e-06 - val_loss: 3.7035e-07\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.4483e-06 - val_loss: 3.6886e-07\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3840e-06 - val_loss: 3.6161e-07\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3110e-06 - val_loss: 3.3382e-07\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5430e-06 - val_loss: 3.1443e-07\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.4410e-06 - val_loss: 2.9723e-07\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5680e-06 - val_loss: 3.0412e-07\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3677e-06 - val_loss: 2.9077e-07\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3372e-06 - val_loss: 2.5053e-07\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3171e-06 - val_loss: 1.8448e-07\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4913e-06 - val_loss: 1.4276e-07\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4133e-06 - val_loss: 1.0355e-07\n",
      "\n",
      "Loading Model: '02-07-2021--07--27-E2E_LSTM_ValSet_1.0-ALPHA0-BETA_SD17-336Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.0024145542900779523\n",
      "Model: \"functional_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_86 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_87 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.6876 - val_loss: 0.5793\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.5735 - val_loss: 0.4716\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4634 - val_loss: 0.3703\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3625 - val_loss: 0.2760\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2700 - val_loss: 0.1935\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1902 - val_loss: 0.1215\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1241 - val_loss: 0.0611\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0681 - val_loss: 0.0219\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0442 - val_loss: 0.0170\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0551 - val_loss: 0.0407\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0885 - val_loss: 0.0537\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1142 - val_loss: 0.0490\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1060 - val_loss: 0.0354\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0844 - val_loss: 0.0220\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0652 - val_loss: 0.0135\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0473 - val_loss: 0.0110\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0420 - val_loss: 0.0134\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0376 - val_loss: 0.0189\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0355 - val_loss: 0.0259\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0404 - val_loss: 0.0326\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0421 - val_loss: 0.0383\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0475 - val_loss: 0.0424\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0461 - val_loss: 0.0445\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0528 - val_loss: 0.0448\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0493 - val_loss: 0.0433\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0479 - val_loss: 0.0405\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0473 - val_loss: 0.0366\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0456 - val_loss: 0.0320\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0438 - val_loss: 0.0273\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0359 - val_loss: 0.0227\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0351 - val_loss: 0.0185\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0328 - val_loss: 0.0149\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0328 - val_loss: 0.0121\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0365 - val_loss: 0.0102\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0316 - val_loss: 0.0089\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0320 - val_loss: 0.0082\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0362 - val_loss: 0.0078\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0327 - val_loss: 0.0076\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0330 - val_loss: 0.0075\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0330 - val_loss: 0.0075\n",
      "Epoch 41/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0342 - val_loss: 0.0076\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0362 - val_loss: 0.0080\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0353 - val_loss: 0.0087\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0315 - val_loss: 0.0098\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0302 - val_loss: 0.0110\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0311 - val_loss: 0.0122\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0306 - val_loss: 0.0132\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0314 - val_loss: 0.0137\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0307 - val_loss: 0.0140\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0312 - val_loss: 0.0138\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0298 - val_loss: 0.0133\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0307 - val_loss: 0.0127\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0282 - val_loss: 0.0118\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0299 - val_loss: 0.0110\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0277 - val_loss: 0.0102\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0279 - val_loss: 0.0094\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0285 - val_loss: 0.0087\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0286 - val_loss: 0.0081\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0260 - val_loss: 0.0076\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0259 - val_loss: 0.0072\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0249 - val_loss: 0.0070\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0265 - val_loss: 0.0068\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0262 - val_loss: 0.0067\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0245 - val_loss: 0.0069\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0251 - val_loss: 0.0071\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0256 - val_loss: 0.0073\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0245 - val_loss: 0.0075\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0251 - val_loss: 0.0079\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0254 - val_loss: 0.0083\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0264 - val_loss: 0.0087\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0227 - val_loss: 0.0089\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0249 - val_loss: 0.0090\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0260 - val_loss: 0.0088\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0238 - val_loss: 0.0085\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0227 - val_loss: 0.0082\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0233 - val_loss: 0.0077\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0249 - val_loss: 0.0073\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0235 - val_loss: 0.0070\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0213 - val_loss: 0.0067\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0234 - val_loss: 0.0065\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0231 - val_loss: 0.0063\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0220 - val_loss: 0.0063\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0219 - val_loss: 0.0064\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0225 - val_loss: 0.0066\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0233 - val_loss: 0.0067\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0216 - val_loss: 0.0069\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0205 - val_loss: 0.0071\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0231 - val_loss: 0.0072\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0216 - val_loss: 0.0073\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0232 - val_loss: 0.0074\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0219 - val_loss: 0.0074\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0208 - val_loss: 0.0073\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0226 - val_loss: 0.0074\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0221 - val_loss: 0.0072\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0219 - val_loss: 0.0069\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0196 - val_loss: 0.0066\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0203 - val_loss: 0.0063\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0197 - val_loss: 0.0060\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0182 - val_loss: 0.0057\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0202 - val_loss: 0.0056\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0188 - val_loss: 0.0058\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0203 - val_loss: 0.0062\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0203 - val_loss: 0.0067\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0194 - val_loss: 0.0073\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0194 - val_loss: 0.0075\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0200 - val_loss: 0.0075\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0202 - val_loss: 0.0071\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0202 - val_loss: 0.0067\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0183 - val_loss: 0.0062\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0181 - val_loss: 0.0058\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0185 - val_loss: 0.0055\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0197 - val_loss: 0.0052\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0189 - val_loss: 0.0051\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0184 - val_loss: 0.0052\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0180 - val_loss: 0.0056\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0178 - val_loss: 0.0061\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0174 - val_loss: 0.0066\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0186 - val_loss: 0.0068\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0178 - val_loss: 0.0068\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0177 - val_loss: 0.0063\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0166 - val_loss: 0.0059\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0169 - val_loss: 0.0056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0177 - val_loss: 0.0055\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0179 - val_loss: 0.0057\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0180 - val_loss: 0.0056\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0179 - val_loss: 0.0052\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0172 - val_loss: 0.0051\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0178 - val_loss: 0.0051\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0162 - val_loss: 0.0052\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0165 - val_loss: 0.0058\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0173 - val_loss: 0.0059\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0173 - val_loss: 0.0055\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0182 - val_loss: 0.0051\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0173 - val_loss: 0.0052\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0174 - val_loss: 0.0053\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0169 - val_loss: 0.0051\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0166 - val_loss: 0.0051\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0159 - val_loss: 0.0051\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0153 - val_loss: 0.0052\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0160 - val_loss: 0.0052\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0142 - val_loss: 0.0052\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0164 - val_loss: 0.0057\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0161 - val_loss: 0.0064\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0150 - val_loss: 0.0060\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0148 - val_loss: 0.0046\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0149 - val_loss: 0.0037\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0164 - val_loss: 0.0037\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0159 - val_loss: 0.0046\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0160 - val_loss: 0.0065\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0161 - val_loss: 0.0074\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0152 - val_loss: 0.0068\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0161 - val_loss: 0.0054\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0158 - val_loss: 0.0042\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0161 - val_loss: 0.0037\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0156 - val_loss: 0.0041\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0163 - val_loss: 0.0052\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0153 - val_loss: 0.0061\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0149 - val_loss: 0.0062\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0153 - val_loss: 0.0056\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0155 - val_loss: 0.0048\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0149 - val_loss: 0.0043\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0158 - val_loss: 0.0037\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0149 - val_loss: 0.0038\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0138 - val_loss: 0.0046\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0137 - val_loss: 0.0058\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0147 - val_loss: 0.0065\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0155 - val_loss: 0.0061\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0151 - val_loss: 0.0048\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0152 - val_loss: 0.0038\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0148 - val_loss: 0.0035\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0145 - val_loss: 0.0040\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0133 - val_loss: 0.0050\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0138 - val_loss: 0.0058\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0143 - val_loss: 0.0057\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0137 - val_loss: 0.0048\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0149 - val_loss: 0.0037\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0132 - val_loss: 0.0031\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0137 - val_loss: 0.0031\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0162 - val_loss: 0.0036\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0151 - val_loss: 0.0047\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0138 - val_loss: 0.0058\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0134 - val_loss: 0.0059\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0143 - val_loss: 0.0046\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0143 - val_loss: 0.0035\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0132 - val_loss: 0.0030\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0143 - val_loss: 0.0030\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0132 - val_loss: 0.0038\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0140 - val_loss: 0.0050\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0141 - val_loss: 0.0057\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0141 - val_loss: 0.0052\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0141 - val_loss: 0.0043\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0137 - val_loss: 0.0033\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0139 - val_loss: 0.0032\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0137 - val_loss: 0.0033\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0145 - val_loss: 0.0036\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0130 - val_loss: 0.0038\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0136 - val_loss: 0.0044\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0152 - val_loss: 0.0046\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0137 - val_loss: 0.0042\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0136 - val_loss: 0.0035\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0131 - val_loss: 0.0032\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0145 - val_loss: 0.0034\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0132 - val_loss: 0.0044\n",
      "Epoch 204/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0130 - val_loss: 0.0052\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0137 - val_loss: 0.0051\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0134 - val_loss: 0.0034\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0125 - val_loss: 0.0025\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0133 - val_loss: 0.0028\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0130 - val_loss: 0.0038\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0131 - val_loss: 0.0047\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0138 - val_loss: 0.0054\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0134 - val_loss: 0.0044\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0124 - val_loss: 0.0034\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0130 - val_loss: 0.0030\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0137 - val_loss: 0.0031\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0128 - val_loss: 0.0036\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0132 - val_loss: 0.0043\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0126 - val_loss: 0.0046\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0127 - val_loss: 0.0042\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0132 - val_loss: 0.0032\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0116 - val_loss: 0.0029\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0133 - val_loss: 0.0031\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0128 - val_loss: 0.0037\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0121 - val_loss: 0.0044\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0135 - val_loss: 0.0044\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0123 - val_loss: 0.0036\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0129 - val_loss: 0.0030\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0124 - val_loss: 0.0031\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0123 - val_loss: 0.0037\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0126 - val_loss: 0.0037\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0127 - val_loss: 0.0036\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0123 - val_loss: 0.0038\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0116 - val_loss: 0.0037\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0127 - val_loss: 0.0031\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0119 - val_loss: 0.0031\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0133 - val_loss: 0.0035\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0111 - val_loss: 0.0042\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0129 - val_loss: 0.0036\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0123 - val_loss: 0.0029\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0128 - val_loss: 0.0027\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0118 - val_loss: 0.0029\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0135 - val_loss: 0.0035\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0124 - val_loss: 0.0040\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0123 - val_loss: 0.0037\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0130 - val_loss: 0.0033\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0121 - val_loss: 0.0032\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0130 - val_loss: 0.0035\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0123 - val_loss: 0.0034\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0121 - val_loss: 0.0036\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0119 - val_loss: 0.0039\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0129 - val_loss: 0.0036\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0127 - val_loss: 0.0035\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0123 - val_loss: 0.0040\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0122 - val_loss: 0.0037\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0125 - val_loss: 0.0035\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0116 - val_loss: 0.0031\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0123 - val_loss: 0.0030\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0121 - val_loss: 0.0036\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0118 - val_loss: 0.0041\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0125 - val_loss: 0.0042\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0120 - val_loss: 0.0038\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0114 - val_loss: 0.0032\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0126 - val_loss: 0.0029\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0128 - val_loss: 0.0034\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0119 - val_loss: 0.0042\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0123 - val_loss: 0.0040\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0119 - val_loss: 0.0034\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0032\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0120 - val_loss: 0.0028\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0106 - val_loss: 0.0032\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0116 - val_loss: 0.0039\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0122 - val_loss: 0.0044\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0035\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0124 - val_loss: 0.0027\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0117 - val_loss: 0.0029\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0107 - val_loss: 0.0037\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0122 - val_loss: 0.0041\n",
      "\n",
      "Loading Model: '02-07-2021--07--40-E2E_LSTM_ValSet_1.0-ALPHA1.0-BETA_SD17-277Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.010981468930364592\n",
      "Model: \"functional_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_90 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_91 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 68.7324 - val_loss: 57.9091\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 57.3138 - val_loss: 47.1336\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 46.2856 - val_loss: 36.9905\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 36.1856 - val_loss: 27.5497\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 26.9261 - val_loss: 19.2949\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 18.9337 - val_loss: 12.0805\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 12.3227 - val_loss: 6.0354\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.7185 - val_loss: 2.1205\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.3255 - val_loss: 1.6487\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.4671 - val_loss: 4.0312\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8184 - val_loss: 5.3236\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.3537 - val_loss: 4.8337\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10.5260 - val_loss: 3.4627\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.3573 - val_loss: 2.1238\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 6.4165 - val_loss: 1.2862\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.6294 - val_loss: 1.0453\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1116 - val_loss: 1.2922\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6760 - val_loss: 1.8550\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4779 - val_loss: 2.5498\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.9687 - val_loss: 3.2253\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1493 - val_loss: 3.7900\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.6808 - val_loss: 4.1991\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5372 - val_loss: 4.4156\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.2129 - val_loss: 4.4366\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.8547 - val_loss: 4.2897\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.7179 - val_loss: 4.0041\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 4.6581 - val_loss: 3.6105\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.4835 - val_loss: 3.1522\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.2932 - val_loss: 2.6777\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5198 - val_loss: 2.2182\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4391 - val_loss: 1.7947\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.2101 - val_loss: 1.4378\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2036 - val_loss: 1.1620\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.5818 - val_loss: 0.9696\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.0995 - val_loss: 0.8472\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.1375 - val_loss: 0.7780\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.5378 - val_loss: 0.7379\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.2041 - val_loss: 0.7151\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.2275 - val_loss: 0.7040\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.2281 - val_loss: 0.7035\n",
      "Epoch 41/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3514 - val_loss: 0.7174\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.5458 - val_loss: 0.7579\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4637 - val_loss: 0.8375\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.0827 - val_loss: 0.9411\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9552 - val_loss: 1.0671\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0471 - val_loss: 1.1843\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9907 - val_loss: 1.2824\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0783 - val_loss: 1.3385\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.0005 - val_loss: 1.3621\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.0541 - val_loss: 1.3379\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9073 - val_loss: 1.2882\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0107 - val_loss: 1.2168\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7498 - val_loss: 1.1286\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9209 - val_loss: 1.0513\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7102 - val_loss: 0.9667\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7248 - val_loss: 0.8825\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7864 - val_loss: 0.8096\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7905 - val_loss: 0.7524\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5359 - val_loss: 0.7095\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.5327 - val_loss: 0.6800\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.4338 - val_loss: 0.6546\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.5810 - val_loss: 0.6400\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.5535 - val_loss: 0.6384\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3788 - val_loss: 0.6526\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.4486 - val_loss: 0.6772\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5017 - val_loss: 0.6962\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3810 - val_loss: 0.7197\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4530 - val_loss: 0.7572\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4828 - val_loss: 0.7938\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5753 - val_loss: 0.8262\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2131 - val_loss: 0.8471\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4256 - val_loss: 0.8489\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5321 - val_loss: 0.8291\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3253 - val_loss: 0.8048\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.2117 - val_loss: 0.7696\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2650 - val_loss: 0.7265\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4307 - val_loss: 0.6831\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2784 - val_loss: 0.6539\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0730 - val_loss: 0.6257\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.2734 - val_loss: 0.6065\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2497 - val_loss: 0.5945\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1411 - val_loss: 0.5896\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1323 - val_loss: 0.6031\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1993 - val_loss: 0.6192\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2726 - val_loss: 0.6323\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0948 - val_loss: 0.6471\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.9910 - val_loss: 0.6653\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2460 - val_loss: 0.6788\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1042 - val_loss: 0.6888\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2587 - val_loss: 0.6988\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1222 - val_loss: 0.6931\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0202 - val_loss: 0.6893\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2037 - val_loss: 0.6924\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.1485 - val_loss: 0.6775\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1278 - val_loss: 0.6462\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9067 - val_loss: 0.6202\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.9690 - val_loss: 0.5874\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.9172 - val_loss: 0.5598\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.7698 - val_loss: 0.5352\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.9649 - val_loss: 0.5221\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8290 - val_loss: 0.5459\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9710 - val_loss: 0.5809\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9762 - val_loss: 0.6340\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8839 - val_loss: 0.6899\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8885 - val_loss: 0.7107\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9448 - val_loss: 0.7069\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9659 - val_loss: 0.6661\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9548 - val_loss: 0.6225\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7687 - val_loss: 0.5788\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7572 - val_loss: 0.5422\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7921 - val_loss: 0.5125\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9128 - val_loss: 0.4842\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.8346 - val_loss: 0.4704\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.7872 - val_loss: 0.4814\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7474 - val_loss: 0.5252\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.7336 - val_loss: 0.5794\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6820 - val_loss: 0.6255\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8056 - val_loss: 0.6446\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7234 - val_loss: 0.6423\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7131 - val_loss: 0.5973\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6059 - val_loss: 0.5497\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6285 - val_loss: 0.5228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7106 - val_loss: 0.5224\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7310 - val_loss: 0.5435\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.7447 - val_loss: 0.5366\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7248 - val_loss: 0.4954\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.6593 - val_loss: 0.4788\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7155 - val_loss: 0.4764\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5622 - val_loss: 0.4879\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5938 - val_loss: 0.5436\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6676 - val_loss: 0.5532\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6656 - val_loss: 0.5170\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7587 - val_loss: 0.4777\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6762 - val_loss: 0.4808\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6755 - val_loss: 0.4933\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6249 - val_loss: 0.4721\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6050 - val_loss: 0.4729\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5421 - val_loss: 0.4734\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4813 - val_loss: 0.4817\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5511 - val_loss: 0.4868\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3666 - val_loss: 0.4833\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5879 - val_loss: 0.5346\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5630 - val_loss: 0.6047\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.4463 - val_loss: 0.5612\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.4317 - val_loss: 0.4132\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.4321 - val_loss: 0.3322\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5923 - val_loss: 0.3351\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5368 - val_loss: 0.4281\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5395 - val_loss: 0.6254\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5575 - val_loss: 0.7129\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4666 - val_loss: 0.6410\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5524 - val_loss: 0.4891\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5219 - val_loss: 0.3697\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.5587 - val_loss: 0.3296\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5114 - val_loss: 0.3802\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5739 - val_loss: 0.4897\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4760 - val_loss: 0.5844\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4443 - val_loss: 0.5896\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4763 - val_loss: 0.5242\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5015 - val_loss: 0.4457\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4421 - val_loss: 0.3846\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.5321 - val_loss: 0.3294\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4393 - val_loss: 0.3434\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3212 - val_loss: 0.4204\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3191 - val_loss: 0.5415\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4197 - val_loss: 0.6189\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5027 - val_loss: 0.5867\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4673 - val_loss: 0.4678\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4641 - val_loss: 0.3591\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4274 - val_loss: 0.3145\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4036 - val_loss: 0.3497\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2833 - val_loss: 0.4479\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3232 - val_loss: 0.5272\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3773 - val_loss: 0.5419\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3186 - val_loss: 0.4599\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4356 - val_loss: 0.3551\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.2760 - val_loss: 0.2776\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.3234 - val_loss: 0.2705\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5654 - val_loss: 0.3102\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4650 - val_loss: 0.4245\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3299 - val_loss: 0.5404\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2979 - val_loss: 0.5684\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3783 - val_loss: 0.4310\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3812 - val_loss: 0.3155\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.2716 - val_loss: 0.2572\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3693 - val_loss: 0.2601\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2757 - val_loss: 0.3387\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3481 - val_loss: 0.4656\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3596 - val_loss: 0.5371\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3616 - val_loss: 0.4857\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3568 - val_loss: 0.3935\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3216 - val_loss: 0.2959\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3307 - val_loss: 0.2785\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3248 - val_loss: 0.2906\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4003 - val_loss: 0.3170\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2545 - val_loss: 0.3447\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3107 - val_loss: 0.4116\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4541 - val_loss: 0.4262\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3178 - val_loss: 0.3884\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3110 - val_loss: 0.3113\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2638 - val_loss: 0.2802\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4032 - val_loss: 0.3021\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2689 - val_loss: 0.3971\n",
      "Epoch 204/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2486 - val_loss: 0.4899\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3206 - val_loss: 0.4815\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2891 - val_loss: 0.3066\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.1955 - val_loss: 0.2179\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2808 - val_loss: 0.2365\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2552 - val_loss: 0.3315\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2589 - val_loss: 0.4283\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3270 - val_loss: 0.5057\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3005 - val_loss: 0.4200\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1935 - val_loss: 0.3159\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2555 - val_loss: 0.2618\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3224 - val_loss: 0.2651\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2348 - val_loss: 0.3088\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2753 - val_loss: 0.3826\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2092 - val_loss: 0.4316\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2292 - val_loss: 0.3967\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2729 - val_loss: 0.3019\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1093 - val_loss: 0.2542\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2827 - val_loss: 0.2633\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2391 - val_loss: 0.3215\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1562 - val_loss: 0.3940\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3042 - val_loss: 0.4124\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1837 - val_loss: 0.3339\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2394 - val_loss: 0.2718\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1909 - val_loss: 0.2740\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1742 - val_loss: 0.3207\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2075 - val_loss: 0.3231\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2185 - val_loss: 0.3294\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1883 - val_loss: 0.3601\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1197 - val_loss: 0.3429\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2347 - val_loss: 0.2711\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1432 - val_loss: 0.2641\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2784 - val_loss: 0.3057\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0646 - val_loss: 0.3904\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2408 - val_loss: 0.3347\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1808 - val_loss: 0.2622\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2248 - val_loss: 0.2386\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1322 - val_loss: 0.2522\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2966 - val_loss: 0.3144\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1949 - val_loss: 0.3651\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1853 - val_loss: 0.3445\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2505 - val_loss: 0.2993\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1674 - val_loss: 0.2810\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2482 - val_loss: 0.3126\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1862 - val_loss: 0.3039\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1659 - val_loss: 0.3219\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1440 - val_loss: 0.3594\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2416 - val_loss: 0.3270\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2236 - val_loss: 0.3200\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1818 - val_loss: 0.3548\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1693 - val_loss: 0.3283\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1946 - val_loss: 0.3167\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1137 - val_loss: 0.2808\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1868 - val_loss: 0.2665\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1593 - val_loss: 0.3236\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1304 - val_loss: 0.3657\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2063 - val_loss: 0.3882\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1480 - val_loss: 0.3564\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1014 - val_loss: 0.2915\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2085 - val_loss: 0.2581\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2417 - val_loss: 0.2980\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1475 - val_loss: 0.3767\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1794 - val_loss: 0.3736\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1366 - val_loss: 0.3223\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0956 - val_loss: 0.2946\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1552 - val_loss: 0.2438\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0214 - val_loss: 0.2825\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1181 - val_loss: 0.3589\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1742 - val_loss: 0.4146\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1088 - val_loss: 0.3324\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1939 - val_loss: 0.2368\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1305 - val_loss: 0.2501\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0334 - val_loss: 0.3333\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1707 - val_loss: 0.3791\n",
      "\n",
      "Loading Model: '02-07-2021--07--53-E2E_LSTM_ValSet_1.0-ALPHA100.0-BETA_SD17-277Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.010997811916933838\n",
      "Model: \"functional_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_94 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_95 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 687.3212 - val_loss: 579.0889\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 573.1343 - val_loss: 471.3335\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 462.8507 - val_loss: 369.9015\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 361.8499 - val_loss: 275.4923\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 269.2534 - val_loss: 192.9432\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 189.3286 - val_loss: 120.7984\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 123.2185 - val_loss: 60.3471\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 67.1761 - val_loss: 21.1984\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 43.2461 - val_loss: 16.4824\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 54.6678 - val_loss: 40.3095\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 88.1820 - val_loss: 53.2316\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 113.5319 - val_loss: 48.3304\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 105.2527 - val_loss: 34.6201\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 83.5642 - val_loss: 21.2316\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 64.1545 - val_loss: 12.8566\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 46.2852 - val_loss: 10.4478\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 41.1084 - val_loss: 12.9187\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 36.7526 - val_loss: 18.5469\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 34.7728 - val_loss: 25.4956\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 39.6806 - val_loss: 32.2506\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 41.4875 - val_loss: 37.8968\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 46.8018 - val_loss: 41.9883\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 45.3661 - val_loss: 44.1521\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 52.1227 - val_loss: 44.3620\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 48.5402 - val_loss: 42.8924\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 47.1725 - val_loss: 40.0363\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 46.5734 - val_loss: 36.0999\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 44.8279 - val_loss: 31.5168\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 42.9245 - val_loss: 26.7716\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 35.1914 - val_loss: 22.1775\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 34.3844 - val_loss: 17.9418\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 32.0949 - val_loss: 14.3732\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 32.0293 - val_loss: 11.6153\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 35.8120 - val_loss: 9.6916\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 30.9908 - val_loss: 8.4683\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 31.3699 - val_loss: 7.7765\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 35.3716 - val_loss: 7.3759\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 32.0352 - val_loss: 7.1476\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 32.2687 - val_loss: 7.0368\n",
      "Epoch 40/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step - loss: 32.2759 - val_loss: 7.0322\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 33.5081 - val_loss: 7.1705\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 35.4520 - val_loss: 7.5756\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 34.6317 - val_loss: 8.3728\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.8210 - val_loss: 9.4083\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 29.5486 - val_loss: 10.6684\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.4660 - val_loss: 11.8412\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 29.9017 - val_loss: 12.8221\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 30.7776 - val_loss: 13.3823\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 30.0003 - val_loss: 13.6178\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 30.5364 - val_loss: 13.3755\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 29.0675 - val_loss: 12.8780\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 30.1019 - val_loss: 12.1631\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 27.4920 - val_loss: 11.2808\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 29.2027 - val_loss: 10.5075\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 27.0963 - val_loss: 9.6619\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 27.2425 - val_loss: 8.8207\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 27.8585 - val_loss: 8.0916\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 27.8985 - val_loss: 7.5209\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 25.3531 - val_loss: 7.0924\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 25.3210 - val_loss: 6.7987\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 24.3333 - val_loss: 6.5449\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 25.8048 - val_loss: 6.3986\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 25.5285 - val_loss: 6.3821\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 23.7819 - val_loss: 6.5236\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 24.4807 - val_loss: 6.7697\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 25.0115 - val_loss: 6.9586\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 23.8044 - val_loss: 7.1912\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 24.5252 - val_loss: 7.5656\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 24.8227 - val_loss: 7.9301\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 25.7475 - val_loss: 8.2531\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.1261 - val_loss: 8.4624\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 24.2492 - val_loss: 8.4809\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 25.3144 - val_loss: 8.2845\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 23.2476 - val_loss: 8.0427\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 22.1111 - val_loss: 7.6928\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 22.6443 - val_loss: 7.2629\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 24.3023 - val_loss: 6.8290\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 22.7774 - val_loss: 6.5376\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 20.7248 - val_loss: 6.2556\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 22.7285 - val_loss: 6.0627\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 22.4913 - val_loss: 5.9422\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 21.4053 - val_loss: 5.8930\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 21.3176 - val_loss: 6.0270\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 21.9886 - val_loss: 6.1877\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 22.7209 - val_loss: 6.3188\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 20.9429 - val_loss: 6.4661\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.9044 - val_loss: 6.6476\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 22.4541 - val_loss: 6.7827\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 21.0367 - val_loss: 6.8830\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 22.5811 - val_loss: 6.9831\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 21.2158 - val_loss: 6.9263\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 20.1966 - val_loss: 6.8888\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.0319 - val_loss: 6.9197\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 21.4796 - val_loss: 6.7709\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 21.2726 - val_loss: 6.4583\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.0617 - val_loss: 6.1984\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.6846 - val_loss: 5.8698\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.1660 - val_loss: 5.5935\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 17.6930 - val_loss: 5.3482\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 19.6429 - val_loss: 5.2167\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 18.2862 - val_loss: 5.4552\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 19.7039 - val_loss: 5.8047\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 19.7560 - val_loss: 6.3357\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 18.8335 - val_loss: 6.8959\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 18.8797 - val_loss: 7.1039\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.4427 - val_loss: 7.0662\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.6540 - val_loss: 6.6580\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 19.5419 - val_loss: 6.2217\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.6818 - val_loss: 5.7843\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.5667 - val_loss: 5.4176\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 17.9156 - val_loss: 5.1210\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 19.1223 - val_loss: 4.8378\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 18.3417 - val_loss: 4.6995\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.8666 - val_loss: 4.8101\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 17.4682 - val_loss: 5.2490\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 17.3309 - val_loss: 5.7916\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.8139 - val_loss: 6.2529\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 18.0499 - val_loss: 6.4430\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.2286 - val_loss: 6.4187\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.1260 - val_loss: 5.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.0541 - val_loss: 5.4908\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.2791 - val_loss: 5.2225\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.0998 - val_loss: 5.2201\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.3051 - val_loss: 5.4317\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.4418 - val_loss: 5.3637\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.2426 - val_loss: 4.9516\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.5869 - val_loss: 4.7850\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 17.1487 - val_loss: 4.7599\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 15.6170 - val_loss: 4.8733\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 15.9337 - val_loss: 5.4293\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.6699 - val_loss: 5.5272\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 16.6509 - val_loss: 5.1667\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 17.5812 - val_loss: 4.7753\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.7566 - val_loss: 4.8062\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.7483 - val_loss: 4.9298\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.2431 - val_loss: 4.7164\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.0444 - val_loss: 4.7226\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.4155 - val_loss: 4.7277\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.8080 - val_loss: 4.8095\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.5057 - val_loss: 4.8616\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 13.6608 - val_loss: 4.8277\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 15.8744 - val_loss: 5.3431\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.6251 - val_loss: 6.0440\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 14.4581 - val_loss: 5.6084\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 14.3123 - val_loss: 4.1277\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 14.3158 - val_loss: 3.3172\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.9178 - val_loss: 3.3455\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.3625 - val_loss: 4.2740\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.3903 - val_loss: 6.2474\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.5686 - val_loss: 7.1265\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 14.6603 - val_loss: 6.4105\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.5183 - val_loss: 4.8912\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.2133 - val_loss: 3.6958\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 15.5802 - val_loss: 3.2929\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 15.1089 - val_loss: 3.7979\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.7335 - val_loss: 4.8922\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.7529 - val_loss: 5.8405\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.4360 - val_loss: 5.8943\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 14.7552 - val_loss: 5.2415\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.0089 - val_loss: 4.4573\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.4141 - val_loss: 3.8453\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.3146 - val_loss: 3.2930\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.3866 - val_loss: 3.4323\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2066 - val_loss: 4.2022\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.1851 - val_loss: 5.4131\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.1893 - val_loss: 6.1868\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.0208 - val_loss: 5.8664\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.6668 - val_loss: 4.6768\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.6352 - val_loss: 3.5894\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 14.2675 - val_loss: 3.1430\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.0293 - val_loss: 3.4955\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.8269 - val_loss: 4.4769\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.2253 - val_loss: 5.2684\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.7660 - val_loss: 5.4169\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 13.1810 - val_loss: 4.5974\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.3502 - val_loss: 3.5486\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 12.7543 - val_loss: 2.7730\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 13.2280 - val_loss: 2.7007\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.6479 - val_loss: 3.0972\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.6433 - val_loss: 4.2410\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2928 - val_loss: 5.4003\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.9734 - val_loss: 5.6809\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.7764 - val_loss: 4.3046\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.8055 - val_loss: 3.1483\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 12.7100 - val_loss: 2.5664\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.6860 - val_loss: 2.5982\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.7499 - val_loss: 3.3858\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.4748 - val_loss: 4.6559\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.5902 - val_loss: 5.3675\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.6106 - val_loss: 4.8506\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.5616 - val_loss: 3.9284\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2099 - val_loss: 2.9539\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.3007 - val_loss: 2.7833\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2420 - val_loss: 2.9064\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.9962 - val_loss: 3.1704\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.5406 - val_loss: 3.4456\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.1018 - val_loss: 4.1120\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.5336 - val_loss: 4.2557\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.1723 - val_loss: 3.8784\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.1036 - val_loss: 3.1101\n",
      "Epoch 201/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 12.6325 - val_loss: 2.8024\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.0261 - val_loss: 3.0226\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.6819 - val_loss: 3.9735\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4807 - val_loss: 4.8978\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.1995 - val_loss: 4.8078\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 12.8819 - val_loss: 3.0586\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 11.9489 - val_loss: 2.1751\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.8043 - val_loss: 2.3653\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.5457 - val_loss: 3.3215\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.5832 - val_loss: 4.2885\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2641 - val_loss: 5.0546\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.9985 - val_loss: 4.1936\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.9285 - val_loss: 3.1537\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.5497 - val_loss: 2.6167\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2187 - val_loss: 2.6530\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.3410 - val_loss: 3.0921\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.7473 - val_loss: 3.8293\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.0865 - val_loss: 4.3144\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.2864 - val_loss: 3.9628\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.7216 - val_loss: 3.0161\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.0881 - val_loss: 2.5432\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.8216 - val_loss: 2.6369\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.3844 - val_loss: 3.2194\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.5566 - val_loss: 3.9412\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.0358 - val_loss: 4.1191\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.8309 - val_loss: 3.3328\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.3874 - val_loss: 2.7153\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.9038 - val_loss: 2.7415\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.7347 - val_loss: 3.2120\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.0686 - val_loss: 3.2333\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.1791 - val_loss: 3.2906\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.8774 - val_loss: 3.5963\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 11.1913 - val_loss: 3.4254\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.3419 - val_loss: 2.7093\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.4259 - val_loss: 2.6421\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.7775 - val_loss: 3.0593\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10.6409 - val_loss: 3.9039\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4028 - val_loss: 3.3419\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.8028 - val_loss: 2.6154\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.2430 - val_loss: 2.3821\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.3166 - val_loss: 2.5220\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.9597 - val_loss: 3.1459\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.9425 - val_loss: 3.6514\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.8478 - val_loss: 3.4402\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.4978 - val_loss: 2.9871\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.6681 - val_loss: 2.8060\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4755 - val_loss: 3.1266\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.8563 - val_loss: 3.0401\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.6519 - val_loss: 3.2161\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.4345 - val_loss: 3.5868\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4093 - val_loss: 3.2633\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.2296 - val_loss: 3.1981\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.8119 - val_loss: 3.5507\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.6872 - val_loss: 3.2837\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.9387 - val_loss: 3.1647\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.1313 - val_loss: 2.8033\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.8629 - val_loss: 2.6626\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.5881 - val_loss: 3.2372\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.2986 - val_loss: 3.6588\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.0577 - val_loss: 3.8800\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.4745 - val_loss: 3.5578\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.0084 - val_loss: 2.9099\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.0782 - val_loss: 2.5791\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4119 - val_loss: 2.9810\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.4689 - val_loss: 3.7669\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.7890 - val_loss: 3.7330\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.3590 - val_loss: 3.2178\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 10.9505 - val_loss: 2.9432\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.5464 - val_loss: 2.4376\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10.2081 - val_loss: 2.8243\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.1739 - val_loss: 3.5873\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.7357 - val_loss: 4.1421\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.0812 - val_loss: 3.3189\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.9314 - val_loss: 2.3647\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.3007 - val_loss: 2.5007\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10.3289 - val_loss: 3.3355\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.7012 - val_loss: 3.7906\n",
      "\n",
      "Loading Model: '02-07-2021--08--06-E2E_LSTM_ValSet_1.0-ALPHA1000.0-BETA_SD17-277Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.010997811916933838\n",
      "Model: \"functional_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_98 (LSTM)               (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_99 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 9.9171e-05 - val_loss: 7.1185e-05\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 9.1432e-05 - val_loss: 6.6263e-05\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.7934e-05 - val_loss: 6.2670e-05\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 8.8388e-05 - val_loss: 5.9285e-05\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 8.1013e-05 - val_loss: 5.6097e-05\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 8.0468e-05 - val_loss: 5.3472e-05\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 7.5261e-05 - val_loss: 5.1574e-05\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 7.0743e-05 - val_loss: 4.9806e-05\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 7.3316e-05 - val_loss: 4.8141e-05\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.5800e-05 - val_loss: 4.6483e-05\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.8070e-05 - val_loss: 4.5134e-05\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.9064e-05 - val_loss: 4.4088e-05\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 6.0342e-05 - val_loss: 4.3106e-05\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.2204e-05 - val_loss: 4.2182e-05\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.6485e-05 - val_loss: 4.1419e-05\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.4089e-05 - val_loss: 4.0853e-05\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.2183e-05 - val_loss: 4.0447e-05\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 6.6365e-05 - val_loss: 4.0103e-05\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.0632e-05 - val_loss: 3.9790e-05\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.4324e-05 - val_loss: 3.9554e-05\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.6140e-05 - val_loss: 3.9341e-05\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.9786e-05 - val_loss: 3.9198e-05\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.0869e-05 - val_loss: 3.9112e-05\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.9626e-05 - val_loss: 3.9054e-05\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.0240e-05 - val_loss: 3.9017e-05\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.7106e-05 - val_loss: 3.9001e-05\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.0049e-05 - val_loss: 3.8997e-05\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.6770e-05 - val_loss: 3.8957e-05\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.3938e-05 - val_loss: 3.8972e-05\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.5939e-05 - val_loss: 3.8953e-05\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.7597e-05 - val_loss: 3.8952e-05\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.3254e-05 - val_loss: 3.8934e-05\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.0308e-05 - val_loss: 3.8946e-05\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.5568e-05 - val_loss: 3.8970e-05\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.3415e-05 - val_loss: 3.8998e-05\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.3061e-05 - val_loss: 3.9020e-05\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2658e-05 - val_loss: 3.9052e-05\n",
      "Epoch 38/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 5.3499e-05 - val_loss: 3.9098e-05\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.4717e-05 - val_loss: 3.9155e-05\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.3374e-05 - val_loss: 3.9146e-05\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5736e-05 - val_loss: 3.9164e-05\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.5473e-05 - val_loss: 3.9181e-05\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3048e-05 - val_loss: 3.9207e-05\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.4680e-05 - val_loss: 3.9151e-05\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.0834e-05 - val_loss: 3.9064e-05\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.2306e-05 - val_loss: 3.8848e-05\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.6062e-05 - val_loss: 3.8609e-05\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 5.7038e-05 - val_loss: 3.8405e-05\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 5.8420e-05 - val_loss: 3.8280e-05\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.0215e-05 - val_loss: 3.8237e-05\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.4490e-05 - val_loss: 3.8142e-05\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.2028e-05 - val_loss: 3.7966e-05\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.3578e-05 - val_loss: 3.7722e-05\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.3254e-05 - val_loss: 3.7435e-05\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.8347e-05 - val_loss: 3.7115e-05\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.1577e-05 - val_loss: 3.6777e-05\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.3125e-05 - val_loss: 3.6475e-05\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.0960e-05 - val_loss: 3.6194e-05\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.8960e-05 - val_loss: 3.5989e-05\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.0562e-05 - val_loss: 3.5905e-05\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.8152e-05 - val_loss: 3.5860e-05\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.0352e-05 - val_loss: 3.5819e-05\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.9850e-05 - val_loss: 3.5845e-05\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.2396e-05 - val_loss: 3.5889e-05\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.8639e-05 - val_loss: 3.5979e-05\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0223e-05 - val_loss: 3.6030e-05\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.0063e-05 - val_loss: 3.6152e-05\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5641e-05 - val_loss: 3.6260e-05\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.7519e-05 - val_loss: 3.6309e-05\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.3648e-05 - val_loss: 3.6427e-05\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 4.7570e-05 - val_loss: 3.6618e-05\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0290e-05 - val_loss: 3.6631e-05\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.1032e-05 - val_loss: 3.6564e-05\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.5521e-05 - val_loss: 3.6513e-05\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5282e-05 - val_loss: 3.6339e-05\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0484e-05 - val_loss: 3.6166e-05\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.7554e-05 - val_loss: 3.6041e-05\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4494e-05 - val_loss: 3.6021e-05\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.7056e-05 - val_loss: 3.5999e-05\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.1601e-05 - val_loss: 3.6074e-05\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.6938e-05 - val_loss: 3.6125e-05\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.7007e-05 - val_loss: 3.6197e-05\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5448e-05 - val_loss: 3.6277e-05\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.3212e-05 - val_loss: 3.6187e-05\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.8253e-05 - val_loss: 3.6146e-05\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9249e-05 - val_loss: 3.6175e-05\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.0944e-05 - val_loss: 3.6211e-05\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.8872e-05 - val_loss: 3.6245e-05\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.8225e-05 - val_loss: 3.6359e-05\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.9439e-05 - val_loss: 3.6509e-05\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0617e-05 - val_loss: 3.6754e-05\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.3826e-05 - val_loss: 3.7085e-05\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4310e-05 - val_loss: 3.7449e-05\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4594e-05 - val_loss: 3.7629e-05\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5213e-05 - val_loss: 3.7710e-05\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.2560e-05 - val_loss: 3.7738e-05\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.6095e-05 - val_loss: 3.7792e-05\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.4271e-05 - val_loss: 3.7789e-05\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.1404e-05 - val_loss: 3.7782e-05\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.7368e-05 - val_loss: 3.7836e-05\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1459e-05 - val_loss: 3.7843e-05\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9695e-05 - val_loss: 3.7862e-05\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.3654e-05 - val_loss: 3.7754e-05\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4761e-05 - val_loss: 3.7660e-05\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.6312e-05 - val_loss: 3.7555e-05\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5016e-05 - val_loss: 3.7237e-05\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.7193e-05 - val_loss: 3.6803e-05\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.6378e-05 - val_loss: 3.6268e-05\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.5864e-05 - val_loss: 3.5872e-05\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.3347e-05 - val_loss: 3.5542e-05\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.5607e-05 - val_loss: 3.5300e-05\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.6081e-05 - val_loss: 3.5298e-05\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.0857e-05 - val_loss: 3.5195e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.3147e-05 - val_loss: 3.5217e-05\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.2599e-05 - val_loss: 3.5145e-05\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.2413e-05 - val_loss: 3.5126e-05\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.8657e-05 - val_loss: 3.5296e-05\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.8467e-05 - val_loss: 3.5521e-05\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1876e-05 - val_loss: 3.5669e-05\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1063e-05 - val_loss: 3.5859e-05\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2457e-05 - val_loss: 3.6164e-05\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4340e-05 - val_loss: 3.6305e-05\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4982e-05 - val_loss: 3.6365e-05\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4205e-05 - val_loss: 3.6392e-05\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.7289e-05 - val_loss: 3.6461e-05\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.3915e-05 - val_loss: 3.6508e-05\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.6558e-05 - val_loss: 3.6534e-05\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.7335e-05 - val_loss: 3.6687e-05\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5913e-05 - val_loss: 3.6822e-05\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.3170e-05 - val_loss: 3.7004e-05\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4345e-05 - val_loss: 3.7113e-05\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.0690e-05 - val_loss: 3.7315e-05\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.5835e-05 - val_loss: 3.7485e-05\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4884e-05 - val_loss: 3.7579e-05\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.7302e-05 - val_loss: 3.7621e-05\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.7440e-05 - val_loss: 3.7559e-05\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2929e-05 - val_loss: 3.7444e-05\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.7315e-05 - val_loss: 3.7289e-05\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.2627e-05 - val_loss: 3.7099e-05\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.3896e-05 - val_loss: 3.6947e-05\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2314e-05 - val_loss: 3.6748e-05\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0573e-05 - val_loss: 3.6522e-05\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8829e-05 - val_loss: 3.6167e-05\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1490e-05 - val_loss: 3.5752e-05\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0721e-05 - val_loss: 3.5391e-05\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.1137e-05 - val_loss: 3.5044e-05\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.1073e-05 - val_loss: 3.4749e-05\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.9426e-05 - val_loss: 3.4430e-05\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.4514e-05 - val_loss: 3.4245e-05\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.3629e-05 - val_loss: 3.4161e-05\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.2893e-05 - val_loss: 3.4156e-05\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.2993e-05 - val_loss: 3.4240e-05\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.4386e-05 - val_loss: 3.4415e-05\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.3552e-05 - val_loss: 3.4818e-05\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.9174e-05 - val_loss: 3.5106e-05\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.5298e-05 - val_loss: 3.5474e-05\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5703e-05 - val_loss: 3.5750e-05\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.3196e-05 - val_loss: 3.6013e-05\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.4518e-05 - val_loss: 3.6310e-05\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.9313e-05 - val_loss: 3.6548e-05\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1352e-05 - val_loss: 3.6665e-05\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2140e-05 - val_loss: 3.6669e-05\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 4.1339e-05 - val_loss: 3.6634e-05\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 4.4032e-05 - val_loss: 3.6531e-05\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9682e-05 - val_loss: 3.6493e-05\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9423e-05 - val_loss: 3.6324e-05\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.3531e-05 - val_loss: 3.6162e-05\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.0513e-05 - val_loss: 3.5830e-05\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0688e-05 - val_loss: 3.5629e-05\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2149e-05 - val_loss: 3.5530e-05\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0823e-05 - val_loss: 3.5400e-05\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2014e-05 - val_loss: 3.5325e-05\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2076e-05 - val_loss: 3.5096e-05\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.2387e-05 - val_loss: 3.4928e-05\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.9548e-05 - val_loss: 3.4762e-05\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.3902e-05 - val_loss: 3.4581e-05\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9923e-05 - val_loss: 3.4406e-05\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9131e-05 - val_loss: 3.4409e-05\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.4022e-05 - val_loss: 3.4493e-05\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2043e-05 - val_loss: 3.4468e-05\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.4805e-05 - val_loss: 3.4587e-05\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.3234e-05 - val_loss: 3.4794e-05\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.3203e-05 - val_loss: 3.5069e-05\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1749e-05 - val_loss: 3.5212e-05\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1362e-05 - val_loss: 3.5319e-05\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 4.6850e-05 - val_loss: 3.5643e-05\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6660e-05 - val_loss: 3.5779e-05\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1494e-05 - val_loss: 3.5809e-05\n",
      "Epoch 189/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 4.3130e-05 - val_loss: 3.5912e-05\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.3058e-05 - val_loss: 3.6136e-05\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2340e-05 - val_loss: 3.6389e-05\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7721e-05 - val_loss: 3.6379e-05\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.1791e-05 - val_loss: 3.6410e-05\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0809e-05 - val_loss: 3.6291e-05\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9968e-05 - val_loss: 3.5954e-05\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8972e-05 - val_loss: 3.5376e-05\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9051e-05 - val_loss: 3.4784e-05\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.5288e-05 - val_loss: 3.4304e-05\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.0532e-05 - val_loss: 3.3797e-05\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.1557e-05 - val_loss: 3.3371e-05\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.8545e-05 - val_loss: 3.3125e-05\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.9872e-05 - val_loss: 3.3010e-05\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.8168e-05 - val_loss: 3.2980e-05\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7083e-05 - val_loss: 3.3074e-05\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1669e-05 - val_loss: 3.3208e-05\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 4.7834e-05 - val_loss: 3.3581e-05\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.3595e-05 - val_loss: 3.4019e-05\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.1516e-05 - val_loss: 3.4337e-05\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0895e-05 - val_loss: 3.4595e-05\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.0885e-05 - val_loss: 3.4717e-05\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0350e-05 - val_loss: 3.4852e-05\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9474e-05 - val_loss: 3.4876e-05\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9278e-05 - val_loss: 3.4854e-05\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8221e-05 - val_loss: 3.4806e-05\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8567e-05 - val_loss: 3.4683e-05\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.1408e-05 - val_loss: 3.4642e-05\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.0529e-05 - val_loss: 3.4669e-05\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.0862e-05 - val_loss: 3.4569e-05\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4556e-05 - val_loss: 3.4514e-05\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.9526e-05 - val_loss: 3.4304e-05\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.8436e-05 - val_loss: 3.4204e-05\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.9205e-05 - val_loss: 3.4007e-05\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.0708e-05 - val_loss: 3.3910e-05\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1069e-05 - val_loss: 3.3866e-05\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.6239e-05 - val_loss: 3.3815e-05\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1345e-05 - val_loss: 3.3822e-05\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0182e-05 - val_loss: 3.3859e-05\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8956e-05 - val_loss: 3.3741e-05\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1526e-05 - val_loss: 3.3766e-05\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 4.2365e-05 - val_loss: 3.3805e-05\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0648e-05 - val_loss: 3.3902e-05\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 4.0925e-05 - val_loss: 3.3975e-05\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4263e-05 - val_loss: 3.3859e-05\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6627e-05 - val_loss: 3.3793e-05\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1138e-05 - val_loss: 3.3807e-05\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9625e-05 - val_loss: 3.3735e-05\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5371e-05 - val_loss: 3.3677e-05\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0974e-05 - val_loss: 3.3584e-05\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0628e-05 - val_loss: 3.3549e-05\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8997e-05 - val_loss: 3.3484e-05\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9251e-05 - val_loss: 3.3308e-05\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.2430e-05 - val_loss: 3.3131e-05\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.8653e-05 - val_loss: 3.2913e-05\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.0496e-05 - val_loss: 3.2758e-05\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0159e-05 - val_loss: 3.2798e-05\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5371e-05 - val_loss: 3.2870e-05\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0908e-05 - val_loss: 3.3014e-05\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.3278e-05 - val_loss: 3.3227e-05\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6492e-05 - val_loss: 3.3459e-05\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.0582e-05 - val_loss: 3.3549e-05\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9697e-05 - val_loss: 3.3739e-05\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7747e-05 - val_loss: 3.3977e-05\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4444e-05 - val_loss: 3.4038e-05\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.0011e-05 - val_loss: 3.4171e-05\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1588e-05 - val_loss: 3.4152e-05\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.8291e-05 - val_loss: 3.3892e-05\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7518e-05 - val_loss: 3.3608e-05\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.1749e-05 - val_loss: 3.3463e-05\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7646e-05 - val_loss: 3.3334e-05\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5734e-05 - val_loss: 3.3248e-05\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8792e-05 - val_loss: 3.3239e-05\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7346e-05 - val_loss: 3.3242e-05\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4911e-05 - val_loss: 3.3431e-05\n",
      "Epoch 264/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step - loss: 3.7010e-05 - val_loss: 3.3718e-05\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1404e-05 - val_loss: 3.3750e-05\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9303e-05 - val_loss: 3.3605e-05\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1389e-05 - val_loss: 3.3358e-05\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.0400e-05 - val_loss: 3.3134e-05\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8923e-05 - val_loss: 3.2879e-05\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.5944e-05 - val_loss: 3.2611e-05\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.7571e-05 - val_loss: 3.2594e-05\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.1498e-05 - val_loss: 3.2533e-05\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.7214e-05 - val_loss: 3.2573e-05\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9343e-05 - val_loss: 3.2624e-05\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.4926e-05 - val_loss: 3.2636e-05\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4966e-05 - val_loss: 3.2592e-05\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.8794e-05 - val_loss: 3.2603e-05\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.5729e-05 - val_loss: 3.2642e-05\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7137e-05 - val_loss: 3.2594e-05\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.4682e-05 - val_loss: 3.2453e-05\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.8532e-05 - val_loss: 3.2358e-05\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.7264e-05 - val_loss: 3.2333e-05\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.7255e-05 - val_loss: 3.2398e-05\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6634e-05 - val_loss: 3.2468e-05\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6518e-05 - val_loss: 3.2556e-05\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.9832e-05 - val_loss: 3.2796e-05\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.2980e-05 - val_loss: 3.3088e-05\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1008e-05 - val_loss: 3.3266e-05\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6415e-05 - val_loss: 3.3455e-05\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5422e-05 - val_loss: 3.3746e-05\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0292e-05 - val_loss: 3.3900e-05\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3987e-05 - val_loss: 3.3901e-05\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3963e-05 - val_loss: 3.3905e-05\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.3083e-05 - val_loss: 3.3771e-05\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8331e-05 - val_loss: 3.3513e-05\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1484e-05 - val_loss: 3.3261e-05\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6552e-05 - val_loss: 3.3004e-05\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9982e-05 - val_loss: 3.2641e-05\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.4748e-05 - val_loss: 3.2329e-05\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.1471e-05 - val_loss: 3.2091e-05\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.2717e-05 - val_loss: 3.1874e-05\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.9683e-05 - val_loss: 3.1719e-05\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.7920e-05 - val_loss: 3.1660e-05\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.7119e-05 - val_loss: 3.1745e-05\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0091e-05 - val_loss: 3.1941e-05\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8310e-05 - val_loss: 3.2297e-05\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.0618e-05 - val_loss: 3.2798e-05\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.7527e-05 - val_loss: 3.3351e-05\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6245e-05 - val_loss: 3.3832e-05\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3661e-05 - val_loss: 3.4250e-05\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.3287e-05 - val_loss: 3.4415e-05\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.1294e-05 - val_loss: 3.4506e-05\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2988e-05 - val_loss: 3.4467e-05\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.5073e-05 - val_loss: 3.4093e-05\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6581e-05 - val_loss: 3.3611e-05\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7180e-05 - val_loss: 3.3235e-05\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4366e-05 - val_loss: 3.2945e-05\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7720e-05 - val_loss: 3.2749e-05\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6164e-05 - val_loss: 3.2614e-05\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6537e-05 - val_loss: 3.2565e-05\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6687e-05 - val_loss: 3.2557e-05\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4684e-05 - val_loss: 3.2584e-05\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7386e-05 - val_loss: 3.2571e-05\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.0462e-05 - val_loss: 3.2689e-05\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0088e-05 - val_loss: 3.2738e-05\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7741e-05 - val_loss: 3.2618e-05\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6906e-05 - val_loss: 3.2464e-05\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.5350e-05 - val_loss: 3.2365e-05\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.4553e-05 - val_loss: 3.2084e-05\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.5045e-05 - val_loss: 3.1799e-05\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1830e-05 - val_loss: 3.1694e-05\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 3.3790e-05 - val_loss: 3.1602e-05\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 3.6391e-05 - val_loss: 3.1480e-05\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.4566e-05 - val_loss: 3.1418e-05\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.8574e-05 - val_loss: 3.1475e-05\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1703e-05 - val_loss: 3.1507e-05\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7549e-05 - val_loss: 3.1653e-05\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3584e-05 - val_loss: 3.1829e-05\n",
      "Epoch 339/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 3.7268e-05 - val_loss: 3.2098e-05\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7395e-05 - val_loss: 3.2389e-05\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7268e-05 - val_loss: 3.2430e-05\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0723e-05 - val_loss: 3.2436e-05\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3550e-05 - val_loss: 3.2464e-05\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.4327e-05 - val_loss: 3.2484e-05\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2213e-05 - val_loss: 3.2248e-05\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.7959e-05 - val_loss: 3.2033e-05\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9824e-05 - val_loss: 3.1933e-05\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8692e-05 - val_loss: 3.2041e-05\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5729e-05 - val_loss: 3.2151e-05\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7061e-05 - val_loss: 3.2125e-05\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4399e-05 - val_loss: 3.2121e-05\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6380e-05 - val_loss: 3.2148e-05\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4454e-05 - val_loss: 3.2082e-05\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4227e-05 - val_loss: 3.2060e-05\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4843e-05 - val_loss: 3.2104e-05\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3782e-05 - val_loss: 3.2226e-05\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7070e-05 - val_loss: 3.2422e-05\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.4822e-05 - val_loss: 3.2622e-05\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2782e-05 - val_loss: 3.2710e-05\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.6754e-05 - val_loss: 3.2811e-05\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4397e-05 - val_loss: 3.2776e-05\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.7328e-05 - val_loss: 3.2698e-05\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.6949e-05 - val_loss: 3.2831e-05\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.3518e-05 - val_loss: 3.3110e-05\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9936e-05 - val_loss: 3.3305e-05\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.5428e-05 - val_loss: 3.3458e-05\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6348e-05 - val_loss: 3.3551e-05\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1967e-05 - val_loss: 3.3355e-05\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1675e-05 - val_loss: 3.3160e-05\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.9643e-05 - val_loss: 3.3013e-05\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3882e-05 - val_loss: 3.2825e-05\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5008e-05 - val_loss: 3.2701e-05\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.3563e-05 - val_loss: 3.2762e-05\n",
      "Epoch 374/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8213e-05 - val_loss: 3.2693e-05\n",
      "Epoch 375/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6863e-05 - val_loss: 3.2592e-05\n",
      "Epoch 376/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4450e-05 - val_loss: 3.2491e-05\n",
      "Epoch 377/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.5645e-05 - val_loss: 3.2203e-05\n",
      "Epoch 378/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2116e-05 - val_loss: 3.2078e-05\n",
      "Epoch 379/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.4512e-05 - val_loss: 3.1959e-05\n",
      "Epoch 380/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.5424e-05 - val_loss: 3.1855e-05\n",
      "Epoch 381/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.0781e-05 - val_loss: 3.1807e-05\n",
      "Epoch 382/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4058e-05 - val_loss: 3.1781e-05\n",
      "Epoch 383/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.3702e-05 - val_loss: 3.1911e-05\n",
      "Epoch 384/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6827e-05 - val_loss: 3.2110e-05\n",
      "Epoch 385/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.3479e-05 - val_loss: 3.2275e-05\n",
      "Epoch 386/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4466e-05 - val_loss: 3.2302e-05\n",
      "Epoch 387/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0680e-05 - val_loss: 3.2203e-05\n",
      "Epoch 388/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6100e-05 - val_loss: 3.2135e-05\n",
      "Epoch 389/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.5319e-05 - val_loss: 3.2207e-05\n",
      "Epoch 390/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5943e-05 - val_loss: 3.2254e-05\n",
      "Epoch 391/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9491e-05 - val_loss: 3.2387e-05\n",
      "Epoch 392/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3807e-05 - val_loss: 3.2490e-05\n",
      "Epoch 393/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.2364e-05 - val_loss: 3.2607e-05\n",
      "Epoch 394/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7125e-05 - val_loss: 3.2667e-05\n",
      "Epoch 395/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.5126e-05 - val_loss: 3.2667e-05\n",
      "Epoch 396/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.4226e-05 - val_loss: 3.2527e-05\n",
      "Epoch 397/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3457e-05 - val_loss: 3.2313e-05\n",
      "Epoch 398/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.6504e-05 - val_loss: 3.1974e-05\n",
      "Epoch 399/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.3698e-05 - val_loss: 3.1561e-05\n",
      "Epoch 400/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.3517e-05 - val_loss: 3.1165e-05\n",
      "Epoch 401/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.2635e-05 - val_loss: 3.0941e-05\n",
      "Epoch 402/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.3142e-05 - val_loss: 3.0850e-05\n",
      "Epoch 403/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.9952e-05 - val_loss: 3.0771e-05\n",
      "Epoch 404/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2626e-05 - val_loss: 3.0835e-05\n",
      "Epoch 405/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3637e-05 - val_loss: 3.0956e-05\n",
      "Epoch 406/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4575e-05 - val_loss: 3.1071e-05\n",
      "Epoch 407/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3830e-05 - val_loss: 3.1046e-05\n",
      "Epoch 408/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3707e-05 - val_loss: 3.0993e-05\n",
      "Epoch 409/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3484e-05 - val_loss: 3.1017e-05\n",
      "Epoch 410/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5459e-05 - val_loss: 3.1051e-05\n",
      "Epoch 411/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.3706e-05 - val_loss: 3.1068e-05\n",
      "Epoch 412/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0127e-05 - val_loss: 3.1274e-05\n",
      "Epoch 413/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9844e-05 - val_loss: 3.1529e-05\n",
      "Epoch 414/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3558e-05 - val_loss: 3.1761e-05\n",
      "Epoch 415/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6445e-05 - val_loss: 3.1964e-05\n",
      "Epoch 416/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4346e-05 - val_loss: 3.2195e-05\n",
      "Epoch 417/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4609e-05 - val_loss: 3.2490e-05\n",
      "Epoch 418/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8367e-05 - val_loss: 3.2666e-05\n",
      "Epoch 419/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5356e-05 - val_loss: 3.2752e-05\n",
      "Epoch 420/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4456e-05 - val_loss: 3.2643e-05\n",
      "Epoch 421/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.3152e-05 - val_loss: 3.2119e-05\n",
      "Epoch 422/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.7869e-05 - val_loss: 3.1590e-05\n",
      "Epoch 423/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1342e-05 - val_loss: 3.1169e-05\n",
      "Epoch 424/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6624e-05 - val_loss: 3.0907e-05\n",
      "Epoch 425/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 3.3595e-05 - val_loss: 3.0729e-05\n",
      "Epoch 426/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.6558e-05 - val_loss: 3.0553e-05\n",
      "Epoch 427/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.4562e-05 - val_loss: 3.0480e-05\n",
      "Epoch 428/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3308e-05 - val_loss: 3.0518e-05\n",
      "Epoch 429/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.4876e-05 - val_loss: 3.0362e-05\n",
      "Epoch 430/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.4183e-05 - val_loss: 3.0259e-05\n",
      "Epoch 431/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4003e-05 - val_loss: 3.0300e-05\n",
      "Epoch 432/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.3349e-05 - val_loss: 3.0391e-05\n",
      "Epoch 433/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9943e-05 - val_loss: 3.0547e-05\n",
      "Epoch 434/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.5568e-05 - val_loss: 3.0772e-05\n",
      "Epoch 435/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2406e-05 - val_loss: 3.1018e-05\n",
      "Epoch 436/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4092e-05 - val_loss: 3.1259e-05\n",
      "Epoch 437/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2403e-05 - val_loss: 3.1606e-05\n",
      "Epoch 438/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0564e-05 - val_loss: 3.1979e-05\n",
      "Epoch 439/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4551e-05 - val_loss: 3.2474e-05\n",
      "Epoch 440/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7979e-05 - val_loss: 3.3085e-05\n",
      "Epoch 441/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.8333e-05 - val_loss: 3.3267e-05\n",
      "Epoch 442/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3118e-05 - val_loss: 3.3440e-05\n",
      "Epoch 443/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.5924e-05 - val_loss: 3.3521e-05\n",
      "Epoch 444/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4188e-05 - val_loss: 3.3430e-05\n",
      "Epoch 445/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2527e-05 - val_loss: 3.3289e-05\n",
      "Epoch 446/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2272e-05 - val_loss: 3.3142e-05\n",
      "Epoch 447/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.7570e-05 - val_loss: 3.3189e-05\n",
      "Epoch 448/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.6027e-05 - val_loss: 3.3321e-05\n",
      "Epoch 449/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4014e-05 - val_loss: 3.3653e-05\n",
      "Epoch 450/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7286e-05 - val_loss: 3.4023e-05\n",
      "Epoch 451/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2034e-05 - val_loss: 3.4159e-05\n",
      "Epoch 452/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2468e-05 - val_loss: 3.4153e-05\n",
      "Epoch 453/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0285e-05 - val_loss: 3.4023e-05\n",
      "Epoch 454/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5044e-05 - val_loss: 3.3853e-05\n",
      "Epoch 455/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1005e-05 - val_loss: 3.3347e-05\n",
      "Epoch 456/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.6481e-05 - val_loss: 3.2708e-05\n",
      "Epoch 457/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8601e-05 - val_loss: 3.2266e-05\n",
      "Epoch 458/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3544e-05 - val_loss: 3.1881e-05\n",
      "Epoch 459/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.4409e-05 - val_loss: 3.1377e-05\n",
      "Epoch 460/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1078e-05 - val_loss: 3.1033e-05\n",
      "Epoch 461/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2750e-05 - val_loss: 3.0856e-05\n",
      "Epoch 462/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1878e-05 - val_loss: 3.0783e-05\n",
      "Epoch 463/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5609e-05 - val_loss: 3.0636e-05\n",
      "Epoch 464/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.0167e-05 - val_loss: 3.0773e-05\n",
      "Epoch 465/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7044e-05 - val_loss: 3.0907e-05\n",
      "Epoch 466/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1941e-05 - val_loss: 3.0805e-05\n",
      "Epoch 467/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2531e-05 - val_loss: 3.0762e-05\n",
      "Epoch 468/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0310e-05 - val_loss: 3.0667e-05\n",
      "Epoch 469/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.2673e-05 - val_loss: 3.0642e-05\n",
      "Epoch 470/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9046e-05 - val_loss: 3.0523e-05\n",
      "Epoch 471/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.1501e-05 - val_loss: 3.0399e-05\n",
      "Epoch 472/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1794e-05 - val_loss: 3.0411e-05\n",
      "Epoch 473/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1899e-05 - val_loss: 3.0479e-05\n",
      "Epoch 474/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0707e-05 - val_loss: 3.0619e-05\n",
      "Epoch 475/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1293e-05 - val_loss: 3.0718e-05\n",
      "Epoch 476/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3986e-05 - val_loss: 3.0869e-05\n",
      "Epoch 477/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0781e-05 - val_loss: 3.1099e-05\n",
      "Epoch 478/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.2468e-05 - val_loss: 3.1183e-05\n",
      "Epoch 479/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.9424e-05 - val_loss: 3.1340e-05\n",
      "Epoch 480/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9824e-05 - val_loss: 3.1342e-05\n",
      "Epoch 481/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.9401e-05 - val_loss: 3.1059e-05\n",
      "Epoch 482/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9547e-05 - val_loss: 3.0756e-05\n",
      "Epoch 483/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.7892e-05 - val_loss: 3.0557e-05\n",
      "Epoch 484/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.2055e-05 - val_loss: 3.0509e-05\n",
      "Epoch 485/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1454e-05 - val_loss: 3.0506e-05\n",
      "Epoch 486/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.0883e-05 - val_loss: 3.0712e-05\n",
      "Epoch 487/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.8888e-05 - val_loss: 3.0853e-05\n",
      "Epoch 488/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.1464e-05 - val_loss: 3.0838e-05\n",
      "Epoch 489/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step - loss: 3.4119e-05 - val_loss: 3.0917e-05\n",
      "Epoch 490/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0396e-05 - val_loss: 3.0730e-05\n",
      "Epoch 491/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0648e-05 - val_loss: 3.0498e-05\n",
      "Epoch 492/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.1127e-05 - val_loss: 3.0293e-05\n",
      "Epoch 493/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.1609e-05 - val_loss: 3.0065e-05\n",
      "Epoch 494/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4641e-05 - val_loss: 3.0090e-05\n",
      "Epoch 495/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.2001e-05 - val_loss: 3.0046e-05\n",
      "Epoch 496/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.0481e-05 - val_loss: 3.0056e-05\n",
      "Epoch 497/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.2525e-05 - val_loss: 2.9938e-05\n",
      "Epoch 498/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 3.3336e-05 - val_loss: 2.9601e-05\n",
      "Epoch 499/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.1103e-05 - val_loss: 2.9294e-05\n",
      "Epoch 500/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.3002e-05 - val_loss: 2.9035e-05\n",
      "Epoch 501/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.1029e-05 - val_loss: 2.8884e-05\n",
      "Epoch 502/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.2681e-05 - val_loss: 2.8869e-05\n",
      "Epoch 503/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.1746e-05 - val_loss: 2.8951e-05\n",
      "Epoch 504/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9231e-05 - val_loss: 2.9028e-05\n",
      "Epoch 505/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.1771e-05 - val_loss: 2.9261e-05\n",
      "Epoch 506/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8646e-05 - val_loss: 2.9704e-05\n",
      "Epoch 507/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1936e-05 - val_loss: 3.0101e-05\n",
      "Epoch 508/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0552e-05 - val_loss: 3.0234e-05\n",
      "Epoch 509/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1553e-05 - val_loss: 3.0066e-05\n",
      "Epoch 510/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.0195e-05 - val_loss: 2.9776e-05\n",
      "Epoch 511/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.1272e-05 - val_loss: 2.9350e-05\n",
      "Epoch 512/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2877e-05 - val_loss: 2.9129e-05\n",
      "Epoch 513/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0994e-05 - val_loss: 2.8979e-05\n",
      "Epoch 514/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9542e-05 - val_loss: 2.8879e-05\n",
      "Epoch 515/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.1015e-05 - val_loss: 2.8805e-05\n",
      "Epoch 516/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.7947e-05 - val_loss: 2.8768e-05\n",
      "Epoch 517/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3261e-05 - val_loss: 2.8778e-05\n",
      "Epoch 518/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9396e-05 - val_loss: 2.8889e-05\n",
      "Epoch 519/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.5503e-05 - val_loss: 2.9024e-05\n",
      "Epoch 520/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5904e-05 - val_loss: 2.9049e-05\n",
      "Epoch 521/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5980e-05 - val_loss: 2.8991e-05\n",
      "Epoch 522/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1202e-05 - val_loss: 2.8914e-05\n",
      "Epoch 523/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0912e-05 - val_loss: 2.9014e-05\n",
      "Epoch 524/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7078e-05 - val_loss: 2.9131e-05\n",
      "Epoch 525/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8669e-05 - val_loss: 2.9292e-05\n",
      "Epoch 526/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9107e-05 - val_loss: 2.9602e-05\n",
      "Epoch 527/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9160e-05 - val_loss: 3.0142e-05\n",
      "Epoch 528/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0689e-05 - val_loss: 3.0405e-05\n",
      "Epoch 529/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.1308e-05 - val_loss: 3.0405e-05\n",
      "Epoch 530/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1072e-05 - val_loss: 3.0259e-05\n",
      "Epoch 531/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9977e-05 - val_loss: 3.0033e-05\n",
      "Epoch 532/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1068e-05 - val_loss: 2.9743e-05\n",
      "Epoch 533/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9665e-05 - val_loss: 2.9497e-05\n",
      "Epoch 534/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.7027e-05 - val_loss: 2.9437e-05\n",
      "Epoch 535/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.1462e-05 - val_loss: 2.9433e-05\n",
      "Epoch 536/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9486e-05 - val_loss: 2.9527e-05\n",
      "Epoch 537/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5157e-05 - val_loss: 2.9764e-05\n",
      "Epoch 538/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.9515e-05 - val_loss: 3.0095e-05\n",
      "Epoch 539/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1689e-05 - val_loss: 3.0225e-05\n",
      "Epoch 540/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1704e-05 - val_loss: 3.0475e-05\n",
      "Epoch 541/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1222e-05 - val_loss: 3.0760e-05\n",
      "Epoch 542/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6985e-05 - val_loss: 3.0936e-05\n",
      "Epoch 543/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1695e-05 - val_loss: 3.0717e-05\n",
      "Epoch 544/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1689e-05 - val_loss: 3.0592e-05\n",
      "Epoch 545/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4710e-05 - val_loss: 3.0438e-05\n",
      "Epoch 546/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7202e-05 - val_loss: 3.0240e-05\n",
      "Epoch 547/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0801e-05 - val_loss: 3.0180e-05\n",
      "Epoch 548/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8948e-05 - val_loss: 3.0168e-05\n",
      "Epoch 549/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9704e-05 - val_loss: 3.0214e-05\n",
      "Epoch 550/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9654e-05 - val_loss: 3.0337e-05\n",
      "Epoch 551/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0412e-05 - val_loss: 3.0148e-05\n",
      "Epoch 552/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7849e-05 - val_loss: 2.9723e-05\n",
      "Epoch 553/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0398e-05 - val_loss: 2.9352e-05\n",
      "Epoch 554/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1495e-05 - val_loss: 2.9144e-05\n",
      "Epoch 555/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0700e-05 - val_loss: 2.8989e-05\n",
      "Epoch 556/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.8735e-05 - val_loss: 2.8764e-05\n",
      "Epoch 557/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.9103e-05 - val_loss: 2.8593e-05\n",
      "Epoch 558/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.0257e-05 - val_loss: 2.8545e-05\n",
      "Epoch 559/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.9015e-05 - val_loss: 2.8551e-05\n",
      "Epoch 560/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3309e-05 - val_loss: 2.8761e-05\n",
      "Epoch 561/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8572e-05 - val_loss: 2.9056e-05\n",
      "Epoch 562/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9350e-05 - val_loss: 2.9467e-05\n",
      "Epoch 563/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.7917e-05 - val_loss: 2.9861e-05\n",
      "Epoch 564/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8971e-05 - val_loss: 3.0452e-05\n",
      "Epoch 565/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9610e-05 - val_loss: 3.0728e-05\n",
      "Epoch 566/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.1008e-05 - val_loss: 3.0658e-05\n",
      "Epoch 567/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0646e-05 - val_loss: 3.0236e-05\n",
      "Epoch 568/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.9673e-05 - val_loss: 2.9847e-05\n",
      "Epoch 569/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1433e-05 - val_loss: 2.9510e-05\n",
      "Epoch 570/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.1161e-05 - val_loss: 2.9365e-05\n",
      "Epoch 571/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7194e-05 - val_loss: 2.9251e-05\n",
      "Epoch 572/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1122e-05 - val_loss: 2.9182e-05\n",
      "Epoch 573/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9033e-05 - val_loss: 2.9102e-05\n",
      "Epoch 574/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6887e-05 - val_loss: 2.8951e-05\n",
      "Epoch 575/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.2248e-05 - val_loss: 2.8903e-05\n",
      "Epoch 576/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9957e-05 - val_loss: 2.8919e-05\n",
      "Epoch 577/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6323e-05 - val_loss: 2.9067e-05\n",
      "Epoch 578/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3166e-05 - val_loss: 2.9605e-05\n",
      "Epoch 579/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2172e-05 - val_loss: 3.0300e-05\n",
      "Epoch 580/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.1963e-05 - val_loss: 3.0885e-05\n",
      "Epoch 581/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5124e-05 - val_loss: 3.0821e-05\n",
      "Epoch 582/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0625e-05 - val_loss: 3.0725e-05\n",
      "Epoch 583/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8569e-05 - val_loss: 3.0708e-05\n",
      "Epoch 584/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.9824e-05 - val_loss: 3.0731e-05\n",
      "Epoch 585/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.8030e-05 - val_loss: 2.9937e-05\n",
      "Epoch 586/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7780e-05 - val_loss: 2.9483e-05\n",
      "Epoch 587/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9849e-05 - val_loss: 2.9124e-05\n",
      "Epoch 588/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8235e-05 - val_loss: 2.8892e-05\n",
      "Epoch 589/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8770e-05 - val_loss: 2.8642e-05\n",
      "Epoch 590/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.1419e-05 - val_loss: 2.8482e-05\n",
      "Epoch 591/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.3236e-05 - val_loss: 2.8426e-05\n",
      "Epoch 592/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7612e-05 - val_loss: 2.8435e-05\n",
      "Epoch 593/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3404e-05 - val_loss: 2.8854e-05\n",
      "Epoch 594/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0172e-05 - val_loss: 2.9539e-05\n",
      "Epoch 595/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5490e-05 - val_loss: 3.0082e-05\n",
      "Epoch 596/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3794e-05 - val_loss: 3.0278e-05\n",
      "Epoch 597/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.6974e-05 - val_loss: 2.9954e-05\n",
      "Epoch 598/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6789e-05 - val_loss: 2.9343e-05\n",
      "Epoch 599/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8182e-05 - val_loss: 2.8789e-05\n",
      "Epoch 600/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.6533e-05 - val_loss: 2.8352e-05\n",
      "Epoch 601/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.0393e-05 - val_loss: 2.8059e-05\n",
      "Epoch 602/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.9757e-05 - val_loss: 2.7889e-05\n",
      "Epoch 603/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.8239e-05 - val_loss: 2.7781e-05\n",
      "Epoch 604/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.9079e-05 - val_loss: 2.7773e-05\n",
      "Epoch 605/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6044e-05 - val_loss: 2.7882e-05\n",
      "Epoch 606/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.7886e-05 - val_loss: 2.8250e-05\n",
      "Epoch 607/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.7837e-05 - val_loss: 2.8637e-05\n",
      "Epoch 608/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9976e-05 - val_loss: 2.8913e-05\n",
      "Epoch 609/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7591e-05 - val_loss: 2.8828e-05\n",
      "Epoch 610/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8663e-05 - val_loss: 2.8637e-05\n",
      "Epoch 611/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9402e-05 - val_loss: 2.8396e-05\n",
      "Epoch 612/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5806e-05 - val_loss: 2.7887e-05\n",
      "Epoch 613/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.7830e-05 - val_loss: 2.7602e-05\n",
      "Epoch 614/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.5532e-05 - val_loss: 2.7440e-05\n",
      "Epoch 615/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.1688e-05 - val_loss: 2.7386e-05\n",
      "Epoch 616/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.6841e-05 - val_loss: 2.7345e-05\n",
      "Epoch 617/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.8879e-05 - val_loss: 2.7277e-05\n",
      "Epoch 618/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.4345e-05 - val_loss: 2.7265e-05\n",
      "Epoch 619/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.9738e-05 - val_loss: 2.7461e-05\n",
      "Epoch 620/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.9317e-05 - val_loss: 2.7973e-05\n",
      "Epoch 621/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2329e-05 - val_loss: 2.8623e-05\n",
      "Epoch 622/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7773e-05 - val_loss: 2.9130e-05\n",
      "Epoch 623/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.6709e-05 - val_loss: 2.9510e-05\n",
      "Epoch 624/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9530e-05 - val_loss: 2.9717e-05\n",
      "Epoch 625/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.8811e-05 - val_loss: 2.9934e-05\n",
      "Epoch 626/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6278e-05 - val_loss: 2.9541e-05\n",
      "Epoch 627/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8112e-05 - val_loss: 2.8842e-05\n",
      "Epoch 628/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8278e-05 - val_loss: 2.8151e-05\n",
      "Epoch 629/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6256e-05 - val_loss: 2.7761e-05\n",
      "Epoch 630/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.6541e-05 - val_loss: 2.7475e-05\n",
      "Epoch 631/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9091e-05 - val_loss: 2.7319e-05\n",
      "Epoch 632/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.6682e-05 - val_loss: 2.7154e-05\n",
      "Epoch 633/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.7471e-05 - val_loss: 2.7005e-05\n",
      "Epoch 634/1500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 3.1291e-05 - val_loss: 2.6911e-05\n",
      "Epoch 635/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 3.1701e-05 - val_loss: 2.6871e-05\n",
      "Epoch 636/1500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.6581e-05 - val_loss: 2.6880e-05\n",
      "Epoch 637/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.6412e-05 - val_loss: 2.6901e-05\n",
      "Epoch 638/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6350e-05 - val_loss: 2.6981e-05\n",
      "Epoch 639/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8114e-05 - val_loss: 2.7130e-05\n",
      "Epoch 640/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.6864e-05 - val_loss: 2.7318e-05\n",
      "Epoch 641/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7026e-05 - val_loss: 2.7557e-05\n",
      "Epoch 642/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1305e-05 - val_loss: 2.8084e-05\n",
      "Epoch 643/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9751e-05 - val_loss: 2.8252e-05\n",
      "Epoch 644/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4592e-05 - val_loss: 2.8223e-05\n",
      "Epoch 645/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4853e-05 - val_loss: 2.8202e-05\n",
      "Epoch 646/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9936e-05 - val_loss: 2.8331e-05\n",
      "Epoch 647/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9128e-05 - val_loss: 2.8412e-05\n",
      "Epoch 648/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6627e-05 - val_loss: 2.8459e-05\n",
      "Epoch 649/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0307e-05 - val_loss: 2.8637e-05\n",
      "Epoch 650/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8989e-05 - val_loss: 2.8963e-05\n",
      "Epoch 651/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.1245e-05 - val_loss: 2.9231e-05\n",
      "Epoch 652/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.8160e-05 - val_loss: 2.9706e-05\n",
      "Epoch 653/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7443e-05 - val_loss: 3.0002e-05\n",
      "Epoch 654/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0140e-05 - val_loss: 3.0017e-05\n",
      "Epoch 655/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7618e-05 - val_loss: 2.9810e-05\n",
      "Epoch 656/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7290e-05 - val_loss: 2.9354e-05\n",
      "Epoch 657/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6538e-05 - val_loss: 2.8546e-05\n",
      "Epoch 658/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8473e-05 - val_loss: 2.7856e-05\n",
      "Epoch 659/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7780e-05 - val_loss: 2.7252e-05\n",
      "Epoch 660/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7323e-05 - val_loss: 2.7099e-05\n",
      "Epoch 661/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7965e-05 - val_loss: 2.7088e-05\n",
      "Epoch 662/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7386e-05 - val_loss: 2.7088e-05\n",
      "Epoch 663/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2308e-05 - val_loss: 2.7134e-05\n",
      "Epoch 664/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1708e-05 - val_loss: 2.7236e-05\n",
      "Epoch 665/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7945e-05 - val_loss: 2.7400e-05\n",
      "Epoch 666/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9393e-05 - val_loss: 2.7789e-05\n",
      "Epoch 667/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5422e-05 - val_loss: 2.8399e-05\n",
      "Epoch 668/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8702e-05 - val_loss: 2.9124e-05\n",
      "Epoch 669/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7699e-05 - val_loss: 2.9603e-05\n",
      "Epoch 670/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8250e-05 - val_loss: 2.9605e-05\n",
      "Epoch 671/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.2227e-05 - val_loss: 2.9376e-05\n",
      "Epoch 672/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6458e-05 - val_loss: 2.8868e-05\n",
      "Epoch 673/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1999e-05 - val_loss: 2.8525e-05\n",
      "Epoch 674/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7538e-05 - val_loss: 2.8449e-05\n",
      "Epoch 675/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8959e-05 - val_loss: 2.8258e-05\n",
      "Epoch 676/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.8759e-05 - val_loss: 2.8016e-05\n",
      "Epoch 677/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2226e-05 - val_loss: 2.7845e-05\n",
      "Epoch 678/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0613e-05 - val_loss: 2.7804e-05\n",
      "Epoch 679/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6975e-05 - val_loss: 2.7871e-05\n",
      "Epoch 680/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1119e-05 - val_loss: 2.8337e-05\n",
      "Epoch 681/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5125e-05 - val_loss: 2.8797e-05\n",
      "Epoch 682/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0820e-05 - val_loss: 2.9184e-05\n",
      "Epoch 683/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8048e-05 - val_loss: 2.9279e-05\n",
      "Epoch 684/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6932e-05 - val_loss: 2.9315e-05\n",
      "Epoch 685/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8825e-05 - val_loss: 2.8960e-05\n",
      "Epoch 686/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0272e-05 - val_loss: 2.8611e-05\n",
      "Epoch 687/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.4506e-05 - val_loss: 2.8569e-05\n",
      "Epoch 688/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.7079e-05 - val_loss: 2.8541e-05\n",
      "Epoch 689/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7132e-05 - val_loss: 2.8472e-05\n",
      "Epoch 690/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.6637e-05 - val_loss: 2.8327e-05\n",
      "Epoch 691/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4667e-05 - val_loss: 2.8155e-05\n",
      "Epoch 692/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6416e-05 - val_loss: 2.7993e-05\n",
      "Epoch 693/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7821e-05 - val_loss: 2.7741e-05\n",
      "Epoch 694/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3350e-05 - val_loss: 2.7777e-05\n",
      "Epoch 695/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5714e-05 - val_loss: 2.7939e-05\n",
      "Epoch 696/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6475e-05 - val_loss: 2.7686e-05\n",
      "Epoch 697/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2199e-05 - val_loss: 2.7517e-05\n",
      "Epoch 698/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5346e-05 - val_loss: 2.7124e-05\n",
      "Epoch 699/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0259e-05 - val_loss: 2.7043e-05\n",
      "Epoch 700/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5888e-05 - val_loss: 2.7011e-05\n",
      "Epoch 701/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5990e-05 - val_loss: 2.7030e-05\n",
      "Epoch 702/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5926e-05 - val_loss: 2.7199e-05\n",
      "Epoch 703/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6169e-05 - val_loss: 2.7305e-05\n",
      "Epoch 704/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7568e-05 - val_loss: 2.7483e-05\n",
      "Epoch 705/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6180e-05 - val_loss: 2.7617e-05\n",
      "\n",
      "Loading Model: '02-07-2021--08--24-E2E_LSTM_ValSet_0.1-ALPHA0.0001-BETA_SD17-705Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 0.0004915344642354092\n",
      "Model: \"functional_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_102 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_103 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 7.1776e-04 - val_loss: 6.0258e-04\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 6.1837e-04 - val_loss: 5.0835e-04\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.2464e-04 - val_loss: 4.3637e-04\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.5896e-04 - val_loss: 3.6858e-04\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.8857e-04 - val_loss: 3.0640e-04\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.3168e-04 - val_loss: 2.5060e-04\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.7622e-04 - val_loss: 2.0024e-04\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1878e-04 - val_loss: 1.5492e-04\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.8800e-04 - val_loss: 1.1683e-04\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.4169e-04 - val_loss: 8.7470e-05\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.2531e-04 - val_loss: 7.0445e-05\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.2371e-04 - val_loss: 6.7688e-05\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1727e-04 - val_loss: 7.5581e-05\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3173e-04 - val_loss: 8.5500e-05\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5935e-04 - val_loss: 8.9380e-05\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6112e-04 - val_loss: 8.5820e-05\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6265e-04 - val_loss: 7.7387e-05\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5823e-04 - val_loss: 6.8226e-05\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.2974e-04 - val_loss: 6.1311e-05\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.2751e-04 - val_loss: 5.7710e-05\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0732e-04 - val_loss: 5.7500e-05\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1572e-04 - val_loss: 6.0085e-05\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0871e-04 - val_loss: 6.4411e-05\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1151e-04 - val_loss: 6.9370e-05\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1057e-04 - val_loss: 7.4192e-05\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0898e-04 - val_loss: 7.8291e-05\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1451e-04 - val_loss: 8.1241e-05\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1462e-04 - val_loss: 8.2867e-05\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2547e-04 - val_loss: 8.3255e-05\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0955e-04 - val_loss: 8.2335e-05\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1288e-04 - val_loss: 8.0236e-05\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0398e-04 - val_loss: 7.7196e-05\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1788e-04 - val_loss: 7.3580e-05\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0820e-04 - val_loss: 6.9654e-05\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0064e-04 - val_loss: 6.5657e-05\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.9237e-05 - val_loss: 6.1885e-05\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1715e-04 - val_loss: 5.8528e-05\n",
      "Epoch 38/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step - loss: 9.6329e-05 - val_loss: 5.5683e-05\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 9.7951e-05 - val_loss: 5.3468e-05\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 9.6010e-05 - val_loss: 5.1826e-05\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0279e-04 - val_loss: 5.0677e-05\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0486e-04 - val_loss: 4.9968e-05\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.0207e-04 - val_loss: 4.9565e-05\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.0114e-04 - val_loss: 4.9313e-05\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 9.6396e-05 - val_loss: 4.9221e-05\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4508e-05 - val_loss: 4.9240e-05\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0311e-04 - val_loss: 4.9443e-05\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0029e-04 - val_loss: 4.9815e-05\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0534e-04 - val_loss: 5.0445e-05\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3183e-05 - val_loss: 5.1147e-05\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.8180e-05 - val_loss: 5.1998e-05\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3017e-05 - val_loss: 5.2845e-05\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4576e-05 - val_loss: 5.3537e-05\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.8689e-05 - val_loss: 5.4037e-05\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.8998e-05 - val_loss: 5.4171e-05\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1222e-05 - val_loss: 5.3967e-05\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4526e-05 - val_loss: 5.3518e-05\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4260e-05 - val_loss: 5.2854e-05\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7641e-05 - val_loss: 5.2063e-05\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8626e-05 - val_loss: 5.1188e-05\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.1363e-05 - val_loss: 5.0133e-05\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 8.9552e-05 - val_loss: 4.9067e-05\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 8.5594e-05 - val_loss: 4.8137e-05\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 8.7842e-05 - val_loss: 4.7435e-05\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 8.4986e-05 - val_loss: 4.6891e-05\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 8.7164e-05 - val_loss: 4.6417e-05\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 8.6031e-05 - val_loss: 4.6161e-05\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 8.0334e-05 - val_loss: 4.6157e-05\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.2930e-05 - val_loss: 4.6285e-05\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2369e-05 - val_loss: 4.6614e-05\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.8093e-05 - val_loss: 4.7063e-05\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.5416e-05 - val_loss: 4.7471e-05\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0569e-05 - val_loss: 4.7854e-05\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.7001e-05 - val_loss: 4.8181e-05\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.8880e-05 - val_loss: 4.8275e-05\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.3764e-05 - val_loss: 4.8207e-05\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.0009e-05 - val_loss: 4.7934e-05\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2202e-05 - val_loss: 4.7776e-05\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.7896e-05 - val_loss: 4.7479e-05\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.4857e-05 - val_loss: 4.7246e-05\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.0189e-05 - val_loss: 4.7014e-05\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.8870e-05 - val_loss: 4.6784e-05\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.8498e-05 - val_loss: 4.6614e-05\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 7.2266e-05 - val_loss: 4.6319e-05\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 8.1109e-05 - val_loss: 4.6070e-05\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 8.2170e-05 - val_loss: 4.5988e-05\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.1637e-05 - val_loss: 4.6092e-05\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.3647e-05 - val_loss: 4.6305e-05\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.4542e-05 - val_loss: 4.6617e-05\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.4317e-05 - val_loss: 4.7032e-05\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.5065e-05 - val_loss: 4.7494e-05\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.2885e-05 - val_loss: 4.8093e-05\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 7.6816e-05 - val_loss: 4.8697e-05\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 7.5532e-05 - val_loss: 4.8846e-05\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 7.6323e-05 - val_loss: 4.8678e-05\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.7938e-05 - val_loss: 4.8397e-05\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.5054e-05 - val_loss: 4.7832e-05\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.3391e-05 - val_loss: 4.7299e-05\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.6738e-05 - val_loss: 4.6873e-05\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.7699e-05 - val_loss: 4.6718e-05\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.5242e-05 - val_loss: 4.6943e-05\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 7.9408e-05 - val_loss: 4.7362e-05\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.3618e-05 - val_loss: 4.7981e-05\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.4024e-05 - val_loss: 4.8702e-05\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.5611e-05 - val_loss: 4.9266e-05\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.0592e-05 - val_loss: 4.9430e-05\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.4747e-05 - val_loss: 4.9007e-05\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.8125e-05 - val_loss: 4.8394e-05\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.1352e-05 - val_loss: 4.7691e-05\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.1317e-05 - val_loss: 4.6914e-05\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.3441e-05 - val_loss: 4.6050e-05\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 7.3904e-05 - val_loss: 4.5289e-05\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.7060e-05 - val_loss: 4.4513e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 7.1277e-05 - val_loss: 4.4112e-05\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 7.0642e-05 - val_loss: 4.3878e-05\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 6.6271e-05 - val_loss: 4.3873e-05\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.5127e-05 - val_loss: 4.4134e-05\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.7861e-05 - val_loss: 4.4546e-05\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.6859e-05 - val_loss: 4.4956e-05\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.7915e-05 - val_loss: 4.5312e-05\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.7961e-05 - val_loss: 4.5664e-05\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.1614e-05 - val_loss: 4.5856e-05\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.1612e-05 - val_loss: 4.5888e-05\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.0398e-05 - val_loss: 4.5789e-05\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.5513e-05 - val_loss: 4.5350e-05\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.0961e-05 - val_loss: 4.4639e-05\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.3559e-05 - val_loss: 4.4097e-05\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 7.3118e-05 - val_loss: 4.3848e-05\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 7.3765e-05 - val_loss: 4.3787e-05\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.6918e-05 - val_loss: 4.4154e-05\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.1207e-05 - val_loss: 4.4624e-05\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.7362e-05 - val_loss: 4.5202e-05\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 7.2615e-05 - val_loss: 4.5765e-05\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 7.2609e-05 - val_loss: 4.6427e-05\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.3109e-05 - val_loss: 4.6967e-05\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.5721e-05 - val_loss: 4.7005e-05\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.8142e-05 - val_loss: 4.6740e-05\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.9768e-05 - val_loss: 4.6240e-05\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.4870e-05 - val_loss: 4.5791e-05\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.6128e-05 - val_loss: 4.5516e-05\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2671e-05 - val_loss: 4.5427e-05\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.4127e-05 - val_loss: 4.5614e-05\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.2800e-05 - val_loss: 4.5923e-05\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.3047e-05 - val_loss: 4.6140e-05\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.2499e-05 - val_loss: 4.6016e-05\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.4103e-05 - val_loss: 4.5757e-05\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.4112e-05 - val_loss: 4.5388e-05\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.3228e-05 - val_loss: 4.4980e-05\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.8672e-05 - val_loss: 4.4942e-05\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.6342e-05 - val_loss: 4.4825e-05\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.4977e-05 - val_loss: 4.4606e-05\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.6637e-05 - val_loss: 4.4221e-05\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.7660e-05 - val_loss: 4.3829e-05\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 6.6811e-05 - val_loss: 4.3631e-05\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.0902e-05 - val_loss: 4.3452e-05\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.1292e-05 - val_loss: 4.3558e-05\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.9116e-05 - val_loss: 4.3555e-05\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.5060e-05 - val_loss: 4.3365e-05\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.8461e-05 - val_loss: 4.3218e-05\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.2433e-05 - val_loss: 4.3156e-05\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.3661e-05 - val_loss: 4.3175e-05\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 6.4215e-05 - val_loss: 4.3031e-05\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.4787e-05 - val_loss: 4.3265e-05\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.7376e-05 - val_loss: 4.3724e-05\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.0833e-05 - val_loss: 4.4331e-05\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.0131e-05 - val_loss: 4.4833e-05\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.4818e-05 - val_loss: 4.5268e-05\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.3712e-05 - val_loss: 4.5259e-05\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.4701e-05 - val_loss: 4.5065e-05\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.4739e-05 - val_loss: 4.4929e-05\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.3720e-05 - val_loss: 4.4797e-05\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.0155e-05 - val_loss: 4.4866e-05\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.6822e-05 - val_loss: 4.4685e-05\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.4594e-05 - val_loss: 4.4692e-05\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.9686e-05 - val_loss: 4.4403e-05\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.6349e-05 - val_loss: 4.3746e-05\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.1874e-05 - val_loss: 4.2835e-05\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.8783e-05 - val_loss: 4.2282e-05\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.8937e-05 - val_loss: 4.2106e-05\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.6117e-05 - val_loss: 4.2227e-05\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.3008e-05 - val_loss: 4.2619e-05\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.1568e-05 - val_loss: 4.3304e-05\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5498e-05 - val_loss: 4.3644e-05\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.1828e-05 - val_loss: 4.3601e-05\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.1388e-05 - val_loss: 4.2900e-05\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.8882e-05 - val_loss: 4.2340e-05\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.8090e-05 - val_loss: 4.1829e-05\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 6.3016e-05 - val_loss: 4.1714e-05\n",
      "Epoch 189/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 6.6914e-05 - val_loss: 4.2061e-05\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2779e-05 - val_loss: 4.2771e-05\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2098e-05 - val_loss: 4.3646e-05\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.9086e-05 - val_loss: 4.3893e-05\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.4900e-05 - val_loss: 4.4198e-05\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.9516e-05 - val_loss: 4.3956e-05\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.4400e-05 - val_loss: 4.3545e-05\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8665e-05 - val_loss: 4.2962e-05\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.8721e-05 - val_loss: 4.2679e-05\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.2664e-05 - val_loss: 4.2853e-05\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.4011e-05 - val_loss: 4.3256e-05\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.2523e-05 - val_loss: 4.3302e-05\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.7949e-05 - val_loss: 4.2977e-05\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8675e-05 - val_loss: 4.2374e-05\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.7058e-05 - val_loss: 4.1697e-05\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.8561e-05 - val_loss: 4.1366e-05\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.3706e-05 - val_loss: 4.1450e-05\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.6608e-05 - val_loss: 4.1374e-05\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.4081e-05 - val_loss: 4.1435e-05\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.0366e-05 - val_loss: 4.1451e-05\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.0703e-05 - val_loss: 4.1476e-05\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.0868e-05 - val_loss: 4.1225e-05\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.1410e-05 - val_loss: 4.1482e-05\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.5838e-05 - val_loss: 4.1352e-05\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.5472e-05 - val_loss: 4.1447e-05\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6451e-05 - val_loss: 4.1627e-05\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.1331e-05 - val_loss: 4.1802e-05\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2318e-05 - val_loss: 4.2019e-05\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8328e-05 - val_loss: 4.2461e-05\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8192e-05 - val_loss: 4.2770e-05\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.2503e-05 - val_loss: 4.2875e-05\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.9633e-05 - val_loss: 4.2747e-05\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.4963e-05 - val_loss: 4.2529e-05\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8106e-05 - val_loss: 4.2279e-05\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.9695e-05 - val_loss: 4.2043e-05\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.0763e-05 - val_loss: 4.1820e-05\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.7202e-05 - val_loss: 4.1435e-05\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.7180e-05 - val_loss: 4.0787e-05\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.8909e-05 - val_loss: 4.0346e-05\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 5.7812e-05 - val_loss: 4.0084e-05\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.0667e-05 - val_loss: 4.0121e-05\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.8707e-05 - val_loss: 3.9939e-05\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.0361e-05 - val_loss: 4.0071e-05\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.7154e-05 - val_loss: 4.0481e-05\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.8906e-05 - val_loss: 4.0345e-05\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.3786e-05 - val_loss: 3.9837e-05\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.0653e-05 - val_loss: 3.9823e-05\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1351e-05 - val_loss: 4.0010e-05\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.9644e-05 - val_loss: 4.0343e-05\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1689e-05 - val_loss: 4.0506e-05\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8800e-05 - val_loss: 4.0625e-05\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.0812e-05 - val_loss: 4.0603e-05\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.6365e-05 - val_loss: 4.0228e-05\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.2404e-05 - val_loss: 3.9968e-05\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.7183e-05 - val_loss: 3.9728e-05\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.6569e-05 - val_loss: 3.9580e-05\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.0203e-05 - val_loss: 3.9782e-05\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3730e-05 - val_loss: 3.9909e-05\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.8948e-05 - val_loss: 4.0057e-05\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.0457e-05 - val_loss: 3.9935e-05\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.3980e-05 - val_loss: 3.9977e-05\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.9525e-05 - val_loss: 4.0323e-05\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.9883e-05 - val_loss: 4.0725e-05\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.6274e-05 - val_loss: 4.1417e-05\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.1886e-05 - val_loss: 4.2420e-05\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8925e-05 - val_loss: 4.2581e-05\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.9496e-05 - val_loss: 4.2060e-05\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6221e-05 - val_loss: 4.0993e-05\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5327e-05 - val_loss: 4.0228e-05\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.5647e-05 - val_loss: 4.0144e-05\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5909e-05 - val_loss: 4.0548e-05\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.3539e-05 - val_loss: 4.1341e-05\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7143e-05 - val_loss: 4.1836e-05\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4334e-05 - val_loss: 4.1365e-05\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.0155e-05 - val_loss: 4.0602e-05\n",
      "Epoch 264/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step - loss: 5.4045e-05 - val_loss: 4.0005e-05\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.7947e-05 - val_loss: 3.9871e-05\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6570e-05 - val_loss: 3.9970e-05\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7332e-05 - val_loss: 4.0438e-05\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.6101e-05 - val_loss: 4.0708e-05\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.5982e-05 - val_loss: 3.9729e-05\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.2650e-05 - val_loss: 3.8712e-05\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.4929e-05 - val_loss: 3.8362e-05\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1150e-05 - val_loss: 3.8911e-05\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3682e-05 - val_loss: 3.9757e-05\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8199e-05 - val_loss: 4.0168e-05\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.1369e-05 - val_loss: 3.9740e-05\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.0189e-05 - val_loss: 3.8775e-05\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7509e-05 - val_loss: 3.8388e-05\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.0523e-05 - val_loss: 3.8767e-05\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.4464e-05 - val_loss: 3.8983e-05\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.0740e-05 - val_loss: 3.8866e-05\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6889e-05 - val_loss: 3.8660e-05\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8114e-05 - val_loss: 3.8606e-05\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3151e-05 - val_loss: 3.8586e-05\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3956e-05 - val_loss: 3.8782e-05\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.1478e-05 - val_loss: 3.8975e-05\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.2956e-05 - val_loss: 3.9167e-05\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.4878e-05 - val_loss: 3.9719e-05\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8346e-05 - val_loss: 4.0178e-05\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4929e-05 - val_loss: 4.0342e-05\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4286e-05 - val_loss: 4.0338e-05\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.9051e-05 - val_loss: 4.0329e-05\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9840e-05 - val_loss: 4.0002e-05\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.1488e-05 - val_loss: 3.9863e-05\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.1762e-05 - val_loss: 4.0142e-05\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7326e-05 - val_loss: 4.0445e-05\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.0150e-05 - val_loss: 4.0920e-05\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.1844e-05 - val_loss: 4.0620e-05\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8631e-05 - val_loss: 3.9712e-05\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.8395e-05 - val_loss: 3.9260e-05\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 5.5931e-05 - val_loss: 3.9388e-05\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.8145e-05 - val_loss: 3.9666e-05\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8918e-05 - val_loss: 3.8796e-05\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.3128e-05 - val_loss: 3.7755e-05\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 5.2353e-05 - val_loss: 3.7290e-05\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.6383e-05 - val_loss: 3.7397e-05\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4634e-05 - val_loss: 3.8719e-05\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.3788e-05 - val_loss: 3.9938e-05\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5885e-05 - val_loss: 4.0347e-05\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3176e-05 - val_loss: 4.0049e-05\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.1377e-05 - val_loss: 3.9184e-05\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9925e-05 - val_loss: 3.8837e-05\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.7387e-05 - val_loss: 3.9080e-05\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.8005e-05 - val_loss: 3.9835e-05\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.0833e-05 - val_loss: 4.0826e-05\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3259e-05 - val_loss: 4.1492e-05\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.4605e-05 - val_loss: 4.1081e-05\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9813e-05 - val_loss: 4.0110e-05\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.3991e-05 - val_loss: 3.9504e-05\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3433e-05 - val_loss: 3.9227e-05\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3640e-05 - val_loss: 3.9606e-05\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.4593e-05 - val_loss: 4.0272e-05\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.1337e-05 - val_loss: 4.0637e-05\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5574e-05 - val_loss: 4.0499e-05\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.5647e-05 - val_loss: 3.9945e-05\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.4889e-05 - val_loss: 3.9023e-05\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.2022e-05 - val_loss: 3.8274e-05\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.5971e-05 - val_loss: 3.8148e-05\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.1282e-05 - val_loss: 3.8886e-05\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.1581e-05 - val_loss: 3.9238e-05\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.2582e-05 - val_loss: 3.8212e-05\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.3765e-05 - val_loss: 3.7171e-05\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.1049e-05 - val_loss: 3.6940e-05\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.1912e-05 - val_loss: 3.7295e-05\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.1300e-05 - val_loss: 3.8279e-05\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3189e-05 - val_loss: 3.9293e-05\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.6394e-05 - val_loss: 3.8854e-05\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.5626e-05 - val_loss: 3.8287e-05\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.6384e-05 - val_loss: 3.7860e-05\n",
      "Epoch 339/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 5.6284e-05 - val_loss: 3.8395e-05\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.2906e-05 - val_loss: 3.9227e-05\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4121e-05 - val_loss: 4.0186e-05\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.5688e-05 - val_loss: 4.0074e-05\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.7927e-05 - val_loss: 3.9549e-05\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9435e-05 - val_loss: 3.9082e-05\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.6396e-05 - val_loss: 3.8978e-05\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.5454e-05 - val_loss: 3.9430e-05\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.7520e-05 - val_loss: 4.0626e-05\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.4556e-05 - val_loss: 4.1830e-05\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.1843e-05 - val_loss: 4.1822e-05\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6467e-05 - val_loss: 4.0852e-05\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.0642e-05 - val_loss: 3.9692e-05\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5090e-05 - val_loss: 3.9182e-05\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0090e-05 - val_loss: 3.8981e-05\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.1857e-05 - val_loss: 3.9471e-05\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.0716e-05 - val_loss: 4.0655e-05\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0103e-05 - val_loss: 4.0430e-05\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.3004e-05 - val_loss: 3.9670e-05\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.2613e-05 - val_loss: 3.8514e-05\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.8919e-05 - val_loss: 3.7992e-05\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.2873e-05 - val_loss: 3.8240e-05\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.8987e-05 - val_loss: 3.8997e-05\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.5372e-05 - val_loss: 4.0323e-05\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.9517e-05 - val_loss: 4.0826e-05\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.9840e-05 - val_loss: 4.0140e-05\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5202e-05 - val_loss: 3.9384e-05\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.3115e-05 - val_loss: 3.9148e-05\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.2164e-05 - val_loss: 3.9650e-05\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 4.7307e-05 - val_loss: 4.0363e-05\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.7644e-05 - val_loss: 4.0987e-05\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.1739e-05 - val_loss: 4.1228e-05\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.9786e-05 - val_loss: 4.0222e-05\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.3111e-05 - val_loss: 3.9374e-05\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.8895e-05 - val_loss: 3.9041e-05\n",
      "Epoch 374/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5789e-05 - val_loss: 3.9355e-05\n",
      "Epoch 375/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3120e-05 - val_loss: 3.9633e-05\n",
      "Epoch 376/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 4.8829e-05 - val_loss: 3.9702e-05\n",
      "Epoch 377/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.2145e-05 - val_loss: 3.9484e-05\n",
      "Epoch 378/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.6881e-05 - val_loss: 3.9257e-05\n",
      "Epoch 379/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.2924e-05 - val_loss: 3.8942e-05\n",
      "Epoch 380/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.2091e-05 - val_loss: 3.8549e-05\n",
      "Epoch 381/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5220e-05 - val_loss: 3.8194e-05\n",
      "Epoch 382/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.3335e-05 - val_loss: 3.7984e-05\n",
      "Epoch 383/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.7702e-05 - val_loss: 3.7791e-05\n",
      "Epoch 384/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.2640e-05 - val_loss: 3.7599e-05\n",
      "Epoch 385/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.8954e-05 - val_loss: 3.7332e-05\n",
      "Epoch 386/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9463e-05 - val_loss: 3.7232e-05\n",
      "Epoch 387/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.5676e-05 - val_loss: 3.7487e-05\n",
      "Epoch 388/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 5.2817e-05 - val_loss: 3.7891e-05\n",
      "Epoch 389/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.4382e-05 - val_loss: 3.8544e-05\n",
      "Epoch 390/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.1792e-05 - val_loss: 3.9206e-05\n",
      "Epoch 391/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6319e-05 - val_loss: 3.9387e-05\n",
      "Epoch 392/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9666e-05 - val_loss: 3.9356e-05\n",
      "Epoch 393/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.7470e-05 - val_loss: 3.9833e-05\n",
      "Epoch 394/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.5588e-05 - val_loss: 4.0464e-05\n",
      "Epoch 395/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.2740e-05 - val_loss: 4.1116e-05\n",
      "Epoch 396/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.2678e-05 - val_loss: 4.1820e-05\n",
      "Epoch 397/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.9140e-05 - val_loss: 4.1467e-05\n",
      "Epoch 398/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0782e-05 - val_loss: 4.0578e-05\n",
      "Epoch 399/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9333e-05 - val_loss: 3.9690e-05\n",
      "Epoch 400/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.1264e-05 - val_loss: 3.9160e-05\n",
      "Epoch 401/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.7035e-05 - val_loss: 3.8673e-05\n",
      "Epoch 402/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.8682e-05 - val_loss: 3.8630e-05\n",
      "\n",
      "Loading Model: '02-07-2021--08--39-E2E_LSTM_ValSet_0.1-ALPHA0.001-BETA_SD17-402Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.01308687262805687\n",
      "Model: \"functional_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_106 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_107 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0014 - val_loss: 7.5631e-04\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 8.2655e-04 - val_loss: 3.3064e-04\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 5.4805e-04 - val_loss: 1.9409e-04\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3096e-04 - val_loss: 3.6647e-04\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.1959e-04 - val_loss: 5.3639e-04\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 5.5349e-04\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 4.5402e-04\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6951e-04 - val_loss: 3.2183e-04\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.0569e-04 - val_loss: 2.1633e-04\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 6.0623e-04 - val_loss: 1.6208e-04\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.3264e-04 - val_loss: 1.5796e-04\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.6855e-04 - val_loss: 1.9228e-04\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 4.1214e-04 - val_loss: 2.4885e-04\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.5268e-04 - val_loss: 3.1245e-04\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5457e-04 - val_loss: 3.7216e-04\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.1766e-04 - val_loss: 4.2173e-04\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.0514e-04 - val_loss: 4.5573e-04\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7838e-04 - val_loss: 4.7199e-04\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.5187e-04 - val_loss: 4.7167e-04\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4559e-04 - val_loss: 4.5645e-04\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4966e-04 - val_loss: 4.2859e-04\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.3597e-04 - val_loss: 3.9128e-04\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.2870e-04 - val_loss: 3.4860e-04\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4158e-04 - val_loss: 3.0366e-04\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.3472e-04 - val_loss: 2.5931e-04\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0047e-04 - val_loss: 2.1920e-04\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0942e-04 - val_loss: 1.8565e-04\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2785e-04 - val_loss: 1.5994e-04\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.7393e-04 - val_loss: 1.4177e-04\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.7425e-04 - val_loss: 1.3026e-04\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.3297e-04 - val_loss: 1.2313e-04\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.8211e-04 - val_loss: 1.1910e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.9037e-04 - val_loss: 1.1689e-04\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 3.9389e-04 - val_loss: 1.1554e-04\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 4.1332e-04 - val_loss: 1.1501e-04\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.3734e-04 - val_loss: 1.1618e-04\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2443e-04 - val_loss: 1.2028e-04\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8368e-04 - val_loss: 1.2692e-04\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6762e-04 - val_loss: 1.3655e-04\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7111e-04 - val_loss: 1.4725e-04\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7078e-04 - val_loss: 1.5808e-04\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7661e-04 - val_loss: 1.6643e-04\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7458e-04 - val_loss: 1.7255e-04\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6925e-04 - val_loss: 1.7443e-04\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6258e-04 - val_loss: 1.7360e-04\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.6882e-04 - val_loss: 1.6993e-04\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4939e-04 - val_loss: 1.6359e-04\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6663e-04 - val_loss: 1.5728e-04\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3921e-04 - val_loss: 1.4911e-04\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4232e-04 - val_loss: 1.3993e-04\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5107e-04 - val_loss: 1.3108e-04\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5073e-04 - val_loss: 1.2350e-04\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1865e-04 - val_loss: 1.1750e-04\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.2121e-04 - val_loss: 1.1254e-04\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.0292e-04 - val_loss: 1.0800e-04\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.2739e-04 - val_loss: 1.0493e-04\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 3.1845e-04 - val_loss: 1.0361e-04\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0592e-04 - val_loss: 1.0459e-04\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0979e-04 - val_loss: 1.0710e-04\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1596e-04 - val_loss: 1.0949e-04\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0393e-04 - val_loss: 1.1275e-04\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0219e-04 - val_loss: 1.1777e-04\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0933e-04 - val_loss: 1.2305e-04\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2633e-04 - val_loss: 1.2817e-04\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7995e-04 - val_loss: 1.3154e-04\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0804e-04 - val_loss: 1.3175e-04\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.2151e-04 - val_loss: 1.2865e-04\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8899e-04 - val_loss: 1.2464e-04\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.8310e-04 - val_loss: 1.1895e-04\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.8906e-04 - val_loss: 1.1255e-04\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0050e-04 - val_loss: 1.0660e-04\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.9928e-04 - val_loss: 1.0297e-04\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.6702e-04 - val_loss: 9.9899e-05\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 2.9090e-04 - val_loss: 9.8483e-05\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.8453e-04 - val_loss: 9.8303e-05\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.7394e-04 - val_loss: 9.9198e-05\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7401e-04 - val_loss: 1.0218e-04\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7431e-04 - val_loss: 1.0516e-04\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.8773e-04 - val_loss: 1.0767e-04\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7369e-04 - val_loss: 1.0999e-04\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6179e-04 - val_loss: 1.1203e-04\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9239e-04 - val_loss: 1.1267e-04\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6431e-04 - val_loss: 1.1218e-04\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9123e-04 - val_loss: 1.1141e-04\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8066e-04 - val_loss: 1.0896e-04\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5608e-04 - val_loss: 1.0769e-04\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7714e-04 - val_loss: 1.0798e-04\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7265e-04 - val_loss: 1.0606e-04\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.7040e-04 - val_loss: 1.0265e-04\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4026e-04 - val_loss: 1.0052e-04\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.5485e-04 - val_loss: 9.7641e-05\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.4894e-04 - val_loss: 9.5744e-05\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.2693e-04 - val_loss: 9.4093e-05\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.6233e-04 - val_loss: 9.3302e-05\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2852e-04 - val_loss: 9.7316e-05\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.6162e-04 - val_loss: 1.0167e-04\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.5509e-04 - val_loss: 1.0728e-04\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4656e-04 - val_loss: 1.1191e-04\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4886e-04 - val_loss: 1.0987e-04\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4991e-04 - val_loss: 1.0439e-04\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5153e-04 - val_loss: 9.6134e-05\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.5731e-04 - val_loss: 9.1046e-05\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.3670e-04 - val_loss: 8.8357e-05\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.3498e-04 - val_loss: 8.8268e-05\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4042e-04 - val_loss: 8.9690e-05\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4918e-04 - val_loss: 8.9869e-05\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3336e-04 - val_loss: 9.0505e-05\n",
      "Epoch 114/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3278e-04 - val_loss: 9.2223e-05\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2888e-04 - val_loss: 9.5331e-05\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2447e-04 - val_loss: 9.6411e-05\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3267e-04 - val_loss: 9.5574e-05\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4185e-04 - val_loss: 9.3430e-05\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2798e-04 - val_loss: 9.2394e-05\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2514e-04 - val_loss: 9.0734e-05\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1803e-04 - val_loss: 9.0607e-05\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2178e-04 - val_loss: 9.3259e-05\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3078e-04 - val_loss: 9.5496e-05\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.3050e-04 - val_loss: 9.6560e-05\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3521e-04 - val_loss: 9.0434e-05\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.3121e-04 - val_loss: 8.1086e-05\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2383e-04 - val_loss: 7.7214e-05\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3197e-04 - val_loss: 7.7646e-05\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1414e-04 - val_loss: 8.1117e-05\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0968e-04 - val_loss: 9.1422e-05\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.2352e-04 - val_loss: 9.6979e-05\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2471e-04 - val_loss: 9.3814e-05\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3597e-04 - val_loss: 8.6333e-05\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.2895e-04 - val_loss: 8.2950e-05\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.2905e-04 - val_loss: 8.0989e-05\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.1950e-04 - val_loss: 7.8381e-05\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1295e-04 - val_loss: 8.0536e-05\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0843e-04 - val_loss: 8.3282e-05\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9628e-04 - val_loss: 8.5762e-05\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0511e-04 - val_loss: 8.6853e-05\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8572e-04 - val_loss: 8.4831e-05\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0512e-04 - val_loss: 8.6648e-05\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0374e-04 - val_loss: 9.0187e-05\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9286e-04 - val_loss: 8.8057e-05\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8892e-04 - val_loss: 7.7637e-05\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9598e-04 - val_loss: 7.3049e-05\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0664e-04 - val_loss: 7.5690e-05\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9950e-04 - val_loss: 8.6312e-05\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0160e-04 - val_loss: 1.0457e-04\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1050e-04 - val_loss: 1.0245e-04\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9829e-04 - val_loss: 8.6580e-05\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0528e-04 - val_loss: 7.2440e-05\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0687e-04 - val_loss: 6.7330e-05\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0971e-04 - val_loss: 7.1004e-05\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9640e-04 - val_loss: 8.5450e-05\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0977e-04 - val_loss: 1.0218e-04\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0707e-04 - val_loss: 1.0186e-04\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9803e-04 - val_loss: 8.5501e-05\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9739e-04 - val_loss: 7.0593e-05\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9965e-04 - val_loss: 6.4769e-05\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9862e-04 - val_loss: 6.6204e-05\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0500e-04 - val_loss: 7.0258e-05\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9597e-04 - val_loss: 8.0436e-05\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.8564e-04 - val_loss: 9.1416e-05\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8438e-04 - val_loss: 9.5161e-05\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9166e-04 - val_loss: 8.8382e-05\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0058e-04 - val_loss: 7.7729e-05\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9585e-04 - val_loss: 6.9676e-05\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.9834e-04 - val_loss: 6.7467e-05\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9595e-04 - val_loss: 7.1181e-05\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9211e-04 - val_loss: 8.0893e-05\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.7655e-04 - val_loss: 9.1345e-05\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9066e-04 - val_loss: 9.1748e-05\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9057e-04 - val_loss: 8.5375e-05\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7871e-04 - val_loss: 7.5222e-05\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9908e-04 - val_loss: 6.8360e-05\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7875e-04 - val_loss: 6.4973e-05\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.8106e-04 - val_loss: 6.7617e-05\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1417e-04 - val_loss: 7.4965e-05\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9818e-04 - val_loss: 8.5853e-05\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8297e-04 - val_loss: 9.0029e-05\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.8175e-04 - val_loss: 8.5829e-05\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8785e-04 - val_loss: 7.4071e-05\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8538e-04 - val_loss: 6.7485e-05\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7638e-04 - val_loss: 6.5294e-05\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.9277e-04 - val_loss: 6.7348e-05\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7478e-04 - val_loss: 7.4418e-05\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8865e-04 - val_loss: 8.2048e-05\n",
      "Epoch 189/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8863e-04 - val_loss: 8.3493e-05\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.8611e-04 - val_loss: 7.7786e-05\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8576e-04 - val_loss: 7.1862e-05\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8093e-04 - val_loss: 6.6621e-05\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8968e-04 - val_loss: 6.8687e-05\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8290e-04 - val_loss: 7.1364e-05\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9076e-04 - val_loss: 7.1941e-05\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7446e-04 - val_loss: 7.0810e-05\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7834e-04 - val_loss: 7.3561e-05\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0699e-04 - val_loss: 7.5403e-05\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.8444e-04 - val_loss: 7.6326e-05\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8165e-04 - val_loss: 7.2765e-05\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7356e-04 - val_loss: 7.0409e-05\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8635e-04 - val_loss: 7.0240e-05\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7387e-04 - val_loss: 7.4716e-05\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7452e-04 - val_loss: 8.0125e-05\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8380e-04 - val_loss: 8.2858e-05\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8660e-04 - val_loss: 7.2069e-05\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7131e-04 - val_loss: 6.3696e-05\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.7413e-04 - val_loss: 6.3026e-05\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7434e-04 - val_loss: 6.7825e-05\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8078e-04 - val_loss: 7.3624e-05\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.8255e-04 - val_loss: 8.3017e-05\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7173e-04 - val_loss: 7.9110e-05\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6476e-04 - val_loss: 7.1107e-05\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7199e-04 - val_loss: 6.5116e-05\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8298e-04 - val_loss: 6.4486e-05\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7561e-04 - val_loss: 6.7777e-05\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7580e-04 - val_loss: 7.4280e-05\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6977e-04 - val_loss: 7.8544e-05\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6612e-04 - val_loss: 7.4898e-05\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.7731e-04 - val_loss: 6.6537e-05\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.5645e-04 - val_loss: 6.3013e-05\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7232e-04 - val_loss: 6.4883e-05\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7259e-04 - val_loss: 7.0388e-05\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6795e-04 - val_loss: 7.5673e-05\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7639e-04 - val_loss: 7.5735e-05\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6479e-04 - val_loss: 6.8943e-05\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7273e-04 - val_loss: 6.4814e-05\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6805e-04 - val_loss: 6.5907e-05\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7058e-04 - val_loss: 6.9839e-05\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7333e-04 - val_loss: 6.8929e-05\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7404e-04 - val_loss: 6.8970e-05\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6865e-04 - val_loss: 7.2249e-05\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5235e-04 - val_loss: 7.2379e-05\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.6806e-04 - val_loss: 6.6395e-05\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6401e-04 - val_loss: 6.5195e-05\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7706e-04 - val_loss: 6.7302e-05\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4820e-04 - val_loss: 7.3129e-05\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7853e-04 - val_loss: 6.9942e-05\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6600e-04 - val_loss: 6.4703e-05\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7428e-04 - val_loss: 6.1720e-05\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6267e-04 - val_loss: 6.1282e-05\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8373e-04 - val_loss: 6.5954e-05\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6816e-04 - val_loss: 7.2623e-05\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6597e-04 - val_loss: 7.3638e-05\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7567e-04 - val_loss: 6.9835e-05\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.6287e-04 - val_loss: 6.4992e-05\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7835e-04 - val_loss: 6.4768e-05\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7315e-04 - val_loss: 6.3340e-05\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6308e-04 - val_loss: 6.6731e-05\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6651e-04 - val_loss: 7.4198e-05\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7763e-04 - val_loss: 7.2627e-05\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7070e-04 - val_loss: 6.9734e-05\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7216e-04 - val_loss: 7.0704e-05\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6884e-04 - val_loss: 6.7270e-05\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7408e-04 - val_loss: 6.8115e-05\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6136e-04 - val_loss: 6.6419e-05\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6580e-04 - val_loss: 6.5076e-05\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6246e-04 - val_loss: 6.8207e-05\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6362e-04 - val_loss: 7.1288e-05\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6632e-04 - val_loss: 7.4212e-05\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6403e-04 - val_loss: 7.3883e-05\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5852e-04 - val_loss: 6.8635e-05\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7359e-04 - val_loss: 6.4095e-05\n",
      "Epoch 264/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7166e-04 - val_loss: 6.5033e-05\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6427e-04 - val_loss: 7.0903e-05\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6925e-04 - val_loss: 7.3723e-05\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6235e-04 - val_loss: 7.1671e-05\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5832e-04 - val_loss: 6.8782e-05\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.6580e-04 - val_loss: 6.0911e-05\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5046e-04 - val_loss: 6.1212e-05\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6688e-04 - val_loss: 6.7445e-05\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7254e-04 - val_loss: 7.8102e-05\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6039e-04 - val_loss: 7.4708e-05\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7414e-04 - val_loss: 6.2949e-05\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.5728e-04 - val_loss: 5.8652e-05\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4844e-04 - val_loss: 6.1152e-05\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6842e-04 - val_loss: 6.8360e-05\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5422e-04 - val_loss: 7.9782e-05\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5550e-04 - val_loss: 7.0582e-05\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5265e-04 - val_loss: 6.1868e-05\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.6379e-04 - val_loss: 5.8150e-05\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.6651e-04 - val_loss: 6.2089e-05\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5269e-04 - val_loss: 7.2404e-05\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5939e-04 - val_loss: 7.7991e-05\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5417e-04 - val_loss: 7.0384e-05\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5157e-04 - val_loss: 6.0822e-05\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5216e-04 - val_loss: 6.2037e-05\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6141e-04 - val_loss: 6.8035e-05\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5788e-04 - val_loss: 7.3082e-05\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5950e-04 - val_loss: 7.3192e-05\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6215e-04 - val_loss: 6.7238e-05\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5495e-04 - val_loss: 6.0327e-05\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6132e-04 - val_loss: 6.0661e-05\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7626e-04 - val_loss: 6.5707e-05\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6076e-04 - val_loss: 7.4025e-05\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6714e-04 - val_loss: 7.2807e-05\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5356e-04 - val_loss: 6.7072e-05\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7559e-04 - val_loss: 5.9982e-05\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6553e-04 - val_loss: 6.3065e-05\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5990e-04 - val_loss: 7.3315e-05\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5180e-04 - val_loss: 8.3598e-05\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7009e-04 - val_loss: 6.7340e-05\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.5094e-04 - val_loss: 5.4611e-05\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.5394e-04 - val_loss: 5.2794e-05\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6108e-04 - val_loss: 5.8756e-05\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5385e-04 - val_loss: 7.6801e-05\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5490e-04 - val_loss: 8.1693e-05\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5872e-04 - val_loss: 6.9348e-05\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4145e-04 - val_loss: 6.2334e-05\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5259e-04 - val_loss: 5.7891e-05\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4988e-04 - val_loss: 6.0009e-05\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4221e-04 - val_loss: 6.6042e-05\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4644e-04 - val_loss: 7.2974e-05\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5452e-04 - val_loss: 7.2084e-05\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5094e-04 - val_loss: 6.4964e-05\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5427e-04 - val_loss: 6.2406e-05\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3956e-04 - val_loss: 6.4191e-05\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5102e-04 - val_loss: 6.6736e-05\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4796e-04 - val_loss: 6.5893e-05\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5473e-04 - val_loss: 6.4667e-05\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6030e-04 - val_loss: 6.3303e-05\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5108e-04 - val_loss: 6.5565e-05\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5855e-04 - val_loss: 6.7596e-05\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6597e-04 - val_loss: 6.9566e-05\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4161e-04 - val_loss: 6.9884e-05\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5153e-04 - val_loss: 6.5955e-05\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6150e-04 - val_loss: 6.0838e-05\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4187e-04 - val_loss: 6.2878e-05\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5611e-04 - val_loss: 6.6328e-05\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4323e-04 - val_loss: 6.2072e-05\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5123e-04 - val_loss: 5.9445e-05\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4462e-04 - val_loss: 6.2104e-05\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4336e-04 - val_loss: 6.6280e-05\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4754e-04 - val_loss: 6.6515e-05\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5326e-04 - val_loss: 6.4052e-05\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3710e-04 - val_loss: 6.0655e-05\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.6438e-04 - val_loss: 6.5655e-05\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3461e-04 - val_loss: 6.9889e-05\n",
      "Epoch 339/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5379e-04 - val_loss: 7.0439e-05\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5057e-04 - val_loss: 6.2381e-05\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4252e-04 - val_loss: 6.1156e-05\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3668e-04 - val_loss: 6.1610e-05\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4289e-04 - val_loss: 6.5296e-05\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4292e-04 - val_loss: 6.2724e-05\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3629e-04 - val_loss: 6.1111e-05\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4953e-04 - val_loss: 6.1617e-05\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5754e-04 - val_loss: 6.3334e-05\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4942e-04 - val_loss: 6.8511e-05\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4545e-04 - val_loss: 7.8266e-05\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5811e-04 - val_loss: 7.1468e-05\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4717e-04 - val_loss: 6.0292e-05\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4712e-04 - val_loss: 5.7029e-05\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4039e-04 - val_loss: 6.2232e-05\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4526e-04 - val_loss: 7.3356e-05\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4388e-04 - val_loss: 7.9362e-05\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5093e-04 - val_loss: 6.2391e-05\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5405e-04 - val_loss: 5.5951e-05\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4867e-04 - val_loss: 5.7185e-05\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4951e-04 - val_loss: 6.2874e-05\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4597e-04 - val_loss: 7.3498e-05\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4945e-04 - val_loss: 7.1817e-05\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5590e-04 - val_loss: 6.5036e-05\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3578e-04 - val_loss: 5.9341e-05\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3890e-04 - val_loss: 5.8478e-05\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2908e-04 - val_loss: 6.2912e-05\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5065e-04 - val_loss: 6.6131e-05\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4504e-04 - val_loss: 7.3158e-05\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3753e-04 - val_loss: 6.7256e-05\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3599e-04 - val_loss: 6.1569e-05\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4505e-04 - val_loss: 6.3812e-05\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3999e-04 - val_loss: 6.5728e-05\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4282e-04 - val_loss: 6.5800e-05\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3587e-04 - val_loss: 6.0948e-05\n",
      "Epoch 374/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5532e-04 - val_loss: 6.7759e-05\n",
      "\n",
      "Loading Model: '02-07-2021--08--53-E2E_LSTM_ValSet_0.1-ALPHA0.01-BETA_SD17-374Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.012402016347331443\n",
      "Model: \"functional_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_110 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_111 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.0688 - val_loss: 0.0580\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0574 - val_loss: 0.0472\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0464 - val_loss: 0.0371\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0364 - val_loss: 0.0277\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0271 - val_loss: 0.0195\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0192 - val_loss: 0.0123\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0126 - val_loss: 0.0063\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0069 - val_loss: 0.0023\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0113 - val_loss: 0.0050\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0107 - val_loss: 0.0036\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0086 - val_loss: 0.0023\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0067 - val_loss: 0.0014\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0048 - val_loss: 0.0011\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - val_loss: 0.0010\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0032 - val_loss: 9.0358e-04\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - val_loss: 8.2861e-04\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - val_loss: 7.8469e-04\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - val_loss: 7.5923e-04\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - val_loss: 7.4514e-04\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - val_loss: 7.3982e-04\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - val_loss: 7.4765e-04\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0036 - val_loss: 7.8033e-04\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - val_loss: 8.4935e-04\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - val_loss: 9.4336e-04\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.0010\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 9.5950e-04\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0029 - val_loss: 8.8203e-04\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 8.1689e-04\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 7.6485e-04\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0026 - val_loss: 7.2569e-04\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0025 - val_loss: 6.9143e-04\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0026 - val_loss: 6.6903e-04\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0026 - val_loss: 6.5998e-04\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0024 - val_loss: 6.6736e-04\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 6.8630e-04\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 7.0263e-04\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - val_loss: 7.2551e-04\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 7.6452e-04\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0025 - val_loss: 8.0740e-04\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 8.5116e-04\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0023 - val_loss: 8.8596e-04\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 9.0003e-04\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 8.8952e-04\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0024 - val_loss: 8.6978e-04\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0023 - val_loss: 8.3510e-04\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0023 - val_loss: 7.9010e-04\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 7.4272e-04\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - val_loss: 7.0829e-04\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0021 - val_loss: 6.7422e-04\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - val_loss: 6.4930e-04\n",
      "Epoch 81/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - val_loss: 6.3202e-04\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - val_loss: 6.2263e-04\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 6.3190e-04\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - val_loss: 6.4493e-04\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0023 - val_loss: 6.5677e-04\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 6.7210e-04\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0021 - val_loss: 6.9221e-04\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - val_loss: 7.0903e-04\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 7.2238e-04\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - val_loss: 7.3554e-04\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 7.3366e-04\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0021 - val_loss: 7.3284e-04\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - val_loss: 7.3733e-04\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 7.2209e-04\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 6.8981e-04\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - val_loss: 6.6187e-04\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - val_loss: 6.2664e-04\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0020 - val_loss: 5.9661e-04\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - val_loss: 5.6953e-04\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - val_loss: 5.5273e-04\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 5.7216e-04\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 6.0349e-04\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0021 - val_loss: 6.5474e-04\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - val_loss: 7.1244e-04\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - val_loss: 7.3877e-04\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - val_loss: 7.3968e-04\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 7.0312e-04\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0020 - val_loss: 6.6517e-04\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0019 - val_loss: 6.2460e-04\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 5.8833e-04\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 5.5638e-04\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0020 - val_loss: 5.2471e-04\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0019 - val_loss: 5.0709e-04\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0019 - val_loss: 5.1483e-04\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 5.5330e-04\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - val_loss: 6.0055e-04\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 6.4375e-04\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - val_loss: 6.6887e-04\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 6.7676e-04\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 6.4446e-04\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 6.0208e-04\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0017 - val_loss: 5.6949e-04\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 5.5190e-04\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 5.5287e-04\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 5.3455e-04\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - val_loss: 4.9501e-04\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0017 - val_loss: 4.8363e-04\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 4.8931e-04\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 5.0569e-04\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 5.6054e-04\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0017 - val_loss: 5.6886e-04\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 5.3383e-04\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 4.9829e-04\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 5.0481e-04\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 5.2358e-04\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - val_loss: 5.0963e-04\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 5.1572e-04\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0016 - val_loss: 5.1700e-04\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 5.2243e-04\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 5.2773e-04\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 5.2541e-04\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 5.7970e-04\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 6.5232e-04\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 6.1768e-04\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0015 - val_loss: 4.7442e-04\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0015 - val_loss: 3.8402e-04\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0017 - val_loss: 3.7632e-04\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - val_loss: 4.5502e-04\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0016 - val_loss: 6.3670e-04\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 7.3993e-04\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 6.9140e-04\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0016 - val_loss: 5.4905e-04\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 4.2290e-04\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0016 - val_loss: 3.6921e-04\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0016 - val_loss: 4.0189e-04\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 4.9166e-04\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 5.7631e-04\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 5.9168e-04\n",
      "Epoch 159/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 5.4639e-04\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 4.8480e-04\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 4.3211e-04\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 3.7790e-04\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 3.8655e-04\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 4.5063e-04\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 5.6009e-04\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 6.3524e-04\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 6.0671e-04\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 4.9170e-04\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 3.8726e-04\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0015 - val_loss: 3.4767e-04\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 3.8739e-04\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 4.8794e-04\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0014 - val_loss: 5.5733e-04\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 5.5879e-04\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 4.7012e-04\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 3.6987e-04\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0013 - val_loss: 3.0337e-04\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 3.0611e-04\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 3.5829e-04\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 4.8011e-04\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 5.7875e-04\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 5.8152e-04\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 4.4318e-04\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 3.4238e-04\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0013 - val_loss: 2.9829e-04\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 3.1339e-04\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 4.0097e-04\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 5.2312e-04\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 5.6925e-04\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 4.9505e-04\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 4.0495e-04\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 3.2650e-04\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 3.3162e-04\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 3.5851e-04\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 3.8315e-04\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.8892e-04\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0014 - val_loss: 4.2961e-04\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 4.3759e-04\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 4.1991e-04\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 3.6551e-04\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 3.4063e-04\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 3.5657e-04\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 4.3252e-04\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 5.0445e-04\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 5.0167e-04\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 3.4502e-04\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0013 - val_loss: 2.6260e-04\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - val_loss: 2.8388e-04\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.7813e-04\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - val_loss: 4.5807e-04\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 5.2055e-04\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 4.2718e-04\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.3202e-04\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 2.9280e-04\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 3.1356e-04\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 3.6893e-04\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 4.3693e-04\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 4.5365e-04\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.9160e-04\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.0567e-04\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 2.8324e-04\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.2079e-04\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.9585e-04\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 4.4784e-04\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 4.2681e-04\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0012 - val_loss: 3.3878e-04\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 2.9495e-04\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0013 - val_loss: 3.2088e-04\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 3.8444e-04\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.7474e-04\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0013 - val_loss: 3.5327e-04\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0013 - val_loss: 3.6447e-04\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 3.5666e-04\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0013 - val_loss: 3.0628e-04\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 3.1010e-04\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - val_loss: 3.4905e-04\n",
      "Epoch 237/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 4.1071e-04\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.4247e-04\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0012 - val_loss: 2.8156e-04\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 2.7180e-04\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 2.9355e-04\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0014 - val_loss: 3.5288e-04\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - val_loss: 3.8939e-04\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0012 - val_loss: 3.5741e-04\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.1842e-04\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.1238e-04\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.5151e-04\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.3336e-04\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.3935e-04\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 3.7160e-04\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.4805e-04\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.5090e-04\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 3.8699e-04\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 3.5207e-04\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 3.3362e-04\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 2.9811e-04\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 2.8762e-04\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0012 - val_loss: 3.4760e-04\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 3.9730e-04\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 4.1258e-04\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 3.7506e-04\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 3.0749e-04\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0013 - val_loss: 2.7919e-04\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - val_loss: 3.2009e-04\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 3.9625e-04\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.9091e-04\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.3608e-04\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.1440e-04\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 2.6686e-04\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.0557e-04\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.7613e-04\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 4.3074e-04\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.4936e-04\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0013 - val_loss: 2.5871e-04\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0012 - val_loss: 2.7185e-04\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 3.4790e-04\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 3.9351e-04\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 4.1320e-04\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0011 - val_loss: 3.0067e-04\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 2.6674e-04\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 2.8479e-04\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 3.5526e-04\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 4.0803e-04\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 3.8206e-04\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 3.1374e-04\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 2.7468e-04\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 3.3988e-04\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 4.0923e-04\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.9190e-04\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 3.4122e-04\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0012 - val_loss: 3.0640e-04\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 2.8526e-04\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.2239e-04\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.5969e-04\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.7175e-04\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0012 - val_loss: 3.1836e-04\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 3.0131e-04\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 2.8582e-04\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.5500e-04\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 4.2867e-04\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 4.3309e-04\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0012 - val_loss: 2.4846e-04\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0011 - val_loss: 2.0304e-04\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 2.7938e-04\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0011 - val_loss: 3.8215e-04\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 4.2496e-04\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 2.8576e-04\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0011 - val_loss: 2.2324e-04\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0010 - val_loss: 3.2907e-04\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 4.0636e-04\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.5723e-04\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 2.6031e-04\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 2.5459e-04\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 3.2541e-04\n",
      "Epoch 315/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 4.0431e-04\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 4.0221e-04\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.8489e-04 - val_loss: 3.1250e-04\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 2.4624e-04\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 2.5055e-04\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.3020e-04\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 3.8691e-04\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.5725e-04\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 2.8226e-04\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 2.8071e-04\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0010 - val_loss: 3.5617e-04\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.8289e-04\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 3.1297e-04\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.9024e-04 - val_loss: 2.9072e-04\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 2.9200e-04\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 2.6766e-04\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0011 - val_loss: 2.9572e-04\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.8736e-04 - val_loss: 3.4269e-04\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0010 - val_loss: 3.4202e-04\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0010 - val_loss: 3.0166e-04\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 2.8780e-04\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.8193e-04 - val_loss: 2.8234e-04\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 3.6098e-04\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3400e-04 - val_loss: 3.7885e-04\n",
      "Epoch 339/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 3.2581e-04\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 2.4394e-04\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0010 - val_loss: 2.8336e-04\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.7133e-04 - val_loss: 3.2839e-04\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 3.4030e-04\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 2.4061e-04\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.5824e-04 - val_loss: 2.3266e-04\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0010 - val_loss: 2.9959e-04\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 3.2939e-04\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.8985e-04 - val_loss: 3.1899e-04\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 3.5210e-04\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.0527e-04\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 2.6330e-04\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.9682e-04 - val_loss: 2.5511e-04\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.8201e-04 - val_loss: 2.9375e-04\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 3.4866e-04\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 3.7044e-04\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0010 - val_loss: 2.5118e-04\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 2.3468e-04\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0010 - val_loss: 2.6665e-04\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0010 - val_loss: 2.8910e-04\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.9704e-04 - val_loss: 3.3771e-04\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.1824e-04\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0010 - val_loss: 2.9630e-04\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6055e-04 - val_loss: 2.8083e-04\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.5993e-04 - val_loss: 2.5677e-04\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1562e-04 - val_loss: 2.7031e-04\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0010 - val_loss: 2.5608e-04\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 3.7612e-04\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4611e-04 - val_loss: 3.3595e-04\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.7053e-04 - val_loss: 2.4942e-04\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.7191e-04 - val_loss: 2.7646e-04\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0010 - val_loss: 3.1981e-04\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.7099e-04 - val_loss: 3.0560e-04\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6311e-04 - val_loss: 2.4275e-04\n",
      "\n",
      "Loading Model: '02-07-2021--09--07-E2E_LSTM_ValSet_0.1-ALPHA0.1-BETA_SD17-373Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.013039562060504906\n",
      "Model: \"functional_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_114 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_115 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 3.0439e-05 - val_loss: 6.6254e-06\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.5994e-05 - val_loss: 6.6649e-06\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.7355e-05 - val_loss: 6.2264e-06\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.8980e-05 - val_loss: 5.8983e-06\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.4906e-05 - val_loss: 5.4337e-06\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.4335e-05 - val_loss: 4.9027e-06\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.1140e-05 - val_loss: 4.2969e-06\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0591e-05 - val_loss: 3.6247e-06\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0811e-05 - val_loss: 3.0342e-06\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6916e-05 - val_loss: 2.6190e-06\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.7461e-05 - val_loss: 2.3485e-06\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6301e-05 - val_loss: 1.9913e-06\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.3040e-05 - val_loss: 1.5129e-06\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.1596e-05 - val_loss: 1.0472e-06\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1341e-05 - val_loss: 2.6742e-07\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 9.0354e-06 - val_loss: 2.1667e-07\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 6.0608e-06 - val_loss: 1.9764e-07\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.4535e-06 - val_loss: 2.1624e-07\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9464e-06 - val_loss: 2.3443e-07\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5750e-06 - val_loss: 2.3837e-07\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1026e-06 - val_loss: 2.3582e-07\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0694e-06 - val_loss: 2.3343e-07\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0324e-06 - val_loss: 2.3411e-07\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9963e-06 - val_loss: 2.4244e-07\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6612e-06 - val_loss: 2.5951e-07\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.1566e-06 - val_loss: 2.7837e-07\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.1143e-06 - val_loss: 2.9718e-07\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.2143e-06 - val_loss: 3.1343e-07\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3730e-06 - val_loss: 3.2418e-07\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7788e-06 - val_loss: 3.3315e-07\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.6860e-06 - val_loss: 3.4233e-07\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0353e-06 - val_loss: 3.5088e-07\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1348e-06 - val_loss: 3.5869e-07\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.1512e-06 - val_loss: 3.6585e-07\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.4760e-06 - val_loss: 3.7345e-07\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3362e-06 - val_loss: 3.8116e-07\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8836e-06 - val_loss: 3.8964e-07\n",
      "Epoch 38/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4291e-06 - val_loss: 3.9711e-07\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9612e-06 - val_loss: 4.0327e-07\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5564e-06 - val_loss: 4.0893e-07\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3856e-06 - val_loss: 4.1254e-07\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2505e-06 - val_loss: 4.1574e-07\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4919e-06 - val_loss: 4.1783e-07\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2031e-06 - val_loss: 4.1913e-07\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3749e-06 - val_loss: 4.1910e-07\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1280e-06 - val_loss: 4.2102e-07\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2886e-06 - val_loss: 4.2347e-07\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.2976e-06 - val_loss: 4.2359e-07\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0757e-06 - val_loss: 4.2165e-07\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9073e-06 - val_loss: 4.1847e-07\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7922e-06 - val_loss: 4.1204e-07\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7687e-06 - val_loss: 4.0261e-07\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8494e-06 - val_loss: 3.9102e-07\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5583e-06 - val_loss: 3.7515e-07\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6690e-06 - val_loss: 3.5352e-07\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7800e-06 - val_loss: 3.3034e-07\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6737e-06 - val_loss: 3.0532e-07\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8197e-06 - val_loss: 2.7820e-07\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4035e-06 - val_loss: 2.5100e-07\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5021e-06 - val_loss: 2.2637e-07\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3879e-06 - val_loss: 2.1034e-07\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.2622e-06 - val_loss: 1.9762e-07\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.3959e-06 - val_loss: 1.8732e-07\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.2345e-06 - val_loss: 1.7618e-07\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.2222e-06 - val_loss: 1.6699e-07\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.2324e-06 - val_loss: 1.5991e-07\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.2102e-06 - val_loss: 1.5683e-07\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.0872e-06 - val_loss: 1.5188e-07\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.2098e-06 - val_loss: 1.4423e-07\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.1406e-06 - val_loss: 1.4220e-07\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.2725e-07 - val_loss: 1.4272e-07\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0662e-06 - val_loss: 1.4855e-07\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1280e-06 - val_loss: 1.5174e-07\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1316e-06 - val_loss: 1.5581e-07\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0383e-06 - val_loss: 1.6202e-07\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.7518e-07 - val_loss: 1.6901e-07\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9438e-07 - val_loss: 1.7233e-07\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0059e-06 - val_loss: 1.9484e-07\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3094e-07 - val_loss: 2.1689e-07\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1749e-06 - val_loss: 2.5162e-07\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6655e-07 - val_loss: 2.8346e-07\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.9503e-07 - val_loss: 3.0877e-07\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1703e-06 - val_loss: 3.2137e-07\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.7926e-07 - val_loss: 3.2574e-07\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.3527e-07 - val_loss: 3.2716e-07\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.1576e-07 - val_loss: 3.2554e-07\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7609e-07 - val_loss: 3.2260e-07\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 8.3216e-07 - val_loss: 3.1534e-07\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.6409e-07 - val_loss: 3.0468e-07\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.9891e-07 - val_loss: 2.9383e-07\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.1258e-07 - val_loss: 2.8236e-07\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.9890e-07 - val_loss: 2.7034e-07\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.7636e-07 - val_loss: 2.5414e-07\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.3698e-07 - val_loss: 2.3807e-07\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.9727e-07 - val_loss: 2.2179e-07\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.8136e-07 - val_loss: 2.0802e-07\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.0107e-07 - val_loss: 1.9513e-07\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.9795e-07 - val_loss: 1.8242e-07\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8247e-07 - val_loss: 1.7041e-07\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.6220e-07 - val_loss: 1.5969e-07\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 7.4858e-07 - val_loss: 1.5043e-07\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.2358e-07 - val_loss: 1.4233e-07\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.0426e-07 - val_loss: 1.4251e-07\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.3021e-07 - val_loss: 1.4503e-07\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1866e-07 - val_loss: 1.4817e-07\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.9228e-07 - val_loss: 1.5031e-07\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.4183e-07 - val_loss: 1.5121e-07\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7133e-07 - val_loss: 1.5006e-07\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.2217e-07 - val_loss: 1.4928e-07\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6.3522e-07 - val_loss: 1.4539e-07\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.3308e-07 - val_loss: 1.4123e-07\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.3004e-07 - val_loss: 1.3791e-07\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.5385e-07 - val_loss: 1.3752e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.9112e-07 - val_loss: 1.3669e-07\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.7896e-07 - val_loss: 1.3265e-07\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.1200e-07 - val_loss: 1.2900e-07\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.0363e-07 - val_loss: 1.2889e-07\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.2922e-07 - val_loss: 1.3117e-07\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.1881e-07 - val_loss: 1.3293e-07\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6744e-07 - val_loss: 1.3453e-07\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3893e-07 - val_loss: 1.3650e-07\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.4839e-07 - val_loss: 1.3684e-07\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.2000e-07 - val_loss: 1.3677e-07\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.1453e-07 - val_loss: 1.3483e-07\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.5551e-07 - val_loss: 1.3236e-07\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9998e-07 - val_loss: 1.2897e-07\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.9749e-07 - val_loss: 1.2566e-07\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.9595e-07 - val_loss: 1.2235e-07\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.4667e-07 - val_loss: 1.1924e-07\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.7823e-07 - val_loss: 1.1613e-07\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.7258e-07 - val_loss: 1.1368e-07\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 4.8391e-07 - val_loss: 1.1155e-07\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.4352e-07 - val_loss: 1.0948e-07\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.3234e-07 - val_loss: 1.0895e-07\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0350e-07 - val_loss: 1.1383e-07\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1234e-07 - val_loss: 1.2262e-07\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9998e-07 - val_loss: 1.3176e-07\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5075e-07 - val_loss: 1.3925e-07\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.2792e-07 - val_loss: 1.4436e-07\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.2739e-07 - val_loss: 1.4778e-07\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1142e-07 - val_loss: 1.4927e-07\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.0511e-07 - val_loss: 1.4887e-07\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5748e-07 - val_loss: 1.4451e-07\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.8844e-07 - val_loss: 1.3612e-07\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8183e-07 - val_loss: 1.2701e-07\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4336e-07 - val_loss: 1.1628e-07\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 4.1780e-07 - val_loss: 1.0642e-07\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.9563e-07 - val_loss: 9.9193e-08\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.5454e-07 - val_loss: 9.1604e-08\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7899e-07 - val_loss: 9.2300e-08\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.5999e-07 - val_loss: 9.0735e-08\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6539e-07 - val_loss: 9.1055e-08\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.2937e-07 - val_loss: 9.1321e-08\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 3.6983e-07 - val_loss: 9.0655e-08\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.5623e-07 - val_loss: 8.2461e-08\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.4911e-07 - val_loss: 7.3646e-08\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.0071e-07 - val_loss: 6.6462e-08\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.6021e-07 - val_loss: 6.0963e-08\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.0458e-07 - val_loss: 5.5057e-08\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.6450e-07 - val_loss: 5.0834e-08\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.3290e-07 - val_loss: 4.9338e-08\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.6068e-07 - val_loss: 4.8936e-08\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7281e-07 - val_loss: 4.9498e-08\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4039e-07 - val_loss: 5.0018e-08\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1382e-07 - val_loss: 5.2271e-08\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3798e-07 - val_loss: 5.4184e-08\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1008e-07 - val_loss: 6.6395e-08\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.3012e-07 - val_loss: 7.5610e-08\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6380e-07 - val_loss: 8.2676e-08\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0712e-07 - val_loss: 8.8117e-08\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6269e-07 - val_loss: 9.4166e-08\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0387e-07 - val_loss: 9.7745e-08\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.7100e-07 - val_loss: 9.8974e-08\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9729e-07 - val_loss: 9.8174e-08\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9510e-07 - val_loss: 9.5912e-08\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3325e-07 - val_loss: 9.1762e-08\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4911e-07 - val_loss: 8.6677e-08\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8573e-07 - val_loss: 8.0728e-08\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.0516e-07 - val_loss: 7.3551e-08\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2015e-07 - val_loss: 6.4668e-08\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9848e-07 - val_loss: 5.9740e-08\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2421e-07 - val_loss: 6.3370e-08\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5655e-07 - val_loss: 6.6235e-08\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9506e-07 - val_loss: 6.6262e-08\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4715e-07 - val_loss: 6.5376e-08\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5972e-07 - val_loss: 6.4731e-08\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7697e-07 - val_loss: 6.1397e-08\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6793e-07 - val_loss: 5.6987e-08\n",
      "Epoch 189/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0420e-07 - val_loss: 5.2422e-08\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.6080e-07 - val_loss: 4.8568e-08\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.7160e-07 - val_loss: 4.7535e-08\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.6287e-07 - val_loss: 4.3958e-08\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.5287e-07 - val_loss: 4.0993e-08\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.6881e-07 - val_loss: 3.8237e-08\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.5425e-07 - val_loss: 3.6203e-08\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.5969e-07 - val_loss: 3.2616e-08\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.7771e-07 - val_loss: 2.9359e-08\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.4301e-07 - val_loss: 2.7470e-08\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.6773e-07 - val_loss: 2.5789e-08\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2838e-07 - val_loss: 2.4508e-08\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.3742e-07 - val_loss: 2.3579e-08\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.6047e-07 - val_loss: 2.3109e-08\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6534e-07 - val_loss: 2.3573e-08\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3547e-07 - val_loss: 2.4066e-08\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.4058e-07 - val_loss: 2.4005e-08\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4327e-07 - val_loss: 2.5934e-08\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3745e-07 - val_loss: 2.8540e-08\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4361e-07 - val_loss: 3.0242e-08\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2648e-07 - val_loss: 3.1906e-08\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4550e-07 - val_loss: 3.2232e-08\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3982e-07 - val_loss: 3.2616e-08\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3603e-07 - val_loss: 3.1952e-08\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4755e-07 - val_loss: 3.1343e-08\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.5677e-07 - val_loss: 3.0249e-08\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3131e-07 - val_loss: 3.0128e-08\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1256e-07 - val_loss: 3.1087e-08\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5773e-07 - val_loss: 3.1776e-08\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2158e-07 - val_loss: 3.3121e-08\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.1817e-07 - val_loss: 3.7220e-08\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5749e-07 - val_loss: 3.7951e-08\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8584e-07 - val_loss: 3.8542e-08\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3782e-07 - val_loss: 3.6955e-08\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2878e-07 - val_loss: 3.4843e-08\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3950e-07 - val_loss: 3.1757e-08\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.1420e-07 - val_loss: 2.8768e-08\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.3915e-07 - val_loss: 2.6736e-08\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2149e-07 - val_loss: 2.4468e-08\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.3076e-07 - val_loss: 2.3038e-08\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.9715e-07 - val_loss: 2.1693e-08\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0326e-07 - val_loss: 2.0640e-08\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9925e-07 - val_loss: 2.0317e-08\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0197e-07 - val_loss: 1.9918e-08\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.2092e-07 - val_loss: 1.9544e-08\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2659e-07 - val_loss: 1.9548e-08\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9772e-07 - val_loss: 1.9960e-08\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0504e-07 - val_loss: 2.0981e-08\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2740e-07 - val_loss: 2.4259e-08\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6055e-07 - val_loss: 2.4943e-08\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0568e-07 - val_loss: 2.5940e-08\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1681e-07 - val_loss: 2.7161e-08\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8907e-07 - val_loss: 2.6450e-08\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1268e-07 - val_loss: 2.7695e-08\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4773e-07 - val_loss: 2.8824e-08\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9152e-07 - val_loss: 2.8588e-08\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0970e-07 - val_loss: 2.8107e-08\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8152e-07 - val_loss: 2.6468e-08\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0172e-07 - val_loss: 3.0181e-08\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2760e-07 - val_loss: 3.2098e-08\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9071e-07 - val_loss: 3.2480e-08\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0487e-07 - val_loss: 3.0372e-08\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1187e-07 - val_loss: 2.8654e-08\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5131e-07 - val_loss: 3.2375e-08\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3968e-07 - val_loss: 5.1181e-08\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9236e-07 - val_loss: 6.8788e-08\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9670e-07 - val_loss: 8.2900e-08\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1298e-07 - val_loss: 9.1988e-08\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2047e-07 - val_loss: 9.7303e-08\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8919e-07 - val_loss: 1.0010e-07\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0910e-07 - val_loss: 9.9761e-08\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1955e-07 - val_loss: 9.6821e-08\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1699e-07 - val_loss: 9.1439e-08\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0199e-07 - val_loss: 8.3987e-08\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.9642e-07 - val_loss: 7.5305e-08\n",
      "Epoch 264/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8511e-07 - val_loss: 6.6065e-08\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7813e-07 - val_loss: 5.6089e-08\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9631e-07 - val_loss: 4.6090e-08\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8329e-07 - val_loss: 3.7280e-08\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9118e-07 - val_loss: 3.1258e-08\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0598e-07 - val_loss: 2.7118e-08\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9123e-07 - val_loss: 2.2963e-08\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8757e-07 - val_loss: 2.0600e-08\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9381e-07 - val_loss: 1.8105e-08\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2544e-07 - val_loss: 1.6872e-08\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1302e-07 - val_loss: 1.6196e-08\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.7474e-07 - val_loss: 1.5648e-08\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9492e-07 - val_loss: 1.5546e-08\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.9301e-07 - val_loss: 1.6099e-08\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8829e-07 - val_loss: 1.7092e-08\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9517e-07 - val_loss: 1.8017e-08\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8206e-07 - val_loss: 1.8540e-08\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7618e-07 - val_loss: 1.8744e-08\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0748e-07 - val_loss: 1.8100e-08\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7577e-07 - val_loss: 2.2547e-08\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1398e-07 - val_loss: 2.6883e-08\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1595e-07 - val_loss: 4.0491e-08\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7865e-07 - val_loss: 5.4206e-08\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7859e-07 - val_loss: 6.6611e-08\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6694e-07 - val_loss: 7.4488e-08\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1642e-07 - val_loss: 7.7055e-08\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5299e-07 - val_loss: 6.7952e-08\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8291e-07 - val_loss: 5.6775e-08\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8634e-07 - val_loss: 4.1639e-08\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8414e-07 - val_loss: 2.7531e-08\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.7382e-07 - val_loss: 1.8553e-08\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8101e-07 - val_loss: 1.7199e-08\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1582e-07 - val_loss: 1.6136e-08\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4178e-07 - val_loss: 2.3592e-08\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7703e-07 - val_loss: 4.0293e-08\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7469e-07 - val_loss: 5.4297e-08\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8381e-07 - val_loss: 6.4737e-08\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9582e-07 - val_loss: 7.2649e-08\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6723e-07 - val_loss: 7.7785e-08\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.6577e-07 - val_loss: 8.1734e-08\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6830e-07 - val_loss: 8.3930e-08\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7394e-07 - val_loss: 8.4843e-08\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.9202e-07 - val_loss: 8.3399e-08\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6215e-07 - val_loss: 8.0922e-08\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9765e-07 - val_loss: 7.5809e-08\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1941e-07 - val_loss: 6.8916e-08\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9746e-07 - val_loss: 5.9964e-08\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0715e-07 - val_loss: 5.1214e-08\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1314e-07 - val_loss: 4.1953e-08\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7516e-07 - val_loss: 3.3724e-08\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7488e-07 - val_loss: 2.7606e-08\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7791e-07 - val_loss: 2.2989e-08\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8542e-07 - val_loss: 1.9736e-08\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8884e-07 - val_loss: 1.7961e-08\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7946e-07 - val_loss: 1.8210e-08\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6309e-07 - val_loss: 1.9211e-08\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8557e-07 - val_loss: 2.3292e-08\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7489e-07 - val_loss: 3.0958e-08\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9765e-07 - val_loss: 3.7226e-08\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9075e-07 - val_loss: 4.1361e-08\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5775e-07 - val_loss: 4.7984e-08\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8504e-07 - val_loss: 5.0014e-08\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6824e-07 - val_loss: 4.9386e-08\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6819e-07 - val_loss: 4.8191e-08\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5436e-07 - val_loss: 4.8679e-08\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7554e-07 - val_loss: 5.1897e-08\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7436e-07 - val_loss: 5.8633e-08\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9462e-07 - val_loss: 6.3292e-08\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9178e-07 - val_loss: 6.1657e-08\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6100e-07 - val_loss: 5.6408e-08\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6048e-07 - val_loss: 4.7375e-08\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7269e-07 - val_loss: 3.9118e-08\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7065e-07 - val_loss: 3.4112e-08\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7705e-07 - val_loss: 2.9010e-08\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5165e-07 - val_loss: 2.6145e-08\n",
      "Epoch 339/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6594e-07 - val_loss: 2.3269e-08\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6850e-07 - val_loss: 2.1674e-08\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3856e-07 - val_loss: 2.1628e-08\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9529e-07 - val_loss: 2.3062e-08\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7945e-07 - val_loss: 2.4357e-08\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6346e-07 - val_loss: 2.6361e-08\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7423e-07 - val_loss: 2.6798e-08\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6903e-07 - val_loss: 2.3326e-08\n",
      "\n",
      "Loading Model: '02-07-2021--09--21-E2E_LSTM_ValSet_0.1-ALPHA0-BETA_SD17-346Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 0.009274126476494835\n",
      "Model: \"functional_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_118 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_119 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.6874 - val_loss: 0.5792\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.5732 - val_loss: 0.4715\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4630 - val_loss: 0.3701\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3621 - val_loss: 0.2757\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2696 - val_loss: 0.1932\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1897 - val_loss: 0.1211\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1236 - val_loss: 0.0607\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0675 - val_loss: 0.0214\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0434 - val_loss: 0.0164\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0544 - val_loss: 0.0401\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0879 - val_loss: 0.0532\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1134 - val_loss: 0.0485\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1054 - val_loss: 0.0349\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0839 - val_loss: 0.0215\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0645 - val_loss: 0.0130\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0466 - val_loss: 0.0105\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0413 - val_loss: 0.0129\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0369 - val_loss: 0.0185\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0348 - val_loss: 0.0254\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0397 - val_loss: 0.0322\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0415 - val_loss: 0.0378\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0468 - val_loss: 0.0419\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0454 - val_loss: 0.0441\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0522 - val_loss: 0.0444\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0486 - val_loss: 0.0429\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0473 - val_loss: 0.0401\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0467 - val_loss: 0.0362\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0449 - val_loss: 0.0316\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0430 - val_loss: 0.0269\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0353 - val_loss: 0.0223\n",
      "Epoch 31/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0345 - val_loss: 0.0180\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0322 - val_loss: 0.0145\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0321 - val_loss: 0.0117\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0359 - val_loss: 0.0098\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0310 - val_loss: 0.0085\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0314 - val_loss: 0.0078\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0354 - val_loss: 0.0074\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0321 - val_loss: 0.0072\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0324 - val_loss: 0.0071\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0324 - val_loss: 0.0071\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0336 - val_loss: 0.0072\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0356 - val_loss: 0.0076\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0348 - val_loss: 0.0083\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0309 - val_loss: 0.0094\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0296 - val_loss: 0.0106\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0305 - val_loss: 0.0118\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0299 - val_loss: 0.0128\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0308 - val_loss: 0.0134\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0300 - val_loss: 0.0136\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0306 - val_loss: 0.0134\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0291 - val_loss: 0.0130\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0302 - val_loss: 0.0123\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0276 - val_loss: 0.0114\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0293 - val_loss: 0.0106\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0272 - val_loss: 0.0098\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0273 - val_loss: 0.0090\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0279 - val_loss: 0.0082\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0279 - val_loss: 0.0077\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0254 - val_loss: 0.0072\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0254 - val_loss: 0.0069\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0244 - val_loss: 0.0066\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0259 - val_loss: 0.0064\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0256 - val_loss: 0.0064\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0239 - val_loss: 0.0065\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0246 - val_loss: 0.0067\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0251 - val_loss: 0.0069\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0239 - val_loss: 0.0071\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0246 - val_loss: 0.0075\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0249 - val_loss: 0.0079\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0258 - val_loss: 0.0083\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0222 - val_loss: 0.0085\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0243 - val_loss: 0.0086\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0254 - val_loss: 0.0084\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0233 - val_loss: 0.0081\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0222 - val_loss: 0.0078\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0227 - val_loss: 0.0074\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0244 - val_loss: 0.0069\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0229 - val_loss: 0.0066\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0208 - val_loss: 0.0063\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0228 - val_loss: 0.0061\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0226 - val_loss: 0.0060\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0215 - val_loss: 0.0059\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0214 - val_loss: 0.0060\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0221 - val_loss: 0.0062\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0228 - val_loss: 0.0063\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0210 - val_loss: 0.0065\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0200 - val_loss: 0.0067\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0226 - val_loss: 0.0068\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0211 - val_loss: 0.0069\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0227 - val_loss: 0.0070\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0213 - val_loss: 0.0070\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0203 - val_loss: 0.0069\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0221 - val_loss: 0.0070\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0216 - val_loss: 0.0068\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0214 - val_loss: 0.0065\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0192 - val_loss: 0.0062\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0198 - val_loss: 0.0059\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0193 - val_loss: 0.0056\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0178 - val_loss: 0.0054\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0198 - val_loss: 0.0052\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0184 - val_loss: 0.0055\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0198 - val_loss: 0.0058\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0199 - val_loss: 0.0063\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0190 - val_loss: 0.0069\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0190 - val_loss: 0.0071\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0196 - val_loss: 0.0071\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0198 - val_loss: 0.0067\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0197 - val_loss: 0.0063\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0178 - val_loss: 0.0059\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0177 - val_loss: 0.0055\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0181 - val_loss: 0.0052\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0193 - val_loss: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0185 - val_loss: 0.0047\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0180 - val_loss: 0.0048\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0176 - val_loss: 0.0052\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0174 - val_loss: 0.0057\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0169 - val_loss: 0.0062\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0181 - val_loss: 0.0064\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0174 - val_loss: 0.0064\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0172 - val_loss: 0.0060\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0162 - val_loss: 0.0056\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0164 - val_loss: 0.0053\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0172 - val_loss: 0.0052\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0174 - val_loss: 0.0053\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0176 - val_loss: 0.0052\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0174 - val_loss: 0.0048\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0167 - val_loss: 0.0047\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0173 - val_loss: 0.0047\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0157 - val_loss: 0.0048\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0160 - val_loss: 0.0054\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0168 - val_loss: 0.0055\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0168 - val_loss: 0.0051\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0177 - val_loss: 0.0048\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0169 - val_loss: 0.0048\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0169 - val_loss: 0.0050\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0164 - val_loss: 0.0048\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0162 - val_loss: 0.0048\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0155 - val_loss: 0.0048\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0149 - val_loss: 0.0049\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0156 - val_loss: 0.0049\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0138 - val_loss: 0.0049\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0160 - val_loss: 0.0054\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0158 - val_loss: 0.0061\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0146 - val_loss: 0.0057\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0145 - val_loss: 0.0043\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0144 - val_loss: 0.0034\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0160 - val_loss: 0.0034\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0155 - val_loss: 0.0042\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0156 - val_loss: 0.0061\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0157 - val_loss: 0.0071\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0148 - val_loss: 0.0065\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0157 - val_loss: 0.0051\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0153 - val_loss: 0.0038\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0157 - val_loss: 0.0033\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0152 - val_loss: 0.0038\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0159 - val_loss: 0.0047\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0149 - val_loss: 0.0056\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0145 - val_loss: 0.0058\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0149 - val_loss: 0.0052\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0151 - val_loss: 0.0046\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0146 - val_loss: 0.0040\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0155 - val_loss: 0.0034\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0145 - val_loss: 0.0035\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0133 - val_loss: 0.0042\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0133 - val_loss: 0.0054\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0143 - val_loss: 0.0061\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0151 - val_loss: 0.0058\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0147 - val_loss: 0.0046\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0147 - val_loss: 0.0036\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0144 - val_loss: 0.0032\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0141 - val_loss: 0.0036\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0129 - val_loss: 0.0046\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0133 - val_loss: 0.0054\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0139 - val_loss: 0.0054\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0133 - val_loss: 0.0045\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0144 - val_loss: 0.0034\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0128 - val_loss: 0.0028\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0133 - val_loss: 0.0028\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0157 - val_loss: 0.0032\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0147 - val_loss: 0.0044\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0134 - val_loss: 0.0054\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0131 - val_loss: 0.0056\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0138 - val_loss: 0.0042\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0139 - val_loss: 0.0031\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0128 - val_loss: 0.0026\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0138 - val_loss: 0.0027\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0128 - val_loss: 0.0035\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0135 - val_loss: 0.0047\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0137 - val_loss: 0.0054\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0137 - val_loss: 0.0048\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0136 - val_loss: 0.0040\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0133 - val_loss: 0.0030\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0134 - val_loss: 0.0029\n",
      "Epoch 194/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0133 - val_loss: 0.0030\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0141 - val_loss: 0.0032\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0126 - val_loss: 0.0035\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0132 - val_loss: 0.0041\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0147 - val_loss: 0.0043\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0133 - val_loss: 0.0039\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0132 - val_loss: 0.0032\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0127 - val_loss: 0.0029\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0141 - val_loss: 0.0031\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0128 - val_loss: 0.0040\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0125 - val_loss: 0.0049\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0133 - val_loss: 0.0048\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0130 - val_loss: 0.0031\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0120 - val_loss: 0.0022\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0129 - val_loss: 0.0024\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0126 - val_loss: 0.0034\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0127 - val_loss: 0.0044\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0134 - val_loss: 0.0050\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0130 - val_loss: 0.0041\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0120 - val_loss: 0.0031\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0126 - val_loss: 0.0026\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0133 - val_loss: 0.0027\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0124 - val_loss: 0.0032\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0128 - val_loss: 0.0040\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0122 - val_loss: 0.0043\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0124 - val_loss: 0.0039\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0128 - val_loss: 0.0029\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0112 - val_loss: 0.0025\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0129 - val_loss: 0.0027\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0125 - val_loss: 0.0033\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0116 - val_loss: 0.0040\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0131 - val_loss: 0.0041\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0119 - val_loss: 0.0033\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0125 - val_loss: 0.0027\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0120 - val_loss: 0.0028\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0118 - val_loss: 0.0033\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0122 - val_loss: 0.0033\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0123 - val_loss: 0.0033\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0120 - val_loss: 0.0035\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0113 - val_loss: 0.0034\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0124 - val_loss: 0.0027\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0115 - val_loss: 0.0027\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0129 - val_loss: 0.0031\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0107 - val_loss: 0.0039\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0125 - val_loss: 0.0033\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0119 - val_loss: 0.0026\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0123 - val_loss: 0.0024\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0026\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0131 - val_loss: 0.0032\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0120 - val_loss: 0.0037\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0119 - val_loss: 0.0034\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0126 - val_loss: 0.0030\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0117 - val_loss: 0.0028\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0126 - val_loss: 0.0032\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0119 - val_loss: 0.0031\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0118 - val_loss: 0.0032\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0115 - val_loss: 0.0036\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0125 - val_loss: 0.0033\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0123 - val_loss: 0.0032\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0119 - val_loss: 0.0036\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0118 - val_loss: 0.0033\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0121 - val_loss: 0.0032\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0112 - val_loss: 0.0028\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0119 - val_loss: 0.0026\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0117 - val_loss: 0.0032\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0114 - val_loss: 0.0037\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0122 - val_loss: 0.0039\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0116 - val_loss: 0.0035\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0111 - val_loss: 0.0029\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0122 - val_loss: 0.0026\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0125 - val_loss: 0.0030\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0115 - val_loss: 0.0038\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0119 - val_loss: 0.0037\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0115 - val_loss: 0.0032\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0110 - val_loss: 0.0029\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0116 - val_loss: 0.0024\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0103 - val_loss: 0.0029\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0113 - val_loss: 0.0036\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0118 - val_loss: 0.0041\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0112 - val_loss: 0.0032\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0120 - val_loss: 0.0024\n",
      "Epoch 275/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0114 - val_loss: 0.0025\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0104 - val_loss: 0.0034\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0118 - val_loss: 0.0038\n",
      "\n",
      "Loading Model: '02-07-2021--09--34-E2E_LSTM_ValSet_0.1-ALPHA1.0-BETA_SD17-277Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.010981468930364592\n",
      "Model: \"functional_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_122 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_123 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 68.7321 - val_loss: 57.9090\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 57.3135 - val_loss: 47.1335\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 46.2852 - val_loss: 36.9903\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 36.1852 - val_loss: 27.5495\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 26.9256 - val_loss: 19.2946\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 18.9332 - val_loss: 12.0801\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 12.3222 - val_loss: 6.0350\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.7179 - val_loss: 2.1200\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.3247 - val_loss: 1.6481\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.4664 - val_loss: 4.0306\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.8178 - val_loss: 5.3230\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.3530 - val_loss: 4.8332\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10.5254 - val_loss: 3.4622\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.3567 - val_loss: 2.1233\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.4158 - val_loss: 1.2857\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.6287 - val_loss: 1.0448\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.1110 - val_loss: 1.2918\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6753 - val_loss: 1.8545\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4772 - val_loss: 2.5494\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9680 - val_loss: 3.2249\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1487 - val_loss: 3.7896\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.6801 - val_loss: 4.1987\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 4.5366 - val_loss: 4.4152\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.2123 - val_loss: 4.4362\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.8541 - val_loss: 4.2893\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.7173 - val_loss: 4.0037\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.6574 - val_loss: 3.6101\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4829 - val_loss: 3.1518\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2925 - val_loss: 2.6773\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5192 - val_loss: 2.2178\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4385 - val_loss: 1.7942\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2095 - val_loss: 1.4374\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2029 - val_loss: 1.1616\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.5812 - val_loss: 0.9692\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.0989 - val_loss: 0.8468\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.1369 - val_loss: 0.7776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.5371 - val_loss: 0.7375\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.2035 - val_loss: 0.7147\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.2268 - val_loss: 0.7036\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.2275 - val_loss: 0.7031\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3508 - val_loss: 0.7170\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.5452 - val_loss: 0.7575\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.4631 - val_loss: 0.8372\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0821 - val_loss: 0.9407\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9547 - val_loss: 1.0667\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0465 - val_loss: 1.1840\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9901 - val_loss: 1.2820\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.0776 - val_loss: 1.3381\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9998 - val_loss: 1.3617\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0535 - val_loss: 1.3375\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9066 - val_loss: 1.2879\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0101 - val_loss: 1.2164\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7491 - val_loss: 1.1282\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9202 - val_loss: 1.0509\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.7096 - val_loss: 0.9664\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7242 - val_loss: 0.8822\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7858 - val_loss: 0.8092\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7899 - val_loss: 0.7521\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5353 - val_loss: 0.7091\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.5321 - val_loss: 0.6797\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.4333 - val_loss: 0.6542\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.5804 - val_loss: 0.6396\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.5529 - val_loss: 0.6380\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3782 - val_loss: 0.6522\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4480 - val_loss: 0.6769\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5011 - val_loss: 0.6959\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3804 - val_loss: 0.7193\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4525 - val_loss: 0.7569\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4822 - val_loss: 0.7935\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5747 - val_loss: 0.8258\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2126 - val_loss: 0.8468\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4250 - val_loss: 0.8485\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5316 - val_loss: 0.8287\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3248 - val_loss: 0.8044\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2111 - val_loss: 0.7693\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2644 - val_loss: 0.7262\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4302 - val_loss: 0.6827\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2778 - val_loss: 0.6535\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0725 - val_loss: 0.6253\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2729 - val_loss: 0.6061\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.2492 - val_loss: 0.5941\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1406 - val_loss: 0.5892\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1318 - val_loss: 0.6027\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1989 - val_loss: 0.6188\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2721 - val_loss: 0.6320\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0943 - val_loss: 0.6468\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.9905 - val_loss: 0.6649\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2455 - val_loss: 0.6784\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1037 - val_loss: 0.6884\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.2581 - val_loss: 0.6984\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1216 - val_loss: 0.6927\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0197 - val_loss: 0.6889\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2032 - val_loss: 0.6919\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1480 - val_loss: 0.6770\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1274 - val_loss: 0.6458\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9062 - val_loss: 0.6198\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.9685 - val_loss: 0.5870\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9167 - val_loss: 0.5593\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.7694 - val_loss: 0.5348\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9644 - val_loss: 0.5217\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8287 - val_loss: 0.5455\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9705 - val_loss: 0.5805\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9757 - val_loss: 0.6335\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8835 - val_loss: 0.6895\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8880 - val_loss: 0.7103\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9444 - val_loss: 0.7065\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.9655 - val_loss: 0.6657\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9543 - val_loss: 0.6222\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7683 - val_loss: 0.5785\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7568 - val_loss: 0.5418\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.7917 - val_loss: 0.5122\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.9124 - val_loss: 0.4839\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8342 - val_loss: 0.4701\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7868 - val_loss: 0.4811\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.7470 - val_loss: 0.5249\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7331 - val_loss: 0.5791\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6815 - val_loss: 0.6252\n",
      "Epoch 118/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8051 - val_loss: 0.6445\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7230 - val_loss: 0.6423\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7128 - val_loss: 0.5972\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6055 - val_loss: 0.5495\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6280 - val_loss: 0.5225\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7101 - val_loss: 0.5219\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7306 - val_loss: 0.5427\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7442 - val_loss: 0.5357\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7243 - val_loss: 0.4945\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6589 - val_loss: 0.4781\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7151 - val_loss: 0.4759\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5618 - val_loss: 0.4876\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5934 - val_loss: 0.5434\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6672 - val_loss: 0.5530\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6652 - val_loss: 0.5168\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7583 - val_loss: 0.4774\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6758 - val_loss: 0.4804\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6751 - val_loss: 0.4928\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6244 - val_loss: 0.4717\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6046 - val_loss: 0.4725\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5416 - val_loss: 0.4732\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4809 - val_loss: 0.4815\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5507 - val_loss: 0.4865\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3662 - val_loss: 0.4829\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5877 - val_loss: 0.5341\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5627 - val_loss: 0.6041\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4459 - val_loss: 0.5607\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.4313 - val_loss: 0.4128\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.4317 - val_loss: 0.3319\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5919 - val_loss: 0.3348\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5364 - val_loss: 0.4277\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5391 - val_loss: 0.6248\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5571 - val_loss: 0.7123\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4661 - val_loss: 0.6404\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5519 - val_loss: 0.4885\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5214 - val_loss: 0.3693\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.5582 - val_loss: 0.3292\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5110 - val_loss: 0.3799\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5733 - val_loss: 0.4894\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4755 - val_loss: 0.5841\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4438 - val_loss: 0.5892\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4758 - val_loss: 0.5236\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5010 - val_loss: 0.4451\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4417 - val_loss: 0.3840\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.5317 - val_loss: 0.3290\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4389 - val_loss: 0.3430\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3207 - val_loss: 0.4201\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3186 - val_loss: 0.5412\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4193 - val_loss: 0.6183\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5022 - val_loss: 0.5861\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4669 - val_loss: 0.4671\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4637 - val_loss: 0.3585\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.4269 - val_loss: 0.3141\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4031 - val_loss: 0.3494\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2828 - val_loss: 0.4477\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3227 - val_loss: 0.5268\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3768 - val_loss: 0.5413\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3182 - val_loss: 0.4592\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4352 - val_loss: 0.3545\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.2756 - val_loss: 0.2773\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.3230 - val_loss: 0.2702\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5650 - val_loss: 0.3100\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4646 - val_loss: 0.4240\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3296 - val_loss: 0.5399\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2975 - val_loss: 0.5679\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3779 - val_loss: 0.4301\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3807 - val_loss: 0.3147\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.2713 - val_loss: 0.2568\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3687 - val_loss: 0.2600\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2752 - val_loss: 0.3387\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3476 - val_loss: 0.4656\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3592 - val_loss: 0.5367\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3612 - val_loss: 0.4852\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3563 - val_loss: 0.3932\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3212 - val_loss: 0.2958\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3302 - val_loss: 0.2785\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3243 - val_loss: 0.2904\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3999 - val_loss: 0.3166\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2542 - val_loss: 0.3441\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3104 - val_loss: 0.4111\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4536 - val_loss: 0.4258\n",
      "Epoch 199/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3175 - val_loss: 0.3881\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3106 - val_loss: 0.3110\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2634 - val_loss: 0.2800\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4028 - val_loss: 0.3018\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2685 - val_loss: 0.3968\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2482 - val_loss: 0.4895\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3202 - val_loss: 0.4811\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2886 - val_loss: 0.3064\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.1950 - val_loss: 0.2177\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2802 - val_loss: 0.2362\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2548 - val_loss: 0.3311\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2585 - val_loss: 0.4278\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3267 - val_loss: 0.5053\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3000 - val_loss: 0.4199\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1931 - val_loss: 0.3158\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2551 - val_loss: 0.2616\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3220 - val_loss: 0.2648\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2344 - val_loss: 0.3083\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2750 - val_loss: 0.3820\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2088 - val_loss: 0.4312\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2288 - val_loss: 0.3966\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2725 - val_loss: 0.3017\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1089 - val_loss: 0.2539\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2823 - val_loss: 0.2629\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2387 - val_loss: 0.3208\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1557 - val_loss: 0.3932\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3037 - val_loss: 0.4119\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1834 - val_loss: 0.3338\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2391 - val_loss: 0.2717\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1904 - val_loss: 0.2736\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1739 - val_loss: 0.3199\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2071 - val_loss: 0.3221\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2181 - val_loss: 0.3285\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1880 - val_loss: 0.3596\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1195 - val_loss: 0.3428\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2344 - val_loss: 0.2708\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1427 - val_loss: 0.2635\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2781 - val_loss: 0.3048\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.0644 - val_loss: 0.3892\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2402 - val_loss: 0.3340\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1804 - val_loss: 0.2618\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2244 - val_loss: 0.2382\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1318 - val_loss: 0.2515\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2963 - val_loss: 0.3133\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1945 - val_loss: 0.3642\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1849 - val_loss: 0.3440\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2501 - val_loss: 0.2990\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1671 - val_loss: 0.2805\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2479 - val_loss: 0.3118\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1858 - val_loss: 0.3030\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1655 - val_loss: 0.3211\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1438 - val_loss: 0.3588\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2413 - val_loss: 0.3265\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2233 - val_loss: 0.3194\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1815 - val_loss: 0.3540\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1690 - val_loss: 0.3272\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1943 - val_loss: 0.3158\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1134 - val_loss: 0.2801\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1866 - val_loss: 0.2660\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1589 - val_loss: 0.3230\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1303 - val_loss: 0.3648\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2060 - val_loss: 0.3870\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1477 - val_loss: 0.3555\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1011 - val_loss: 0.2911\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2083 - val_loss: 0.2578\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2414 - val_loss: 0.2978\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1472 - val_loss: 0.3762\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1792 - val_loss: 0.3728\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1362 - val_loss: 0.3215\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0954 - val_loss: 0.2943\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1550 - val_loss: 0.2439\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0211 - val_loss: 0.2826\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1179 - val_loss: 0.3588\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1738 - val_loss: 0.4141\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1086 - val_loss: 0.3317\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1936 - val_loss: 0.2364\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1305 - val_loss: 0.2502\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0331 - val_loss: 0.3336\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1705 - val_loss: 0.3788\n",
      "\n",
      "Loading Model: '02-07-2021--09--47-E2E_LSTM_ValSet_0.1-ALPHA100.0-BETA_SD17-277Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.010997811916933838\n",
      "Model: \"functional_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_126 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_127 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 687.3209 - val_loss: 579.0888\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 573.1340 - val_loss: 471.3334\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 462.8503 - val_loss: 369.9014\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 361.8495 - val_loss: 275.4921\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 269.2529 - val_loss: 192.9429\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 189.3280 - val_loss: 120.7981\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 123.2179 - val_loss: 60.3467\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 67.1755 - val_loss: 21.1979\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 43.2453 - val_loss: 16.4818\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 54.6671 - val_loss: 40.3089\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 88.1813 - val_loss: 53.2311\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 113.5312 - val_loss: 48.3299\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 105.2522 - val_loss: 34.6196\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 83.5636 - val_loss: 21.2311\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 64.1539 - val_loss: 12.8561\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 46.2845 - val_loss: 10.4473\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 41.1077 - val_loss: 12.9182\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 36.7519 - val_loss: 18.5464\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 34.7721 - val_loss: 25.4951\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 39.6799 - val_loss: 32.2502\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 41.4870 - val_loss: 37.8964\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 46.8011 - val_loss: 41.9879\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 45.3654 - val_loss: 44.1517\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 52.1221 - val_loss: 44.3616\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 48.5395 - val_loss: 42.8920\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 47.1719 - val_loss: 40.0359\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 46.5727 - val_loss: 36.0995\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 44.8272 - val_loss: 31.5164\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 42.9238 - val_loss: 26.7712\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 35.1908 - val_loss: 22.1771\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 34.3838 - val_loss: 17.9414\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 32.0943 - val_loss: 14.3728\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 32.0286 - val_loss: 11.6149\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 35.8114 - val_loss: 9.6912\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 30.9902 - val_loss: 8.4679\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 31.3692 - val_loss: 7.7761\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 35.3708 - val_loss: 7.3755\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 32.0346 - val_loss: 7.1472\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 32.2681 - val_loss: 7.0364\n",
      "Epoch 40/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step - loss: 32.2752 - val_loss: 7.0318\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 33.5074 - val_loss: 7.1701\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 35.4514 - val_loss: 7.5752\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 34.6311 - val_loss: 8.3724\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 30.8204 - val_loss: 9.4079\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 29.5480 - val_loss: 10.6679\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.4654 - val_loss: 11.8408\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 29.9010 - val_loss: 12.8217\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 30.7770 - val_loss: 13.3819\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 29.9996 - val_loss: 13.6174\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.5358 - val_loss: 13.3751\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 29.0668 - val_loss: 12.8775\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.1013 - val_loss: 12.1627\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 27.4913 - val_loss: 11.2804\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 29.2020 - val_loss: 10.5070\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 27.0956 - val_loss: 9.6614\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 27.2418 - val_loss: 8.8203\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 27.8578 - val_loss: 8.0913\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 27.8978 - val_loss: 7.5204\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 25.3525 - val_loss: 7.0917\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 25.3203 - val_loss: 6.7979\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 24.3325 - val_loss: 6.5440\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 25.8040 - val_loss: 6.3978\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 25.5278 - val_loss: 6.3815\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 23.7812 - val_loss: 6.5232\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 24.4799 - val_loss: 6.7697\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 25.0109 - val_loss: 6.9589\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 23.8036 - val_loss: 7.1916\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 24.5246 - val_loss: 7.5663\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 24.8222 - val_loss: 7.9306\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 25.7471 - val_loss: 8.2534\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.1258 - val_loss: 8.4623\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 24.2488 - val_loss: 8.4804\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 25.3141 - val_loss: 8.2836\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 23.2470 - val_loss: 8.0416\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 22.1103 - val_loss: 7.6915\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.6437 - val_loss: 7.2615\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 24.3014 - val_loss: 6.8277\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 22.7769 - val_loss: 6.5365\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 20.7244 - val_loss: 6.2547\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 22.7280 - val_loss: 6.0621\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 22.4908 - val_loss: 5.9418\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 21.4049 - val_loss: 5.8928\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 21.3169 - val_loss: 6.0269\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 21.9882 - val_loss: 6.1877\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 22.7204 - val_loss: 6.3188\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 20.9424 - val_loss: 6.4661\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 19.9038 - val_loss: 6.6475\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 22.4537 - val_loss: 6.7823\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 21.0361 - val_loss: 6.8823\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 22.5804 - val_loss: 6.9821\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 21.2151 - val_loss: 6.9250\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 20.1959 - val_loss: 6.8873\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.0315 - val_loss: 6.9181\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 21.4793 - val_loss: 6.7693\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 21.2723 - val_loss: 6.4567\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.0606 - val_loss: 6.1971\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.6841 - val_loss: 5.8687\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 19.1652 - val_loss: 5.5926\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 17.6921 - val_loss: 5.3475\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.6419 - val_loss: 5.2160\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 18.2856 - val_loss: 5.4547\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.7032 - val_loss: 5.8043\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 19.7554 - val_loss: 6.3355\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 18.8329 - val_loss: 6.8957\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 18.8790 - val_loss: 7.1034\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.4423 - val_loss: 7.0652\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 19.6533 - val_loss: 6.6564\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 19.5410 - val_loss: 6.2199\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.6813 - val_loss: 5.7826\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.5662 - val_loss: 5.4161\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 17.9151 - val_loss: 5.1200\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.1218 - val_loss: 4.8373\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 18.3409 - val_loss: 4.6995\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 17.8656 - val_loss: 4.8105\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 17.4669 - val_loss: 5.2501\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.3303 - val_loss: 5.7925\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.8138 - val_loss: 6.2529\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 18.0489 - val_loss: 6.4418\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.2277 - val_loss: 6.4164\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.1248 - val_loss: 5.9637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.0532 - val_loss: 5.4882\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.2785 - val_loss: 5.2210\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.0992 - val_loss: 5.2199\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 17.3043 - val_loss: 5.4322\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 17.4409 - val_loss: 5.3641\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.2419 - val_loss: 4.9509\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.5866 - val_loss: 4.7834\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.1479 - val_loss: 4.7583\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.6164 - val_loss: 4.8724\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.9330 - val_loss: 5.4293\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.6691 - val_loss: 5.5284\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 16.6504 - val_loss: 5.1683\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.5804 - val_loss: 4.7765\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.7560 - val_loss: 4.8062\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.7479 - val_loss: 4.9292\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.2420 - val_loss: 4.7154\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.0439 - val_loss: 4.7221\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 15.4147 - val_loss: 4.7284\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.8077 - val_loss: 4.8116\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.5054 - val_loss: 4.8643\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.6601 - val_loss: 4.8298\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 15.8737 - val_loss: 5.3437\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 15.6245 - val_loss: 6.0427\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.4571 - val_loss: 5.6052\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 14.3107 - val_loss: 4.1251\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 14.3154 - val_loss: 3.3173\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 15.9175 - val_loss: 3.3475\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.3615 - val_loss: 4.2778\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.3889 - val_loss: 6.2518\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.5693 - val_loss: 7.1275\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 14.6599 - val_loss: 6.4079\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.5168 - val_loss: 4.8875\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.2127 - val_loss: 3.6929\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 15.5810 - val_loss: 3.2918\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.1092 - val_loss: 3.7987\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 15.7328 - val_loss: 4.8951\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.7525 - val_loss: 5.8437\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.4367 - val_loss: 5.8958\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.7553 - val_loss: 5.2405\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.0083 - val_loss: 4.4547\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.4138 - val_loss: 3.8424\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 15.3143 - val_loss: 3.2910\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.3860 - val_loss: 3.4316\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2062 - val_loss: 4.2030\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.1848 - val_loss: 5.4151\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.1895 - val_loss: 6.1882\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.0209 - val_loss: 5.8661\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.6666 - val_loss: 4.6754\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.6346 - val_loss: 3.5879\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 14.2673 - val_loss: 3.1421\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.0290 - val_loss: 3.4952\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.8264 - val_loss: 4.4776\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2253 - val_loss: 5.2695\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.7656 - val_loss: 5.4173\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 13.1807 - val_loss: 4.5973\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.3503 - val_loss: 3.5488\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 12.7542 - val_loss: 2.7733\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 13.2285 - val_loss: 2.7008\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.6484 - val_loss: 3.0973\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.6429 - val_loss: 4.2408\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2929 - val_loss: 5.4004\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.9740 - val_loss: 5.6820\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.7769 - val_loss: 4.3063\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.8054 - val_loss: 3.1491\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 12.7098 - val_loss: 2.5661\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 13.6857 - val_loss: 2.5967\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.7504 - val_loss: 3.3831\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.4747 - val_loss: 4.6537\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.5897 - val_loss: 5.3684\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.6104 - val_loss: 4.8542\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.5618 - val_loss: 3.9321\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.2093 - val_loss: 2.9555\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.2998 - val_loss: 2.7827\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 13.2417 - val_loss: 2.9039\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 13.9963 - val_loss: 3.1678\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 12.5401 - val_loss: 3.4448\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.1014 - val_loss: 4.1142\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 14.5338 - val_loss: 4.2589\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.1724 - val_loss: 3.8799\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.1036 - val_loss: 3.1092\n",
      "Epoch 201/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 12.6318 - val_loss: 2.8003\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.0261 - val_loss: 3.0206\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.6821 - val_loss: 3.9732\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4802 - val_loss: 4.8999\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.1994 - val_loss: 4.8107\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.8827 - val_loss: 3.0604\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 11.9484 - val_loss: 2.1756\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.8036 - val_loss: 2.3644\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.5458 - val_loss: 3.3186\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.5826 - val_loss: 4.2875\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 13.2636 - val_loss: 5.0579\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.9989 - val_loss: 4.1996\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 11.9291 - val_loss: 3.1579\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.5490 - val_loss: 2.6177\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.2186 - val_loss: 2.6511\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.3417 - val_loss: 3.0889\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.7471 - val_loss: 3.8274\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.0858 - val_loss: 4.3164\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 12.2861 - val_loss: 3.9673\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 12.7223 - val_loss: 3.0187\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.0876 - val_loss: 2.5431\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.8213 - val_loss: 2.6347\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.3850 - val_loss: 3.2163\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.5562 - val_loss: 3.9400\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.0357 - val_loss: 4.1206\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.8306 - val_loss: 3.3353\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.3875 - val_loss: 2.7167\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.9028 - val_loss: 2.7411\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.7348 - val_loss: 3.2101\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.0679 - val_loss: 3.2326\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.1787 - val_loss: 3.2924\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.8770 - val_loss: 3.5994\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.1913 - val_loss: 3.4275\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.3417 - val_loss: 2.7096\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.4255 - val_loss: 2.6416\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.7779 - val_loss: 3.0592\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 10.6409 - val_loss: 3.9047\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4022 - val_loss: 3.3438\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.8023 - val_loss: 2.6167\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.2428 - val_loss: 2.3818\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.3155 - val_loss: 2.5205\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.9591 - val_loss: 3.1444\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.9423 - val_loss: 3.6513\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.8472 - val_loss: 3.4417\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4981 - val_loss: 2.9882\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.6675 - val_loss: 2.8055\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 12.4750 - val_loss: 3.1244\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 11.8553 - val_loss: 3.0388\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.6517 - val_loss: 3.2163\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.4336 - val_loss: 3.5877\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4087 - val_loss: 3.2636\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.2293 - val_loss: 3.1967\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.8109 - val_loss: 3.5485\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.6866 - val_loss: 3.2824\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.9383 - val_loss: 3.1640\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 11.1314 - val_loss: 2.8025\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.8619 - val_loss: 2.6616\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.5875 - val_loss: 3.2362\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.2976 - val_loss: 3.6579\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.0572 - val_loss: 3.8798\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.4740 - val_loss: 3.5583\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.0078 - val_loss: 2.9098\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 12.0782 - val_loss: 2.5786\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 12.4112 - val_loss: 2.9813\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 11.4686 - val_loss: 3.7662\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.7887 - val_loss: 3.7309\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.3586 - val_loss: 3.2157\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10.9504 - val_loss: 2.9416\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.5459 - val_loss: 2.4377\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 10.2071 - val_loss: 2.8249\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.1728 - val_loss: 3.5868\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.7354 - val_loss: 4.1377\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.0802 - val_loss: 3.3139\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.9309 - val_loss: 2.3624\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.2999 - val_loss: 2.5015\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10.3273 - val_loss: 3.3366\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.7013 - val_loss: 3.7877\n",
      "\n",
      "Loading Model: '02-07-2021--10--00-E2E_LSTM_ValSet_0.1-ALPHA1000.0-BETA_SD17-277Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.010997811916933838\n",
      "Model: \"functional_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_130 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_131 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 7.1776e-05 - val_loss: 6.3177e-05\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 6.4818e-05 - val_loss: 5.5937e-05\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.7807e-05 - val_loss: 5.0299e-05\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.2730e-05 - val_loss: 4.4760e-05\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 4.6913e-05 - val_loss: 3.9409e-05\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.2097e-05 - val_loss: 3.4392e-05\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.7372e-05 - val_loss: 2.9744e-05\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.1834e-05 - val_loss: 2.5550e-05\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.8690e-05 - val_loss: 2.1696e-05\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.3848e-05 - val_loss: 1.8106e-05\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1232e-05 - val_loss: 1.4850e-05\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.8259e-05 - val_loss: 1.2043e-05\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.4876e-05 - val_loss: 9.7122e-06\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.3096e-05 - val_loss: 7.9008e-06\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.2784e-05 - val_loss: 6.6807e-06\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.1884e-05 - val_loss: 6.0834e-06\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.2100e-05 - val_loss: 6.0409e-06\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3455e-05 - val_loss: 6.3620e-06\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2975e-05 - val_loss: 6.8016e-06\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4824e-05 - val_loss: 7.1290e-06\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4283e-05 - val_loss: 7.2075e-06\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.6357e-05 - val_loss: 7.0039e-06\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5120e-05 - val_loss: 6.6262e-06\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4712e-05 - val_loss: 6.1955e-06\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.3879e-05 - val_loss: 5.8180e-06\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.2681e-05 - val_loss: 5.5749e-06\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.2223e-05 - val_loss: 5.5000e-06\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1742e-05 - val_loss: 5.5953e-06\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2703e-05 - val_loss: 5.8421e-06\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0506e-05 - val_loss: 6.1923e-06\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0828e-05 - val_loss: 6.5872e-06\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0071e-05 - val_loss: 6.9743e-06\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2118e-05 - val_loss: 7.3192e-06\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1321e-05 - val_loss: 7.5908e-06\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0803e-05 - val_loss: 7.7665e-06\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1022e-05 - val_loss: 7.8457e-06\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3108e-05 - val_loss: 7.8312e-06\n",
      "Epoch 38/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1070e-05 - val_loss: 7.7247e-06\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1089e-05 - val_loss: 7.5475e-06\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0987e-05 - val_loss: 7.3125e-06\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1616e-05 - val_loss: 7.0388e-06\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1298e-05 - val_loss: 6.7582e-06\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0738e-05 - val_loss: 6.4914e-06\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0974e-05 - val_loss: 6.2361e-06\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0152e-05 - val_loss: 6.0085e-06\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0052e-05 - val_loss: 5.8055e-06\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0835e-05 - val_loss: 5.6383e-06\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0749e-05 - val_loss: 5.5004e-06\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.1239e-05 - val_loss: 5.3969e-06\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.0180e-05 - val_loss: 5.3154e-06\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.0698e-05 - val_loss: 5.2595e-06\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0205e-05 - val_loss: 5.2214e-06\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.0406e-05 - val_loss: 5.1972e-06\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.1105e-05 - val_loss: 5.1900e-06\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.8728e-06 - val_loss: 5.1909e-06\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.9839e-06 - val_loss: 5.1993e-06\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0521e-05 - val_loss: 5.2180e-06\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0526e-05 - val_loss: 5.2474e-06\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.7316e-06 - val_loss: 5.2867e-06\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.7134e-06 - val_loss: 5.3335e-06\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8015e-06 - val_loss: 5.3754e-06\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.9362e-06 - val_loss: 5.4132e-06\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3884e-06 - val_loss: 5.4465e-06\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6040e-06 - val_loss: 5.4796e-06\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.5224e-06 - val_loss: 5.5043e-06\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.7017e-06 - val_loss: 5.5068e-06\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6307e-06 - val_loss: 5.4981e-06\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.0290e-06 - val_loss: 5.4838e-06\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1839e-06 - val_loss: 5.4556e-06\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0146e-05 - val_loss: 5.4210e-06\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7056e-06 - val_loss: 5.3741e-06\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.7941e-06 - val_loss: 5.3175e-06\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0208e-05 - val_loss: 5.2553e-06\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.9958e-06 - val_loss: 5.1965e-06\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 9.1557e-06 - val_loss: 5.1362e-06\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 9.2027e-06 - val_loss: 5.0771e-06\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 9.2420e-06 - val_loss: 5.0223e-06\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0533e-05 - val_loss: 4.9830e-06\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 8.9567e-06 - val_loss: 4.9485e-06\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 9.9331e-06 - val_loss: 4.9253e-06\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 8.9385e-06 - val_loss: 4.9055e-06\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 8.8703e-06 - val_loss: 4.8888e-06\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 8.8878e-06 - val_loss: 4.8815e-06\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 8.2841e-06 - val_loss: 4.8728e-06\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 9.3632e-06 - val_loss: 4.8659e-06\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 9.2961e-06 - val_loss: 4.8648e-06\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2101e-06 - val_loss: 4.8699e-06\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.6666e-06 - val_loss: 4.8787e-06\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.9759e-06 - val_loss: 4.8937e-06\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.7374e-06 - val_loss: 4.9166e-06\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5892e-06 - val_loss: 4.9356e-06\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.3350e-06 - val_loss: 4.9531e-06\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0970e-06 - val_loss: 4.9705e-06\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6397e-06 - val_loss: 4.9690e-06\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8492e-06 - val_loss: 4.9567e-06\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.1814e-06 - val_loss: 4.9412e-06\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.4531e-06 - val_loss: 4.9150e-06\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.1769e-06 - val_loss: 4.8838e-06\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.7431e-06 - val_loss: 4.8525e-06\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 8.7934e-06 - val_loss: 4.8236e-06\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.3841e-06 - val_loss: 4.8115e-06\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 9.1957e-06 - val_loss: 4.8084e-06\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 8.1938e-06 - val_loss: 4.8161e-06\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.4878e-06 - val_loss: 4.8341e-06\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.2206e-06 - val_loss: 4.8498e-06\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.8676e-06 - val_loss: 4.8626e-06\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.3864e-06 - val_loss: 4.8738e-06\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6661e-06 - val_loss: 4.8855e-06\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.2981e-06 - val_loss: 4.8997e-06\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.1728e-06 - val_loss: 4.9099e-06\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.3898e-06 - val_loss: 4.9128e-06\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.3911e-06 - val_loss: 4.9129e-06\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.9718e-06 - val_loss: 4.9032e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.9677e-06 - val_loss: 4.8921e-06\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.0711e-06 - val_loss: 4.8740e-06\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.3461e-06 - val_loss: 4.8479e-06\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6031e-06 - val_loss: 4.8267e-06\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0543e-06 - val_loss: 4.8091e-06\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 8.0856e-06 - val_loss: 4.7921e-06\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 7.7851e-06 - val_loss: 4.7737e-06\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 8.0676e-06 - val_loss: 4.7653e-06\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 8.0679e-06 - val_loss: 4.7540e-06\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 8.3312e-06 - val_loss: 4.7496e-06\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.9890e-06 - val_loss: 4.7532e-06\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7319e-06 - val_loss: 4.7546e-06\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.1283e-06 - val_loss: 4.7505e-06\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 8.4730e-06 - val_loss: 4.7490e-06\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 8.0264e-06 - val_loss: 4.7468e-06\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 8.4120e-06 - val_loss: 4.7416e-06\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.4867e-06 - val_loss: 4.7418e-06\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 8.0453e-06 - val_loss: 4.7391e-06\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 8.6148e-06 - val_loss: 4.7333e-06\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 8.3818e-06 - val_loss: 4.7268e-06\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.0788e-06 - val_loss: 4.7325e-06\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 8.3856e-06 - val_loss: 4.7451e-06\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.5329e-06 - val_loss: 4.7450e-06\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.6862e-06 - val_loss: 4.7465e-06\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.1869e-06 - val_loss: 4.7435e-06\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.4070e-06 - val_loss: 4.7397e-06\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.6305e-06 - val_loss: 4.7389e-06\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.1986e-06 - val_loss: 4.7434e-06\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.0978e-06 - val_loss: 4.7512e-06\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.9590e-06 - val_loss: 4.7537e-06\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.3313e-06 - val_loss: 4.7432e-06\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 7.0579e-06 - val_loss: 4.7140e-06\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.1948e-06 - val_loss: 4.6806e-06\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.5011e-06 - val_loss: 4.6543e-06\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 7.1430e-06 - val_loss: 4.6301e-06\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.8684e-06 - val_loss: 4.6303e-06\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.5230e-06 - val_loss: 4.6327e-06\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.5314e-06 - val_loss: 4.6415e-06\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.5649e-06 - val_loss: 4.6465e-06\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.5725e-06 - val_loss: 4.6555e-06\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.7302e-06 - val_loss: 4.6684e-06\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.1096e-06 - val_loss: 4.6731e-06\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.1552e-06 - val_loss: 4.6820e-06\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.2443e-06 - val_loss: 4.6823e-06\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.8272e-06 - val_loss: 4.6710e-06\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.9008e-06 - val_loss: 4.6528e-06\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 7.0967e-06 - val_loss: 4.6218e-06\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 7.6200e-06 - val_loss: 4.5881e-06\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 7.5208e-06 - val_loss: 4.5446e-06\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 7.2661e-06 - val_loss: 4.5090e-06\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.5383e-06 - val_loss: 4.4832e-06\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.7852e-06 - val_loss: 4.4728e-06\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.8393e-06 - val_loss: 4.4708e-06\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 7.4963e-06 - val_loss: 4.4838e-06\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.2409e-06 - val_loss: 4.4956e-06\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.4253e-06 - val_loss: 4.5130e-06\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 7.4946e-06 - val_loss: 4.5375e-06\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.1835e-06 - val_loss: 4.5605e-06\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.9090e-06 - val_loss: 4.5908e-06\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.6599e-06 - val_loss: 4.6112e-06\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.4496e-06 - val_loss: 4.6305e-06\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.9957e-06 - val_loss: 4.6365e-06\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.6259e-06 - val_loss: 4.6289e-06\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.1002e-06 - val_loss: 4.5954e-06\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.8670e-06 - val_loss: 4.5586e-06\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.0906e-06 - val_loss: 4.5227e-06\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.4800e-06 - val_loss: 4.4884e-06\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 7.1714e-06 - val_loss: 4.4642e-06\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.0659e-06 - val_loss: 4.4554e-06\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 7.8083e-06 - val_loss: 4.4530e-06\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.0859e-06 - val_loss: 4.4539e-06\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.1135e-06 - val_loss: 4.4531e-06\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.7579e-06 - val_loss: 4.4657e-06\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.6255e-06 - val_loss: 4.4755e-06\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.4700e-06 - val_loss: 4.4929e-06\n",
      "Epoch 189/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 7.6010e-06 - val_loss: 4.5142e-06\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 7.2847e-06 - val_loss: 4.5388e-06\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.4141e-06 - val_loss: 4.5737e-06\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.7998e-06 - val_loss: 4.5834e-06\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.7338e-06 - val_loss: 4.6029e-06\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.8124e-06 - val_loss: 4.6003e-06\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.5425e-06 - val_loss: 4.5795e-06\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.7582e-06 - val_loss: 4.5450e-06\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.6758e-06 - val_loss: 4.5163e-06\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 7.8783e-06 - val_loss: 4.4887e-06\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.4520e-06 - val_loss: 4.4652e-06\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 7.3851e-06 - val_loss: 4.4457e-06\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 7.0045e-06 - val_loss: 4.4395e-06\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.1553e-06 - val_loss: 4.4443e-06\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.8438e-06 - val_loss: 4.4622e-06\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.7272e-06 - val_loss: 4.4905e-06\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 7.1673e-06 - val_loss: 4.5208e-06\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.9007e-06 - val_loss: 4.5498e-06\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.4553e-06 - val_loss: 4.5738e-06\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.0680e-06 - val_loss: 4.5808e-06\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.9343e-06 - val_loss: 4.5751e-06\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 7.3888e-06 - val_loss: 4.5541e-06\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.0320e-06 - val_loss: 4.5393e-06\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.3791e-06 - val_loss: 4.5075e-06\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5835e-06 - val_loss: 4.4752e-06\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 6.7986e-06 - val_loss: 4.4368e-06\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 7.1901e-06 - val_loss: 4.3992e-06\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.2972e-06 - val_loss: 4.3806e-06\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.8046e-06 - val_loss: 4.3848e-06\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.9825e-06 - val_loss: 4.3938e-06\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.3528e-06 - val_loss: 4.4039e-06\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.8809e-06 - val_loss: 4.4143e-06\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.5326e-06 - val_loss: 4.4306e-06\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5590e-06 - val_loss: 4.4491e-06\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.0218e-06 - val_loss: 4.4697e-06\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.2175e-06 - val_loss: 4.4930e-06\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.5851e-06 - val_loss: 4.5090e-06\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.6389e-06 - val_loss: 4.5211e-06\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.1262e-06 - val_loss: 4.5301e-06\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.4624e-06 - val_loss: 4.5259e-06\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.2777e-06 - val_loss: 4.5276e-06\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.3668e-06 - val_loss: 4.5226e-06\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.9602e-06 - val_loss: 4.5163e-06\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.1304e-06 - val_loss: 4.5246e-06\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.0074e-06 - val_loss: 4.5137e-06\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.3980e-06 - val_loss: 4.4969e-06\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.7876e-06 - val_loss: 4.4890e-06\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.0717e-06 - val_loss: 4.4813e-06\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8131e-06 - val_loss: 4.4757e-06\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.3903e-06 - val_loss: 4.4667e-06\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.7523e-06 - val_loss: 4.4643e-06\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.8830e-06 - val_loss: 4.4630e-06\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.8649e-06 - val_loss: 4.4539e-06\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.3413e-06 - val_loss: 4.4511e-06\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.8602e-06 - val_loss: 4.4447e-06\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.8951e-06 - val_loss: 4.4371e-06\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 7.2424e-06 - val_loss: 4.4471e-06\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5000e-06 - val_loss: 4.4577e-06\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.1825e-06 - val_loss: 4.4716e-06\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 7.0565e-06 - val_loss: 4.4687e-06\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5275e-06 - val_loss: 4.4650e-06\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.1524e-06 - val_loss: 4.4624e-06\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.0511e-06 - val_loss: 4.4559e-06\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.7296e-06 - val_loss: 4.4580e-06\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 7.4844e-06 - val_loss: 4.4737e-06\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.1305e-06 - val_loss: 4.4887e-06\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 6.8441e-06 - val_loss: 4.4952e-06\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.6482e-06 - val_loss: 4.4765e-06\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.5850e-06 - val_loss: 4.4530e-06\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.3487e-06 - val_loss: 4.4461e-06\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.8251e-06 - val_loss: 4.4408e-06\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.4371e-06 - val_loss: 4.4457e-06\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.6652e-06 - val_loss: 4.4634e-06\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.4175e-06 - val_loss: 4.4758e-06\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.2803e-06 - val_loss: 4.5034e-06\n",
      "Epoch 264/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step - loss: 6.3795e-06 - val_loss: 4.5364e-06\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.9323e-06 - val_loss: 4.5634e-06\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.8468e-06 - val_loss: 4.5753e-06\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.9300e-06 - val_loss: 4.5847e-06\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.7615e-06 - val_loss: 4.5810e-06\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.7783e-06 - val_loss: 4.5499e-06\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.3169e-06 - val_loss: 4.5136e-06\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.8780e-06 - val_loss: 4.4864e-06\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.2313e-06 - val_loss: 4.4646e-06\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.7808e-06 - val_loss: 4.4483e-06\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.7713e-06 - val_loss: 4.4322e-06\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2112e-06 - val_loss: 4.4240e-06\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.1226e-06 - val_loss: 4.4055e-06\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.8291e-06 - val_loss: 4.3892e-06\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.9482e-06 - val_loss: 4.3894e-06\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 6.3836e-06 - val_loss: 4.3746e-06\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.1668e-06 - val_loss: 4.3437e-06\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.7550e-06 - val_loss: 4.3162e-06\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.2732e-06 - val_loss: 4.2925e-06\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.3599e-06 - val_loss: 4.2779e-06\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.2375e-06 - val_loss: 4.2662e-06\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.3057e-06 - val_loss: 4.2554e-06\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.3516e-06 - val_loss: 4.2554e-06\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.2175e-06 - val_loss: 4.2739e-06\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.0006e-06 - val_loss: 4.2968e-06\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.4570e-06 - val_loss: 4.3199e-06\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.6314e-06 - val_loss: 4.3523e-06\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.9777e-06 - val_loss: 4.3862e-06\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1602e-06 - val_loss: 4.4030e-06\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.9722e-06 - val_loss: 4.4110e-06\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.9845e-06 - val_loss: 4.4165e-06\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.7225e-06 - val_loss: 4.4153e-06\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.9691e-06 - val_loss: 4.4152e-06\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1018e-06 - val_loss: 4.4122e-06\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5736e-06 - val_loss: 4.3994e-06\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.0393e-06 - val_loss: 4.3985e-06\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.9786e-06 - val_loss: 4.4097e-06\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.5818e-06 - val_loss: 4.4245e-06\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.0759e-06 - val_loss: 4.4279e-06\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.5132e-06 - val_loss: 4.4267e-06\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2380e-06 - val_loss: 4.4165e-06\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.6964e-06 - val_loss: 4.4042e-06\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.4340e-06 - val_loss: 4.4050e-06\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.5711e-06 - val_loss: 4.4142e-06\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.0885e-06 - val_loss: 4.4175e-06\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5512e-06 - val_loss: 4.4313e-06\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.2244e-06 - val_loss: 4.4350e-06\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.8306e-06 - val_loss: 4.4281e-06\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7067e-06 - val_loss: 4.4117e-06\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8528e-06 - val_loss: 4.3962e-06\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.9612e-06 - val_loss: 4.3769e-06\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2883e-06 - val_loss: 4.3654e-06\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.3540e-06 - val_loss: 4.3690e-06\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.9147e-06 - val_loss: 4.3740e-06\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.5676e-06 - val_loss: 4.3905e-06\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.0510e-06 - val_loss: 4.3939e-06\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5875e-06 - val_loss: 4.4120e-06\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.3540e-06 - val_loss: 4.4202e-06\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2821e-06 - val_loss: 4.4205e-06\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.8741e-06 - val_loss: 4.4055e-06\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5819e-06 - val_loss: 4.4014e-06\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.3851e-06 - val_loss: 4.3764e-06\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.0451e-06 - val_loss: 4.3416e-06\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.7119e-06 - val_loss: 4.3202e-06\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.8030e-06 - val_loss: 4.3084e-06\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.1712e-06 - val_loss: 4.2812e-06\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.0301e-06 - val_loss: 4.2396e-06\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.3942e-06 - val_loss: 4.2145e-06\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.9834e-06 - val_loss: 4.2016e-06\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.4056e-06 - val_loss: 4.1940e-06\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.2300e-06 - val_loss: 4.1960e-06\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2047e-06 - val_loss: 4.2113e-06\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5323e-06 - val_loss: 4.2194e-06\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5324e-06 - val_loss: 4.2380e-06\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.6556e-06 - val_loss: 4.2520e-06\n",
      "Epoch 339/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step - loss: 6.5230e-06 - val_loss: 4.2679e-06\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5203e-06 - val_loss: 4.2754e-06\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5607e-06 - val_loss: 4.2734e-06\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.5336e-06 - val_loss: 4.2493e-06\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.8735e-06 - val_loss: 4.2211e-06\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.1945e-06 - val_loss: 4.1838e-06\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.9445e-06 - val_loss: 4.1479e-06\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.4668e-06 - val_loss: 4.1301e-06\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.8919e-06 - val_loss: 4.1345e-06\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.5400e-06 - val_loss: 4.1667e-06\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.4293e-06 - val_loss: 4.2247e-06\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.5079e-06 - val_loss: 4.2830e-06\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.2754e-06 - val_loss: 4.3409e-06\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.8081e-06 - val_loss: 4.3925e-06\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.9516e-06 - val_loss: 4.4012e-06\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.7808e-06 - val_loss: 4.3852e-06\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.9288e-06 - val_loss: 4.3673e-06\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.9345e-06 - val_loss: 4.3311e-06\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5510e-06 - val_loss: 4.3113e-06\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.3553e-06 - val_loss: 4.2937e-06\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.9659e-06 - val_loss: 4.2694e-06\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.3209e-06 - val_loss: 4.2589e-06\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8828e-06 - val_loss: 4.2495e-06\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.4326e-06 - val_loss: 4.2609e-06\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8630e-06 - val_loss: 4.2841e-06\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.1012e-06 - val_loss: 4.3096e-06\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.6874e-06 - val_loss: 4.3297e-06\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.4571e-06 - val_loss: 4.3330e-06\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1161e-06 - val_loss: 4.3476e-06\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.6556e-06 - val_loss: 4.3406e-06\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.4914e-06 - val_loss: 4.3216e-06\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.7169e-06 - val_loss: 4.3200e-06\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7424e-06 - val_loss: 4.3086e-06\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.3913e-06 - val_loss: 4.3068e-06\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.8602e-06 - val_loss: 4.3061e-06\n",
      "Epoch 374/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.7313e-06 - val_loss: 4.3271e-06\n",
      "Epoch 375/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1574e-06 - val_loss: 4.3233e-06\n",
      "Epoch 376/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1511e-06 - val_loss: 4.3083e-06\n",
      "Epoch 377/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.2599e-06 - val_loss: 4.2828e-06\n",
      "Epoch 378/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6782e-06 - val_loss: 4.2635e-06\n",
      "Epoch 379/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.1041e-06 - val_loss: 4.2472e-06\n",
      "Epoch 380/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.9535e-06 - val_loss: 4.2293e-06\n",
      "Epoch 381/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.5075e-06 - val_loss: 4.2243e-06\n",
      "Epoch 382/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.3169e-06 - val_loss: 4.2254e-06\n",
      "Epoch 383/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.7783e-06 - val_loss: 4.2285e-06\n",
      "Epoch 384/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.5368e-06 - val_loss: 4.2312e-06\n",
      "Epoch 385/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.9029e-06 - val_loss: 4.2142e-06\n",
      "Epoch 386/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1140e-06 - val_loss: 4.1904e-06\n",
      "Epoch 387/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.6835e-06 - val_loss: 4.1673e-06\n",
      "Epoch 388/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.9224e-06 - val_loss: 4.1539e-06\n",
      "Epoch 389/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5395e-06 - val_loss: 4.1650e-06\n",
      "Epoch 390/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.3975e-06 - val_loss: 4.1944e-06\n",
      "Epoch 391/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.4948e-06 - val_loss: 4.2284e-06\n",
      "Epoch 392/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.5765e-06 - val_loss: 4.2526e-06\n",
      "Epoch 393/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.6812e-06 - val_loss: 4.2872e-06\n",
      "Epoch 394/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.4010e-06 - val_loss: 4.3266e-06\n",
      "Epoch 395/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.3061e-06 - val_loss: 4.3532e-06\n",
      "Epoch 396/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1579e-06 - val_loss: 4.3707e-06\n",
      "Epoch 397/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.8545e-06 - val_loss: 4.3669e-06\n",
      "Epoch 398/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.1829e-06 - val_loss: 4.3466e-06\n",
      "Epoch 399/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8974e-06 - val_loss: 4.3206e-06\n",
      "Epoch 400/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1707e-06 - val_loss: 4.2954e-06\n",
      "Epoch 401/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6967e-06 - val_loss: 4.2612e-06\n",
      "Epoch 402/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.9966e-06 - val_loss: 4.2411e-06\n",
      "Epoch 403/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.5053e-06 - val_loss: 4.2174e-06\n",
      "Epoch 404/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4183e-06 - val_loss: 4.2099e-06\n",
      "Epoch 405/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.0822e-06 - val_loss: 4.2127e-06\n",
      "Epoch 406/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 6.1502e-06 - val_loss: 4.1985e-06\n",
      "Epoch 407/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2585e-06 - val_loss: 4.1966e-06\n",
      "Epoch 408/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.8878e-06 - val_loss: 4.2139e-06\n",
      "Epoch 409/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.3131e-06 - val_loss: 4.2302e-06\n",
      "Epoch 410/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4755e-06 - val_loss: 4.2255e-06\n",
      "Epoch 411/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5782e-06 - val_loss: 4.1972e-06\n",
      "Epoch 412/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.8107e-06 - val_loss: 4.1841e-06\n",
      "Epoch 413/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.3209e-06 - val_loss: 4.1649e-06\n",
      "Epoch 414/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1269e-06 - val_loss: 4.1453e-06\n",
      "Epoch 415/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.0417e-06 - val_loss: 4.1428e-06\n",
      "Epoch 416/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1247e-06 - val_loss: 4.1447e-06\n",
      "\n",
      "Loading Model: '02-07-2021--10--14-E2E_LSTM_ValSet_0.01-ALPHA0.0001-BETA_SD17-416Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.008305564169278625\n",
      "Model: \"functional_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_134 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_135 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 6.9036e-04 - val_loss: 5.9357e-04\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 5.9076e-04 - val_loss: 4.9605e-04\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 4.9195e-04 - val_loss: 4.2111e-04\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.1861e-04 - val_loss: 3.4980e-04\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.4808e-04 - val_loss: 2.8317e-04\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.8418e-04 - val_loss: 2.2329e-04\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.2829e-04 - val_loss: 1.6922e-04\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.6820e-04 - val_loss: 1.2006e-04\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.2589e-04 - val_loss: 7.7750e-05\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 8.4172e-05 - val_loss: 4.4145e-05\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.1253e-05 - val_loss: 2.2978e-05\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 4.7904e-05 - val_loss: 1.7632e-05\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.2385e-05 - val_loss: 2.6186e-05\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.8493e-05 - val_loss: 3.9356e-05\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1305e-05 - val_loss: 4.6536e-05\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.7391e-05 - val_loss: 4.4612e-05\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0322e-04 - val_loss: 3.6183e-05\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.1509e-05 - val_loss: 2.6354e-05\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.1023e-05 - val_loss: 1.8803e-05\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 5.9889e-05 - val_loss: 1.5056e-05\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0761e-05 - val_loss: 1.5086e-05\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.0717e-05 - val_loss: 1.8199e-05\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1673e-05 - val_loss: 2.3225e-05\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.6855e-05 - val_loss: 2.8880e-05\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5992e-05 - val_loss: 3.4280e-05\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.7915e-05 - val_loss: 3.8819e-05\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.1702e-05 - val_loss: 4.2075e-05\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.4325e-05 - val_loss: 4.3907e-05\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.6725e-05 - val_loss: 4.4380e-05\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.0716e-05 - val_loss: 4.3512e-05\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.2335e-05 - val_loss: 4.1399e-05\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.9076e-05 - val_loss: 3.8345e-05\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9754e-05 - val_loss: 3.4672e-05\n",
      "Epoch 34/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step - loss: 4.9961e-05 - val_loss: 3.0718e-05\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.3136e-05 - val_loss: 2.6746e-05\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.0163e-05 - val_loss: 2.3062e-05\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5763e-05 - val_loss: 1.9784e-05\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.8374e-05 - val_loss: 1.7077e-05\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 3.7348e-05 - val_loss: 1.5053e-05\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.8481e-05 - val_loss: 1.3631e-05\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 4.1205e-05 - val_loss: 1.2716e-05\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 4.4340e-05 - val_loss: 1.2211e-05\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.5113e-05 - val_loss: 1.1955e-05\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 4.0722e-05 - val_loss: 1.1807e-05\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 4.1681e-05 - val_loss: 1.1761e-05\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.0239e-05 - val_loss: 1.1819e-05\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0667e-05 - val_loss: 1.2035e-05\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9523e-05 - val_loss: 1.2418e-05\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0224e-05 - val_loss: 1.3024e-05\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7488e-05 - val_loss: 1.3747e-05\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8059e-05 - val_loss: 1.4621e-05\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8488e-05 - val_loss: 1.5543e-05\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.5498e-05 - val_loss: 1.6390e-05\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.8859e-05 - val_loss: 1.7242e-05\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.6030e-05 - val_loss: 1.7813e-05\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.6453e-05 - val_loss: 1.8045e-05\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.8467e-05 - val_loss: 1.7991e-05\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7329e-05 - val_loss: 1.7704e-05\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.4550e-05 - val_loss: 1.7229e-05\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.4337e-05 - val_loss: 1.6607e-05\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2759e-05 - val_loss: 1.5774e-05\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.4858e-05 - val_loss: 1.4888e-05\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3587e-05 - val_loss: 1.4038e-05\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2077e-05 - val_loss: 1.3316e-05\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2931e-05 - val_loss: 1.2708e-05\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.3817e-05 - val_loss: 1.2137e-05\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.2896e-05 - val_loss: 1.1711e-05\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.4113e-05 - val_loss: 1.1504e-05\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.3366e-05 - val_loss: 1.1433e-05\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.5688e-05 - val_loss: 1.1497e-05\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.0177e-05 - val_loss: 1.1645e-05\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3928e-05 - val_loss: 1.1855e-05\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.5373e-05 - val_loss: 1.2083e-05\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.2314e-05 - val_loss: 1.2402e-05\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1075e-05 - val_loss: 1.2723e-05\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1810e-05 - val_loss: 1.2985e-05\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.3500e-05 - val_loss: 1.3165e-05\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3211e-05 - val_loss: 1.3318e-05\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0017e-05 - val_loss: 1.3323e-05\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.2448e-05 - val_loss: 1.3246e-05\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1093e-05 - val_loss: 1.3050e-05\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0086e-05 - val_loss: 1.2762e-05\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.9661e-05 - val_loss: 1.2498e-05\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.0030e-05 - val_loss: 1.2160e-05\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2284e-05 - val_loss: 1.1764e-05\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.0167e-05 - val_loss: 1.1392e-05\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.9012e-05 - val_loss: 1.1086e-05\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.2955e-05 - val_loss: 1.0832e-05\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.9542e-05 - val_loss: 1.0646e-05\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.2344e-05 - val_loss: 1.0572e-05\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 3.0322e-05 - val_loss: 1.0519e-05\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.8529e-05 - val_loss: 1.0571e-05\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.0645e-05 - val_loss: 1.0736e-05\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9085e-05 - val_loss: 1.0860e-05\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9970e-05 - val_loss: 1.0929e-05\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6856e-05 - val_loss: 1.1012e-05\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7530e-05 - val_loss: 1.0998e-05\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7395e-05 - val_loss: 1.0934e-05\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5575e-05 - val_loss: 1.0800e-05\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8545e-05 - val_loss: 1.0610e-05\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5100e-05 - val_loss: 1.0594e-05\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.8470e-05 - val_loss: 1.0582e-05\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7869e-05 - val_loss: 1.0661e-05\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7412e-05 - val_loss: 1.0785e-05\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6909e-05 - val_loss: 1.0796e-05\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7427e-05 - val_loss: 1.0783e-05\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7518e-05 - val_loss: 1.0658e-05\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8756e-05 - val_loss: 1.0585e-05\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.6129e-05 - val_loss: 1.0512e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.5714e-05 - val_loss: 1.0417e-05\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.6936e-05 - val_loss: 1.0277e-05\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.7930e-05 - val_loss: 1.0056e-05\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.6740e-05 - val_loss: 9.8057e-06\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.6297e-05 - val_loss: 9.6324e-06\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.6046e-05 - val_loss: 9.5721e-06\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.4525e-05 - val_loss: 9.5406e-06\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5650e-05 - val_loss: 9.5516e-06\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7369e-05 - val_loss: 9.6123e-06\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6464e-05 - val_loss: 9.7125e-06\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5399e-05 - val_loss: 9.8125e-06\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.5926e-05 - val_loss: 9.9438e-06\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.5080e-05 - val_loss: 1.0092e-05\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.6317e-05 - val_loss: 1.0202e-05\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6434e-05 - val_loss: 1.0259e-05\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7230e-05 - val_loss: 1.0095e-05\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6742e-05 - val_loss: 9.7434e-06\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.5751e-05 - val_loss: 9.3948e-06\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.6171e-05 - val_loss: 9.0786e-06\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.4964e-05 - val_loss: 8.8043e-06\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.4135e-05 - val_loss: 8.7042e-06\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.5977e-05 - val_loss: 8.6759e-06\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.6156e-05 - val_loss: 8.6690e-06\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7152e-05 - val_loss: 8.7807e-06\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.6358e-05 - val_loss: 9.0809e-06\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6745e-05 - val_loss: 9.4598e-06\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.5758e-05 - val_loss: 9.6442e-06\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5138e-05 - val_loss: 9.7751e-06\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5083e-05 - val_loss: 9.7499e-06\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.3464e-05 - val_loss: 9.6469e-06\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4254e-05 - val_loss: 9.5025e-06\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1954e-05 - val_loss: 9.3528e-06\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4169e-05 - val_loss: 9.3519e-06\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3569e-05 - val_loss: 9.4251e-06\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3280e-05 - val_loss: 9.4271e-06\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2724e-05 - val_loss: 9.1798e-06\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1954e-05 - val_loss: 8.9143e-06\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4666e-05 - val_loss: 8.7915e-06\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3570e-05 - val_loss: 8.7692e-06\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5479e-05 - val_loss: 9.0649e-06\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3819e-05 - val_loss: 9.3821e-06\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3173e-05 - val_loss: 9.6909e-06\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4547e-05 - val_loss: 9.7556e-06\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3785e-05 - val_loss: 9.5994e-06\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4007e-05 - val_loss: 9.3381e-06\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2899e-05 - val_loss: 9.1308e-06\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4876e-05 - val_loss: 9.0106e-06\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4934e-05 - val_loss: 8.8030e-06\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.3651e-05 - val_loss: 8.5776e-06\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.3422e-05 - val_loss: 8.4173e-06\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.3081e-05 - val_loss: 8.3864e-06\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4352e-05 - val_loss: 8.4707e-06\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.4057e-05 - val_loss: 8.4098e-06\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2769e-05 - val_loss: 8.5455e-06\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.2218e-05 - val_loss: 8.7604e-06\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.1174e-05 - val_loss: 9.0547e-06\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2061e-05 - val_loss: 9.3759e-06\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.3620e-05 - val_loss: 9.5764e-06\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3001e-05 - val_loss: 9.4256e-06\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.3528e-05 - val_loss: 8.9738e-06\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.3634e-05 - val_loss: 8.5769e-06\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.2744e-05 - val_loss: 8.3676e-06\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0708e-05 - val_loss: 8.5163e-06\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2221e-05 - val_loss: 8.7483e-06\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2545e-05 - val_loss: 9.0970e-06\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.1168e-05 - val_loss: 9.2705e-06\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2671e-05 - val_loss: 9.1054e-06\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1685e-05 - val_loss: 8.5786e-06\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0610e-05 - val_loss: 8.1096e-06\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.5243e-05 - val_loss: 7.7580e-06\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2760e-05 - val_loss: 7.8506e-06\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1922e-05 - val_loss: 8.1979e-06\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.1343e-05 - val_loss: 8.7924e-06\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.2567e-05 - val_loss: 9.1095e-06\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.2053e-05 - val_loss: 9.2495e-06\n",
      "Epoch 185/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step - loss: 2.1031e-05 - val_loss: 8.8205e-06\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.1636e-05 - val_loss: 8.1818e-06\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0205e-05 - val_loss: 7.7110e-06\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.2154e-05 - val_loss: 7.6063e-06\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3030e-05 - val_loss: 7.7655e-06\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.1569e-05 - val_loss: 8.1594e-06\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.1046e-05 - val_loss: 8.7464e-06\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0945e-05 - val_loss: 9.0114e-06\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1480e-05 - val_loss: 9.1750e-06\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1163e-05 - val_loss: 8.8167e-06\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3053e-05 - val_loss: 8.0990e-06\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9863e-05 - val_loss: 7.4441e-06\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0283e-05 - val_loss: 7.3623e-06\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2750e-05 - val_loss: 7.4531e-06\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1702e-05 - val_loss: 7.8660e-06\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1258e-05 - val_loss: 8.2301e-06\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0124e-05 - val_loss: 8.6998e-06\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1499e-05 - val_loss: 9.0123e-06\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0578e-05 - val_loss: 9.1157e-06\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0240e-05 - val_loss: 9.1130e-06\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0987e-05 - val_loss: 8.9521e-06\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1975e-05 - val_loss: 8.1736e-06\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0158e-05 - val_loss: 7.6056e-06\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9947e-05 - val_loss: 7.4651e-06\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.9373e-05 - val_loss: 7.6501e-06\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.0772e-05 - val_loss: 7.9560e-06\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1331e-05 - val_loss: 8.6868e-06\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.9679e-05 - val_loss: 9.0762e-06\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8860e-05 - val_loss: 9.2088e-06\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.0198e-05 - val_loss: 8.8653e-06\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.1174e-05 - val_loss: 8.3131e-06\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0241e-05 - val_loss: 7.7491e-06\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.0361e-05 - val_loss: 7.6183e-06\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9765e-05 - val_loss: 7.7460e-06\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9020e-05 - val_loss: 8.0113e-06\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9547e-05 - val_loss: 8.2811e-06\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7885e-05 - val_loss: 8.5134e-06\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.9824e-05 - val_loss: 8.6826e-06\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0092e-05 - val_loss: 8.5948e-06\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.8872e-05 - val_loss: 8.2720e-06\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9604e-05 - val_loss: 7.9552e-06\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.8852e-05 - val_loss: 7.6892e-06\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0387e-05 - val_loss: 7.6786e-06\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.8448e-05 - val_loss: 7.9617e-06\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.9612e-05 - val_loss: 8.2608e-06\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.9993e-05 - val_loss: 8.1917e-06\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.9133e-05 - val_loss: 8.1050e-06\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9187e-05 - val_loss: 8.2071e-06\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7746e-05 - val_loss: 8.1389e-06\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.9186e-05 - val_loss: 7.8082e-06\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.8484e-05 - val_loss: 7.7172e-06\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0589e-05 - val_loss: 7.7959e-06\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6949e-05 - val_loss: 8.0574e-06\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9914e-05 - val_loss: 7.9566e-06\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8553e-05 - val_loss: 7.7701e-06\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.9789e-05 - val_loss: 7.5916e-06\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8613e-05 - val_loss: 7.3925e-06\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0442e-05 - val_loss: 7.4596e-06\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9198e-05 - val_loss: 7.6740e-06\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8792e-05 - val_loss: 7.9205e-06\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.9827e-05 - val_loss: 8.2199e-06\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.8373e-05 - val_loss: 8.2734e-06\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0013e-05 - val_loss: 8.1702e-06\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8927e-05 - val_loss: 7.6767e-06\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8846e-05 - val_loss: 7.4766e-06\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8833e-05 - val_loss: 7.6032e-06\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9528e-05 - val_loss: 7.6947e-06\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9360e-05 - val_loss: 8.0290e-06\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9287e-05 - val_loss: 8.4901e-06\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9602e-05 - val_loss: 8.3155e-06\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9029e-05 - val_loss: 7.8920e-06\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.7728e-05 - val_loss: 7.2854e-06\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.8577e-05 - val_loss: 6.9022e-06\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8605e-05 - val_loss: 7.1646e-06\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.8698e-05 - val_loss: 7.8061e-06\n",
      "Epoch 260/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9187e-05 - val_loss: 8.6877e-06\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8592e-05 - val_loss: 9.2258e-06\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7860e-05 - val_loss: 8.7021e-06\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0137e-05 - val_loss: 7.6733e-06\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8649e-05 - val_loss: 6.9839e-06\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8679e-05 - val_loss: 6.9268e-06\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.9322e-05 - val_loss: 7.3020e-06\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9327e-05 - val_loss: 8.0807e-06\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7598e-05 - val_loss: 8.7961e-06\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9133e-05 - val_loss: 8.2737e-06\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6739e-05 - val_loss: 7.4410e-06\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.8687e-05 - val_loss: 6.8804e-06\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.9318e-05 - val_loss: 6.9850e-06\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.8124e-05 - val_loss: 7.3728e-06\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.9404e-05 - val_loss: 7.7259e-06\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7590e-05 - val_loss: 8.1135e-06\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6748e-05 - val_loss: 7.9445e-06\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.8858e-05 - val_loss: 7.4240e-06\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.7057e-05 - val_loss: 7.2831e-06\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6959e-05 - val_loss: 6.9309e-06\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.7710e-05 - val_loss: 7.0114e-06\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.8528e-05 - val_loss: 7.2106e-06\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.8128e-05 - val_loss: 7.5528e-06\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7440e-05 - val_loss: 7.7578e-06\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7570e-05 - val_loss: 7.6483e-06\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6932e-05 - val_loss: 7.3403e-06\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7324e-05 - val_loss: 7.0832e-06\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6452e-05 - val_loss: 7.3738e-06\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7600e-05 - val_loss: 7.5991e-06\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7829e-05 - val_loss: 7.5880e-06\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8103e-05 - val_loss: 7.6266e-06\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8320e-05 - val_loss: 7.5363e-06\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7337e-05 - val_loss: 7.2120e-06\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8097e-05 - val_loss: 7.0335e-06\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.8850e-05 - val_loss: 7.0261e-06\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8320e-05 - val_loss: 7.2455e-06\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8458e-05 - val_loss: 7.4869e-06\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7402e-05 - val_loss: 7.6224e-06\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9176e-05 - val_loss: 7.3487e-06\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8317e-05 - val_loss: 7.2149e-06\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7804e-05 - val_loss: 7.3958e-06\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7146e-05 - val_loss: 7.8876e-06\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.8573e-05 - val_loss: 7.4239e-06\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.6258e-05 - val_loss: 6.8265e-06\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.6946e-05 - val_loss: 6.3904e-06\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.7791e-05 - val_loss: 6.2701e-06\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7329e-05 - val_loss: 6.8343e-06\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6816e-05 - val_loss: 7.4925e-06\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6720e-05 - val_loss: 7.8889e-06\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6145e-05 - val_loss: 8.1787e-06\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7391e-05 - val_loss: 7.4547e-06\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6813e-05 - val_loss: 6.6168e-06\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.5957e-05 - val_loss: 6.2136e-06\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6435e-05 - val_loss: 6.4993e-06\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7577e-05 - val_loss: 7.2759e-06\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6547e-05 - val_loss: 8.1242e-06\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7366e-05 - val_loss: 8.4125e-06\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5486e-05 - val_loss: 7.6379e-06\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7010e-05 - val_loss: 6.6877e-06\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.6498e-05 - val_loss: 6.1106e-06\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7558e-05 - val_loss: 6.2229e-06\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8195e-05 - val_loss: 6.8938e-06\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6982e-05 - val_loss: 7.9271e-06\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8036e-05 - val_loss: 8.2733e-06\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.8660e-05 - val_loss: 7.9424e-06\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5790e-05 - val_loss: 7.1502e-06\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6909e-05 - val_loss: 6.5862e-06\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7616e-05 - val_loss: 6.4425e-06\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5483e-05 - val_loss: 6.9736e-06\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7200e-05 - val_loss: 7.5307e-06\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6390e-05 - val_loss: 7.2339e-06\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7146e-05 - val_loss: 6.7357e-06\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5953e-05 - val_loss: 6.5069e-06\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5936e-05 - val_loss: 6.6078e-06\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5884e-05 - val_loss: 6.9731e-06\n",
      "Epoch 335/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6524e-05 - val_loss: 7.5215e-06\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5476e-05 - val_loss: 7.4357e-06\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7853e-05 - val_loss: 7.1831e-06\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4896e-05 - val_loss: 6.8741e-06\n",
      "Epoch 339/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6572e-05 - val_loss: 6.8546e-06\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6466e-05 - val_loss: 6.6756e-06\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6111e-05 - val_loss: 6.8296e-06\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5349e-05 - val_loss: 6.7825e-06\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5568e-05 - val_loss: 6.6374e-06\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.5842e-05 - val_loss: 6.0740e-06\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4908e-05 - val_loss: 6.0190e-06\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6573e-05 - val_loss: 6.3188e-06\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7393e-05 - val_loss: 6.7658e-06\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6254e-05 - val_loss: 7.2814e-06\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5874e-05 - val_loss: 7.8465e-06\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7276e-05 - val_loss: 7.3970e-06\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6251e-05 - val_loss: 6.5993e-06\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6488e-05 - val_loss: 6.0316e-06\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5684e-05 - val_loss: 6.0215e-06\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6053e-05 - val_loss: 6.8133e-06\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5795e-05 - val_loss: 8.2453e-06\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6262e-05 - val_loss: 7.9648e-06\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7160e-05 - val_loss: 6.9588e-06\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6399e-05 - val_loss: 5.8968e-06\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.6419e-05 - val_loss: 5.6002e-06\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6458e-05 - val_loss: 6.2503e-06\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6503e-05 - val_loss: 7.6088e-06\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6937e-05 - val_loss: 8.5933e-06\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5460e-05 - val_loss: 7.8438e-06\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5712e-05 - val_loss: 6.2636e-06\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.4437e-05 - val_loss: 5.5814e-06\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7188e-05 - val_loss: 5.6305e-06\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6901e-05 - val_loss: 6.9532e-06\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4866e-05 - val_loss: 8.5897e-06\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5220e-05 - val_loss: 8.6710e-06\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5919e-05 - val_loss: 7.4649e-06\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5796e-05 - val_loss: 6.1712e-06\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6132e-05 - val_loss: 5.7322e-06\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5590e-05 - val_loss: 5.9291e-06\n",
      "Epoch 374/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7392e-05 - val_loss: 7.1860e-06\n",
      "Epoch 375/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7351e-05 - val_loss: 8.0626e-06\n",
      "Epoch 376/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5668e-05 - val_loss: 7.6488e-06\n",
      "Epoch 377/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6237e-05 - val_loss: 6.7361e-06\n",
      "Epoch 378/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4732e-05 - val_loss: 6.4413e-06\n",
      "Epoch 379/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6629e-05 - val_loss: 6.5390e-06\n",
      "Epoch 380/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5971e-05 - val_loss: 6.7824e-06\n",
      "Epoch 381/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4385e-05 - val_loss: 7.2994e-06\n",
      "Epoch 382/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.7028e-05 - val_loss: 7.7166e-06\n",
      "Epoch 383/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5759e-05 - val_loss: 7.0878e-06\n",
      "Epoch 384/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6193e-05 - val_loss: 6.2432e-06\n",
      "Epoch 385/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5265e-05 - val_loss: 5.6960e-06\n",
      "Epoch 386/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5204e-05 - val_loss: 5.7589e-06\n",
      "Epoch 387/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5096e-05 - val_loss: 6.6210e-06\n",
      "Epoch 388/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5730e-05 - val_loss: 7.6135e-06\n",
      "Epoch 389/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6101e-05 - val_loss: 7.6265e-06\n",
      "Epoch 390/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6021e-05 - val_loss: 7.0753e-06\n",
      "Epoch 391/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6575e-05 - val_loss: 6.1540e-06\n",
      "Epoch 392/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5613e-05 - val_loss: 5.8141e-06\n",
      "Epoch 393/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5359e-05 - val_loss: 6.5108e-06\n",
      "Epoch 394/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5869e-05 - val_loss: 7.6211e-06\n",
      "Epoch 395/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6301e-05 - val_loss: 8.0774e-06\n",
      "Epoch 396/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6592e-05 - val_loss: 7.7395e-06\n",
      "Epoch 397/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5213e-05 - val_loss: 6.5601e-06\n",
      "Epoch 398/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5240e-05 - val_loss: 5.9205e-06\n",
      "Epoch 399/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5729e-05 - val_loss: 5.9137e-06\n",
      "Epoch 400/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6075e-05 - val_loss: 6.5610e-06\n",
      "Epoch 401/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5026e-05 - val_loss: 7.0722e-06\n",
      "Epoch 402/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4784e-05 - val_loss: 7.3857e-06\n",
      "Epoch 403/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4435e-05 - val_loss: 7.0414e-06\n",
      "Epoch 404/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4145e-05 - val_loss: 6.5725e-06\n",
      "Epoch 405/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6333e-05 - val_loss: 6.2204e-06\n",
      "Epoch 406/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5597e-05 - val_loss: 5.7961e-06\n",
      "Epoch 407/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5865e-05 - val_loss: 6.2025e-06\n",
      "Epoch 408/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4622e-05 - val_loss: 7.3928e-06\n",
      "Epoch 409/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6133e-05 - val_loss: 7.8649e-06\n",
      "Epoch 410/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5102e-05 - val_loss: 7.1899e-06\n",
      "Epoch 411/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6248e-05 - val_loss: 5.8441e-06\n",
      "Epoch 412/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.6207e-05 - val_loss: 5.3974e-06\n",
      "Epoch 413/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5154e-05 - val_loss: 5.7534e-06\n",
      "Epoch 414/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5656e-05 - val_loss: 6.8650e-06\n",
      "Epoch 415/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5284e-05 - val_loss: 8.3232e-06\n",
      "Epoch 416/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5798e-05 - val_loss: 7.9072e-06\n",
      "Epoch 417/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6748e-05 - val_loss: 6.3871e-06\n",
      "Epoch 418/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4505e-05 - val_loss: 5.5307e-06\n",
      "Epoch 419/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6689e-05 - val_loss: 5.5880e-06\n",
      "Epoch 420/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5100e-05 - val_loss: 6.4686e-06\n",
      "Epoch 421/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5818e-05 - val_loss: 8.0756e-06\n",
      "Epoch 422/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5830e-05 - val_loss: 8.5254e-06\n",
      "Epoch 423/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5302e-05 - val_loss: 7.5052e-06\n",
      "Epoch 424/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6143e-05 - val_loss: 6.2933e-06\n",
      "Epoch 425/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4078e-05 - val_loss: 5.5703e-06\n",
      "Epoch 426/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5879e-05 - val_loss: 5.5518e-06\n",
      "Epoch 427/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5713e-05 - val_loss: 6.1537e-06\n",
      "Epoch 428/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4926e-05 - val_loss: 7.2723e-06\n",
      "Epoch 429/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4869e-05 - val_loss: 8.3532e-06\n",
      "Epoch 430/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6103e-05 - val_loss: 8.0724e-06\n",
      "Epoch 431/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5226e-05 - val_loss: 6.8581e-06\n",
      "Epoch 432/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5174e-05 - val_loss: 6.0704e-06\n",
      "Epoch 433/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6458e-05 - val_loss: 5.8602e-06\n",
      "Epoch 434/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6322e-05 - val_loss: 6.1939e-06\n",
      "Epoch 435/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5173e-05 - val_loss: 6.7393e-06\n",
      "Epoch 436/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4733e-05 - val_loss: 7.1697e-06\n",
      "Epoch 437/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3780e-05 - val_loss: 7.1091e-06\n",
      "Epoch 438/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3939e-05 - val_loss: 6.6643e-06\n",
      "Epoch 439/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6104e-05 - val_loss: 6.2451e-06\n",
      "Epoch 440/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5754e-05 - val_loss: 6.2325e-06\n",
      "Epoch 441/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3406e-05 - val_loss: 6.6014e-06\n",
      "Epoch 442/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5056e-05 - val_loss: 7.0300e-06\n",
      "Epoch 443/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.4891e-05 - val_loss: 6.7761e-06\n",
      "Epoch 444/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6057e-05 - val_loss: 6.0549e-06\n",
      "Epoch 445/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4605e-05 - val_loss: 5.7372e-06\n",
      "Epoch 446/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4619e-05 - val_loss: 5.8117e-06\n",
      "Epoch 447/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6339e-05 - val_loss: 6.5992e-06\n",
      "Epoch 448/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5770e-05 - val_loss: 7.0594e-06\n",
      "Epoch 449/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5537e-05 - val_loss: 7.1569e-06\n",
      "Epoch 450/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5581e-05 - val_loss: 6.8528e-06\n",
      "Epoch 451/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5458e-05 - val_loss: 6.5200e-06\n",
      "Epoch 452/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4856e-05 - val_loss: 6.4247e-06\n",
      "Epoch 453/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4639e-05 - val_loss: 6.2191e-06\n",
      "Epoch 454/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5599e-05 - val_loss: 6.4158e-06\n",
      "Epoch 455/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4679e-05 - val_loss: 6.7611e-06\n",
      "Epoch 456/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6583e-05 - val_loss: 7.4014e-06\n",
      "Epoch 457/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4736e-05 - val_loss: 7.3272e-06\n",
      "Epoch 458/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5326e-05 - val_loss: 6.4822e-06\n",
      "Epoch 459/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4703e-05 - val_loss: 5.9155e-06\n",
      "Epoch 460/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4126e-05 - val_loss: 5.7546e-06\n",
      "Epoch 461/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5038e-05 - val_loss: 6.2040e-06\n",
      "Epoch 462/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4448e-05 - val_loss: 7.0532e-06\n",
      "Epoch 463/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5232e-05 - val_loss: 7.3627e-06\n",
      "Epoch 464/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3717e-05 - val_loss: 6.9507e-06\n",
      "Epoch 465/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4769e-05 - val_loss: 6.1032e-06\n",
      "Epoch 466/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4721e-05 - val_loss: 5.9773e-06\n",
      "Epoch 467/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5217e-05 - val_loss: 6.2049e-06\n",
      "Epoch 468/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3595e-05 - val_loss: 6.6819e-06\n",
      "Epoch 469/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4895e-05 - val_loss: 6.8719e-06\n",
      "Epoch 470/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4425e-05 - val_loss: 6.6923e-06\n",
      "Epoch 471/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4209e-05 - val_loss: 6.4268e-06\n",
      "Epoch 472/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5310e-05 - val_loss: 6.0954e-06\n",
      "Epoch 473/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5036e-05 - val_loss: 6.0850e-06\n",
      "Epoch 474/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4920e-05 - val_loss: 6.1054e-06\n",
      "Epoch 475/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4872e-05 - val_loss: 6.7849e-06\n",
      "Epoch 476/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5082e-05 - val_loss: 6.8539e-06\n",
      "Epoch 477/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4379e-05 - val_loss: 6.5678e-06\n",
      "Epoch 478/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5964e-05 - val_loss: 6.1920e-06\n",
      "Epoch 479/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3990e-05 - val_loss: 5.8571e-06\n",
      "Epoch 480/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4787e-05 - val_loss: 5.8938e-06\n",
      "Epoch 481/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4952e-05 - val_loss: 6.7048e-06\n",
      "Epoch 482/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4823e-05 - val_loss: 7.4443e-06\n",
      "\n",
      "Loading Model: '02-07-2021--10--30-E2E_LSTM_ValSet_0.01-ALPHA0.001-BETA_SD17-482Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.011496561314106361\n",
      "Model: \"functional_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_138 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_139 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0013 - val_loss: 7.0829e-04\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 7.6099e-04 - val_loss: 2.7737e-04\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.6877e-04 - val_loss: 1.3755e-04\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.6590e-04 - val_loss: 3.1157e-04\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.5882e-04 - val_loss: 4.8401e-04\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 5.0226e-04\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 4.0250e-04\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1214e-04 - val_loss: 2.7029e-04\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.3410e-04 - val_loss: 1.6575e-04\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.3466e-04 - val_loss: 1.1319e-04\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.6331e-04 - val_loss: 1.1100e-04\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.9433e-04 - val_loss: 1.4717e-04\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.4748e-04 - val_loss: 2.0531e-04\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8310e-04 - val_loss: 2.7005e-04\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9571e-04 - val_loss: 3.3061e-04\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5151e-04 - val_loss: 3.8077e-04\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.3866e-04 - val_loss: 4.1497e-04\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.1318e-04 - val_loss: 4.3116e-04\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.8614e-04 - val_loss: 4.3053e-04\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.8133e-04 - val_loss: 4.1473e-04\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.8399e-04 - val_loss: 3.8592e-04\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.7240e-04 - val_loss: 3.4784e-04\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5409e-04 - val_loss: 3.0484e-04\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.7761e-04 - val_loss: 2.5970e-04\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.7001e-04 - val_loss: 2.1528e-04\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.4153e-04 - val_loss: 1.7526e-04\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3566e-04 - val_loss: 1.4186e-04\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6556e-04 - val_loss: 1.1638e-04\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.1178e-04 - val_loss: 9.8450e-05\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.1199e-04 - val_loss: 8.7158e-05\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.5719e-04 - val_loss: 8.0254e-05\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.2187e-04 - val_loss: 7.6363e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.2779e-04 - val_loss: 7.4277e-05\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.3092e-04 - val_loss: 7.3018e-05\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.4704e-04 - val_loss: 7.2664e-05\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7358e-04 - val_loss: 7.4244e-05\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6190e-04 - val_loss: 7.9251e-05\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2044e-04 - val_loss: 8.6813e-05\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.0804e-04 - val_loss: 9.7597e-05\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.1214e-04 - val_loss: 1.0903e-04\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0791e-04 - val_loss: 1.1984e-04\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.1457e-04 - val_loss: 1.2724e-04\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0967e-04 - val_loss: 1.3185e-04\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1022e-04 - val_loss: 1.3230e-04\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9875e-04 - val_loss: 1.3054e-04\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1122e-04 - val_loss: 1.2648e-04\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.8493e-04 - val_loss: 1.2021e-04\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0279e-04 - val_loss: 1.1425e-04\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8087e-04 - val_loss: 1.0672e-04\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8345e-04 - val_loss: 9.8282e-05\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8895e-04 - val_loss: 9.0073e-05\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8681e-04 - val_loss: 8.2995e-05\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6226e-04 - val_loss: 7.7441e-05\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6093e-04 - val_loss: 7.3422e-05\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.5166e-04 - val_loss: 6.9953e-05\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.6590e-04 - val_loss: 6.7670e-05\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.6391e-04 - val_loss: 6.6681e-05\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4739e-04 - val_loss: 6.7199e-05\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5423e-04 - val_loss: 6.8753e-05\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5946e-04 - val_loss: 7.0033e-05\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5053e-04 - val_loss: 7.2061e-05\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5511e-04 - val_loss: 7.5799e-05\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5706e-04 - val_loss: 7.9772e-05\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6922e-04 - val_loss: 8.3651e-05\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2968e-04 - val_loss: 8.6586e-05\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.5332e-04 - val_loss: 8.7792e-05\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6257e-04 - val_loss: 8.7025e-05\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4327e-04 - val_loss: 8.5691e-05\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.3381e-04 - val_loss: 8.3187e-05\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3819e-04 - val_loss: 7.9679e-05\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5557e-04 - val_loss: 7.5795e-05\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4066e-04 - val_loss: 7.2797e-05\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1870e-04 - val_loss: 6.9529e-05\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3941e-04 - val_loss: 6.6911e-05\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.3468e-04 - val_loss: 6.4732e-05\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.2537e-04 - val_loss: 6.3295e-05\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2508e-04 - val_loss: 6.3739e-05\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3209e-04 - val_loss: 6.4714e-05\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4001e-04 - val_loss: 6.5737e-05\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2157e-04 - val_loss: 6.7191e-05\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1133e-04 - val_loss: 6.9308e-05\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4019e-04 - val_loss: 7.1187e-05\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2114e-04 - val_loss: 7.2806e-05\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3901e-04 - val_loss: 7.4479e-05\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2548e-04 - val_loss: 7.4603e-05\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1352e-04 - val_loss: 7.4803e-05\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.3154e-04 - val_loss: 7.5579e-05\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2647e-04 - val_loss: 7.3818e-05\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2656e-04 - val_loss: 7.0017e-05\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0147e-04 - val_loss: 6.6781e-05\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0878e-04 - val_loss: 6.2626e-05\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0624e-04 - val_loss: 5.9218e-05\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.8747e-04 - val_loss: 5.6209e-05\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1475e-04 - val_loss: 5.4175e-05\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9445e-04 - val_loss: 5.6018e-05\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1294e-04 - val_loss: 5.9051e-05\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1116e-04 - val_loss: 6.4244e-05\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.0423e-04 - val_loss: 7.0186e-05\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0567e-04 - val_loss: 7.2906e-05\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1079e-04 - val_loss: 7.3241e-05\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1091e-04 - val_loss: 6.9870e-05\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1182e-04 - val_loss: 6.6216e-05\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.9515e-04 - val_loss: 6.2093e-05\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.9175e-04 - val_loss: 5.8322e-05\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.9945e-04 - val_loss: 5.4985e-05\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1009e-04 - val_loss: 5.1470e-05\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0020e-04 - val_loss: 4.9375e-05\n",
      "Epoch 114/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9241e-04 - val_loss: 4.9656e-05\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9086e-04 - val_loss: 5.2627e-05\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8502e-04 - val_loss: 5.6384e-05\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8601e-04 - val_loss: 6.0451e-05\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9747e-04 - val_loss: 6.3676e-05\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9306e-04 - val_loss: 6.5644e-05\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8752e-04 - val_loss: 6.4108e-05\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.8397e-04 - val_loss: 6.0814e-05\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.7828e-04 - val_loss: 5.7736e-05\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.8963e-04 - val_loss: 5.4866e-05\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9077e-04 - val_loss: 5.3086e-05\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.9254e-04 - val_loss: 4.9790e-05\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9159e-04 - val_loss: 4.5612e-05\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.8133e-04 - val_loss: 4.4407e-05\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9133e-04 - val_loss: 4.5210e-05\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6998e-04 - val_loss: 4.6895e-05\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7180e-04 - val_loss: 5.2690e-05\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8312e-04 - val_loss: 5.6394e-05\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7954e-04 - val_loss: 5.5714e-05\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9351e-04 - val_loss: 5.2410e-05\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8662e-04 - val_loss: 5.1080e-05\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8754e-04 - val_loss: 5.0114e-05\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.7945e-04 - val_loss: 4.6501e-05\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7765e-04 - val_loss: 4.6388e-05\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7020e-04 - val_loss: 4.7721e-05\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6147e-04 - val_loss: 5.0903e-05\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6909e-04 - val_loss: 5.3968e-05\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5152e-04 - val_loss: 5.5229e-05\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7435e-04 - val_loss: 5.8143e-05\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7163e-04 - val_loss: 5.9946e-05\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5992e-04 - val_loss: 5.5388e-05\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5747e-04 - val_loss: 4.4447e-05\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.5429e-04 - val_loss: 3.9054e-05\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7222e-04 - val_loss: 4.0938e-05\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6657e-04 - val_loss: 5.0546e-05\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.7004e-04 - val_loss: 6.8862e-05\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7065e-04 - val_loss: 7.3340e-05\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5950e-04 - val_loss: 6.2151e-05\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7205e-04 - val_loss: 4.6488e-05\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.6301e-04 - val_loss: 3.6714e-05\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.7192e-04 - val_loss: 3.5280e-05\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6658e-04 - val_loss: 4.3008e-05\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6864e-04 - val_loss: 5.6718e-05\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6426e-04 - val_loss: 6.4431e-05\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5849e-04 - val_loss: 6.0227e-05\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6007e-04 - val_loss: 4.9712e-05\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6465e-04 - val_loss: 4.0927e-05\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6469e-04 - val_loss: 3.6880e-05\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.7039e-04 - val_loss: 3.4965e-05\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5873e-04 - val_loss: 3.9412e-05\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4511e-04 - val_loss: 4.8120e-05\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4672e-04 - val_loss: 5.8775e-05\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5799e-04 - val_loss: 6.4043e-05\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6545e-04 - val_loss: 6.0732e-05\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5887e-04 - val_loss: 5.0650e-05\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6137e-04 - val_loss: 4.0897e-05\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5868e-04 - val_loss: 3.6436e-05\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5673e-04 - val_loss: 3.8716e-05\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3783e-04 - val_loss: 4.7648e-05\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4886e-04 - val_loss: 5.6721e-05\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5383e-04 - val_loss: 6.2844e-05\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4347e-04 - val_loss: 5.9038e-05\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5837e-04 - val_loss: 4.7961e-05\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4155e-04 - val_loss: 3.7196e-05\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4266e-04 - val_loss: 3.2880e-05\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7423e-04 - val_loss: 3.4095e-05\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5773e-04 - val_loss: 4.3466e-05\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4590e-04 - val_loss: 5.6978e-05\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4297e-04 - val_loss: 6.7047e-05\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4990e-04 - val_loss: 6.0550e-05\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5056e-04 - val_loss: 4.8591e-05\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3724e-04 - val_loss: 3.6663e-05\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.4683e-04 - val_loss: 3.0866e-05\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3830e-04 - val_loss: 3.2195e-05\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4928e-04 - val_loss: 4.0229e-05\n",
      "Epoch 189/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4746e-04 - val_loss: 5.1648e-05\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4426e-04 - val_loss: 5.9677e-05\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4514e-04 - val_loss: 5.9611e-05\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4531e-04 - val_loss: 4.8390e-05\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4142e-04 - val_loss: 3.9509e-05\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4307e-04 - val_loss: 3.3028e-05\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.5176e-04 - val_loss: 3.0542e-05\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3679e-04 - val_loss: 3.2550e-05\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4153e-04 - val_loss: 4.2545e-05\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5821e-04 - val_loss: 5.3599e-05\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4231e-04 - val_loss: 5.8285e-05\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4418e-04 - val_loss: 5.0256e-05\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3410e-04 - val_loss: 4.0356e-05\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4730e-04 - val_loss: 3.4525e-05\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3751e-04 - val_loss: 3.5574e-05\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3565e-04 - val_loss: 4.2668e-05\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4178e-04 - val_loss: 5.2596e-05\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3947e-04 - val_loss: 5.0462e-05\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2897e-04 - val_loss: 4.2772e-05\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3315e-04 - val_loss: 3.7298e-05\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3238e-04 - val_loss: 3.4905e-05\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3783e-04 - val_loss: 3.4797e-05\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4426e-04 - val_loss: 4.2139e-05\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3314e-04 - val_loss: 4.7184e-05\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2647e-04 - val_loss: 4.8750e-05\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3498e-04 - val_loss: 4.5017e-05\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4027e-04 - val_loss: 3.9716e-05\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3266e-04 - val_loss: 3.5255e-05\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3856e-04 - val_loss: 3.5242e-05\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2982e-04 - val_loss: 3.8731e-05\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3097e-04 - val_loss: 4.2729e-05\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3473e-04 - val_loss: 4.2667e-05\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1843e-04 - val_loss: 4.0982e-05\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3438e-04 - val_loss: 3.9110e-05\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3201e-04 - val_loss: 3.7722e-05\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2510e-04 - val_loss: 3.7878e-05\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3895e-04 - val_loss: 3.9512e-05\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2665e-04 - val_loss: 3.9169e-05\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3390e-04 - val_loss: 3.9813e-05\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2797e-04 - val_loss: 4.1680e-05\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2720e-04 - val_loss: 4.1625e-05\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3300e-04 - val_loss: 3.5751e-05\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3166e-04 - val_loss: 3.3652e-05\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2983e-04 - val_loss: 3.8224e-05\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2132e-04 - val_loss: 4.2885e-05\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3243e-04 - val_loss: 4.0579e-05\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2206e-04 - val_loss: 3.8241e-05\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3710e-04 - val_loss: 3.6486e-05\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1473e-04 - val_loss: 3.8463e-05\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3263e-04 - val_loss: 3.5802e-05\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2723e-04 - val_loss: 3.4263e-05\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3338e-04 - val_loss: 3.4165e-05\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2451e-04 - val_loss: 3.4041e-05\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4095e-04 - val_loss: 3.6020e-05\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2950e-04 - val_loss: 3.9445e-05\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2827e-04 - val_loss: 3.9969e-05\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3464e-04 - val_loss: 3.8921e-05\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2463e-04 - val_loss: 3.7281e-05\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3648e-04 - val_loss: 3.7825e-05\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2851e-04 - val_loss: 3.4518e-05\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2842e-04 - val_loss: 3.5382e-05\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2470e-04 - val_loss: 4.0330e-05\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3483e-04 - val_loss: 3.9994e-05\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3230e-04 - val_loss: 4.0600e-05\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2707e-04 - val_loss: 4.2538e-05\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2718e-04 - val_loss: 3.7144e-05\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3297e-04 - val_loss: 3.5233e-05\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2015e-04 - val_loss: 3.3317e-05\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2867e-04 - val_loss: 3.3726e-05\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2577e-04 - val_loss: 3.8928e-05\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2406e-04 - val_loss: 4.2281e-05\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3186e-04 - val_loss: 4.3430e-05\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2483e-04 - val_loss: 4.1404e-05\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2078e-04 - val_loss: 3.5963e-05\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3334e-04 - val_loss: 3.2380e-05\n",
      "Epoch 264/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3342e-04 - val_loss: 3.4427e-05\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2469e-04 - val_loss: 4.0645e-05\n",
      "\n",
      "Loading Model: '02-07-2021--10--44-E2E_LSTM_ValSet_0.01-ALPHA0.01-BETA_SD17-265Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.00936637557632516\n",
      "Model: \"functional_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_142 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_143 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.0687 - val_loss: 0.0580\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0574 - val_loss: 0.0472\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0464 - val_loss: 0.0371\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0363 - val_loss: 0.0277\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0271 - val_loss: 0.0195\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0191 - val_loss: 0.0123\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0125 - val_loss: 0.0062\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0069 - val_loss: 0.0022\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0106 - val_loss: 0.0036\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0085 - val_loss: 0.0022\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - val_loss: 0.0013\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - val_loss: 0.0010\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - val_loss: 0.0012\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - val_loss: 9.9196e-04\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - val_loss: 8.6188e-04\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - val_loss: 7.8709e-04\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - val_loss: 7.4338e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - val_loss: 7.1824e-04\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - val_loss: 7.0448e-04\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - val_loss: 6.9963e-04\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - val_loss: 7.0809e-04\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - val_loss: 7.4110e-04\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - val_loss: 8.1058e-04\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 9.0500e-04\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 9.9777e-04\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 9.1355e-04\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 8.3672e-04\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0028 - val_loss: 7.7322e-04\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0025 - val_loss: 7.2315e-04\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0025 - val_loss: 6.8582e-04\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - val_loss: 6.5291e-04\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0026 - val_loss: 6.3158e-04\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0026 - val_loss: 6.2341e-04\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0024 - val_loss: 6.3148e-04\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0025 - val_loss: 6.5093e-04\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 6.6748e-04\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0024 - val_loss: 6.9023e-04\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 7.2877e-04\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 7.7101e-04\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 8.1380e-04\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0022 - val_loss: 8.4750e-04\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0024 - val_loss: 8.6080e-04\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 8.4981e-04\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0023 - val_loss: 8.3013e-04\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0022 - val_loss: 7.9549e-04\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0023 - val_loss: 7.5055e-04\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0024 - val_loss: 7.0338e-04\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0023 - val_loss: 6.6920e-04\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0021 - val_loss: 6.3542e-04\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0023 - val_loss: 6.1070e-04\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023 - val_loss: 5.9354e-04\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0021 - val_loss: 5.8422e-04\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0021 - val_loss: 5.9357e-04\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 6.0672e-04\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0023 - val_loss: 6.1866e-04\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0021 - val_loss: 6.3400e-04\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - val_loss: 6.5401e-04\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0023 - val_loss: 6.7061e-04\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0021 - val_loss: 6.8390e-04\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0023 - val_loss: 6.9701e-04\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0021 - val_loss: 6.9505e-04\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - val_loss: 6.9401e-04\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 6.9826e-04\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 6.8325e-04\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 6.5148e-04\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0019 - val_loss: 6.2386e-04\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0020 - val_loss: 5.8894e-04\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0019 - val_loss: 5.5913e-04\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - val_loss: 5.3208e-04\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - val_loss: 5.1507e-04\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 5.3384e-04\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 5.6427e-04\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 6.1421e-04\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 6.7024e-04\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - val_loss: 6.9666e-04\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - val_loss: 6.9975e-04\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 6.6673e-04\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - val_loss: 6.3091e-04\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 5.9178e-04\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 5.5562e-04\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 5.2276e-04\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0020 - val_loss: 4.8946e-04\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0019 - val_loss: 4.6801e-04\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - val_loss: 4.7056e-04\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 5.0518e-04\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 5.5227e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 5.9845e-04\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - val_loss: 6.2955e-04\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 6.4468e-04\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 6.1884e-04\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 5.7868e-04\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 5.4338e-04\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - val_loss: 5.1940e-04\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0018 - val_loss: 5.1250e-04\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 4.8938e-04\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0018 - val_loss: 4.5057e-04\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0017 - val_loss: 4.4243e-04\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 4.5388e-04\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 4.7630e-04\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 5.3349e-04\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 5.4095e-04\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - val_loss: 5.0291e-04\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - val_loss: 4.6364e-04\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 4.6654e-04\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - val_loss: 4.8442e-04\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 4.7298e-04\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 4.8232e-04\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 4.8649e-04\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 4.9313e-04\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 4.9660e-04\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 4.9092e-04\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 5.4154e-04\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - val_loss: 6.1248e-04\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 5.8484e-04\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 4.4673e-04\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0015 - val_loss: 3.5445e-04\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0016 - val_loss: 3.4310e-04\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 4.1704e-04\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 5.9256e-04\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0016 - val_loss: 6.9595e-04\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 6.5340e-04\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - val_loss: 5.1701e-04\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 3.9300e-04\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0016 - val_loss: 3.3842e-04\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 3.6932e-04\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 4.5589e-04\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 5.3714e-04\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0015 - val_loss: 5.5196e-04\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 5.0925e-04\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 4.5121e-04\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 4.0096e-04\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - val_loss: 3.4752e-04\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 3.5518e-04\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 4.1562e-04\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 5.1977e-04\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 5.9817e-04\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 5.8691e-04\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 4.8376e-04\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 3.7551e-04\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0014 - val_loss: 3.2383e-04\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 3.5027e-04\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 4.4068e-04\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 5.1008e-04\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 5.1758e-04\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 4.3309e-04\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 3.3504e-04\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0013 - val_loss: 2.6969e-04\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 2.7362e-04\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0016 - val_loss: 3.2513e-04\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 4.4314e-04\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 5.3906e-04\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 5.4468e-04\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 4.1045e-04\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 3.1117e-04\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0013 - val_loss: 2.6622e-04\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 2.7896e-04\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.6381e-04\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 4.8476e-04\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 5.3288e-04\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 4.6132e-04\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0014 - val_loss: 3.7260e-04\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 2.9367e-04\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0014 - val_loss: 2.9752e-04\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.2297e-04\n",
      "Epoch 195/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 3.4693e-04\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0013 - val_loss: 3.5321e-04\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 3.9528e-04\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 4.0354e-04\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 3.8499e-04\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 3.2948e-04\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0013 - val_loss: 3.0430e-04\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0014 - val_loss: 3.2095e-04\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.9829e-04\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 4.7085e-04\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 4.6600e-04\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 3.0798e-04\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0012 - val_loss: 2.2668e-04\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0013 - val_loss: 2.4900e-04\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.4451e-04\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0013 - val_loss: 4.2556e-04\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 4.8651e-04\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 3.9255e-04\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 2.9785e-04\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 2.5908e-04\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 2.7858e-04\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 3.3288e-04\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0013 - val_loss: 4.0083e-04\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 4.2021e-04\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 3.6147e-04\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 2.7469e-04\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 2.4907e-04\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 2.8294e-04\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.5608e-04\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 4.1131e-04\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0013 - val_loss: 3.9453e-04\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 3.0611e-04\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0013 - val_loss: 2.6022e-04\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 2.8377e-04\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.4656e-04\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.3864e-04\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.1827e-04\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.3064e-04\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 3.2218e-04\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 2.7024e-04\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 2.7287e-04\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 3.1259e-04\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.7748e-04\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 3.0975e-04\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 2.4753e-04\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 2.3685e-04\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 2.5871e-04\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.1903e-04\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 3.5606e-04\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.2320e-04\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 2.8370e-04\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 2.7836e-04\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 3.1865e-04\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 3.0124e-04\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 3.0685e-04\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 3.3631e-04\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0013 - val_loss: 3.1190e-04\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 3.1564e-04\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.5185e-04\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.1804e-04\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 2.9905e-04\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 2.6302e-04\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 2.5183e-04\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 3.1145e-04\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.6230e-04\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.7866e-04\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 3.4116e-04\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 2.7296e-04\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 2.4431e-04\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - val_loss: 2.8454e-04\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 3.6026e-04\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.5777e-04\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 3.0495e-04\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 2.8138e-04\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 2.3300e-04\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 2.7019e-04\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 3.4118e-04\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.9694e-04\n",
      "Epoch 273/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 3.1669e-04\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0012 - val_loss: 2.2595e-04\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 2.3834e-04\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 3.1422e-04\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 3.5909e-04\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0011 - val_loss: 3.7801e-04\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0011 - val_loss: 2.6779e-04\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0011 - val_loss: 2.3503e-04\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0012 - val_loss: 2.5193e-04\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 3.2099e-04\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 3.7440e-04\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 3.5034e-04\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 2.8321e-04\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 2.4351e-04\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.0783e-04\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.7651e-04\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.5869e-04\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 3.0900e-04\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 2.7585e-04\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0011 - val_loss: 2.5578e-04\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 2.9222e-04\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0012 - val_loss: 3.2621e-04\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 3.3636e-04\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 2.8550e-04\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0011 - val_loss: 2.7073e-04\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 2.5528e-04\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 3.2118e-04\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0011 - val_loss: 3.9165e-04\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 3.9942e-04\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0012 - val_loss: 2.1827e-04\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0010 - val_loss: 1.7332e-04\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0011 - val_loss: 2.5096e-04\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 3.5119e-04\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0011 - val_loss: 3.9113e-04\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 2.5283e-04\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 1.9317e-04\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.9752e-04 - val_loss: 3.0045e-04\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 3.7643e-04\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.2558e-04\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 2.2855e-04\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0010 - val_loss: 2.2369e-04\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 2.9473e-04\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0010 - val_loss: 3.7399e-04\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.7349e-04\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.4919e-04 - val_loss: 2.8293e-04\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 2.1529e-04\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 2.1842e-04\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 2.9806e-04\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.5625e-04\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.2766e-04\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0011 - val_loss: 2.5187e-04\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0012 - val_loss: 2.4974e-04\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 3.2613e-04\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 3.5336e-04\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 2.8449e-04\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5479e-04 - val_loss: 2.6276e-04\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 2.6351e-04\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.8810e-04 - val_loss: 2.3840e-04\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0011 - val_loss: 2.6721e-04\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.5130e-04 - val_loss: 3.1471e-04\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.8094e-04 - val_loss: 3.1397e-04\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.9486e-04 - val_loss: 2.7398e-04\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 2.6026e-04\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5126e-04 - val_loss: 2.5303e-04\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 3.3050e-04\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0209e-04 - val_loss: 3.5004e-04\n",
      "Epoch 339/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.8577e-04 - val_loss: 2.9717e-04\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 2.1183e-04\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.6604e-04 - val_loss: 2.5056e-04\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.4077e-04 - val_loss: 2.9786e-04\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.9039e-04 - val_loss: 3.1216e-04\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.8908e-04 - val_loss: 2.0879e-04\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2327e-04 - val_loss: 1.9936e-04\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 2.6761e-04\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0011 - val_loss: 3.0041e-04\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5100e-04 - val_loss: 2.9120e-04\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.8422e-04 - val_loss: 3.2384e-04\n",
      "Epoch 350/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 2.7595e-04\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 2.3427e-04\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5756e-04 - val_loss: 2.2611e-04\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4784e-04 - val_loss: 2.6390e-04\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6567e-04 - val_loss: 3.1928e-04\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6553e-04 - val_loss: 3.4314e-04\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.9849e-04 - val_loss: 2.2452e-04\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0010 - val_loss: 2.0620e-04\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 2.3461e-04\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 2.5736e-04\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.6044e-04 - val_loss: 3.0889e-04\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 2.9036e-04\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0010 - val_loss: 2.6661e-04\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 9.2722e-04 - val_loss: 2.4879e-04\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.2790e-04 - val_loss: 2.2512e-04\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8492e-04 - val_loss: 2.4197e-04\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.8850e-04 - val_loss: 2.2751e-04\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 3.4657e-04\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1091e-04 - val_loss: 3.0817e-04\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3717e-04 - val_loss: 2.2289e-04\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3424e-04 - val_loss: 2.5114e-04\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.6821e-04 - val_loss: 2.9376e-04\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3417e-04 - val_loss: 2.7704e-04\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.2967e-04 - val_loss: 2.1296e-04\n",
      "\n",
      "Loading Model: '02-07-2021--10--58-E2E_LSTM_ValSet_0.01-ALPHA0.1-BETA_SD17-373Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.013060282804676733\n",
      "Model: \"functional_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_37 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_146 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_147 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 3.0439e-06 - val_loss: 7.0746e-07\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.7289e-06 - val_loss: 7.2799e-07\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9898e-06 - val_loss: 7.2965e-07\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.2609e-06 - val_loss: 7.3560e-07\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9381e-06 - val_loss: 7.2701e-07\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9682e-06 - val_loss: 7.1813e-07\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7033e-06 - val_loss: 7.0755e-07\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.6651e-06 - val_loss: 6.8654e-07\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.8234e-06 - val_loss: 6.6680e-07\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.3438e-06 - val_loss: 6.4829e-07\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.4827e-06 - val_loss: 6.3114e-07\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.5802e-06 - val_loss: 6.1120e-07\n",
      "Epoch 13/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1067e-06 - val_loss: 5.8331e-07\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0893e-06 - val_loss: 5.4713e-07\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.3194e-06 - val_loss: 5.1262e-07\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.1948e-06 - val_loss: 4.7402e-07\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.1009e-06 - val_loss: 4.3103e-07\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.2163e-06 - val_loss: 3.9491e-07\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.8667e-06 - val_loss: 3.6814e-07\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.7385e-06 - val_loss: 3.4259e-07\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.7031e-06 - val_loss: 3.1643e-07\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.7501e-06 - val_loss: 2.9508e-07\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.7615e-06 - val_loss: 2.7549e-07\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.5709e-06 - val_loss: 2.5520e-07\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.4935e-06 - val_loss: 2.3464e-07\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5847e-06 - val_loss: 2.1255e-07\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5203e-06 - val_loss: 1.8527e-07\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.4325e-06 - val_loss: 1.5556e-07\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.3841e-06 - val_loss: 1.1400e-07\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.0996e-06 - val_loss: 4.5017e-08\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 8.9363e-07 - val_loss: 1.9854e-08\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 7.9166e-07 - val_loss: 2.1261e-08\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 7.1532e-07 - val_loss: 2.3495e-08\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.1764e-07 - val_loss: 2.6694e-08\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4250e-07 - val_loss: 2.9942e-08\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.9424e-07 - val_loss: 3.2872e-08\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6958e-07 - val_loss: 3.5076e-08\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.8709e-07 - val_loss: 3.6901e-08\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4229e-07 - val_loss: 3.8015e-08\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.2637e-07 - val_loss: 3.8474e-08\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9364e-07 - val_loss: 3.8401e-08\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9296e-07 - val_loss: 3.7689e-08\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2896e-07 - val_loss: 3.6428e-08\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0795e-07 - val_loss: 3.4845e-08\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2875e-07 - val_loss: 3.3183e-08\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2708e-07 - val_loss: 3.1408e-08\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.4916e-07 - val_loss: 2.9646e-08\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3811e-07 - val_loss: 2.8101e-08\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2432e-07 - val_loss: 2.6779e-08\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9898e-07 - val_loss: 2.5768e-08\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0792e-07 - val_loss: 2.4925e-08\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0365e-07 - val_loss: 2.4350e-08\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2537e-07 - val_loss: 2.4090e-08\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.8046e-07 - val_loss: 2.4175e-08\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9310e-07 - val_loss: 2.4590e-08\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3474e-07 - val_loss: 2.5304e-08\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.0081e-07 - val_loss: 2.6278e-08\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3501e-07 - val_loss: 2.7430e-08\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6768e-07 - val_loss: 2.8711e-08\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7336e-07 - val_loss: 3.0054e-08\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.6431e-07 - val_loss: 3.1452e-08\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6882e-07 - val_loss: 3.2868e-08\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.8835e-07 - val_loss: 3.4333e-08\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6565e-07 - val_loss: 3.5854e-08\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4900e-07 - val_loss: 3.7344e-08\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5195e-07 - val_loss: 3.8788e-08\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6128e-07 - val_loss: 4.0172e-08\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3819e-07 - val_loss: 4.1668e-08\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5952e-07 - val_loss: 4.3138e-08\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4784e-07 - val_loss: 4.4468e-08\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0677e-07 - val_loss: 4.5677e-08\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2121e-07 - val_loss: 4.6759e-08\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3917e-07 - val_loss: 4.7838e-08\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5587e-07 - val_loss: 4.8849e-08\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.3576e-07 - val_loss: 4.9825e-08\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2138e-07 - val_loss: 5.0618e-08\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.1424e-07 - val_loss: 5.1261e-08\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.2883e-07 - val_loss: 5.1738e-08\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.9494e-07 - val_loss: 5.2074e-08\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2886e-07 - val_loss: 5.2407e-08\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1012e-07 - val_loss: 5.2665e-08\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0821e-07 - val_loss: 5.2854e-08\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2870e-07 - val_loss: 5.3222e-08\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8193e-07 - val_loss: 5.3543e-08\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9442e-07 - val_loss: 5.3752e-08\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8908e-07 - val_loss: 5.3892e-08\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8743e-07 - val_loss: 5.3798e-08\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8441e-07 - val_loss: 5.3655e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7924e-07 - val_loss: 5.3379e-08\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8907e-07 - val_loss: 5.2956e-08\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8475e-07 - val_loss: 5.2286e-08\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7765e-07 - val_loss: 5.1399e-08\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6715e-07 - val_loss: 5.0425e-08\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6526e-07 - val_loss: 4.9426e-08\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.6046e-07 - val_loss: 4.8313e-08\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8581e-07 - val_loss: 4.6985e-08\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6336e-07 - val_loss: 4.5525e-08\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8127e-07 - val_loss: 4.3892e-08\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3422e-07 - val_loss: 4.2146e-08\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7394e-07 - val_loss: 4.0257e-08\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.7515e-07 - val_loss: 3.8296e-08\n",
      "\n",
      "Loading Model: '02-07-2021--11--09-E2E_LSTM_ValSet_0.01-ALPHA0-BETA_SD17-101Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 0.0023120121325249402\n",
      "Model: \"functional_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_38 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_150 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_151 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.6873 - val_loss: 0.5792\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.5732 - val_loss: 0.4715\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4630 - val_loss: 0.3701\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3621 - val_loss: 0.2757\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2695 - val_loss: 0.1932\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1896 - val_loss: 0.1211\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1235 - val_loss: 0.0606\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0674 - val_loss: 0.0213\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0433 - val_loss: 0.0163\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0544 - val_loss: 0.0401\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0878 - val_loss: 0.0532\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1134 - val_loss: 0.0484\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1054 - val_loss: 0.0348\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0838 - val_loss: 0.0214\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0644 - val_loss: 0.0129\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0465 - val_loss: 0.0105\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0412 - val_loss: 0.0129\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0368 - val_loss: 0.0184\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0347 - val_loss: 0.0254\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0396 - val_loss: 0.0321\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0414 - val_loss: 0.0378\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0468 - val_loss: 0.0419\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0453 - val_loss: 0.0441\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0521 - val_loss: 0.0443\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0485 - val_loss: 0.0429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0472 - val_loss: 0.0401\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0466 - val_loss: 0.0361\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0449 - val_loss: 0.0316\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0430 - val_loss: 0.0268\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0352 - val_loss: 0.0222\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0344 - val_loss: 0.0180\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0321 - val_loss: 0.0144\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0320 - val_loss: 0.0117\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0358 - val_loss: 0.0097\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0310 - val_loss: 0.0085\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0314 - val_loss: 0.0078\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0354 - val_loss: 0.0074\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0320 - val_loss: 0.0071\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0323 - val_loss: 0.0070\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0323 - val_loss: 0.0070\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0335 - val_loss: 0.0072\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0355 - val_loss: 0.0075\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0347 - val_loss: 0.0083\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0308 - val_loss: 0.0094\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0296 - val_loss: 0.0106\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0305 - val_loss: 0.0118\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0299 - val_loss: 0.0128\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0308 - val_loss: 0.0133\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0300 - val_loss: 0.0136\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0305 - val_loss: 0.0134\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0291 - val_loss: 0.0129\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0301 - val_loss: 0.0122\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0275 - val_loss: 0.0113\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0292 - val_loss: 0.0106\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0271 - val_loss: 0.0097\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0273 - val_loss: 0.0089\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0279 - val_loss: 0.0081\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0279 - val_loss: 0.0076\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0254 - val_loss: 0.0071\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0253 - val_loss: 0.0068\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0243 - val_loss: 0.0065\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0258 - val_loss: 0.0064\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0256 - val_loss: 0.0064\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0238 - val_loss: 0.0065\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0245 - val_loss: 0.0067\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0250 - val_loss: 0.0069\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0238 - val_loss: 0.0072\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0246 - val_loss: 0.0075\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0248 - val_loss: 0.0079\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0258 - val_loss: 0.0083\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0222 - val_loss: 0.0085\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0243 - val_loss: 0.0085\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0254 - val_loss: 0.0083\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0233 - val_loss: 0.0081\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0222 - val_loss: 0.0077\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0227 - val_loss: 0.0073\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0243 - val_loss: 0.0069\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0228 - val_loss: 0.0066\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0208 - val_loss: 0.0063\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0228 - val_loss: 0.0061\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0225 - val_loss: 0.0059\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0214 - val_loss: 0.0059\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0214 - val_loss: 0.0060\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0220 - val_loss: 0.0062\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0228 - val_loss: 0.0063\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0210 - val_loss: 0.0064\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0199 - val_loss: 0.0066\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0225 - val_loss: 0.0068\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0211 - val_loss: 0.0069\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0226 - val_loss: 0.0070\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0213 - val_loss: 0.0069\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0202 - val_loss: 0.0069\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0221 - val_loss: 0.0069\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0215 - val_loss: 0.0068\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0213 - val_loss: 0.0065\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0191 - val_loss: 0.0062\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0197 - val_loss: 0.0059\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0192 - val_loss: 0.0056\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0177 - val_loss: 0.0053\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0197 - val_loss: 0.0052\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0183 - val_loss: 0.0054\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0198 - val_loss: 0.0058\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0198 - val_loss: 0.0063\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0189 - val_loss: 0.0069\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0190 - val_loss: 0.0071\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0195 - val_loss: 0.0071\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0197 - val_loss: 0.0067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0196 - val_loss: 0.0063\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0178 - val_loss: 0.0058\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0176 - val_loss: 0.0055\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0180 - val_loss: 0.0052\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0192 - val_loss: 0.0049\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0184 - val_loss: 0.0047\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0179 - val_loss: 0.0048\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0176 - val_loss: 0.0052\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0174 - val_loss: 0.0057\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0169 - val_loss: 0.0061\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0181 - val_loss: 0.0064\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0173 - val_loss: 0.0064\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0172 - val_loss: 0.0060\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0161 - val_loss: 0.0055\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0163 - val_loss: 0.0052\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0172 - val_loss: 0.0052\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0174 - val_loss: 0.0053\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0175 - val_loss: 0.0052\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0173 - val_loss: 0.0048\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0167 - val_loss: 0.0047\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0172 - val_loss: 0.0047\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0157 - val_loss: 0.0048\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0160 - val_loss: 0.0054\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0168 - val_loss: 0.0055\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0167 - val_loss: 0.0051\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0177 - val_loss: 0.0048\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0168 - val_loss: 0.0048\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0169 - val_loss: 0.0049\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0163 - val_loss: 0.0048\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0161 - val_loss: 0.0048\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0155 - val_loss: 0.0048\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0149 - val_loss: 0.0048\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0156 - val_loss: 0.0049\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0137 - val_loss: 0.0048\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0160 - val_loss: 0.0053\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0157 - val_loss: 0.0060\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0145 - val_loss: 0.0057\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0144 - val_loss: 0.0042\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0144 - val_loss: 0.0034\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0160 - val_loss: 0.0033\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0155 - val_loss: 0.0042\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0155 - val_loss: 0.0061\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0156 - val_loss: 0.0070\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0147 - val_loss: 0.0065\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0156 - val_loss: 0.0050\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0153 - val_loss: 0.0038\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0156 - val_loss: 0.0033\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0151 - val_loss: 0.0037\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0158 - val_loss: 0.0047\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0148 - val_loss: 0.0056\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0145 - val_loss: 0.0058\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0148 - val_loss: 0.0052\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0151 - val_loss: 0.0045\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0145 - val_loss: 0.0039\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0154 - val_loss: 0.0034\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0144 - val_loss: 0.0035\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0133 - val_loss: 0.0042\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0132 - val_loss: 0.0054\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0143 - val_loss: 0.0061\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0151 - val_loss: 0.0058\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0147 - val_loss: 0.0046\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0147 - val_loss: 0.0035\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0143 - val_loss: 0.0031\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0141 - val_loss: 0.0035\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0128 - val_loss: 0.0046\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0133 - val_loss: 0.0053\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0138 - val_loss: 0.0054\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0132 - val_loss: 0.0045\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0144 - val_loss: 0.0034\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0128 - val_loss: 0.0027\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0133 - val_loss: 0.0027\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0157 - val_loss: 0.0032\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0147 - val_loss: 0.0043\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0134 - val_loss: 0.0054\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0130 - val_loss: 0.0056\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0138 - val_loss: 0.0043\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0138 - val_loss: 0.0032\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0128 - val_loss: 0.0026\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0137 - val_loss: 0.0026\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0128 - val_loss: 0.0034\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0135 - val_loss: 0.0046\n",
      "Epoch 189/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0136 - val_loss: 0.0054\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0136 - val_loss: 0.0049\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0136 - val_loss: 0.0040\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0133 - val_loss: 0.0030\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0133 - val_loss: 0.0028\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0133 - val_loss: 0.0029\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0141 - val_loss: 0.0031\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0126 - val_loss: 0.0034\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0131 - val_loss: 0.0041\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0146 - val_loss: 0.0043\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0132 - val_loss: 0.0039\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0132 - val_loss: 0.0031\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0127 - val_loss: 0.0028\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0141 - val_loss: 0.0030\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0128 - val_loss: 0.0040\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0125 - val_loss: 0.0049\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0133 - val_loss: 0.0048\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0129 - val_loss: 0.0031\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0120 - val_loss: 0.0022\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0128 - val_loss: 0.0024\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0126 - val_loss: 0.0033\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0126 - val_loss: 0.0043\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0133 - val_loss: 0.0051\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0130 - val_loss: 0.0042\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0120 - val_loss: 0.0032\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0126 - val_loss: 0.0026\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0133 - val_loss: 0.0027\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0124 - val_loss: 0.0031\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0128 - val_loss: 0.0039\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0121 - val_loss: 0.0043\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0123 - val_loss: 0.0040\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0127 - val_loss: 0.0030\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0111 - val_loss: 0.0025\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0129 - val_loss: 0.0026\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0124 - val_loss: 0.0032\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0116 - val_loss: 0.0039\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0131 - val_loss: 0.0041\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0119 - val_loss: 0.0033\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0125 - val_loss: 0.0027\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0119 - val_loss: 0.0027\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0118 - val_loss: 0.0032\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0121 - val_loss: 0.0032\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0122 - val_loss: 0.0033\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0119 - val_loss: 0.0036\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0112 - val_loss: 0.0034\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0124 - val_loss: 0.0027\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0026\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0128 - val_loss: 0.0030\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0107 - val_loss: 0.0039\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0124 - val_loss: 0.0034\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0118 - val_loss: 0.0027\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0123 - val_loss: 0.0024\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0114 - val_loss: 0.0025\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0130 - val_loss: 0.0031\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0120 - val_loss: 0.0036\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0119 - val_loss: 0.0035\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0125 - val_loss: 0.0030\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0117 - val_loss: 0.0028\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0125 - val_loss: 0.0031\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0119 - val_loss: 0.0030\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0117 - val_loss: 0.0032\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0036\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0125 - val_loss: 0.0033\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0123 - val_loss: 0.0032\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0119 - val_loss: 0.0035\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0117 - val_loss: 0.0032\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0120 - val_loss: 0.0031\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0112 - val_loss: 0.0028\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0119 - val_loss: 0.0027\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0117 - val_loss: 0.0032\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0036\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0121 - val_loss: 0.0038\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0115 - val_loss: 0.0036\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0111 - val_loss: 0.0029\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0122 - val_loss: 0.0025\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0125 - val_loss: 0.0029\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0115 - val_loss: 0.0037\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0118 - val_loss: 0.0037\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0115 - val_loss: 0.0032\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0110 - val_loss: 0.0029\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0116 - val_loss: 0.0024\n",
      "Epoch 270/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0103 - val_loss: 0.0028\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0113 - val_loss: 0.0035\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0118 - val_loss: 0.0041\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0112 - val_loss: 0.0033\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0120 - val_loss: 0.0023\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0113 - val_loss: 0.0025\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0104 - val_loss: 0.0033\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0118 - val_loss: 0.0037\n",
      "\n",
      "Loading Model: '02-07-2021--11--22-E2E_LSTM_ValSet_0.01-ALPHA1.0-BETA_SD17-277Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.010981468930364592\n",
      "Model: \"functional_77\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_154 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_155 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 68.7321 - val_loss: 57.9090\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 57.3135 - val_loss: 47.1335\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 46.2852 - val_loss: 36.9903\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 36.1852 - val_loss: 27.5495\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 26.9256 - val_loss: 19.2946\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 18.9331 - val_loss: 12.0801\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 12.3221 - val_loss: 6.0350\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.7178 - val_loss: 2.1199\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 4.3246 - val_loss: 1.6480\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4663 - val_loss: 4.0306\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.8177 - val_loss: 5.3230\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.3530 - val_loss: 4.8331\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10.5254 - val_loss: 3.4622\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.3567 - val_loss: 2.1233\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 6.4157 - val_loss: 1.2857\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 4.6287 - val_loss: 1.0447\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1109 - val_loss: 1.2917\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6752 - val_loss: 1.8545\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4772 - val_loss: 2.5494\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9679 - val_loss: 3.2249\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1486 - val_loss: 3.7895\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.6801 - val_loss: 4.1987\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.5365 - val_loss: 4.4151\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.2122 - val_loss: 4.4362\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.8540 - val_loss: 4.2892\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.7172 - val_loss: 4.0037\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.6574 - val_loss: 3.6101\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.4828 - val_loss: 3.1517\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2924 - val_loss: 2.6772\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5191 - val_loss: 2.2178\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4384 - val_loss: 1.7942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2095 - val_loss: 1.4373\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2028 - val_loss: 1.1615\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.5811 - val_loss: 0.9691\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 3.0989 - val_loss: 0.8468\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.1368 - val_loss: 0.7776\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.5370 - val_loss: 0.7375\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 3.2034 - val_loss: 0.7147\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.2268 - val_loss: 0.7036\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 3.2275 - val_loss: 0.7031\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.3507 - val_loss: 0.7169\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5451 - val_loss: 0.7574\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4630 - val_loss: 0.8371\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0820 - val_loss: 0.9406\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9546 - val_loss: 1.0666\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.0465 - val_loss: 1.1839\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9900 - val_loss: 1.2820\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0775 - val_loss: 1.3381\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9998 - val_loss: 1.3617\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0535 - val_loss: 1.3375\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9066 - val_loss: 1.2878\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0100 - val_loss: 1.2164\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7491 - val_loss: 1.1282\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9201 - val_loss: 1.0509\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7095 - val_loss: 0.9663\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7242 - val_loss: 0.8821\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.7857 - val_loss: 0.8092\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7898 - val_loss: 0.7520\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5352 - val_loss: 0.7091\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.5320 - val_loss: 0.6796\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.4332 - val_loss: 0.6542\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.5804 - val_loss: 0.6396\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.5529 - val_loss: 0.6380\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.3781 - val_loss: 0.6522\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4480 - val_loss: 0.6768\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5010 - val_loss: 0.6959\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3803 - val_loss: 0.7193\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4524 - val_loss: 0.7569\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4822 - val_loss: 0.7934\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5747 - val_loss: 0.8258\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2126 - val_loss: 0.8467\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4250 - val_loss: 0.8485\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5315 - val_loss: 0.8287\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3247 - val_loss: 0.8044\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2111 - val_loss: 0.7693\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2644 - val_loss: 0.7261\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.4301 - val_loss: 0.6827\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2777 - val_loss: 0.6535\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0724 - val_loss: 0.6253\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.2728 - val_loss: 0.6060\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2491 - val_loss: 0.5940\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1405 - val_loss: 0.5892\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1317 - val_loss: 0.6026\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1989 - val_loss: 0.6188\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2721 - val_loss: 0.6319\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0942 - val_loss: 0.6467\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9904 - val_loss: 0.6649\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2454 - val_loss: 0.6784\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1037 - val_loss: 0.6884\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.2581 - val_loss: 0.6984\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1216 - val_loss: 0.6926\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0197 - val_loss: 0.6888\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2032 - val_loss: 0.6919\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1479 - val_loss: 0.6770\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1273 - val_loss: 0.6457\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9062 - val_loss: 0.6197\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9684 - val_loss: 0.5869\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9166 - val_loss: 0.5593\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7693 - val_loss: 0.5348\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9643 - val_loss: 0.5216\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8286 - val_loss: 0.5455\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9704 - val_loss: 0.5804\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9756 - val_loss: 0.6335\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8834 - val_loss: 0.6895\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8880 - val_loss: 0.7104\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9443 - val_loss: 0.7066\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9655 - val_loss: 0.6658\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9543 - val_loss: 0.6222\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7682 - val_loss: 0.5785\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7567 - val_loss: 0.5418\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.7916 - val_loss: 0.5121\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9123 - val_loss: 0.4838\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.8342 - val_loss: 0.4699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7867 - val_loss: 0.4809\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7469 - val_loss: 0.5247\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7331 - val_loss: 0.5789\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6814 - val_loss: 0.6251\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8050 - val_loss: 0.6442\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7229 - val_loss: 0.6420\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7127 - val_loss: 0.5969\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6055 - val_loss: 0.5493\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6280 - val_loss: 0.5223\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7100 - val_loss: 0.5219\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7306 - val_loss: 0.5429\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7442 - val_loss: 0.5360\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7243 - val_loss: 0.4948\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6588 - val_loss: 0.4783\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7150 - val_loss: 0.4760\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5617 - val_loss: 0.4875\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5934 - val_loss: 0.5432\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6671 - val_loss: 0.5530\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6652 - val_loss: 0.5169\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7582 - val_loss: 0.4777\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6757 - val_loss: 0.4807\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6750 - val_loss: 0.4931\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6244 - val_loss: 0.4718\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6046 - val_loss: 0.4725\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5416 - val_loss: 0.4732\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4808 - val_loss: 0.4815\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5506 - val_loss: 0.4867\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3661 - val_loss: 0.4831\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5876 - val_loss: 0.5343\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5626 - val_loss: 0.6042\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4458 - val_loss: 0.5608\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.4313 - val_loss: 0.4129\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4316 - val_loss: 0.3320\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5918 - val_loss: 0.3349\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5364 - val_loss: 0.4279\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5391 - val_loss: 0.6252\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5571 - val_loss: 0.7126\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4661 - val_loss: 0.6406\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5519 - val_loss: 0.4887\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5214 - val_loss: 0.3694\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.5582 - val_loss: 0.3294\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5110 - val_loss: 0.3801\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5734 - val_loss: 0.4896\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4755 - val_loss: 0.5844\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4438 - val_loss: 0.5896\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4757 - val_loss: 0.5241\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5010 - val_loss: 0.4455\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4416 - val_loss: 0.3843\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.5316 - val_loss: 0.3291\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4389 - val_loss: 0.3432\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3207 - val_loss: 0.4202\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3186 - val_loss: 0.5413\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4191 - val_loss: 0.6187\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5022 - val_loss: 0.5868\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4669 - val_loss: 0.4679\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4637 - val_loss: 0.3590\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4269 - val_loss: 0.3143\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4031 - val_loss: 0.3494\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2828 - val_loss: 0.4475\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3226 - val_loss: 0.5266\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3767 - val_loss: 0.5415\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3182 - val_loss: 0.4598\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4352 - val_loss: 0.3552\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.2756 - val_loss: 0.2776\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.3229 - val_loss: 0.2703\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5650 - val_loss: 0.3099\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4647 - val_loss: 0.4237\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3295 - val_loss: 0.5398\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2974 - val_loss: 0.5682\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3780 - val_loss: 0.4308\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3807 - val_loss: 0.3152\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.2712 - val_loss: 0.2570\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3686 - val_loss: 0.2599\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2753 - val_loss: 0.3383\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3476 - val_loss: 0.4651\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3591 - val_loss: 0.5365\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3612 - val_loss: 0.4853\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3563 - val_loss: 0.3934\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3212 - val_loss: 0.2957\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3301 - val_loss: 0.2783\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3243 - val_loss: 0.2901\n",
      "Epoch 195/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3999 - val_loss: 0.3163\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2541 - val_loss: 0.3439\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3103 - val_loss: 0.4110\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.4536 - val_loss: 0.4259\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3174 - val_loss: 0.3881\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3106 - val_loss: 0.3109\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2634 - val_loss: 0.2797\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4028 - val_loss: 0.3014\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2685 - val_loss: 0.3965\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2482 - val_loss: 0.4895\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3201 - val_loss: 0.4812\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2886 - val_loss: 0.3063\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.1950 - val_loss: 0.2175\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2803 - val_loss: 0.2360\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2548 - val_loss: 0.3308\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2584 - val_loss: 0.4275\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3266 - val_loss: 0.5051\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3000 - val_loss: 0.4198\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1931 - val_loss: 0.3158\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2550 - val_loss: 0.2616\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3219 - val_loss: 0.2646\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2343 - val_loss: 0.3080\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2750 - val_loss: 0.3817\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2088 - val_loss: 0.4310\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2288 - val_loss: 0.3967\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2725 - val_loss: 0.3019\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1088 - val_loss: 0.2540\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2822 - val_loss: 0.2628\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2387 - val_loss: 0.3205\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1557 - val_loss: 0.3929\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3037 - val_loss: 0.4118\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1833 - val_loss: 0.3338\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2390 - val_loss: 0.2717\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1904 - val_loss: 0.2734\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1738 - val_loss: 0.3196\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2070 - val_loss: 0.3220\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2180 - val_loss: 0.3286\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1879 - val_loss: 0.3598\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1194 - val_loss: 0.3427\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2344 - val_loss: 0.2706\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1427 - val_loss: 0.2632\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2780 - val_loss: 0.3046\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0644 - val_loss: 0.3894\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2403 - val_loss: 0.3343\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1804 - val_loss: 0.2619\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2243 - val_loss: 0.2380\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1318 - val_loss: 0.2512\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2963 - val_loss: 0.3132\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1944 - val_loss: 0.3644\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1849 - val_loss: 0.3443\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2501 - val_loss: 0.2990\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1670 - val_loss: 0.2802\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2479 - val_loss: 0.3114\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1857 - val_loss: 0.3028\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1655 - val_loss: 0.3212\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1437 - val_loss: 0.3591\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2413 - val_loss: 0.3266\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2232 - val_loss: 0.3191\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1814 - val_loss: 0.3535\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1689 - val_loss: 0.3271\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1942 - val_loss: 0.3159\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1133 - val_loss: 0.2803\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1865 - val_loss: 0.2661\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1589 - val_loss: 0.3227\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1302 - val_loss: 0.3645\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2060 - val_loss: 0.3871\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1477 - val_loss: 0.3558\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1011 - val_loss: 0.2911\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2082 - val_loss: 0.2576\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2414 - val_loss: 0.2974\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1472 - val_loss: 0.3760\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1792 - val_loss: 0.3731\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1363 - val_loss: 0.3219\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0953 - val_loss: 0.2943\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1550 - val_loss: 0.2436\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0211 - val_loss: 0.2823\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1178 - val_loss: 0.3588\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1738 - val_loss: 0.4143\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1086 - val_loss: 0.3316\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1936 - val_loss: 0.2361\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1304 - val_loss: 0.2500\n",
      "Epoch 276/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0330 - val_loss: 0.3336\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1704 - val_loss: 0.3787\n",
      "\n",
      "Loading Model: '02-07-2021--11--35-E2E_LSTM_ValSet_0.01-ALPHA100.0-BETA_SD17-277Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.010997811916933838\n",
      "Model: \"functional_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_158 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_159 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 687.3209 - val_loss: 579.0888\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 573.1340 - val_loss: 471.3334\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 462.8503 - val_loss: 369.9013\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 361.8495 - val_loss: 275.4920\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 269.2529 - val_loss: 192.9429\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 189.3280 - val_loss: 120.7980\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 123.2179 - val_loss: 60.3467\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 67.1754 - val_loss: 21.1978\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 43.2452 - val_loss: 16.4818\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 54.6670 - val_loss: 40.3089\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 88.1813 - val_loss: 53.2310\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 113.5312 - val_loss: 48.3298\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 105.2521 - val_loss: 34.6195\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 83.5636 - val_loss: 21.2310\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 64.1538 - val_loss: 12.8560\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 46.2845 - val_loss: 10.4473\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 41.1076 - val_loss: 12.9182\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 36.7518 - val_loss: 18.5464\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 34.7720 - val_loss: 25.4951\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 39.6799 - val_loss: 32.2502\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 41.4869 - val_loss: 37.8964\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 46.8011 - val_loss: 41.9878\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 45.3653 - val_loss: 44.1517\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 52.1220 - val_loss: 44.3616\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 48.5394 - val_loss: 42.8920\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 47.1718 - val_loss: 40.0358\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 46.5727 - val_loss: 36.0995\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 44.8272 - val_loss: 31.5164\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 42.9237 - val_loss: 26.7712\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 35.1907 - val_loss: 22.1770\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 34.3837 - val_loss: 17.9413\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 32.0942 - val_loss: 14.3728\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 32.0285 - val_loss: 11.6149\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 35.8113 - val_loss: 9.6911\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 30.9902 - val_loss: 8.4678\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 31.3692 - val_loss: 7.7761\n",
      "Epoch 37/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 35.3707 - val_loss: 7.3754\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 32.0345 - val_loss: 7.1472\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 32.2680 - val_loss: 7.0364\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 32.2752 - val_loss: 7.0318\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 33.5074 - val_loss: 7.1700\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 35.4513 - val_loss: 7.5752\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 34.6310 - val_loss: 8.3724\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.8203 - val_loss: 9.4079\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 29.5479 - val_loss: 10.6679\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 30.4653 - val_loss: 11.8408\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 29.9009 - val_loss: 12.8217\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.7769 - val_loss: 13.3819\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 29.9996 - val_loss: 13.6173\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.5357 - val_loss: 13.3750\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 29.0668 - val_loss: 12.8775\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 30.1013 - val_loss: 12.1626\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 27.4913 - val_loss: 11.2803\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 29.2020 - val_loss: 10.5069\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 27.0956 - val_loss: 9.6614\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 27.2418 - val_loss: 8.8202\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 27.8578 - val_loss: 8.0912\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 27.8977 - val_loss: 7.5203\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 25.3524 - val_loss: 7.0917\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 25.3203 - val_loss: 6.7978\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 24.3325 - val_loss: 6.5439\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 25.8040 - val_loss: 6.3977\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 25.5278 - val_loss: 6.3814\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 23.7811 - val_loss: 6.5231\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 24.4798 - val_loss: 6.7697\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 25.0108 - val_loss: 6.9589\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 23.8036 - val_loss: 7.1917\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 24.5245 - val_loss: 7.5664\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 24.8222 - val_loss: 7.9308\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 25.7471 - val_loss: 8.2536\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.1258 - val_loss: 8.4625\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 24.2489 - val_loss: 8.4804\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 25.3142 - val_loss: 8.2835\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 23.2470 - val_loss: 8.0414\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 22.1103 - val_loss: 7.6912\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.6437 - val_loss: 7.2613\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 24.3013 - val_loss: 6.8275\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 22.7769 - val_loss: 6.5363\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 20.7244 - val_loss: 6.2546\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 22.7280 - val_loss: 6.0620\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 22.4908 - val_loss: 5.9418\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 21.4048 - val_loss: 5.8928\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 21.3169 - val_loss: 6.0270\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 21.9881 - val_loss: 6.1878\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 22.7204 - val_loss: 6.3189\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 20.9424 - val_loss: 6.4662\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.9038 - val_loss: 6.6475\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 22.4537 - val_loss: 6.7823\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 21.0360 - val_loss: 6.8823\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.5804 - val_loss: 6.9821\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 21.2151 - val_loss: 6.9250\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 20.1959 - val_loss: 6.8872\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22.0315 - val_loss: 6.9180\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 21.4793 - val_loss: 6.7691\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 21.2723 - val_loss: 6.4565\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.0606 - val_loss: 6.1969\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.6841 - val_loss: 5.8686\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.1652 - val_loss: 5.5925\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 17.6921 - val_loss: 5.3474\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.6420 - val_loss: 5.2160\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 18.2856 - val_loss: 5.4546\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 19.7032 - val_loss: 5.8042\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 19.7553 - val_loss: 6.3354\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 18.8329 - val_loss: 6.8957\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 18.8790 - val_loss: 7.1036\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.4424 - val_loss: 7.0657\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.6535 - val_loss: 6.6569\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 19.5411 - val_loss: 6.2203\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.6813 - val_loss: 5.7828\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.5663 - val_loss: 5.4162\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 17.9151 - val_loss: 5.1198\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.1218 - val_loss: 4.8369\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 18.3410 - val_loss: 4.6990\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 17.8655 - val_loss: 4.8100\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.4670 - val_loss: 5.2493\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.3303 - val_loss: 5.7916\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 16.8137 - val_loss: 6.2520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 18.0487 - val_loss: 6.4415\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 17.2278 - val_loss: 6.4168\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.1249 - val_loss: 5.9645\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.0533 - val_loss: 5.4888\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.2784 - val_loss: 5.2212\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 17.0992 - val_loss: 5.2197\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.3043 - val_loss: 5.4319\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.4410 - val_loss: 5.3636\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 17.2418 - val_loss: 4.9498\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.5866 - val_loss: 4.7821\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 17.1481 - val_loss: 4.7577\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.6164 - val_loss: 4.8722\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.9329 - val_loss: 5.4298\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 16.6693 - val_loss: 5.5281\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.6502 - val_loss: 5.1669\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 17.5805 - val_loss: 4.7747\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.7561 - val_loss: 4.8049\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.7480 - val_loss: 4.9289\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 16.2422 - val_loss: 4.7162\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 16.0440 - val_loss: 4.7231\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.4149 - val_loss: 4.7289\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.8077 - val_loss: 4.8114\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 15.5055 - val_loss: 4.8634\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.6602 - val_loss: 4.8287\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 15.8740 - val_loss: 5.3425\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.6245 - val_loss: 6.0426\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.4568 - val_loss: 5.6074\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 14.3114 - val_loss: 4.1276\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 14.3153 - val_loss: 3.3182\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.9169 - val_loss: 3.3472\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.3612 - val_loss: 4.2767\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.3892 - val_loss: 6.2506\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.5690 - val_loss: 7.1244\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.6595 - val_loss: 6.4044\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 15.5160 - val_loss: 4.8850\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.2126 - val_loss: 3.6925\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 15.5805 - val_loss: 3.2928\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.1076 - val_loss: 3.8005\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 15.7312 - val_loss: 4.8969\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 14.7525 - val_loss: 5.8437\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 14.4366 - val_loss: 5.8933\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.7538 - val_loss: 5.2367\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 15.0083 - val_loss: 4.4518\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 14.4130 - val_loss: 3.8414\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 15.3136 - val_loss: 3.2919\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 14.3854 - val_loss: 3.4335\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 13.2054 - val_loss: 4.2049\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 13.1833 - val_loss: 5.4154\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.1874 - val_loss: 6.1871\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 15.0193 - val_loss: 5.8667\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.6638 - val_loss: 4.6777\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.6319 - val_loss: 3.5894\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 14.2666 - val_loss: 3.1417\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.0264 - val_loss: 3.4935\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.8253 - val_loss: 4.4751\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.2238 - val_loss: 5.2667\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.7613 - val_loss: 5.4147\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.1787 - val_loss: 4.5941\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 14.3492 - val_loss: 3.5436\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 12.7511 - val_loss: 2.7677\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 13.2236 - val_loss: 2.6967\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 15.6400 - val_loss: 3.1010\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 14.6319 - val_loss: 4.2616\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.2898 - val_loss: 5.3979\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.9755 - val_loss: 5.6459\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.7592 - val_loss: 4.2626\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.8027 - val_loss: 3.1206\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 12.7058 - val_loss: 2.5584\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.6878 - val_loss: 2.6079\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.7414 - val_loss: 3.4123\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.4735 - val_loss: 4.6811\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.5902 - val_loss: 5.3642\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.6058 - val_loss: 4.8177\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.5548 - val_loss: 3.8938\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2018 - val_loss: 2.9387\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.3040 - val_loss: 2.7911\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2419 - val_loss: 2.9322\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 13.9904 - val_loss: 3.1985\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.5383 - val_loss: 3.4564\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.1014 - val_loss: 4.0972\n",
      "Epoch 198/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 14.5300 - val_loss: 4.2252\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 13.1692 - val_loss: 3.8583\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.1009 - val_loss: 3.1101\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.6340 - val_loss: 2.8175\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 14.0201 - val_loss: 3.0454\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.6748 - val_loss: 3.9953\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4829 - val_loss: 4.8928\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 13.1925 - val_loss: 4.7760\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.8675 - val_loss: 3.0286\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 11.9483 - val_loss: 2.1667\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.8094 - val_loss: 2.3798\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.5349 - val_loss: 3.3640\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.5839 - val_loss: 4.3232\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 13.2645 - val_loss: 5.0402\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.9934 - val_loss: 4.1323\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.9192 - val_loss: 3.1034\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.5533 - val_loss: 2.6038\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.2194 - val_loss: 2.6778\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.3303 - val_loss: 3.1432\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 12.7373 - val_loss: 3.8709\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.0880 - val_loss: 4.3007\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.2799 - val_loss: 3.9006\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.7048 - val_loss: 2.9618\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.0943 - val_loss: 2.5293\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.8228 - val_loss: 2.6664\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.3749 - val_loss: 3.2777\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.5525 - val_loss: 3.9753\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 13.0364 - val_loss: 4.0869\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.8215 - val_loss: 3.2740\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.3842 - val_loss: 2.6834\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.9089 - val_loss: 2.7542\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.7322 - val_loss: 3.2637\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 12.0738 - val_loss: 3.2734\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 12.1774 - val_loss: 3.2823\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.8757 - val_loss: 3.5470\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.1830 - val_loss: 3.3899\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.3317 - val_loss: 2.7165\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.4225 - val_loss: 2.6757\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.7692 - val_loss: 3.0914\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10.6346 - val_loss: 3.8998\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.3994 - val_loss: 3.3035\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.7952 - val_loss: 2.5883\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 12.2452 - val_loss: 2.3852\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.3117 - val_loss: 2.5513\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.9497 - val_loss: 3.1828\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.9429 - val_loss: 3.6541\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.8436 - val_loss: 3.4070\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.4915 - val_loss: 2.9581\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.6670 - val_loss: 2.8088\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4712 - val_loss: 3.1635\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.8582 - val_loss: 3.0724\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.6473 - val_loss: 3.2189\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.4310 - val_loss: 3.5604\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.4004 - val_loss: 3.2362\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.2275 - val_loss: 3.1994\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.8086 - val_loss: 3.5873\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.6887 - val_loss: 3.3106\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.9338 - val_loss: 3.1602\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.1291 - val_loss: 2.7791\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.8607 - val_loss: 2.6498\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.5887 - val_loss: 3.2575\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.2950 - val_loss: 3.6959\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.0563 - val_loss: 3.8924\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.4718 - val_loss: 3.5344\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.0019 - val_loss: 2.8860\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 12.0772 - val_loss: 2.5820\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.4079 - val_loss: 3.0118\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.4633 - val_loss: 3.7977\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.7893 - val_loss: 3.7246\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.3542 - val_loss: 3.1889\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10.9483 - val_loss: 2.9315\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.5407 - val_loss: 2.4532\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 10.1997 - val_loss: 2.8556\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.1663 - val_loss: 3.6051\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.7321 - val_loss: 4.1214\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.0718 - val_loss: 3.2876\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.9227 - val_loss: 2.3588\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 11.3000 - val_loss: 2.5254\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10.3194 - val_loss: 3.3739\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 11.7004 - val_loss: 3.7912\n",
      "\n",
      "Loading Model: '02-07-2021--11--48-E2E_LSTM_ValSet_0.01-ALPHA1000.0-BETA_SD17-277Epochs-rlf-Loss-64-HU-'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.010997811916933838\n",
      "Model: \"functional_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_41 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_162 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_163 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 6.9036e-05 - val_loss: 6.2374e-05\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 6.2111e-05 - val_loss: 5.4892e-05\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.4673e-05 - val_loss: 4.9040e-05\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.8962e-05 - val_loss: 4.3276e-05\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 4.3248e-05 - val_loss: 3.7684e-05\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.7878e-05 - val_loss: 3.2362e-05\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.3146e-05 - val_loss: 2.7409e-05\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.7471e-05 - val_loss: 2.2920e-05\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.3490e-05 - val_loss: 1.8801e-05\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.8967e-05 - val_loss: 1.4951e-05\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.5750e-05 - val_loss: 1.1443e-05\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.1935e-05 - val_loss: 8.3718e-06\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 9.2599e-06 - val_loss: 5.7879e-06\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.9231e-06 - val_loss: 3.7608e-06\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.7361e-06 - val_loss: 2.3784e-06\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 4.7859e-06 - val_loss: 1.6931e-06\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.0228e-06 - val_loss: 1.6624e-06\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8827e-06 - val_loss: 2.1010e-06\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.4354e-06 - val_loss: 2.7219e-06\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.7768e-06 - val_loss: 3.2321e-06\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8722e-06 - val_loss: 3.4122e-06\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0079e-05 - val_loss: 3.2199e-06\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.5272e-06 - val_loss: 2.7903e-06\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.1980e-06 - val_loss: 2.2911e-06\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.3442e-06 - val_loss: 1.8519e-06\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.3797e-06 - val_loss: 1.5593e-06\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.5182e-06 - val_loss: 1.4519e-06\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.1785e-06 - val_loss: 1.5237e-06\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.1866e-06 - val_loss: 1.7471e-06\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1889e-06 - val_loss: 2.0760e-06\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2972e-06 - val_loss: 2.4547e-06\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.2635e-06 - val_loss: 2.8360e-06\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.7323e-06 - val_loss: 3.1807e-06\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.1803e-06 - val_loss: 3.4610e-06\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.7992e-06 - val_loss: 3.6537e-06\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.7726e-06 - val_loss: 3.7556e-06\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7351e-06 - val_loss: 3.7592e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.0526e-06 - val_loss: 3.6736e-06\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.7947e-06 - val_loss: 3.5179e-06\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.9999e-06 - val_loss: 3.3035e-06\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.1689e-06 - val_loss: 3.0490e-06\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.9446e-06 - val_loss: 2.7835e-06\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.6921e-06 - val_loss: 2.5268e-06\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.5548e-06 - val_loss: 2.2743e-06\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.3019e-06 - val_loss: 2.0475e-06\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2847e-06 - val_loss: 1.8461e-06\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2419e-06 - val_loss: 1.6799e-06\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.2876e-06 - val_loss: 1.5458e-06\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.3199e-06 - val_loss: 1.4475e-06\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.1063e-06 - val_loss: 1.3748e-06\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.2644e-06 - val_loss: 1.3273e-06\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.4028e-06 - val_loss: 1.2973e-06\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.9905e-06 - val_loss: 1.2797e-06\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.6254e-06 - val_loss: 1.2763e-06\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.0971e-06 - val_loss: 1.2810e-06\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.9888e-06 - val_loss: 1.2935e-06\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.3645e-06 - val_loss: 1.3165e-06\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.1614e-06 - val_loss: 1.3522e-06\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8634e-06 - val_loss: 1.4004e-06\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8102e-06 - val_loss: 1.4590e-06\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4961e-06 - val_loss: 1.5175e-06\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8088e-06 - val_loss: 1.5753e-06\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6958e-06 - val_loss: 1.6294e-06\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5768e-06 - val_loss: 1.6794e-06\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6648e-06 - val_loss: 1.7200e-06\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.8026e-06 - val_loss: 1.7389e-06\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7051e-06 - val_loss: 1.7442e-06\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7976e-06 - val_loss: 1.7458e-06\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6553e-06 - val_loss: 1.7367e-06\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9168e-06 - val_loss: 1.7198e-06\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3465e-06 - val_loss: 1.6919e-06\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8655e-06 - val_loss: 1.6559e-06\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0884e-06 - val_loss: 1.6122e-06\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6248e-06 - val_loss: 1.5713e-06\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5164e-06 - val_loss: 1.5293e-06\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6270e-06 - val_loss: 1.4868e-06\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8089e-06 - val_loss: 1.4474e-06\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7741e-06 - val_loss: 1.4168e-06\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4511e-06 - val_loss: 1.3883e-06\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6916e-06 - val_loss: 1.3654e-06\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5260e-06 - val_loss: 1.3447e-06\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3963e-06 - val_loss: 1.3283e-06\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3881e-06 - val_loss: 1.3224e-06\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5038e-06 - val_loss: 1.3199e-06\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7565e-06 - val_loss: 1.3181e-06\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4640e-06 - val_loss: 1.3197e-06\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3898e-06 - val_loss: 1.3267e-06\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.9097e-06 - val_loss: 1.3374e-06\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5373e-06 - val_loss: 1.3525e-06\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.8169e-06 - val_loss: 1.3736e-06\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5208e-06 - val_loss: 1.3905e-06\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.3530e-06 - val_loss: 1.4079e-06\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5625e-06 - val_loss: 1.4263e-06\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3589e-06 - val_loss: 1.4335e-06\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.7377e-06 - val_loss: 1.4335e-06\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3243e-06 - val_loss: 1.4294e-06\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2189e-06 - val_loss: 1.4148e-06\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2511e-06 - val_loss: 1.3927e-06\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.2221e-06 - val_loss: 1.3665e-06\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.3904e-06 - val_loss: 1.3336e-06\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0137e-06 - val_loss: 1.3140e-06\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3775e-06 - val_loss: 1.2951e-06\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.2111e-06 - val_loss: 1.2847e-06\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3153e-06 - val_loss: 1.2816e-06\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.2022e-06 - val_loss: 1.2715e-06\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.2762e-06 - val_loss: 1.2643e-06\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.3583e-06 - val_loss: 1.2568e-06\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 3.3613e-06 - val_loss: 1.2539e-06\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.1563e-06 - val_loss: 1.2522e-06\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.0623e-06 - val_loss: 1.2492e-06\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.2317e-06 - val_loss: 1.2420e-06\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.3838e-06 - val_loss: 1.2294e-06\n",
      "Epoch 113/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step - loss: 3.3072e-06 - val_loss: 1.2158e-06\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.1414e-06 - val_loss: 1.2035e-06\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.1356e-06 - val_loss: 1.1974e-06\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.8977e-06 - val_loss: 1.1868e-06\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.0863e-06 - val_loss: 1.1768e-06\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.2829e-06 - val_loss: 1.1706e-06\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.2657e-06 - val_loss: 1.1687e-06\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.9702e-06 - val_loss: 1.1672e-06\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2083e-06 - val_loss: 1.1716e-06\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0160e-06 - val_loss: 1.1778e-06\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.1784e-06 - val_loss: 1.1846e-06\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0921e-06 - val_loss: 1.1923e-06\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.2923e-06 - val_loss: 1.1897e-06\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1801e-06 - val_loss: 1.1781e-06\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.1216e-06 - val_loss: 1.1643e-06\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.1272e-06 - val_loss: 1.1483e-06\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.0197e-06 - val_loss: 1.1291e-06\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.9124e-06 - val_loss: 1.1145e-06\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.0806e-06 - val_loss: 1.0996e-06\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.0708e-06 - val_loss: 1.0818e-06\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.1575e-06 - val_loss: 1.0695e-06\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.1442e-06 - val_loss: 1.0678e-06\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1220e-06 - val_loss: 1.0715e-06\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.1600e-06 - val_loss: 1.0701e-06\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0101e-06 - val_loss: 1.0695e-06\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0942e-06 - val_loss: 1.0696e-06\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8347e-06 - val_loss: 1.0721e-06\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8761e-06 - val_loss: 1.0766e-06\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6936e-06 - val_loss: 1.0855e-06\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8560e-06 - val_loss: 1.1007e-06\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8477e-06 - val_loss: 1.1174e-06\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.8326e-06 - val_loss: 1.1269e-06\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8208e-06 - val_loss: 1.1240e-06\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7351e-06 - val_loss: 1.1148e-06\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0319e-06 - val_loss: 1.1071e-06\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8457e-06 - val_loss: 1.1004e-06\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9751e-06 - val_loss: 1.1026e-06\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8587e-06 - val_loss: 1.1026e-06\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7582e-06 - val_loss: 1.1031e-06\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.9886e-06 - val_loss: 1.0976e-06\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8605e-06 - val_loss: 1.0887e-06\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8761e-06 - val_loss: 1.0764e-06\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8147e-06 - val_loss: 1.0685e-06\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.0106e-06 - val_loss: 1.0638e-06\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.0506e-06 - val_loss: 1.0561e-06\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.9282e-06 - val_loss: 1.0451e-06\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.8482e-06 - val_loss: 1.0342e-06\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.7685e-06 - val_loss: 1.0244e-06\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.0984e-06 - val_loss: 1.0187e-06\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.9350e-06 - val_loss: 1.0090e-06\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.7298e-06 - val_loss: 1.0058e-06\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6763e-06 - val_loss: 1.0064e-06\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5889e-06 - val_loss: 1.0128e-06\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6642e-06 - val_loss: 1.0247e-06\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.8125e-06 - val_loss: 1.0411e-06\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7829e-06 - val_loss: 1.0533e-06\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8070e-06 - val_loss: 1.0561e-06\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8384e-06 - val_loss: 1.0581e-06\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8665e-06 - val_loss: 1.0622e-06\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5245e-06 - val_loss: 1.0700e-06\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7086e-06 - val_loss: 1.0767e-06\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7277e-06 - val_loss: 1.0782e-06\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.6545e-06 - val_loss: 1.0755e-06\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7443e-06 - val_loss: 1.0685e-06\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5926e-06 - val_loss: 1.0489e-06\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5508e-06 - val_loss: 1.0260e-06\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.9853e-06 - val_loss: 9.9893e-07\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.7875e-06 - val_loss: 9.8026e-07\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.6881e-06 - val_loss: 9.6941e-07\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.5507e-06 - val_loss: 9.6687e-07\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8689e-06 - val_loss: 9.6716e-07\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6993e-06 - val_loss: 9.7395e-07\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5680e-06 - val_loss: 9.7544e-07\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6091e-06 - val_loss: 9.7055e-07\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4260e-06 - val_loss: 9.7023e-07\n",
      "Epoch 188/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step - loss: 2.7092e-06 - val_loss: 9.7546e-07\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.7062e-06 - val_loss: 9.8211e-07\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7389e-06 - val_loss: 9.8568e-07\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.6220e-06 - val_loss: 9.9422e-07\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5780e-06 - val_loss: 9.9569e-07\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6352e-06 - val_loss: 1.0020e-06\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6205e-06 - val_loss: 9.9910e-07\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7806e-06 - val_loss: 9.8481e-07\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.3719e-06 - val_loss: 9.6283e-07\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.4763e-06 - val_loss: 9.5284e-07\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.6770e-06 - val_loss: 9.3849e-07\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.7131e-06 - val_loss: 9.3003e-07\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.6437e-06 - val_loss: 9.1828e-07\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.4977e-06 - val_loss: 9.1321e-07\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6916e-06 - val_loss: 9.1680e-07\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5740e-06 - val_loss: 9.3089e-07\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4879e-06 - val_loss: 9.5587e-07\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5022e-06 - val_loss: 9.8693e-07\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5540e-06 - val_loss: 1.0031e-06\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5111e-06 - val_loss: 1.0151e-06\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5424e-06 - val_loss: 1.0253e-06\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3923e-06 - val_loss: 1.0265e-06\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6652e-06 - val_loss: 1.0212e-06\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5620e-06 - val_loss: 1.0176e-06\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3626e-06 - val_loss: 1.0059e-06\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3549e-06 - val_loss: 9.9185e-07\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5769e-06 - val_loss: 9.7292e-07\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4987e-06 - val_loss: 9.4905e-07\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.5417e-06 - val_loss: 9.3035e-07\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4955e-06 - val_loss: 9.2318e-07\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.5453e-06 - val_loss: 9.1672e-07\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.3497e-06 - val_loss: 9.0571e-07\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.4827e-06 - val_loss: 9.0027e-07\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2337e-06 - val_loss: 9.0056e-07\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4325e-06 - val_loss: 9.1346e-07\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4346e-06 - val_loss: 9.2790e-07\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4261e-06 - val_loss: 9.4199e-07\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4565e-06 - val_loss: 9.5725e-07\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4030e-06 - val_loss: 9.6734e-07\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5717e-06 - val_loss: 9.7571e-07\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3026e-06 - val_loss: 9.8097e-07\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5495e-06 - val_loss: 9.8338e-07\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5221e-06 - val_loss: 9.8041e-07\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3623e-06 - val_loss: 9.7591e-07\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5299e-06 - val_loss: 9.8228e-07\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2535e-06 - val_loss: 9.8357e-07\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4117e-06 - val_loss: 9.7691e-07\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2946e-06 - val_loss: 9.7162e-07\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5376e-06 - val_loss: 9.6838e-07\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1503e-06 - val_loss: 9.6828e-07\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5500e-06 - val_loss: 9.5880e-07\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3582e-06 - val_loss: 9.4624e-07\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4024e-06 - val_loss: 9.3409e-07\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3910e-06 - val_loss: 9.2059e-07\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5560e-06 - val_loss: 9.1371e-07\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4572e-06 - val_loss: 9.1143e-07\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4725e-06 - val_loss: 9.0751e-07\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5085e-06 - val_loss: 9.1287e-07\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3577e-06 - val_loss: 9.1970e-07\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.6359e-06 - val_loss: 9.3217e-07\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.4402e-06 - val_loss: 9.3568e-07\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3898e-06 - val_loss: 9.4360e-07\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3894e-06 - val_loss: 9.5374e-07\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4155e-06 - val_loss: 9.5449e-07\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4522e-06 - val_loss: 9.5644e-07\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4227e-06 - val_loss: 9.6196e-07\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5179e-06 - val_loss: 9.5589e-07\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3254e-06 - val_loss: 9.4789e-07\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3540e-06 - val_loss: 9.2551e-07\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4285e-06 - val_loss: 9.0171e-07\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1661e-06 - val_loss: 8.8965e-07\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.3906e-06 - val_loss: 8.7839e-07\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.3526e-06 - val_loss: 8.7836e-07\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3672e-06 - val_loss: 8.9134e-07\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2310e-06 - val_loss: 9.0823e-07\n",
      "Epoch 263/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5370e-06 - val_loss: 9.2458e-07\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4095e-06 - val_loss: 9.4029e-07\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3588e-06 - val_loss: 9.5632e-07\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4082e-06 - val_loss: 9.6495e-07\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3896e-06 - val_loss: 9.6868e-07\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3583e-06 - val_loss: 9.6581e-07\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4087e-06 - val_loss: 9.4497e-07\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1542e-06 - val_loss: 9.2147e-07\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4253e-06 - val_loss: 9.0029e-07\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3419e-06 - val_loss: 8.8812e-07\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.3212e-06 - val_loss: 8.7540e-07\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.4348e-06 - val_loss: 8.6278e-07\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2726e-06 - val_loss: 8.6576e-07\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1582e-06 - val_loss: 8.6936e-07\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4790e-06 - val_loss: 8.6859e-07\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.3039e-06 - val_loss: 8.8225e-07\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1854e-06 - val_loss: 8.8704e-07\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2436e-06 - val_loss: 8.9338e-07\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3073e-06 - val_loss: 8.9478e-07\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1496e-06 - val_loss: 8.9104e-07\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1973e-06 - val_loss: 8.8700e-07\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1450e-06 - val_loss: 8.7810e-07\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1803e-06 - val_loss: 8.6832e-07\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.2457e-06 - val_loss: 8.5988e-07\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1037e-06 - val_loss: 8.6550e-07\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2558e-06 - val_loss: 8.7139e-07\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2548e-06 - val_loss: 8.7665e-07\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2360e-06 - val_loss: 8.8945e-07\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2825e-06 - val_loss: 9.0096e-07\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2995e-06 - val_loss: 9.0548e-07\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1403e-06 - val_loss: 9.0338e-07\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.3321e-06 - val_loss: 9.0032e-07\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2603e-06 - val_loss: 8.9482e-07\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2664e-06 - val_loss: 8.8606e-07\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1731e-06 - val_loss: 8.8094e-07\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3641e-06 - val_loss: 8.7372e-07\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3330e-06 - val_loss: 8.7337e-07\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3657e-06 - val_loss: 8.7849e-07\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1848e-06 - val_loss: 8.9573e-07\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3733e-06 - val_loss: 9.0179e-07\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0863e-06 - val_loss: 9.0220e-07\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1375e-06 - val_loss: 8.8997e-07\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2757e-06 - val_loss: 8.7211e-07\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2680e-06 - val_loss: 8.6066e-07\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.1593e-06 - val_loss: 8.5271e-07\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0464e-06 - val_loss: 8.4599e-07\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1090e-06 - val_loss: 8.5073e-07\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1569e-06 - val_loss: 8.5836e-07\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0572e-06 - val_loss: 8.6680e-07\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0774e-06 - val_loss: 8.6623e-07\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1271e-06 - val_loss: 8.6693e-07\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1518e-06 - val_loss: 8.6819e-07\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1187e-06 - val_loss: 8.6995e-07\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1366e-06 - val_loss: 8.7469e-07\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0207e-06 - val_loss: 8.7580e-07\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2173e-06 - val_loss: 8.7734e-07\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0640e-06 - val_loss: 8.6898e-07\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.2217e-06 - val_loss: 8.6800e-07\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2637e-06 - val_loss: 8.6262e-07\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2442e-06 - val_loss: 8.5967e-07\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3029e-06 - val_loss: 8.5379e-07\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3608e-06 - val_loss: 8.6072e-07\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0286e-06 - val_loss: 8.6535e-07\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1710e-06 - val_loss: 8.7036e-07\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1992e-06 - val_loss: 8.7963e-07\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8825e-06 - val_loss: 8.8864e-07\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1513e-06 - val_loss: 8.8999e-07\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0056e-06 - val_loss: 8.7411e-07\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1209e-06 - val_loss: 8.5777e-07\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.0121e-06 - val_loss: 8.4345e-07\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1660e-06 - val_loss: 8.3467e-07\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.1676e-06 - val_loss: 8.3162e-07\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1829e-06 - val_loss: 8.3352e-07\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0619e-06 - val_loss: 8.3828e-07\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2369e-06 - val_loss: 8.5188e-07\n",
      "Epoch 338/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9364e-06 - val_loss: 8.6779e-07\n",
      "Epoch 339/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0479e-06 - val_loss: 8.8523e-07\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2493e-06 - val_loss: 8.9219e-07\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1456e-06 - val_loss: 9.0076e-07\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9583e-06 - val_loss: 8.9957e-07\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0618e-06 - val_loss: 8.8831e-07\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1365e-06 - val_loss: 8.5519e-07\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0136e-06 - val_loss: 8.2168e-07\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1552e-06 - val_loss: 7.9086e-07\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.2517e-06 - val_loss: 7.6924e-07\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0673e-06 - val_loss: 7.5914e-07\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1853e-06 - val_loss: 7.7344e-07\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1874e-06 - val_loss: 7.9436e-07\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1506e-06 - val_loss: 8.2735e-07\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1795e-06 - val_loss: 8.5823e-07\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0087e-06 - val_loss: 8.7461e-07\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9681e-06 - val_loss: 8.8890e-07\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0365e-06 - val_loss: 9.0234e-07\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0990e-06 - val_loss: 8.9653e-07\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2823e-06 - val_loss: 8.9090e-07\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1357e-06 - val_loss: 8.7654e-07\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1583e-06 - val_loss: 8.5293e-07\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1766e-06 - val_loss: 8.3554e-07\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0392e-06 - val_loss: 8.2218e-07\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1928e-06 - val_loss: 8.2149e-07\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9382e-06 - val_loss: 8.2356e-07\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0336e-06 - val_loss: 8.1997e-07\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0042e-06 - val_loss: 8.2183e-07\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1963e-06 - val_loss: 8.1836e-07\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0071e-06 - val_loss: 8.2927e-07\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9845e-06 - val_loss: 8.4304e-07\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8770e-06 - val_loss: 8.6189e-07\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1218e-06 - val_loss: 8.8608e-07\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9419e-06 - val_loss: 9.0197e-07\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1342e-06 - val_loss: 9.0749e-07\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0470e-06 - val_loss: 8.9849e-07\n",
      "Epoch 374/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1990e-06 - val_loss: 8.9821e-07\n",
      "Epoch 375/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2368e-06 - val_loss: 8.7857e-07\n",
      "Epoch 376/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1265e-06 - val_loss: 8.5250e-07\n",
      "Epoch 377/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0524e-06 - val_loss: 8.3056e-07\n",
      "Epoch 378/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9828e-06 - val_loss: 8.2394e-07\n",
      "Epoch 379/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0475e-06 - val_loss: 8.2548e-07\n",
      "Epoch 380/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0508e-06 - val_loss: 8.2617e-07\n",
      "Epoch 381/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8939e-06 - val_loss: 8.3663e-07\n",
      "Epoch 382/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2377e-06 - val_loss: 8.5444e-07\n",
      "Epoch 383/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0394e-06 - val_loss: 8.6194e-07\n",
      "Epoch 384/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0878e-06 - val_loss: 8.6015e-07\n",
      "Epoch 385/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9578e-06 - val_loss: 8.4108e-07\n",
      "Epoch 386/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0985e-06 - val_loss: 8.2201e-07\n",
      "Epoch 387/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9936e-06 - val_loss: 8.1213e-07\n",
      "Epoch 388/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0247e-06 - val_loss: 8.0751e-07\n",
      "Epoch 389/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0999e-06 - val_loss: 8.0968e-07\n",
      "Epoch 390/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1676e-06 - val_loss: 8.2028e-07\n",
      "Epoch 391/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1185e-06 - val_loss: 8.2604e-07\n",
      "Epoch 392/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9459e-06 - val_loss: 8.2724e-07\n",
      "Epoch 393/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9918e-06 - val_loss: 8.4099e-07\n",
      "Epoch 394/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9800e-06 - val_loss: 8.5778e-07\n",
      "Epoch 395/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0452e-06 - val_loss: 8.6725e-07\n",
      "Epoch 396/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1033e-06 - val_loss: 8.7708e-07\n",
      "Epoch 397/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0061e-06 - val_loss: 8.7901e-07\n",
      "Epoch 398/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9808e-06 - val_loss: 8.7119e-07\n",
      "Epoch 399/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9800e-06 - val_loss: 8.5991e-07\n",
      "Epoch 400/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1377e-06 - val_loss: 8.5130e-07\n",
      "Epoch 401/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9909e-06 - val_loss: 8.2102e-07\n",
      "Epoch 402/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9786e-06 - val_loss: 7.9544e-07\n",
      "Epoch 403/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.9879e-06 - val_loss: 7.7816e-07\n",
      "Epoch 404/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8639e-06 - val_loss: 7.7689e-07\n",
      "Epoch 405/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1483e-06 - val_loss: 7.8569e-07\n",
      "Epoch 406/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0295e-06 - val_loss: 7.8391e-07\n",
      "Epoch 407/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0498e-06 - val_loss: 8.0094e-07\n",
      "Epoch 408/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9529e-06 - val_loss: 8.3254e-07\n",
      "Epoch 409/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0910e-06 - val_loss: 8.5769e-07\n",
      "Epoch 410/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9721e-06 - val_loss: 8.7473e-07\n",
      "Epoch 411/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1105e-06 - val_loss: 8.6624e-07\n",
      "Epoch 412/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1616e-06 - val_loss: 8.4984e-07\n",
      "Epoch 413/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8229e-06 - val_loss: 8.3202e-07\n",
      "Epoch 414/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9907e-06 - val_loss: 8.1171e-07\n",
      "Epoch 415/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9987e-06 - val_loss: 8.0852e-07\n",
      "Epoch 416/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0429e-06 - val_loss: 8.0239e-07\n",
      "Epoch 417/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0940e-06 - val_loss: 7.9470e-07\n",
      "Epoch 418/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9022e-06 - val_loss: 7.9128e-07\n",
      "\n",
      "Loading Model: '02-07-2021--12--03-E2E_LSTM_ValSet_0.001-ALPHA0.0001-BETA_SD17-418Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.008193053666482139\n",
      "Model: \"functional_83\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_42 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_166 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_167 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 6.8763e-04 - val_loss: 5.9262e-04\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 5.8796e-04 - val_loss: 4.9476e-04\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 4.8860e-04 - val_loss: 4.1952e-04\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.1447e-04 - val_loss: 3.4783e-04\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.4391e-04 - val_loss: 2.8073e-04\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.7930e-04 - val_loss: 2.2041e-04\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.2335e-04 - val_loss: 1.6596e-04\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.6299e-04 - val_loss: 1.1641e-04\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.1949e-04 - val_loss: 7.3677e-05\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 7.8250e-05 - val_loss: 3.9634e-05\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.4679e-05 - val_loss: 1.8022e-05\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.0088e-05 - val_loss: 1.2360e-05\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.5663e-05 - val_loss: 2.0899e-05\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1950e-05 - val_loss: 3.4335e-05\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.4233e-05 - val_loss: 4.1816e-05\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0736e-05 - val_loss: 4.0055e-05\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6989e-05 - val_loss: 3.1636e-05\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.4537e-05 - val_loss: 2.1766e-05\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.4910e-05 - val_loss: 1.4199e-05\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 5.2815e-05 - val_loss: 1.0479e-05\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.4844e-05 - val_loss: 1.0571e-05\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.3854e-05 - val_loss: 1.3772e-05\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.4610e-05 - val_loss: 1.8893e-05\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0059e-05 - val_loss: 2.4621e-05\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.9252e-05 - val_loss: 3.0080e-05\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1496e-05 - val_loss: 3.4658e-05\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.5090e-05 - val_loss: 3.7925e-05\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.7951e-05 - val_loss: 3.9741e-05\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.9472e-05 - val_loss: 4.0169e-05\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4493e-05 - val_loss: 3.9272e-05\n",
      "Epoch 31/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 4.5969e-05 - val_loss: 3.7167e-05\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.3291e-05 - val_loss: 3.4126e-05\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.2512e-05 - val_loss: 3.0450e-05\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.3770e-05 - val_loss: 2.6492e-05\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.7062e-05 - val_loss: 2.2525e-05\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.3856e-05 - val_loss: 1.8856e-05\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.8117e-05 - val_loss: 1.5595e-05\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2236e-05 - val_loss: 1.2915e-05\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.0928e-05 - val_loss: 1.0921e-05\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.2282e-05 - val_loss: 9.5287e-06\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.4679e-05 - val_loss: 8.6404e-06\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.7906e-05 - val_loss: 8.1560e-06\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.9054e-05 - val_loss: 7.9138e-06\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.4215e-05 - val_loss: 7.7761e-06\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.5814e-05 - val_loss: 7.7374e-06\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4399e-05 - val_loss: 7.8018e-06\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.3950e-05 - val_loss: 8.0273e-06\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.3013e-05 - val_loss: 8.4206e-06\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.3212e-05 - val_loss: 9.0394e-06\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.1437e-05 - val_loss: 9.7774e-06\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.1508e-05 - val_loss: 1.0662e-05\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.2589e-05 - val_loss: 1.1595e-05\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9019e-05 - val_loss: 1.2451e-05\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.2174e-05 - val_loss: 1.3315e-05\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0142e-05 - val_loss: 1.3897e-05\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0399e-05 - val_loss: 1.4137e-05\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.2238e-05 - val_loss: 1.4088e-05\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0880e-05 - val_loss: 1.3809e-05\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.8592e-05 - val_loss: 1.3342e-05\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.8332e-05 - val_loss: 1.2729e-05\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7397e-05 - val_loss: 1.1904e-05\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.8674e-05 - val_loss: 1.1027e-05\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7861e-05 - val_loss: 1.0182e-05\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.6009e-05 - val_loss: 9.4644e-06\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7024e-05 - val_loss: 8.8609e-06\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7822e-05 - val_loss: 8.2913e-06\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6940e-05 - val_loss: 7.8648e-06\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.8815e-05 - val_loss: 7.6574e-06\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.7837e-05 - val_loss: 7.5868e-06\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9373e-05 - val_loss: 7.6474e-06\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4818e-05 - val_loss: 7.7910e-06\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7985e-05 - val_loss: 7.9958e-06\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9207e-05 - val_loss: 8.2169e-06\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7042e-05 - val_loss: 8.5317e-06\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5300e-05 - val_loss: 8.8501e-06\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6228e-05 - val_loss: 9.1246e-06\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.8167e-05 - val_loss: 9.3525e-06\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6389e-05 - val_loss: 9.5852e-06\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4546e-05 - val_loss: 9.6988e-06\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6289e-05 - val_loss: 9.7244e-06\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5751e-05 - val_loss: 9.5932e-06\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4632e-05 - val_loss: 9.3188e-06\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4163e-05 - val_loss: 9.0476e-06\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5322e-05 - val_loss: 8.7025e-06\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.6678e-05 - val_loss: 8.3029e-06\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4627e-05 - val_loss: 7.9348e-06\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.3374e-05 - val_loss: 7.6485e-06\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.7096e-05 - val_loss: 7.4181e-06\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.4586e-05 - val_loss: 7.2658e-06\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.6391e-05 - val_loss: 7.2195e-06\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.4201e-05 - val_loss: 7.1749e-06\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.3672e-05 - val_loss: 7.2199e-06\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.5086e-05 - val_loss: 7.3675e-06\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3872e-05 - val_loss: 7.4427e-06\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5129e-05 - val_loss: 7.4294e-06\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2157e-05 - val_loss: 7.4149e-06\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2287e-05 - val_loss: 7.2879e-06\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.2383e-05 - val_loss: 7.1118e-06\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.1172e-05 - val_loss: 6.8847e-06\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.3250e-05 - val_loss: 6.6135e-06\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0991e-05 - val_loss: 6.5676e-06\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.2770e-05 - val_loss: 6.5375e-06\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2717e-05 - val_loss: 6.6470e-06\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2237e-05 - val_loss: 6.8373e-06\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.1806e-05 - val_loss: 6.9005e-06\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2695e-05 - val_loss: 6.9388e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2412e-05 - val_loss: 6.8512e-06\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2799e-05 - val_loss: 6.8020e-06\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.1008e-05 - val_loss: 6.7117e-06\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0581e-05 - val_loss: 6.5712e-06\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1663e-05 - val_loss: 6.3651e-06\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.2943e-05 - val_loss: 6.0469e-06\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1845e-05 - val_loss: 5.7462e-06\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0965e-05 - val_loss: 5.5568e-06\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0866e-05 - val_loss: 5.5440e-06\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.0031e-05 - val_loss: 5.5783e-06\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0100e-05 - val_loss: 5.6681e-06\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1612e-05 - val_loss: 5.8280e-06\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1402e-05 - val_loss: 6.0412e-06\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0396e-05 - val_loss: 6.2248e-06\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.0935e-05 - val_loss: 6.4096e-06\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9602e-05 - val_loss: 6.5824e-06\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0936e-05 - val_loss: 6.6300e-06\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1023e-05 - val_loss: 6.5543e-06\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1496e-05 - val_loss: 6.1899e-06\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1329e-05 - val_loss: 5.6265e-06\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.0103e-05 - val_loss: 5.1569e-06\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0828e-05 - val_loss: 4.8136e-06\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.9100e-05 - val_loss: 4.5934e-06\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9496e-05 - val_loss: 4.6496e-06\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0667e-05 - val_loss: 4.8309e-06\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0220e-05 - val_loss: 5.0533e-06\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1890e-05 - val_loss: 5.3650e-06\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1251e-05 - val_loss: 5.8301e-06\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1115e-05 - val_loss: 6.2462e-06\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.9997e-05 - val_loss: 6.2832e-06\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0261e-05 - val_loss: 6.1637e-06\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.9893e-05 - val_loss: 5.8701e-06\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.8582e-05 - val_loss: 5.5493e-06\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9262e-05 - val_loss: 5.2816e-06\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7503e-05 - val_loss: 5.1315e-06\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.9672e-05 - val_loss: 5.2604e-06\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9354e-05 - val_loss: 5.5566e-06\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8684e-05 - val_loss: 5.8123e-06\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8134e-05 - val_loss: 5.7525e-06\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.7215e-05 - val_loss: 5.5913e-06\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.9954e-05 - val_loss: 5.5022e-06\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8961e-05 - val_loss: 5.4509e-06\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0066e-05 - val_loss: 5.7185e-06\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8947e-05 - val_loss: 5.9074e-06\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8097e-05 - val_loss: 6.0557e-06\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.9681e-05 - val_loss: 5.9913e-06\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8886e-05 - val_loss: 5.8022e-06\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9168e-05 - val_loss: 5.5757e-06\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8543e-05 - val_loss: 5.5247e-06\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.9525e-05 - val_loss: 5.5709e-06\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9320e-05 - val_loss: 5.5310e-06\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8531e-05 - val_loss: 5.4121e-06\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8212e-05 - val_loss: 5.2699e-06\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.8693e-05 - val_loss: 5.2294e-06\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.9433e-05 - val_loss: 5.2912e-06\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.9615e-05 - val_loss: 5.1710e-06\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.8229e-05 - val_loss: 5.2513e-06\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.7083e-05 - val_loss: 5.4431e-06\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6950e-05 - val_loss: 5.7969e-06\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7707e-05 - val_loss: 6.1932e-06\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.8903e-05 - val_loss: 6.5164e-06\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8741e-05 - val_loss: 6.5110e-06\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.8702e-05 - val_loss: 6.1662e-06\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.9273e-05 - val_loss: 5.7675e-06\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8224e-05 - val_loss: 5.4830e-06\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6424e-05 - val_loss: 5.4683e-06\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6836e-05 - val_loss: 5.5315e-06\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8050e-05 - val_loss: 5.7117e-06\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6851e-05 - val_loss: 5.8244e-06\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8092e-05 - val_loss: 5.7556e-06\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7077e-05 - val_loss: 5.3704e-06\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6545e-05 - val_loss: 4.9851e-06\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0412e-05 - val_loss: 4.6932e-06\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.8557e-05 - val_loss: 4.8002e-06\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7139e-05 - val_loss: 5.1002e-06\n",
      "Epoch 182/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7118e-05 - val_loss: 5.5531e-06\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7530e-05 - val_loss: 5.7364e-06\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7855e-05 - val_loss: 5.8583e-06\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6416e-05 - val_loss: 5.5651e-06\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6535e-05 - val_loss: 5.0102e-06\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6400e-05 - val_loss: 4.6192e-06\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.7693e-05 - val_loss: 4.5057e-06\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7803e-05 - val_loss: 4.5638e-06\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.7616e-05 - val_loss: 4.8077e-06\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6591e-05 - val_loss: 5.2325e-06\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6885e-05 - val_loss: 5.4226e-06\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6974e-05 - val_loss: 5.6630e-06\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6959e-05 - val_loss: 5.4623e-06\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.8307e-05 - val_loss: 4.8962e-06\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.5585e-05 - val_loss: 4.3430e-06\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.6399e-05 - val_loss: 4.2776e-06\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7364e-05 - val_loss: 4.2996e-06\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7054e-05 - val_loss: 4.6171e-06\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7214e-05 - val_loss: 4.8683e-06\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.6133e-05 - val_loss: 5.2128e-06\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7800e-05 - val_loss: 5.4922e-06\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6315e-05 - val_loss: 5.7568e-06\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5960e-05 - val_loss: 5.9037e-06\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6539e-05 - val_loss: 5.8746e-06\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6646e-05 - val_loss: 5.1637e-06\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5013e-05 - val_loss: 4.5005e-06\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.5740e-05 - val_loss: 4.1884e-06\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5126e-05 - val_loss: 4.2394e-06\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6807e-05 - val_loss: 4.4345e-06\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.6454e-05 - val_loss: 5.0835e-06\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5603e-05 - val_loss: 5.5731e-06\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4857e-05 - val_loss: 5.8451e-06\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6266e-05 - val_loss: 5.5495e-06\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6464e-05 - val_loss: 4.9583e-06\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5754e-05 - val_loss: 4.3527e-06\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.5765e-05 - val_loss: 4.1205e-06\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.5475e-05 - val_loss: 4.0968e-06\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5250e-05 - val_loss: 4.2039e-06\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5745e-05 - val_loss: 4.4011e-06\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3950e-05 - val_loss: 4.7210e-06\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5431e-05 - val_loss: 5.1147e-06\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5542e-05 - val_loss: 5.3068e-06\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4628e-05 - val_loss: 5.1223e-06\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5634e-05 - val_loss: 4.8147e-06\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4981e-05 - val_loss: 4.4347e-06\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5773e-05 - val_loss: 4.2656e-06\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4511e-05 - val_loss: 4.3231e-06\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5089e-05 - val_loss: 4.5231e-06\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5442e-05 - val_loss: 4.5812e-06\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4893e-05 - val_loss: 4.6924e-06\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5274e-05 - val_loss: 4.9606e-06\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4259e-05 - val_loss: 5.0479e-06\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5518e-05 - val_loss: 4.6808e-06\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3935e-05 - val_loss: 4.4282e-06\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5899e-05 - val_loss: 4.3279e-06\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3449e-05 - val_loss: 4.4808e-06\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5360e-05 - val_loss: 4.3492e-06\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.4343e-05 - val_loss: 4.2184e-06\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 1.5273e-05 - val_loss: 4.1534e-06\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 1.4426e-05 - val_loss: 4.0488e-06\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 1.5995e-05 - val_loss: 4.1627e-06\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.4910e-05 - val_loss: 4.3759e-06\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.5060e-05 - val_loss: 4.5786e-06\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5452e-05 - val_loss: 4.7864e-06\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.4502e-05 - val_loss: 4.7425e-06\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5900e-05 - val_loss: 4.5528e-06\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4985e-05 - val_loss: 4.1042e-06\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.5033e-05 - val_loss: 3.9985e-06\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.4354e-05 - val_loss: 4.3184e-06\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5193e-05 - val_loss: 4.5000e-06\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.5349e-05 - val_loss: 4.7534e-06\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4640e-05 - val_loss: 5.0664e-06\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.5327e-05 - val_loss: 4.7757e-06\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4830e-05 - val_loss: 4.4181e-06\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.3765e-05 - val_loss: 3.8556e-06\n",
      "Epoch 257/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 116ms/step - loss: 1.4479e-05 - val_loss: 3.5629e-06\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.4087e-05 - val_loss: 3.9106e-06\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.4630e-05 - val_loss: 4.5795e-06\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5274e-05 - val_loss: 5.4003e-06\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4493e-05 - val_loss: 5.8223e-06\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4082e-05 - val_loss: 5.2356e-06\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.5755e-05 - val_loss: 4.2167e-06\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.5007e-05 - val_loss: 3.6433e-06\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4281e-05 - val_loss: 3.7160e-06\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5256e-05 - val_loss: 4.2105e-06\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4738e-05 - val_loss: 4.9145e-06\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.3781e-05 - val_loss: 5.5184e-06\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5160e-05 - val_loss: 4.9450e-06\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2989e-05 - val_loss: 4.1793e-06\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4645e-05 - val_loss: 3.6770e-06\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4892e-05 - val_loss: 3.8387e-06\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3986e-05 - val_loss: 4.2207e-06\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5442e-05 - val_loss: 4.5007e-06\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4060e-05 - val_loss: 4.8352e-06\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3250e-05 - val_loss: 4.6973e-06\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5069e-05 - val_loss: 4.2256e-06\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3831e-05 - val_loss: 4.1499e-06\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3203e-05 - val_loss: 3.7721e-06\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4044e-05 - val_loss: 3.8921e-06\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4327e-05 - val_loss: 4.1050e-06\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.4037e-05 - val_loss: 4.4098e-06\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.3756e-05 - val_loss: 4.6198e-06\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.3538e-05 - val_loss: 4.5048e-06\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3343e-05 - val_loss: 4.1583e-06\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3707e-05 - val_loss: 3.9060e-06\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2636e-05 - val_loss: 4.2234e-06\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3413e-05 - val_loss: 4.4732e-06\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.3818e-05 - val_loss: 4.5596e-06\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3898e-05 - val_loss: 4.6598e-06\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3994e-05 - val_loss: 4.4658e-06\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4131e-05 - val_loss: 4.0095e-06\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.4293e-05 - val_loss: 3.7749e-06\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4559e-05 - val_loss: 3.7744e-06\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3998e-05 - val_loss: 4.1801e-06\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4045e-05 - val_loss: 4.5547e-06\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3622e-05 - val_loss: 4.7921e-06\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5154e-05 - val_loss: 4.4669e-06\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3942e-05 - val_loss: 4.2238e-06\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4044e-05 - val_loss: 4.2673e-06\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4094e-05 - val_loss: 4.7390e-06\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.4334e-05 - val_loss: 4.4434e-06\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2477e-05 - val_loss: 3.9389e-06\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3454e-05 - val_loss: 3.4934e-06\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.3814e-05 - val_loss: 3.2968e-06\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3365e-05 - val_loss: 3.7143e-06\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3051e-05 - val_loss: 4.3298e-06\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.3010e-05 - val_loss: 4.8997e-06\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2006e-05 - val_loss: 5.5774e-06\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.3490e-05 - val_loss: 5.1739e-06\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.3180e-05 - val_loss: 4.2102e-06\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2626e-05 - val_loss: 3.4089e-06\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2947e-05 - val_loss: 3.3570e-06\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3791e-05 - val_loss: 3.9101e-06\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2646e-05 - val_loss: 4.7238e-06\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3068e-05 - val_loss: 5.4142e-06\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1774e-05 - val_loss: 5.1469e-06\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3225e-05 - val_loss: 4.2326e-06\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.2664e-05 - val_loss: 3.2746e-06\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.3466e-05 - val_loss: 2.9829e-06\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4056e-05 - val_loss: 3.2696e-06\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3322e-05 - val_loss: 4.1988e-06\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3593e-05 - val_loss: 4.9945e-06\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4523e-05 - val_loss: 5.2988e-06\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2799e-05 - val_loss: 4.8224e-06\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.3207e-05 - val_loss: 3.9750e-06\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.3464e-05 - val_loss: 3.2450e-06\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.1784e-05 - val_loss: 3.2549e-06\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.3591e-05 - val_loss: 3.6377e-06\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.2101e-05 - val_loss: 3.8576e-06\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2754e-05 - val_loss: 4.0696e-06\n",
      "Epoch 332/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2159e-05 - val_loss: 4.2276e-06\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2199e-05 - val_loss: 4.2014e-06\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2612e-05 - val_loss: 3.9696e-06\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3272e-05 - val_loss: 3.9195e-06\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2106e-05 - val_loss: 3.9107e-06\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4046e-05 - val_loss: 4.2335e-06\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1742e-05 - val_loss: 4.5787e-06\n",
      "Epoch 339/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2590e-05 - val_loss: 4.7846e-06\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2945e-05 - val_loss: 4.2188e-06\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1914e-05 - val_loss: 3.7861e-06\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2250e-05 - val_loss: 3.4340e-06\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2458e-05 - val_loss: 3.3946e-06\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2396e-05 - val_loss: 3.2367e-06\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1736e-05 - val_loss: 3.3952e-06\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2446e-05 - val_loss: 3.6259e-06\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3324e-05 - val_loss: 3.7663e-06\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2400e-05 - val_loss: 3.9719e-06\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2287e-05 - val_loss: 4.6511e-06\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.3210e-05 - val_loss: 4.6437e-06\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2753e-05 - val_loss: 4.1177e-06\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2424e-05 - val_loss: 3.3826e-06\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1971e-05 - val_loss: 3.0039e-06\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.2603e-05 - val_loss: 3.3560e-06\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.2404e-05 - val_loss: 4.5809e-06\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.2947e-05 - val_loss: 5.0303e-06\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3619e-05 - val_loss: 4.7857e-06\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.2971e-05 - val_loss: 3.7457e-06\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.3137e-05 - val_loss: 2.8823e-06\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.2779e-05 - val_loss: 2.9177e-06\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3247e-05 - val_loss: 3.6357e-06\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3410e-05 - val_loss: 4.8566e-06\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2002e-05 - val_loss: 5.3950e-06\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2366e-05 - val_loss: 4.4447e-06\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1460e-05 - val_loss: 3.2585e-06\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3244e-05 - val_loss: 2.6353e-06\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3137e-05 - val_loss: 3.0562e-06\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1781e-05 - val_loss: 4.0885e-06\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1827e-05 - val_loss: 5.2804e-06\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2358e-05 - val_loss: 5.5953e-06\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2584e-05 - val_loss: 4.5743e-06\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.2525e-05 - val_loss: 3.3638e-06\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1867e-05 - val_loss: 2.7006e-06\n",
      "Epoch 374/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3690e-05 - val_loss: 3.0640e-06\n",
      "Epoch 375/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3730e-05 - val_loss: 3.7782e-06\n",
      "Epoch 376/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2372e-05 - val_loss: 4.5133e-06\n",
      "Epoch 377/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2494e-05 - val_loss: 4.7878e-06\n",
      "Epoch 378/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1687e-05 - val_loss: 4.8649e-06\n",
      "Epoch 379/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3198e-05 - val_loss: 4.3689e-06\n",
      "Epoch 380/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2248e-05 - val_loss: 3.5868e-06\n",
      "Epoch 381/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1803e-05 - val_loss: 3.3193e-06\n",
      "Epoch 382/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3638e-05 - val_loss: 3.6645e-06\n",
      "Epoch 383/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2429e-05 - val_loss: 3.8753e-06\n",
      "Epoch 384/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2286e-05 - val_loss: 3.8615e-06\n",
      "Epoch 385/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1982e-05 - val_loss: 3.4225e-06\n",
      "Epoch 386/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1617e-05 - val_loss: 3.1477e-06\n",
      "Epoch 387/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2086e-05 - val_loss: 3.4028e-06\n",
      "Epoch 388/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2121e-05 - val_loss: 3.7615e-06\n",
      "Epoch 389/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2207e-05 - val_loss: 3.8971e-06\n",
      "Epoch 390/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2132e-05 - val_loss: 4.0751e-06\n",
      "Epoch 391/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2834e-05 - val_loss: 3.6310e-06\n",
      "Epoch 392/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2172e-05 - val_loss: 3.2684e-06\n",
      "Epoch 393/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1888e-05 - val_loss: 3.6288e-06\n",
      "Epoch 394/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1702e-05 - val_loss: 4.1521e-06\n",
      "Epoch 395/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2597e-05 - val_loss: 4.3904e-06\n",
      "Epoch 396/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2843e-05 - val_loss: 4.6023e-06\n",
      "Epoch 397/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1833e-05 - val_loss: 4.0448e-06\n",
      "Epoch 398/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1488e-05 - val_loss: 3.3895e-06\n",
      "Epoch 399/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2079e-05 - val_loss: 3.0717e-06\n",
      "Epoch 400/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2556e-05 - val_loss: 3.3370e-06\n",
      "Epoch 401/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1853e-05 - val_loss: 3.4717e-06\n",
      "Epoch 402/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1588e-05 - val_loss: 3.9180e-06\n",
      "Epoch 403/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1629e-05 - val_loss: 4.1593e-06\n",
      "Epoch 404/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1364e-05 - val_loss: 4.1458e-06\n",
      "Epoch 405/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2949e-05 - val_loss: 3.8089e-06\n",
      "Epoch 406/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2016e-05 - val_loss: 2.9729e-06\n",
      "Epoch 407/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step - loss: 1.2335e-05 - val_loss: 3.0151e-06\n",
      "Epoch 408/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1413e-05 - val_loss: 3.9346e-06\n",
      "Epoch 409/1500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.2219e-05 - val_loss: 4.5551e-06\n",
      "Epoch 410/1500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.2117e-05 - val_loss: 4.4279e-06\n",
      "Epoch 411/1500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2206e-05 - val_loss: 3.2676e-06\n",
      "Epoch 412/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.2184e-05 - val_loss: 2.6572e-06\n",
      "Epoch 413/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1637e-05 - val_loss: 2.8710e-06\n",
      "Epoch 414/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2117e-05 - val_loss: 3.6432e-06\n",
      "Epoch 415/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1739e-05 - val_loss: 4.9320e-06\n",
      "Epoch 416/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2274e-05 - val_loss: 4.8138e-06\n",
      "Epoch 417/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3071e-05 - val_loss: 3.6163e-06\n",
      "Epoch 418/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1340e-05 - val_loss: 2.7387e-06\n",
      "Epoch 419/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2961e-05 - val_loss: 2.6808e-06\n",
      "Epoch 420/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1471e-05 - val_loss: 3.3848e-06\n",
      "Epoch 421/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2527e-05 - val_loss: 4.6674e-06\n",
      "Epoch 422/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1695e-05 - val_loss: 5.1208e-06\n",
      "Epoch 423/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2036e-05 - val_loss: 4.5772e-06\n",
      "Epoch 424/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2410e-05 - val_loss: 3.5157e-06\n",
      "Epoch 425/1500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.0981e-05 - val_loss: 2.5887e-06\n",
      "Epoch 426/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.2041e-05 - val_loss: 2.4179e-06\n",
      "Epoch 427/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2004e-05 - val_loss: 2.8998e-06\n",
      "Epoch 428/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1460e-05 - val_loss: 3.8369e-06\n",
      "Epoch 429/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1164e-05 - val_loss: 4.8818e-06\n",
      "Epoch 430/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.2413e-05 - val_loss: 4.9118e-06\n",
      "Epoch 431/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2049e-05 - val_loss: 4.0092e-06\n",
      "Epoch 432/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2225e-05 - val_loss: 3.4045e-06\n",
      "Epoch 433/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2055e-05 - val_loss: 3.0624e-06\n",
      "Epoch 434/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1977e-05 - val_loss: 3.2032e-06\n",
      "Epoch 435/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1572e-05 - val_loss: 3.5582e-06\n",
      "Epoch 436/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1111e-05 - val_loss: 4.0103e-06\n",
      "Epoch 437/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0726e-05 - val_loss: 4.1861e-06\n",
      "Epoch 438/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0588e-05 - val_loss: 3.9078e-06\n",
      "Epoch 439/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.2101e-05 - val_loss: 3.4967e-06\n",
      "Epoch 440/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1936e-05 - val_loss: 3.3181e-06\n",
      "Epoch 441/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.0912e-05 - val_loss: 3.5064e-06\n",
      "Epoch 442/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1739e-05 - val_loss: 3.8820e-06\n",
      "Epoch 443/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1171e-05 - val_loss: 3.7566e-06\n",
      "Epoch 444/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2377e-05 - val_loss: 3.0422e-06\n",
      "Epoch 445/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1194e-05 - val_loss: 2.7247e-06\n",
      "Epoch 446/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1389e-05 - val_loss: 2.7624e-06\n",
      "Epoch 447/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2385e-05 - val_loss: 3.5159e-06\n",
      "Epoch 448/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2059e-05 - val_loss: 3.8796e-06\n",
      "Epoch 449/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1997e-05 - val_loss: 3.9165e-06\n",
      "Epoch 450/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1940e-05 - val_loss: 3.6420e-06\n",
      "Epoch 451/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1821e-05 - val_loss: 3.3726e-06\n",
      "Epoch 452/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1181e-05 - val_loss: 3.3052e-06\n",
      "Epoch 453/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1536e-05 - val_loss: 3.1373e-06\n",
      "Epoch 454/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1651e-05 - val_loss: 3.2357e-06\n",
      "Epoch 455/1500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1077e-05 - val_loss: 3.5775e-06\n",
      "Epoch 456/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.2036e-05 - val_loss: 4.2651e-06\n",
      "Epoch 457/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1149e-05 - val_loss: 4.3666e-06\n",
      "Epoch 458/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1773e-05 - val_loss: 3.5509e-06\n",
      "Epoch 459/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1068e-05 - val_loss: 2.9034e-06\n",
      "Epoch 460/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.1146e-05 - val_loss: 2.6782e-06\n",
      "Epoch 461/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1876e-05 - val_loss: 3.0502e-06\n",
      "Epoch 462/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0955e-05 - val_loss: 3.7979e-06\n",
      "Epoch 463/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1304e-05 - val_loss: 4.2029e-06\n",
      "Epoch 464/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.0697e-05 - val_loss: 4.1745e-06\n",
      "Epoch 465/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.1210e-05 - val_loss: 3.3454e-06\n",
      "Epoch 466/1500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.1150e-05 - val_loss: 3.0586e-06\n",
      "Epoch 467/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1269e-05 - val_loss: 3.0647e-06\n",
      "Epoch 468/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0345e-05 - val_loss: 3.4596e-06\n",
      "Epoch 469/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1463e-05 - val_loss: 3.7672e-06\n",
      "Epoch 470/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1290e-05 - val_loss: 3.8346e-06\n",
      "Epoch 471/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1154e-05 - val_loss: 3.5879e-06\n",
      "Epoch 472/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1873e-05 - val_loss: 3.1213e-06\n",
      "Epoch 473/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1435e-05 - val_loss: 2.9880e-06\n",
      "Epoch 474/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1797e-05 - val_loss: 2.8831e-06\n",
      "Epoch 475/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1496e-05 - val_loss: 3.6120e-06\n",
      "Epoch 476/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1686e-05 - val_loss: 3.8220e-06\n",
      "Epoch 477/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0714e-05 - val_loss: 3.6659e-06\n",
      "Epoch 478/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2138e-05 - val_loss: 3.1654e-06\n",
      "Epoch 479/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0890e-05 - val_loss: 2.6275e-06\n",
      "Epoch 480/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1878e-05 - val_loss: 2.6048e-06\n",
      "Epoch 481/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1910e-05 - val_loss: 3.5317e-06\n",
      "Epoch 482/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1579e-05 - val_loss: 4.4942e-06\n",
      "Epoch 483/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0220e-05 - val_loss: 4.0682e-06\n",
      "Epoch 484/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0291e-05 - val_loss: 3.5609e-06\n",
      "Epoch 485/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0379e-05 - val_loss: 3.1632e-06\n",
      "Epoch 486/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0529e-05 - val_loss: 3.2166e-06\n",
      "Epoch 487/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0462e-05 - val_loss: 3.2151e-06\n",
      "Epoch 488/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0513e-05 - val_loss: 3.2110e-06\n",
      "Epoch 489/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1002e-05 - val_loss: 3.3975e-06\n",
      "Epoch 490/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0438e-05 - val_loss: 3.5221e-06\n",
      "Epoch 491/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1510e-05 - val_loss: 3.8053e-06\n",
      "Epoch 492/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0869e-05 - val_loss: 3.9020e-06\n",
      "Epoch 493/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1104e-05 - val_loss: 3.3291e-06\n",
      "Epoch 494/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2137e-05 - val_loss: 3.0218e-06\n",
      "Epoch 495/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0809e-05 - val_loss: 2.6603e-06\n",
      "Epoch 496/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0514e-05 - val_loss: 2.9470e-06\n",
      "\n",
      "Loading Model: '02-07-2021--12--20-E2E_LSTM_ValSet_0.001-ALPHA0.001-BETA_SD17-496Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.011373387048855585\n",
      "Model: \"functional_85\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_43 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_170 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_171 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0013 - val_loss: 7.0399e-04\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 7.5483e-04 - val_loss: 2.7233e-04\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 4.6095e-04 - val_loss: 1.3182e-04\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.5908e-04 - val_loss: 3.0578e-04\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 7.5229e-04 - val_loss: 4.7860e-04\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0011 - val_loss: 4.9715e-04\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0011 - val_loss: 3.9747e-04\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 9.0650e-04 - val_loss: 2.6526e-04\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 7.2709e-04 - val_loss: 1.6077e-04\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 5.2762e-04 - val_loss: 1.0831e-04\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 4.5644e-04 - val_loss: 1.0626e-04\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.8691e-04 - val_loss: 1.4257e-04\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.4096e-04 - val_loss: 2.0084e-04\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.7608e-04 - val_loss: 2.6570e-04\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.8979e-04 - val_loss: 3.2637e-04\n",
      "Epoch 22/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step - loss: 4.4487e-04 - val_loss: 3.7659e-04\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.3192e-04 - val_loss: 4.1085e-04\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.0665e-04 - val_loss: 4.2708e-04\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 4.7956e-04 - val_loss: 4.2646e-04\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 4.7498e-04 - val_loss: 4.1067e-04\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.7740e-04 - val_loss: 3.8182e-04\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 4.6602e-04 - val_loss: 3.4368e-04\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 4.4673e-04 - val_loss: 3.0063e-04\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.7129e-04 - val_loss: 2.5547e-04\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.6356e-04 - val_loss: 2.1105e-04\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.3568e-04 - val_loss: 1.7102e-04\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.2834e-04 - val_loss: 1.3763e-04\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.5936e-04 - val_loss: 1.1217e-04\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.0570e-04 - val_loss: 9.4261e-05\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.0583e-04 - val_loss: 8.3002e-05\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.4956e-04 - val_loss: 7.6129e-05\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 3.1585e-04 - val_loss: 7.2264e-05\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 3.2154e-04 - val_loss: 7.0194e-05\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 3.2478e-04 - val_loss: 6.8942e-05\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.4057e-04 - val_loss: 6.8580e-05\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.6721e-04 - val_loss: 7.0135e-05\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.5595e-04 - val_loss: 7.5103e-05\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.1397e-04 - val_loss: 8.2621e-05\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.0224e-04 - val_loss: 9.3254e-05\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.0620e-04 - val_loss: 1.0455e-04\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.0122e-04 - val_loss: 1.1530e-04\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.0786e-04 - val_loss: 1.2272e-04\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.0263e-04 - val_loss: 1.2762e-04\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.0415e-04 - val_loss: 1.2848e-04\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.9234e-04 - val_loss: 1.2697e-04\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 3.0548e-04 - val_loss: 1.2304e-04\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.7871e-04 - val_loss: 1.1680e-04\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.9628e-04 - val_loss: 1.1081e-04\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.7522e-04 - val_loss: 1.0319e-04\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.7760e-04 - val_loss: 9.4648e-05\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.8285e-04 - val_loss: 8.6322e-05\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.8055e-04 - val_loss: 7.9135e-05\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.5644e-04 - val_loss: 7.3485e-05\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.5504e-04 - val_loss: 6.9387e-05\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.4651e-04 - val_loss: 6.5857e-05\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.5984e-04 - val_loss: 6.3527e-05\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.5839e-04 - val_loss: 6.2564e-05\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.4146e-04 - val_loss: 6.3110e-05\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.4861e-04 - val_loss: 6.4727e-05\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.5358e-04 - val_loss: 6.6061e-05\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.4486e-04 - val_loss: 6.8108e-05\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.4998e-04 - val_loss: 7.1868e-05\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.5164e-04 - val_loss: 7.5888e-05\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.6310e-04 - val_loss: 7.9827e-05\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.2454e-04 - val_loss: 8.2814e-05\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.4758e-04 - val_loss: 8.4069e-05\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.5646e-04 - val_loss: 8.3348e-05\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.3828e-04 - val_loss: 8.2058e-05\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.2838e-04 - val_loss: 7.9608e-05\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.3270e-04 - val_loss: 7.6134e-05\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 2.5054e-04 - val_loss: 7.2257e-05\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.3419e-04 - val_loss: 6.9231e-05\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1355e-04 - val_loss: 6.5918e-05\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3372e-04 - val_loss: 6.3239e-05\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.2951e-04 - val_loss: 6.0983e-05\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 2.2008e-04 - val_loss: 5.9476e-05\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1977e-04 - val_loss: 5.9854e-05\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.2753e-04 - val_loss: 6.0771e-05\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.3465e-04 - val_loss: 6.1733e-05\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.1613e-04 - val_loss: 6.3148e-05\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0581e-04 - val_loss: 6.5248e-05\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3453e-04 - val_loss: 6.7169e-05\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.1646e-04 - val_loss: 6.8831e-05\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.3328e-04 - val_loss: 7.0557e-05\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.1941e-04 - val_loss: 7.0736e-05\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0872e-04 - val_loss: 7.0988e-05\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2633e-04 - val_loss: 7.1812e-05\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.2139e-04 - val_loss: 7.0086e-05\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.2169e-04 - val_loss: 6.6305e-05\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.9688e-04 - val_loss: 6.3070e-05\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.0364e-04 - val_loss: 5.8901e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.0137e-04 - val_loss: 5.5461e-05\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.8324e-04 - val_loss: 5.2419e-05\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.0951e-04 - val_loss: 5.0338e-05\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.9061e-04 - val_loss: 5.2162e-05\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0748e-04 - val_loss: 5.5177e-05\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0619e-04 - val_loss: 6.0378e-05\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.9938e-04 - val_loss: 6.6331e-05\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0093e-04 - val_loss: 6.9080e-05\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0643e-04 - val_loss: 6.9483e-05\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0608e-04 - val_loss: 6.6192e-05\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0653e-04 - val_loss: 6.2576e-05\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.9041e-04 - val_loss: 5.8456e-05\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8705e-04 - val_loss: 5.4650e-05\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.9471e-04 - val_loss: 5.1268e-05\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 2.0541e-04 - val_loss: 4.7704e-05\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.9592e-04 - val_loss: 4.5579e-05\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.8772e-04 - val_loss: 4.5850e-05\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8631e-04 - val_loss: 4.8844e-05\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8079e-04 - val_loss: 5.2673e-05\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.8100e-04 - val_loss: 5.6806e-05\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.9238e-04 - val_loss: 6.0121e-05\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.8871e-04 - val_loss: 6.2157e-05\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.8314e-04 - val_loss: 6.0691e-05\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.7967e-04 - val_loss: 5.7439e-05\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7354e-04 - val_loss: 5.4370e-05\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.8497e-04 - val_loss: 5.1427e-05\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.8612e-04 - val_loss: 4.9512e-05\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.8762e-04 - val_loss: 4.6142e-05\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.8688e-04 - val_loss: 4.2005e-05\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.7631e-04 - val_loss: 4.0749e-05\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.8637e-04 - val_loss: 4.1448e-05\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.6493e-04 - val_loss: 4.3087e-05\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.6746e-04 - val_loss: 4.8767e-05\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.7840e-04 - val_loss: 5.2519e-05\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.7452e-04 - val_loss: 5.2077e-05\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.8879e-04 - val_loss: 4.9036e-05\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.8194e-04 - val_loss: 4.7784e-05\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.8259e-04 - val_loss: 4.6689e-05\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7430e-04 - val_loss: 4.2842e-05\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.7331e-04 - val_loss: 4.2368e-05\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.6581e-04 - val_loss: 4.3391e-05\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5734e-04 - val_loss: 4.6463e-05\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.6484e-04 - val_loss: 4.9934e-05\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.4744e-04 - val_loss: 5.1979e-05\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.7032e-04 - val_loss: 5.5456e-05\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6772e-04 - val_loss: 5.7317e-05\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.5619e-04 - val_loss: 5.2311e-05\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5362e-04 - val_loss: 4.0948e-05\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.4979e-04 - val_loss: 3.5256e-05\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.6844e-04 - val_loss: 3.6850e-05\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.6285e-04 - val_loss: 4.6042e-05\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.6589e-04 - val_loss: 6.4244e-05\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6582e-04 - val_loss: 7.0322e-05\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5499e-04 - val_loss: 6.0514e-05\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.6802e-04 - val_loss: 4.4847e-05\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5831e-04 - val_loss: 3.4187e-05\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.6706e-04 - val_loss: 3.1682e-05\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.6277e-04 - val_loss: 3.8122e-05\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.6416e-04 - val_loss: 5.0830e-05\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5898e-04 - val_loss: 5.9359e-05\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5360e-04 - val_loss: 5.7115e-05\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.5550e-04 - val_loss: 4.8014e-05\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.6070e-04 - val_loss: 3.9472e-05\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.6020e-04 - val_loss: 3.4815e-05\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.6601e-04 - val_loss: 3.1899e-05\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5430e-04 - val_loss: 3.5198e-05\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.4062e-04 - val_loss: 4.2868e-05\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.4271e-04 - val_loss: 5.3434e-05\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5360e-04 - val_loss: 5.9959e-05\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.6107e-04 - val_loss: 5.8292e-05\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5482e-04 - val_loss: 4.9034e-05\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5705e-04 - val_loss: 3.8978e-05\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5433e-04 - val_loss: 3.3676e-05\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5200e-04 - val_loss: 3.5007e-05\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3390e-04 - val_loss: 4.2952e-05\n",
      "Epoch 173/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4428e-04 - val_loss: 5.1623e-05\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 1.4938e-04 - val_loss: 5.8399e-05\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.3917e-04 - val_loss: 5.5788e-05\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.5415e-04 - val_loss: 4.5348e-05\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.3762e-04 - val_loss: 3.4462e-05\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.3850e-04 - val_loss: 2.9708e-05\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.6959e-04 - val_loss: 3.0416e-05\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5351e-04 - val_loss: 3.9278e-05\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4191e-04 - val_loss: 5.2543e-05\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3899e-04 - val_loss: 6.3028e-05\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4522e-04 - val_loss: 5.7240e-05\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4671e-04 - val_loss: 4.5755e-05\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3315e-04 - val_loss: 3.3778e-05\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.4205e-04 - val_loss: 2.7748e-05\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3433e-04 - val_loss: 2.8931e-05\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4508e-04 - val_loss: 3.6837e-05\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4324e-04 - val_loss: 4.8176e-05\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4025e-04 - val_loss: 5.6324e-05\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.4089e-04 - val_loss: 5.6465e-05\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4145e-04 - val_loss: 4.5327e-05\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3671e-04 - val_loss: 3.6398e-05\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3919e-04 - val_loss: 2.9772e-05\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.4766e-04 - val_loss: 2.7165e-05\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3282e-04 - val_loss: 2.9096e-05\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3786e-04 - val_loss: 3.9096e-05\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.5311e-04 - val_loss: 5.0215e-05\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3803e-04 - val_loss: 5.5034e-05\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.4008e-04 - val_loss: 4.7074e-05\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.3002e-04 - val_loss: 3.7188e-05\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.4343e-04 - val_loss: 3.1264e-05\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3366e-04 - val_loss: 3.2169e-05\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3171e-04 - val_loss: 3.9109e-05\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3740e-04 - val_loss: 4.9045e-05\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3465e-04 - val_loss: 4.7124e-05\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2440e-04 - val_loss: 3.9614e-05\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.2896e-04 - val_loss: 3.4178e-05\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.2818e-04 - val_loss: 3.1666e-05\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3364e-04 - val_loss: 3.1376e-05\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4004e-04 - val_loss: 3.8507e-05\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2942e-04 - val_loss: 4.3521e-05\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2259e-04 - val_loss: 4.5270e-05\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3111e-04 - val_loss: 4.1784e-05\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3595e-04 - val_loss: 3.6576e-05\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2831e-04 - val_loss: 3.2054e-05\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3457e-04 - val_loss: 3.1907e-05\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.2590e-04 - val_loss: 3.5202e-05\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2736e-04 - val_loss: 3.9076e-05\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3060e-04 - val_loss: 3.9073e-05\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1466e-04 - val_loss: 3.7596e-05\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3056e-04 - val_loss: 3.5915e-05\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2796e-04 - val_loss: 3.4578e-05\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2072e-04 - val_loss: 3.4633e-05\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3512e-04 - val_loss: 3.6093e-05\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2283e-04 - val_loss: 3.5610e-05\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2988e-04 - val_loss: 3.6251e-05\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2390e-04 - val_loss: 3.8207e-05\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2282e-04 - val_loss: 3.8305e-05\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2882e-04 - val_loss: 3.2466e-05\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2740e-04 - val_loss: 3.0308e-05\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2582e-04 - val_loss: 3.4799e-05\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1811e-04 - val_loss: 3.9421e-05\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.2886e-04 - val_loss: 3.7106e-05\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1781e-04 - val_loss: 3.4779e-05\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3302e-04 - val_loss: 3.3087e-05\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1129e-04 - val_loss: 3.5147e-05\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2825e-04 - val_loss: 3.2416e-05\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2321e-04 - val_loss: 3.0789e-05\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2909e-04 - val_loss: 3.0668e-05\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2057e-04 - val_loss: 3.0586e-05\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3669e-04 - val_loss: 3.2644e-05\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2552e-04 - val_loss: 3.6167e-05\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2461e-04 - val_loss: 3.6730e-05\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3048e-04 - val_loss: 3.5616e-05\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.2084e-04 - val_loss: 3.3882e-05\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3246e-04 - val_loss: 3.4395e-05\n",
      "Epoch 248/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2426e-04 - val_loss: 3.1125e-05\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2469e-04 - val_loss: 3.2099e-05\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.2044e-04 - val_loss: 3.7131e-05\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3050e-04 - val_loss: 3.6702e-05\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.2839e-04 - val_loss: 3.7196e-05\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.2273e-04 - val_loss: 3.9060e-05\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.2306e-04 - val_loss: 3.3788e-05\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.2878e-04 - val_loss: 3.2016e-05\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.1618e-04 - val_loss: 3.0150e-05\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.2487e-04 - val_loss: 3.0502e-05\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2175e-04 - val_loss: 3.5598e-05\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2011e-04 - val_loss: 3.8924e-05\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2826e-04 - val_loss: 4.0199e-05\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2084e-04 - val_loss: 3.8266e-05\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1702e-04 - val_loss: 3.2799e-05\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2913e-04 - val_loss: 2.9154e-05\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2968e-04 - val_loss: 3.1120e-05\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2045e-04 - val_loss: 3.7277e-05\n",
      "\n",
      "Loading Model: '02-07-2021--12--40-E2E_LSTM_ValSet_0.001-ALPHA0.01-BETA_SD17-265Epochs-rlf-Loss-64-HU-'\n",
      "Total number of days: 309\n",
      "Day 0 | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 | Day 7 | Day 8 | Day 9 | Day 10 | Day 11 | Day 12 | Day 13 | Day 14 | Day 15 | Day 16 | Day 17 | Day 18 | Day 19 | Day 20 | Day 21 | Day 22 | Day 23 | Day 24 | Day 25 | Day 26 | Day 27 | Day 28 | Day 29 | Day 30 | Day 31 | Day 32 | Day 33 | Day 34 | Day 35 | Day 36 | Day 37 | Day 38 | Day 39 | Day 40 | Day 41 | Day 42 | Day 43 | Day 44 | Day 45 | Day 46 | Day 47 | Day 48 | Day 49 | Day 50 | Day 51 | Day 52 | Day 53 | Day 54 | Day 55 | Day 56 | Day 57 | Day 58 | Day 59 | Day 60 | Day 61 | Day 62 | Day 63 | Day 64 | Day 65 | Day 66 | Day 67 | Day 68 | Day 69 | Day 70 | Day 71 | Day 72 | Day 73 | Day 74 | Day 75 | Day 76 | Day 77 | Day 78 | Day 79 | Day 80 | Day 81 | Day 82 | Day 83 | Day 84 | Day 85 | Day 86 | Day 87 | Day 88 | Day 89 | Day 90 | Day 91 | Day 92 | Day 93 | Day 94 | Day 95 | Day 96 | Day 97 | Day 98 | Day 99 | Day 100 | Day 101 | Day 102 | Day 103 | Day 104 | Day 105 | Day 106 | Day 107 | Day 108 | Day 109 | Day 110 | Day 111 | Day 112 | Day 113 | Day 114 | Day 115 | Day 116 | Day 117 | Day 118 | Day 119 | Day 120 | Day 121 | Day 122 | Day 123 | Day 124 | Day 125 | Day 126 | Day 127 | Day 128 | Day 129 | Day 130 | Day 131 | Day 132 | Day 133 | Day 134 | Day 135 | Day 136 | Day 137 | Day 138 | Day 139 | Day 140 | Day 141 | Day 142 | Day 143 | Day 144 | Day 145 | Day 146 | Day 147 | Day 148 | Day 149 | Day 150 | Day 151 | Day 152 | Day 153 | Day 154 | Day 155 | Day 156 | Day 157 | Day 158 | Day 159 | Day 160 | Day 161 | Day 162 | Day 163 | Day 164 | Day 165 | Day 166 | Day 167 | Day 168 | Day 169 | Day 170 | Day 171 | Day 172 | Day 173 | Day 174 | Day 175 | Day 176 | Day 177 | Day 178 | Day 179 | Day 180 | Day 181 | Day 182 | Day 183 | Day 184 | Day 185 | Day 186 | Day 187 | Day 188 | Day 189 | Day 190 | Day 191 | Day 192 | Day 193 | Day 194 | Day 195 | Day 196 | Day 197 | Day 198 | Day 199 | Day 200 | Day 201 | Day 202 | Day 203 | Day 204 | Day 205 | Day 206 | Day 207 | Day 208 | Day 209 | Day 210 | Day 211 | Day 212 | Day 213 | Day 214 | Day 215 | Day 216 | Day 217 | Day 218 | Day 219 | Day 220 | Day 221 | Day 222 | Day 223 | Day 224 | Day 225 | Day 226 | Day 227 | Day 228 | Day 229 | Day 230 | Day 231 | Day 232 | Day 233 | Day 234 | Day 235 | Day 236 | Day 237 | Day 238 | Day 239 | Day 240 | Day 241 | Day 242 | Day 243 | Day 244 | Day 245 | Day 246 | Day 247 | Day 248 | Day 249 | Day 250 | Day 251 | Day 252 | Day 253 | Day 254 | Day 255 | Day 256 | Day 257 | Day 258 | Day 259 | Day 260 | Day 261 | Day 262 | Day 263 | Day 264 | Day 265 | Day 266 | Day 267 | Day 268 | Day 269 | Day 270 | Day 271 | Day 272 | Day 273 | Day 274 | Day 275 | Day 276 | Day 277 | Day 278 | Day 279 | Day 280 | Day 281 | Day 282 | Day 283 | Day 284 | Day 285 | Day 286 | Day 287 | Day 288 | Day 289 | Day 290 | Day 291 | Day 292 | Day 293 | Day 294 | Day 295 | Day 296 | Day 297 | Day 298 | Day 299 | Day 300 | Day 301 | Day 302 | Day 303 | Day 304 | Day 305 | Day 306 | Day 307 | -0.063431635 0.06305041 0.00073330535 -0.009421022693959903\n",
      "Model: \"functional_87\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_174 (LSTM)              (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_175 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "1/1 [==============================] - 1s 929ms/step - loss: 0.0687 - val_loss: 0.0580\n",
      "Epoch 2/1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tf.config.run_functions_eagerly(True)\n",
    "\n",
    "alpha = [1e-4, 1e-3, 1e-2, 1e-1, 0, 1e0, 1e2, 1e3]\n",
    "beta = [1e-4, 1e-3, 1e-2, 1e-1, 0, 1e0, 1e2, 1e3]\n",
    "alpha.sort(reverse=True)\n",
    "\n",
    "model_folder = './RL_val_models'\n",
    "\n",
    "DMJ = TF_Models('./data_sets/NASDAQ_Cleaned', model_folder, reload=False)\n",
    "data_splits = DMJ.split_data()\n",
    "# model = DMJ.generate_model()\n",
    "# GP = Graph_Predictions(model_folder, \"./strategies/RL_validation_strategies\", DMJ)\n",
    "\n",
    "for a in alpha:\n",
    "    for b in beta:\n",
    "        if a == 0 and b == 0:\n",
    "            continue\n",
    "        # Reset the training object to get rid of old data\n",
    "        DMJ = TF_Models('./data_sets/NASDAQ_Cleaned', model_folder, reload=False)\n",
    "        \n",
    "        # Create the model using parameters we're tuning\n",
    "        DMJ._generate_model(model_type='lstm',loss_function='rank_loss', activation='leaky_relu', hidden_units=64, true_random=True, alpha=a, beta=b)\n",
    "        \n",
    "        # Have it train as much as it can\n",
    "        DMJ.train_model(epochs=1500)\n",
    "        \n",
    "        # Save the model with a tag\n",
    "        DMJ.save_model(tag=f'E2E_LSTM_ValSet_{a}-ALPHA{b}-BETA_SD17')\n",
    "        \n",
    "        # Reset the training object to get rid of old data\n",
    "        GP = Graph_Predictions(model_folder, \"./strategies/RL_validation_strategies\", DMJ)\n",
    "        \n",
    "        # Generate the prediction file\n",
    "        GP.generate_prediction_json(DMJ.model_name, neural_net_type='lstm')\n",
    "        \n",
    "        # Create the diagnostics file for the most recently saved model\n",
    "        GP.generate_model_diagnostics(GP.model_name, datablock_folder='RL_validation_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'hi{1e-4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the  model\n",
    "model = DMJ.train_model(epochs=500)\n",
    "# model = DMJ.train_model(model, data_splits['x_train'], data_splits['y_train'], data_splits['x_val'], data_splits['y_val'], epochs=50, learning_rate=5e-5, gcn_matrix=DMJ.Normalized_Adjacency_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMJ.save_model(tag='E2E_LSTM_VariedLR_RL_ALPHA_1_NOMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GP = Graph_Predictions(\"./models\", \"./strategies\", DMJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GP.strategy_ratio_lstm('11-22-2020--17--32--LSTM--50Epochs--mse-Loss--64-HU--None', avoid_fall=False, name_override='test_')\n",
    "# GP.strategy_ratio_lstm('11-22-2020--17--32--LSTM--50Epochs--mse-Loss--64-HU--None', avoid_fall=False, average=10, name_override='LSTM-MSE-50Epoch-Average10')\n",
    "# GP.strategy_ratio_lstm('11-22-2020--17--32--LSTM--50Epochs--mse-Loss--64-HU--None', avoid_fall=True, name_override='LSTM-MSE-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_lstm('11-22-2020--14--55--LSTM-Rankloss--50Epochs--rlf-Loss--64-HU--', avoid_fall=False, name_override='LSTM-RankLoss-50Epoch')\n",
    "# GP.strategy_ratio_lstm('11-22-2020--14--55--LSTM-Rankloss--50Epochs--rlf-Loss--64-HU--', avoid_fall=False, average=10, name_override='LSTM-RankLoss-50Epoch-Average10')\n",
    "# GP.strategy_ratio_lstm('11-22-2020--14--55--LSTM-Rankloss--50Epochs--rlf-Loss--64-HU--', avoid_fall=True, name_override='LSTM-RankLoss-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--31--GCN1-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN1-MSE-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--31--GCN1-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=True, name_override='GCN1-MSE-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--34--GCN1-Rankloss--50Epochs--rlf-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN1-RankLoss-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--34--GCN1-Rankloss--50Epochs--rlf-Loss--64-HU--', avoid_fall=True, name_override='GCN1-RankLoss-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--37--GCN2-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN2-MSE-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--37--GCN2-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=True, name_override='GCN2-MSE-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--39--GCN2-RankLoss--50Epochs--rlf-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN2-RankLoss-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--39--GCN2-RankLoss--50Epochs--rlf-Loss--64-HU--', avoid_fall=True, name_override='GCN2-RankLoss-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_gcn('11-22-2020--16--46--GCN3-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN3-MSE-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--46--GCN3-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=True, name_override='GCN3-MSE-50Epoch-AvoidFall-2ndBest')\n",
    "\n",
    "# GP.strategy_ratio_gcn('11-22-2020--16--43--GCN3-RankLoss--50Epochs--rlf-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN3-RankLoss-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--43--GCN3-RankLoss--50Epochs--rlf-Loss--64-HU--', avoid_fall=True, name_override='GCN3-RankLoss-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_gcn('11-22-2020--20--46--GCN3-MSE-Ratio+1--50Epochs--mse-Loss--64-HU--', avoid_fall=True, average=1, name_override='GCN3-MSE-200Epoch-Ratio+1')\n",
    "# GP.strategy_ratio_gcn('11-22-2020--20--43--GCN3-RankLoss-Ratio+1--50Epochs--rlf-Loss--64-HU--', avoid_fall=True, average=1, name_override='GCN3-RankLoss-200Epoch-Ratio+1')\n",
    "\n",
    "'''New prediction memory storage'''\n",
    "# GP.generate_prediction_json('11-22-2020--15--01--LSTM-MSE--50Epochs--mse-Loss--64-HU--', neural_net_type='lstm')\n",
    "# GP.generate_prediction_json('11-22-2020--16--46--GCN3-MSE--50Epochs--mse-Loss--64-HU--', neural_net_type='gcn')\n",
    "\n",
    "'''Seperately trained LSTM combo'''\n",
    "# GP.generate_prediction_json('01-04-2021--14--20--SEP_LSTM_GCN3-1e-5LR--70Epochs--mse-Loss--64-HU--', neural_net_type='gcn')\n",
    "\n",
    "''''''\n",
    "GP.generate_prediction_json('02-04-2021--15--11--E2E_LSTM_VariedLR_RL_ALPHA_1_NOMSE--500Epochs--rlf-Loss--64-HU--', neural_net_type='lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strat_name = '02-04-2021--15--11--E2E_LSTM_VariedLR_RL_ALPHA_1_NOMSE--500Epochs--rlf-Loss--64-HU--_PM'\n",
    "\n",
    "# Testing the PM file feature\n",
    "avg = [1, 5, 20, 50, 100, 200]\n",
    "avg = [1]\n",
    "for a in avg:\n",
    "#     GP.prediction_json_strategy_max_entities(strat_name, average=a, avoid_fall=False, name_override=strat_name+ f'{a}AVG')\n",
    "    GP.prediction_json_strategy_determine_best(strat_name, average=a, avoid_fall=False, name_override=strat_name+ f'{a}AVG_Correct_BuyDay_plus1')\n",
    "    GP.save_results()\n",
    "# Testing the mse tracking feature\n",
    "# GP.prediction_json_mse('01-04-2021--15--57--SEP_LSTM_GCN3-5e-6LR--820Epochs--mse-Loss--64-HU--_PM')\n",
    "GP.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP.generate_model_diagnostics('02-04-2021--15--11--E2E_LSTM_VariedLR_RL_ALPHA_1_NOMSE--500Epochs--rlf-Loss--64-HU--_PM', datablock_folder='RL_validation_set')\n",
    "\n",
    "'01-04-2021--15--57--SEP_LSTM_GCN3-5e-6LR--820Epochs--mse-Loss--64-HU--_PM'\n",
    "255025890000.0\n",
    "0.012249682697757544\n",
    "0.7766990291262136\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GP.generate_upper_lower_avg_bounds()\n",
    "\n",
    "GP.display_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP.strategy_ratio_gcn('11-22-2020--16--46--GCN3-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN3-MSE-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--46--GCN3-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=True, name_override='GCN3-MSE-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_gcn('11-22-2020--16--43--GCN3-RankLoss--50Epochs--rlf-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN3-RankLoss-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--43--GCN3-RankLoss--50Epochs--rlf-Loss--64-HU--', avoid_fall=True, name_override='GCN3-RankLoss-50Epoch-AvoidFall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP.save_results('./strategies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import GridBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "bar = widgets.IntProgress(min=0, max=10, description='Loading:', bar_style='info')\n",
    "display(bar)\n",
    "\n",
    "for i in range(11):\n",
    "    time.sleep(0.2)\n",
    "    bar.value = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "widgets.Text(\n",
    "    value='Loading',\n",
    "    description='',\n",
    "    disabled=True\n",
    "    layout=L\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the loading bar by initializing it\n",
    "nam_bar = widgets.IntProgress(min=0, max=5, value=0, description='Loading Normalized Adjacency Matrix:',\n",
    "                              layout=widgets.Layout(width='auto'))\n",
    "text = widgets.Text(value='Loading', description='', disabled=True, layout=widgets.Layout(width='auto'))\n",
    "\n",
    "test = widgets.GridBox(children=[text, nam_bar], layout=widgets.Layout(width='auto'))\n",
    "\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.amax(GP.rr_test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(GP.rr_test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP.rr_test[476,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(GP.rr_test[5, :], GP.rr_test[100, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def swap_random(seq):\n",
    "    idx = range(len(seq))\n",
    "    i1, i2 = random.sample(idx, 2)\n",
    "    seq[i1], seq[i2] = seq[i2], seq[i1]\n",
    "\n",
    "trials_RL = []\n",
    "for e in range(100,300):\n",
    "    RL = []\n",
    "    for t in range(300):\n",
    "        A = []; B = [];\n",
    "        for l in range(e):\n",
    "            n = random.uniform(-1, 1)\n",
    "            A.append(n)\n",
    "            B.append(n)\n",
    "        swap_random(B)\n",
    "        swap_random(B)\n",
    "        swap_random(B)\n",
    "        swap_random(B)\n",
    "        \n",
    "        return_ratio = tf.constant(A, shape=(len(A), 1))\n",
    "        ground_truth = tf.constant(B, shape=(len(B), 1))\n",
    "\n",
    "        ###############################################################\n",
    "        # Create an array of all_ones so that we can calculate all permutations of subtractions\n",
    "        all_ones = tf.ones([len(return_ratio), 1], dtype=tf.float32)\n",
    "\n",
    "        # Creates a N x N matrix with every predicted return ratio for each company subtracted with every other\n",
    "        # company\n",
    "        pred_dif = tf.math.subtract(\n",
    "            tf.matmul(return_ratio, all_ones, transpose_b=True),\n",
    "            tf.matmul(all_ones, return_ratio, transpose_b=True)\n",
    "        )\n",
    "\n",
    "        # Creates an N x N matrix containing every actual return ratio for each company subtracted with every other\n",
    "        # company By switching the order of the all_ones matricies and the actual prices, a negative sign is introduced\n",
    "        # When RELU is applied later, correct predictions will not affect loss while incorrect predictions will affect\n",
    "        # loss depending on how incorrect the prediction was\n",
    "        actual_dif = tf.math.subtract(\n",
    "            tf.matmul(all_ones, ground_truth, transpose_b=True),\n",
    "            tf.matmul(ground_truth, all_ones, transpose_b=True)\n",
    "        )\n",
    "\n",
    "        # Using the above two qualities, the algorithm can be punished for incorrectly calculating when a company is\n",
    "        # doing better than another company Reduces the mean across each dimension until only 1 value remains\n",
    "        rank_loss = tf.reduce_mean(\n",
    "            # Takes if a given value is >0, it is kept, otherwise, it becomes 0\n",
    "            tf.nn.relu(\n",
    "                # Multiplies all of the\n",
    "                tf.multiply(pred_dif, actual_dif)\n",
    "            )\n",
    "        )\n",
    "        RL.append(rank_loss)\n",
    "    trials_RL.append(np.mean(RL))\n",
    "\n",
    "plt.plot(trials_RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [0.1, 0.5, 0.2, 0.3]\n",
    "print(list(zip(range(4), r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [100, 300, 200, 400]\n",
    "predictions = list(zip(range(len(predictions)), predictions))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Normal Rank\n",
    "A = list(range(1, 10001))\n",
    "B = [i**(-1) for i in A]\n",
    "print(np.mean(A))\n",
    "print(np.mean(B)**-1)\n",
    "\n",
    "\n",
    "'000_Avg_RR.p'\n",
    "'000_Highest_RR_Possible.p'\n",
    "'000_Lowest_RR_Possible.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import similaritymeasures as sm\n",
    "import numpy as np\n",
    "\n",
    "# Generate random experimental data\n",
    "n = 5\n",
    "x = list(range(n))\n",
    "y = [11, 26, 26, 11, -60]\n",
    "exp_data = np.zeros((n, 2))\n",
    "exp_data[:, 0] = x\n",
    "exp_data[:, 1] = y\n",
    "\n",
    "# Generate random numerical data\n",
    "x = list(range(n))\n",
    "y = [1, 2, 30, 4, -9000]\n",
    "num_data = np.zeros((n, 2))\n",
    "num_data[:, 0] = x\n",
    "num_data[:, 1] = y\n",
    "\n",
    "area = sm.area_between_two_curves(exp_data, num_data)\n",
    "print(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_name = 'uhhhh.json'\n",
    "# If the .json file was already attached, this will fix the problem\n",
    "pm_name = pm_name.split('.json')\n",
    "pm_name = pm_name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
