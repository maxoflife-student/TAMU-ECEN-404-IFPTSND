{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ignore cuDDa warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enable GPU\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# # Expands the Jupyter Notebook Output Size to fit your window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# Load in tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "from tensorflow_models import TF_Models, Ein_Multiply, leaky_relu, rank_loss_func\n",
    "from graph_predictions import Graph_Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the directory since all files were moved to \"ignorable_data\"\n",
    "import os\n",
    "path = os.getcwd()\n",
    "os.chdir(path + '\\ignorable_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1239, 5)]         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1239, 64)          17920     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1239, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 51,009\n",
      "Trainable params: 51,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 0.0688 - val_loss: 0.0677\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0670 - val_loss: 0.0657\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0649 - val_loss: 0.0637\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0631 - val_loss: 0.0618\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0611 - val_loss: 0.0598\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0592 - val_loss: 0.0580\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0580 - val_loss: 0.0561\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0551 - val_loss: 0.0543\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0538 - val_loss: 0.0525\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0517 - val_loss: 0.0507\n",
      "#############################################################################################################################\n",
      "Increasing learning rate to: 1.60000e-04\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0504 - val_loss: 0.0478\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0471 - val_loss: 0.0450\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0445 - val_loss: 0.0423\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0415 - val_loss: 0.0396\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0390 - val_loss: 0.0369\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0362 - val_loss: 0.0341\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0337 - val_loss: 0.0315\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0308 - val_loss: 0.0290\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0283 - val_loss: 0.0265\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0264 - val_loss: 0.0241\n",
      "#############################################################################################################################\n",
      "Increasing learning rate to: 2.56000e-04\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0233 - val_loss: 0.0205\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0197 - val_loss: 0.0170\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0167 - val_loss: 0.0138\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0139 - val_loss: 0.0107\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0055 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0045 - val_loss: 0.0016\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0043 - val_loss: 0.0016\n",
      "#############################################################################################################################\n",
      "Increasing learning rate to: 4.09600e-04\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0067 - val_loss: 0.0039\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0099 - val_loss: 0.0045\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0101 - val_loss: 0.0041\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0093 - val_loss: 0.0032\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0087 - val_loss: 0.0022\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0061 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0052 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0036 - val_loss: 0.0015\n",
      "#############################################################################################################################\n",
      "Decreasing learning rate to: 4.09600e-05\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0050 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0045 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0041 - val_loss: 0.0012\n",
      "#############################################################################################################################\n",
      "Attempting Large LR Increase in case bad Minimum Found\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0046 - val_loss: 0.0035\n",
      "#############################################################################################################################\n",
      "Decreasing learning rate to: 4.09600e-05\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "#############################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "# tf.config.run_functions_eagerly(True)\n",
    "\n",
    "alpha = [1e-4, 1e-3, 1e-2, 1e-1, 0, 1e0, 1e2, 1e3]\n",
    "beta = [1e-4, 1e-3, 1e-2, 1e-1, 0, 1e0, 1e2, 1e3]\n",
    "alpha.sort(reverse=True)\n",
    "\n",
    "model_folder = './RL_val_models'\n",
    "\n",
    "DMJ = TF_Models('./data_sets/NASDAQ_Cleaned', model_folder, reload=False)\n",
    "data_splits = DMJ.split_data()\n",
    "# model = DMJ.generate_model()\n",
    "# GP = Graph_Predictions(model_folder, \"./strategies/RL_validation_strategies\", DMJ)\n",
    "\n",
    "for a in alpha:\n",
    "    for b in beta:\n",
    "        if a == b:\n",
    "            continue\n",
    "        # Reset the training object to get rid of old data\n",
    "        DMJ = TF_Models('./data_sets/NASDAQ_Cleaned', model_folder, reload=False)\n",
    "        \n",
    "        # Create the model using parameters we're tuning\n",
    "        DMJ._generate_model(model_type='lstm',loss_function='rank_loss', activation='leaky_relu', hidden_units=64, true_random=True, alpha=a, beta=b)\n",
    "        \n",
    "        # Have it train as much as it can\n",
    "        DMJ.train_model_loop(epoch_batches=10)\n",
    "        \n",
    "        # Save the model with a tag\n",
    "        DMJ.save_model(tag=f'E2E_LSTM_ValSet_{a}-ALPHA{b}-BETA_SD17')\n",
    "        \n",
    "        # Reset the training object to get rid of old data\n",
    "        GP = Graph_Predictions(model_folder, \"./strategies/RL_validation_strategies\", DMJ)\n",
    "        \n",
    "        # Generate the prediction file\n",
    "        GP.generate_prediction_json(DMJ.model_name, neural_net_type='lstm')\n",
    "        \n",
    "        # Create the diagnostics file for the most recently saved model\n",
    "        GP.generate_model_diagnostics(GP.model_name, datablock_folder='RL_validation_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DMJ.history.history['val_loss']\n",
    "DMJ.history.history['lr']\n",
    "DMJ.epochs_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the  model\n",
    "model = DMJ.train_model(epochs=500)\n",
    "# model = DMJ.train_model(model, data_splits['x_train'], data_splits['y_train'], data_splits['x_val'], data_splits['y_val'], epochs=50, learning_rate=5e-5, gcn_matrix=DMJ.Normalized_Adjacency_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMJ.save_model(tag='E2E_LSTM_VariedLR_RL_ALPHA_1_NOMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GP = Graph_Predictions(\"./models\", \"./strategies\", DMJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GP.strategy_ratio_lstm('11-22-2020--17--32--LSTM--50Epochs--mse-Loss--64-HU--None', avoid_fall=False, name_override='test_')\n",
    "# GP.strategy_ratio_lstm('11-22-2020--17--32--LSTM--50Epochs--mse-Loss--64-HU--None', avoid_fall=False, average=10, name_override='LSTM-MSE-50Epoch-Average10')\n",
    "# GP.strategy_ratio_lstm('11-22-2020--17--32--LSTM--50Epochs--mse-Loss--64-HU--None', avoid_fall=True, name_override='LSTM-MSE-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_lstm('11-22-2020--14--55--LSTM-Rankloss--50Epochs--rlf-Loss--64-HU--', avoid_fall=False, name_override='LSTM-RankLoss-50Epoch')\n",
    "# GP.strategy_ratio_lstm('11-22-2020--14--55--LSTM-Rankloss--50Epochs--rlf-Loss--64-HU--', avoid_fall=False, average=10, name_override='LSTM-RankLoss-50Epoch-Average10')\n",
    "# GP.strategy_ratio_lstm('11-22-2020--14--55--LSTM-Rankloss--50Epochs--rlf-Loss--64-HU--', avoid_fall=True, name_override='LSTM-RankLoss-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--31--GCN1-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN1-MSE-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--31--GCN1-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=True, name_override='GCN1-MSE-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--34--GCN1-Rankloss--50Epochs--rlf-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN1-RankLoss-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--34--GCN1-Rankloss--50Epochs--rlf-Loss--64-HU--', avoid_fall=True, name_override='GCN1-RankLoss-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--37--GCN2-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN2-MSE-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--37--GCN2-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=True, name_override='GCN2-MSE-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--39--GCN2-RankLoss--50Epochs--rlf-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN2-RankLoss-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--39--GCN2-RankLoss--50Epochs--rlf-Loss--64-HU--', avoid_fall=True, name_override='GCN2-RankLoss-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_gcn('11-22-2020--16--46--GCN3-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN3-MSE-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--46--GCN3-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=True, name_override='GCN3-MSE-50Epoch-AvoidFall-2ndBest')\n",
    "\n",
    "# GP.strategy_ratio_gcn('11-22-2020--16--43--GCN3-RankLoss--50Epochs--rlf-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN3-RankLoss-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--43--GCN3-RankLoss--50Epochs--rlf-Loss--64-HU--', avoid_fall=True, name_override='GCN3-RankLoss-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_gcn('11-22-2020--20--46--GCN3-MSE-Ratio+1--50Epochs--mse-Loss--64-HU--', avoid_fall=True, average=1, name_override='GCN3-MSE-200Epoch-Ratio+1')\n",
    "# GP.strategy_ratio_gcn('11-22-2020--20--43--GCN3-RankLoss-Ratio+1--50Epochs--rlf-Loss--64-HU--', avoid_fall=True, average=1, name_override='GCN3-RankLoss-200Epoch-Ratio+1')\n",
    "\n",
    "'''New prediction memory storage'''\n",
    "# GP.generate_prediction_json('11-22-2020--15--01--LSTM-MSE--50Epochs--mse-Loss--64-HU--', neural_net_type='lstm')\n",
    "# GP.generate_prediction_json('11-22-2020--16--46--GCN3-MSE--50Epochs--mse-Loss--64-HU--', neural_net_type='gcn')\n",
    "\n",
    "'''Seperately trained LSTM combo'''\n",
    "# GP.generate_prediction_json('01-04-2021--14--20--SEP_LSTM_GCN3-1e-5LR--70Epochs--mse-Loss--64-HU--', neural_net_type='gcn')\n",
    "\n",
    "''''''\n",
    "GP.generate_prediction_json('02-04-2021--15--11--E2E_LSTM_VariedLR_RL_ALPHA_1_NOMSE--500Epochs--rlf-Loss--64-HU--', neural_net_type='lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strat_name = '02-04-2021--15--11--E2E_LSTM_VariedLR_RL_ALPHA_1_NOMSE--500Epochs--rlf-Loss--64-HU--_PM'\n",
    "\n",
    "# Testing the PM file feature\n",
    "avg = [1, 5, 20, 50, 100, 200]\n",
    "avg = [1]\n",
    "for a in avg:\n",
    "#     GP.prediction_json_strategy_max_entities(strat_name, average=a, avoid_fall=False, name_override=strat_name+ f'{a}AVG')\n",
    "    GP.prediction_json_strategy_determine_best(strat_name, average=a, avoid_fall=False, name_override=strat_name+ f'{a}AVG_Correct_BuyDay_plus1')\n",
    "    GP.save_results()\n",
    "# Testing the mse tracking feature\n",
    "# GP.prediction_json_mse('01-04-2021--15--57--SEP_LSTM_GCN3-5e-6LR--820Epochs--mse-Loss--64-HU--_PM')\n",
    "GP.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP.generate_model_diagnostics('02-04-2021--15--11--E2E_LSTM_VariedLR_RL_ALPHA_1_NOMSE--500Epochs--rlf-Loss--64-HU--_PM', datablock_folder='RL_validation_set')\n",
    "\n",
    "'01-04-2021--15--57--SEP_LSTM_GCN3-5e-6LR--820Epochs--mse-Loss--64-HU--_PM'\n",
    "255025890000.0\n",
    "0.012249682697757544\n",
    "0.7766990291262136\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GP.generate_upper_lower_avg_bounds()\n",
    "\n",
    "GP.display_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP.strategy_ratio_gcn('11-22-2020--16--46--GCN3-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN3-MSE-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--46--GCN3-MSE--50Epochs--mse-Loss--64-HU--', avoid_fall=True, name_override='GCN3-MSE-50Epoch-AvoidFall')\n",
    "\n",
    "# GP.strategy_ratio_gcn('11-22-2020--16--43--GCN3-RankLoss--50Epochs--rlf-Loss--64-HU--', avoid_fall=False, average=10, name_override='GCN3-RankLoss-50Epoch-Average10')\n",
    "# GP.strategy_ratio_gcn(r'11-22-2020--16--43--GCN3-RankLoss--50Epochs--rlf-Loss--64-HU--', avoid_fall=True, name_override='GCN3-RankLoss-50Epoch-AvoidFall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP.save_results('./strategies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import GridBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "bar = widgets.IntProgress(min=0, max=10, description='Loading:', bar_style='info')\n",
    "display(bar)\n",
    "\n",
    "for i in range(11):\n",
    "    time.sleep(0.2)\n",
    "    bar.value = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "widgets.Text(\n",
    "    value='Loading',\n",
    "    description='',\n",
    "    disabled=True\n",
    "    layout=L\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the loading bar by initializing it\n",
    "nam_bar = widgets.IntProgress(min=0, max=5, value=0, description='Loading Normalized Adjacency Matrix:',\n",
    "                              layout=widgets.Layout(width='auto'))\n",
    "text = widgets.Text(value='Loading', description='', disabled=True, layout=widgets.Layout(width='auto'))\n",
    "\n",
    "test = widgets.GridBox(children=[text, nam_bar], layout=widgets.Layout(width='auto'))\n",
    "\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.amax(GP.rr_test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(GP.rr_test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP.rr_test[476,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(GP.rr_test[5, :], GP.rr_test[100, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def swap_random(seq):\n",
    "    idx = range(len(seq))\n",
    "    i1, i2 = random.sample(idx, 2)\n",
    "    seq[i1], seq[i2] = seq[i2], seq[i1]\n",
    "\n",
    "trials_RL = []\n",
    "for e in range(100,300):\n",
    "    RL = []\n",
    "    for t in range(300):\n",
    "        A = []; B = [];\n",
    "        for l in range(e):\n",
    "            n = random.uniform(-1, 1)\n",
    "            A.append(n)\n",
    "            B.append(n)\n",
    "        swap_random(B)\n",
    "        swap_random(B)\n",
    "        swap_random(B)\n",
    "        swap_random(B)\n",
    "        \n",
    "        return_ratio = tf.constant(A, shape=(len(A), 1))\n",
    "        ground_truth = tf.constant(B, shape=(len(B), 1))\n",
    "\n",
    "        ###############################################################\n",
    "        # Create an array of all_ones so that we can calculate all permutations of subtractions\n",
    "        all_ones = tf.ones([len(return_ratio), 1], dtype=tf.float32)\n",
    "\n",
    "        # Creates a N x N matrix with every predicted return ratio for each company subtracted with every other\n",
    "        # company\n",
    "        pred_dif = tf.math.subtract(\n",
    "            tf.matmul(return_ratio, all_ones, transpose_b=True),\n",
    "            tf.matmul(all_ones, return_ratio, transpose_b=True)\n",
    "        )\n",
    "\n",
    "        # Creates an N x N matrix containing every actual return ratio for each company subtracted with every other\n",
    "        # company By switching the order of the all_ones matricies and the actual prices, a negative sign is introduced\n",
    "        # When RELU is applied later, correct predictions will not affect loss while incorrect predictions will affect\n",
    "        # loss depending on how incorrect the prediction was\n",
    "        actual_dif = tf.math.subtract(\n",
    "            tf.matmul(all_ones, ground_truth, transpose_b=True),\n",
    "            tf.matmul(ground_truth, all_ones, transpose_b=True)\n",
    "        )\n",
    "\n",
    "        # Using the above two qualities, the algorithm can be punished for incorrectly calculating when a company is\n",
    "        # doing better than another company Reduces the mean across each dimension until only 1 value remains\n",
    "        rank_loss = tf.reduce_mean(\n",
    "            # Takes if a given value is >0, it is kept, otherwise, it becomes 0\n",
    "            tf.nn.relu(\n",
    "                # Multiplies all of the\n",
    "                tf.multiply(pred_dif, actual_dif)\n",
    "            )\n",
    "        )\n",
    "        RL.append(rank_loss)\n",
    "    trials_RL.append(np.mean(RL))\n",
    "\n",
    "plt.plot(trials_RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [0.1, 0.5, 0.2, 0.3]\n",
    "print(list(zip(range(4), r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [100, 300, 200, 400]\n",
    "predictions = list(zip(range(len(predictions)), predictions))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Normal Rank\n",
    "A = list(range(1, 10001))\n",
    "B = [i**(-1) for i in A]\n",
    "print(np.mean(A))\n",
    "print(np.mean(B)**-1)\n",
    "\n",
    "\n",
    "'000_Avg_RR.p'\n",
    "'000_Highest_RR_Possible.p'\n",
    "'000_Lowest_RR_Possible.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import similaritymeasures as sm\n",
    "import numpy as np\n",
    "\n",
    "# Generate random experimental data\n",
    "n = 5\n",
    "x = list(range(n))\n",
    "y = [11, 26, 26, 11, -60]\n",
    "exp_data = np.zeros((n, 2))\n",
    "exp_data[:, 0] = x\n",
    "exp_data[:, 1] = y\n",
    "\n",
    "# Generate random numerical data\n",
    "x = list(range(n))\n",
    "y = [1, 2, 30, 4, -9000]\n",
    "num_data = np.zeros((n, 2))\n",
    "num_data[:, 0] = x\n",
    "num_data[:, 1] = y\n",
    "\n",
    "area = sm.area_between_two_curves(exp_data, num_data)\n",
    "print(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_name = 'uhhhh.json'\n",
    "# If the .json file was already attached, this will fix the problem\n",
    "pm_name = pm_name.split('.json')\n",
    "pm_name = pm_name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
