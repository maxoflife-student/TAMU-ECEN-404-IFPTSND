{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = tf.constant([[1, 2, 3, 4, 5],[4, 4, 4, 4, 4],[4, 4, 4, 4, 4]], dtype=tf.float32)\n",
    "y_pred = tf.constant([[2, 4, 6, 8, 10],[4, 4, 4, 4, 4],[4, 4, 4, 4, 4]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n",
      "(3, 5)\n",
      "tf.Tensor([11.  0.  0.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(y_actual.shape)\n",
    "print(y_pred.shape)\n",
    "print(tf.keras.losses.mean_squared_error(y_actual, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[5.]\n",
      " [4.]\n",
      " [4.]], shape=(3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[4.]\n",
      " [4.]\n",
      " [4.]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# How to get the last\n",
    "print(y_actual[:,-1:None])\n",
    "\n",
    "# How to get the second to last\n",
    "print(y_actual[:,-2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_return_ratio = tf.math.divide(tf.math.subtract(y_pred[:, -1:None], y_actual[:, -2:-1]), y_actual[:, -2:-1])\n",
    "actual_return_ratio = tf.math.divide(tf.math.subtract(y_actual[:, -1:None], y_actual[:, -2:-1]), y_actual[:, -2:-1])\n",
    "\n",
    "pred_return_ratio = tf.math.divide(tf.math.subtract(y_pred[:, -2:-1], y_actual[:, -3:-2]), y_actual[:, -3:-2])\n",
    "actual_return_ratio = tf.math.divide(tf.math.subtract(y_actual[:, -2:-1], y_actual[:, -3:-2]), y_actual[:, -3:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.6666666]\n",
      " [0.       ]\n",
      " [0.       ]], shape=(3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.33333334]\n",
      " [0.        ]\n",
      " [0.        ]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(pred_return_ratio)\n",
    "print(actual_return_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "all_ones = all_ones = tf.ones([y_actual[:, -1:None].shape[0], 1], dtype=tf.float32)\n",
    "print(all_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[ 0.       ,  1.6666666,  1.6666666],\n",
       "       [-1.6666666,  0.       ,  0.       ],\n",
       "       [-1.6666666,  0.       ,  0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the predicted difference matrix\n",
    "a = tf.matmul(pred_return_ratio, all_ones, transpose_b=True)\n",
    "# Get the predicted difference matrix\n",
    "b =tf.matmul(all_ones, pred_return_ratio,transpose_b=True)\n",
    "tf.subtract(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's convert to multiple timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2. 3. 4. 5.]\n",
      " [4. 4. 4. 4. 4.]\n",
      " [4. 4. 4. 4. 4.]], shape=(3, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1.         0.5        0.33333334 0.25      ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 2.  4.  6.  8. 10.]\n",
      " [ 4.  4.  4.  4.  4.]\n",
      " [ 4.  4.  4.  4.  4.]], shape=(3, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[3.        2.        1.6666666 1.5      ]\n",
      " [0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.       ]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Nx1 return ratios need to be NxT\n",
    "\n",
    "actual_return_ratio_matrix = tf.math.divide(tf.math.subtract(y_actual[:, 1:], y_actual[:, 0:-1]), y_actual[:, 0:-1])\n",
    "pred_return_ratio_matrix = tf.math.divide(tf.math.subtract(y_pred[:, 1:], y_actual[:, 0:-1]), y_actual[:, 0:-1])\n",
    "print(y_actual)\n",
    "print(actual_return_ratio_matrix)\n",
    "print(y_pred)\n",
    "print(pred_return_ratio_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_ones_matrix = tf.ones(actual_return_ratio_matrix.shape, dtype=tf.float32)\n",
    "# print(all_ones_matrix)\n",
    "# tf.einsum('ij,jk->ik', pred_return_ratio_matrix, tf.transpose(all_ones_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (tf.repeat(tf.expand_dims(pred_return_ratio_matrix, 1), pred_return_ratio_matrix.shape[-1], axis=1))\n",
    "t = (tf.repeat(tf.expand_dims(pred_return_ratio_matrix, 2), pred_return_ratio_matrix.shape[0], axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted difference matrix\n",
    "a = tf.matmul(pred_return_ratio, all_ones, transpose_b=True)\n",
    "# Get the predicted difference matrix\n",
    "b =tf.matmul(all_ones, pred_return_ratio,transpose_b=True)\n",
    "pred_dif_original = tf.subtract(a, b)\n",
    "\n",
    "# Get the predicted difference matrix\n",
    "a = tf.matmul(actual_return_ratio, all_ones, transpose_b=True)\n",
    "# Get the predicted difference matrix\n",
    "b = tf.matmul(all_ones, actual_return_ratio,transpose_b=True)\n",
    "actual_dif_original = tf.subtract(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[-0.        , -0.33333334, -0.33333334],\n",
       "       [ 0.33333334, -0.        , -0.        ],\n",
       "       [ 0.33333334, -0.        , -0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = (tf.repeat(tf.expand_dims(pred_return_ratio_matrix, 2), pred_return_ratio_matrix.shape[0], axis=2))\n",
    "pred_dif = (p-tf.transpose(p))\n",
    "pred_dif[:, -2, :]\n",
    "\n",
    "p = (tf.repeat(tf.expand_dims(actual_return_ratio_matrix, 2), actual_return_ratio_matrix.shape[0], axis=2))\n",
    "actual_dif = -(p-tf.transpose(p))\n",
    "actual_dif[:, -2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all the different (ri-rj) * (ri-rj)hat sets through time)\n",
    "s = tf.multiply(pred_dif, actual_dif)\n",
    "# Remove all negative values\n",
    "s = tf.nn.relu(s)\n",
    "# Average across time\n",
    "s = tf.reduce_mean(s,1)\n",
    "# Average all values\n",
    "s = tf.reduce_mean(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to repeat the NxN matrix across time, so NxTxN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 3])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recreate Nx1\n",
    "t_w = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.float32)\n",
    "# t_w = tf.transpose(t_w)\n",
    "t_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Orginal output matrix\n",
    "# all_ones = tf.ones([t_w.shape[0], 1], dtype=tf.float32)\n",
    "# b = tf.matmul(all_ones, t_w, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 10, 3), dtype=float32, numpy=\n",
       "array([[[1., 2., 3.],\n",
       "        [1., 2., 3.],\n",
       "        [1., 2., 3.],\n",
       "        [1., 2., 3.],\n",
       "        [1., 2., 3.],\n",
       "        [1., 2., 3.],\n",
       "        [1., 2., 3.],\n",
       "        [1., 2., 3.],\n",
       "        [1., 2., 3.],\n",
       "        [1., 2., 3.]],\n",
       "\n",
       "       [[4., 5., 6.],\n",
       "        [4., 5., 6.],\n",
       "        [4., 5., 6.],\n",
       "        [4., 5., 6.],\n",
       "        [4., 5., 6.],\n",
       "        [4., 5., 6.],\n",
       "        [4., 5., 6.],\n",
       "        [4., 5., 6.],\n",
       "        [4., 5., 6.],\n",
       "        [4., 5., 6.]],\n",
       "\n",
       "       [[7., 8., 9.],\n",
       "        [7., 8., 9.],\n",
       "        [7., 8., 9.],\n",
       "        [7., 8., 9.],\n",
       "        [7., 8., 9.],\n",
       "        [7., 8., 9.],\n",
       "        [7., 8., 9.],\n",
       "        [7., 8., 9.],\n",
       "        [7., 8., 9.],\n",
       "        [7., 8., 9.]]], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (tf.repeat(tf.expand_dims(t_w, 1), 10, axis=1))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(a[:, 1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does softmax work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334],\n",
       "       [0.33333334, 0.33333334, 0.33333334]], dtype=float32)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_n = tf.nn.softmax(a, axis=0)\n",
    "a_n = tf.nn.softmax(a_n, axis=2)\n",
    "a_n[:, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0.00235563, 0.00235563, 0.00235563],\n",
       "       [0.04731416, 0.04731416, 0.04731416],\n",
       "       [0.95033026, 0.95033026, 0.95033026]], dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(t_w, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
