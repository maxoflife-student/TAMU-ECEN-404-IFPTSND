{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Ignore cuDDa warning messages\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "# # Expands the Jupyter Notebook Output Size to fit your window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "# Load in tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Change the working directory back to the original to keep paths the same between files\n",
    "os.chdir(r'C:\\Users\\Maxwell\\PycharmProjects\\TAMU-ECEN-403-IFPTSND\\ECEN_403_IFM\\TAMU-ECEN-403-IFPTSND')\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "import sys\n",
    "from os.path import join, isfile\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "from explore_entities import Graph_Entities\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, GridBox\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allows for scrolling windows to be very large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "    IPython.OutputArea.auto_scroll_threshold = 9999\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "    IPython.OutputArea.auto_scroll_threshold = 9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import TF_models and truncate the entities to only contain 880 companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2041d64cb914b5abd77e863a72661f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Dropdown(description='Model Types:', options=('lstm', 'lstm_gcn_1', 'lstm_gcn_2', 'lstm_gcn_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow_models import TF_Models, Ein_Multiply, leaky_relu, rank_loss_func\n",
    "DMJ = TF_Models('./ignorable_data/data_sets/NASDAQ_Cleaned - Contains ZUMZ/', './ignorable_data/models/[55, 25, 20]_split/', reload=False)\n",
    "data_splits = DMJ.split_data()\n",
    "\n",
    "DMJ.Normalized_Adjacency_Matrix = DMJ.Normalized_Adjacency_Matrix[0:880, 0:880]\n",
    "DMJ.XX_tf = DMJ.XX_tf[0:-1, :, :]\n",
    "DMJ.YY_tf = DMJ.YY_tf[0:-1, :]\n",
    "DMJ.RR_tf = DMJ.RR_tf[0:-1, :]\n",
    "DMJ.entities = DMJ.entities[0:-1]\n",
    "DMJ.entities_idx.pop('ZUMZ')\n",
    "\n",
    "model = DMJ.generate_model()\n",
    "\n",
    "from graph_predictions import Graph_Predictions\n",
    "GP = Graph_Predictions(\"./ignorable_data/models/[55, 25, 20]_split/\", \"./ignorable_data/strategies/RL_validation_strategies/\", 'x_val', DMJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if we split the data into time batches ourselves and trained them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(880, 1239, 5)\n",
      "(880, 309, 5)\n",
      "(880, 309, 5)\n",
      "tf.Tensor(0.455917, shape=(), dtype=float32)\n",
      "tf.Tensor(0.461538, shape=(), dtype=float32)\n",
      "tf.Tensor(0.012328968, shape=(), dtype=float32)\n",
      "tf.Tensor(0.425614, shape=(), dtype=float32)\n",
      "tf.Tensor(0.415741, shape=(), dtype=float32)\n",
      "tf.Tensor([0.415741], shape=(1,), dtype=float32)\n",
      "(None, 309, 5)\n"
     ]
    }
   ],
   "source": [
    "# Given a total and list of splits, evenly distributes the total amount proportional to the given list\n",
    "def split_windows(total, percentages_list):\n",
    "    # Get a sum of the initial total\n",
    "    percentage_sum = sum(percentages_list)\n",
    "\n",
    "    # Create a new list based on a percentage of the total\n",
    "    new_splits = []\n",
    "    for perc in percentages_list:\n",
    "        new_splits.append(int(total * (perc / percentage_sum)))\n",
    "    \n",
    "    # Where to shift the extra days that don't exactly divide between the values\n",
    "    if sum(new_splits) != total:\n",
    "        new_splits[-1] = new_splits[-1] + (total - sum(new_splits))\n",
    "\n",
    "    return new_splits\n",
    "\n",
    "# one_x = DMJ.XX_tf[0:2, :, :]\n",
    "# one_y = DMJ.YY_tf[0:2, :]\n",
    "one_x = DMJ.XX_tf\n",
    "print(DMJ.XX_tf.shape)\n",
    "one_y = DMJ.YY_tf\n",
    "\n",
    "# one_x = DMJ.XX_tf[0:-1, :, :]\n",
    "# one_y = DMJ.YY_tf[0:-1, :]\n",
    "\n",
    "# # Given a dataset, let's section off a fifth of the data to be used for testing purposes\n",
    "# time_split = [1000, 239,]\n",
    "# x_train, x_test = tf.split(one_x, split_windows(one_x.shape[1], time_split),\n",
    "#                                   axis=1)\n",
    "# y_train, y_test = tf.split(one_y, split_windows(one_y.shape[1], time_split),\n",
    "#                                   axis=1)\n",
    "# rr_train, rr_test = tf.split(DMJ.RR_tf, split_windows(one_y.shape[1], time_split),\n",
    "#                                      axis=1)\n",
    "\n",
    "# Given a dataset, let's section off a fifth of the data to be used for testing purposes\n",
    "time_split = [90, 710, 239, 199]\n",
    "time_split = [55, 25, 20]\n",
    "\n",
    "time_split = [30, 25, 25, 20]\n",
    "x_g, x_train, x_val, x_test = tf.split(one_x, split_windows(one_x.shape[1], time_split),\n",
    "                                  axis=1)\n",
    "y_g, y_train, y_val, y_test = tf.split(one_y, split_windows(one_y.shape[1], time_split),\n",
    "                                  axis=1)\n",
    "rr_g, rr_train, rr_val, rr_test = tf.split(DMJ.RR_tf, split_windows(one_y.shape[1], time_split),\n",
    "                                     axis=1)\n",
    "\n",
    "# y_train = y_train[:, -1]\n",
    "# y_val = y_val[:, -1]\n",
    "\n",
    "# # Once we have the data partitioned, let's split it into 8 sets of 125\n",
    "# batch_splits = [1]*8\n",
    "# # Create a list of 8 different time batches\n",
    "# x_train_batches = []\n",
    "# x_train_batches.append(tf.split(x_train, split_windows(x_train.shape[1], batch_splits), axis=1))\n",
    "# x_train_batches = [item for sublist in x_train_batches for item in sublist]\n",
    "\n",
    "# y_train_batches = []\n",
    "# y_train_batches.append(tf.split(y_train, split_windows(x_train.shape[1], batch_splits), axis=1))\n",
    "# y_train_batches = [item for sublist in y_train_batches for item in sublist]\n",
    "\n",
    "# # Lets try truncating the values for the labels to only be the final value\n",
    "# for i in range(len(y_train_batches)):\n",
    "#     y_train_batches[i] = y_train_batches[i][:, -1]\n",
    "\n",
    "# print(x_train[0, -1, 0])\n",
    "\n",
    "# print(rr_train[0, -1])\n",
    "\n",
    "# print(x_val[0, 0, 0])\n",
    "# print(y_train[0, -1])\n",
    "# for set in [x_train, x_g, x_val, x_test]:\n",
    "print(x_val.shape)\n",
    "print(x_train.shape)\n",
    "\n",
    "print(x_train[0, 0, 0])\n",
    "print(x_train[0, 1, 0])\n",
    "print(rr_train[0, 0])\n",
    "\n",
    "print(x_train[0, -1, 0])\n",
    "print(x_train[0, -2, 0])\n",
    "print(x_train[0, -2:-1, 0])\n",
    "\n",
    "print(keras.Input(shape=(x_train.shape[1], x_train.shape[2])).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create the one-hot encoded adjacency matrix to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Text(value='Loading Normalized Adjacency Matrix:', disabled=True, layout=Layout(width='auto'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Text(value='Loading Normalized Adjacency Matrix:', disabled=True, layout=Layout(width='auto'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import explore_entities\n",
    "# Load in the code\n",
    "GE = Graph_Entities('./ignorable_data/data_sets/NASDAQ_Cleaned - Contains ZUMZ - Yuning/')\n",
    "# Generate the baseline components we're wokring with\n",
    "NAM, Adj, Rel = GE.get_matrix_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the dimensionality of normalized adjacency matrix we have so far "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks to see if a matrix is normalized among it's rows and columns to 6 decimal places\n",
    "def is_normalized(m):\n",
    "    m_t = np.transpose(m)\n",
    "    r_trigger = True\n",
    "    c_trigger = True\n",
    "    for i in m:\n",
    "        if (round(np.sum(i), 6)) != 1 and r_trigger:\n",
    "            print('Rows Not Normalized')\n",
    "            r_trigger = not r_trigger\n",
    "    for i in m_t:\n",
    "        if (round(np.sum(i), 6)) != 1 and c_trigger:\n",
    "            print('Columns Not Normalized')\n",
    "            c_trigger = not c_trigger\n",
    "    \n",
    "    if r_trigger and c_trigger:\n",
    "        print('Normalized')\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Created with D^-1/2 * A * D^-1/2\n",
    "print(f\"Symetrically Normalized DMJ: {NAM.shape}\")\n",
    "is_normalized(NAM)\n",
    "print(\"####\")\n",
    "# All relationships, but still seperated by the different groups\n",
    "print(f\"One-Hot Encoded Relationships Split by Group: {Rel.shape}\")\n",
    "print(\"####\")\n",
    "# All relationships squished into one matrix\n",
    "print(f\"One-Hot Encoded All Relationships: {Adj.shape}\")\n",
    "is_normalized(Adj)\n",
    "print(\"####\")\n",
    "\n",
    "None\n",
    "\n",
    "print(np.sum(Rel[9, :, :])/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a total and list of splits, evenly distributes the total amount proportional to the given list\n",
    "def split_windows(total, percentages_list):\n",
    "    # Get a sum of the initial total\n",
    "    percentage_sum = sum(percentages_list)\n",
    "\n",
    "    # Create a new list based on a percentage of the total\n",
    "    new_splits = []\n",
    "    for perc in percentages_list:\n",
    "        new_splits.append(int(total * (perc / percentage_sum)))\n",
    "    \n",
    "    # Where to shift the extra days that don't exactly divide between the values\n",
    "    if sum(new_splits) != total:\n",
    "        new_splits[-1] = new_splits[-1] + (total - sum(new_splits))\n",
    "\n",
    "    return new_splits\n",
    "\n",
    "one_x = DMJ.XX_tf\n",
    "one_y = DMJ.YY_tf\n",
    "\n",
    "time_split = [90, 710, 239, 199]\n",
    "time_split = [55, 25, 20]\n",
    "\n",
    "time_split = [30, 25, 25, 20]\n",
    "x_g, x_train, x_val, x_test = tf.split(one_x, split_windows(one_x.shape[1], time_split),\n",
    "                                  axis=1)\n",
    "y_g, y_train, y_val, y_test = tf.split(one_y, split_windows(one_y.shape[1], time_split),\n",
    "                                  axis=1)\n",
    "rr_g, rr_train, rr_val, rr_test = tf.split(DMJ.RR_tf, split_windows(one_y.shape[1], time_split),\n",
    "                                     axis=1)\n",
    "\n",
    "# For the Adjacency Matrix we would like to introduce to the algorithm\n",
    "# N x N x K\n",
    "adj_matrix = np.transpose(Rel)\n",
    "\n",
    "# Since some implementations removed the last company...\n",
    "# if adj_matrix.shape[0] == 881:\n",
    "#     adj_matrix = adj_matrix[0:-1, 0:-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in an already trained LSTM model & Adding Topographical Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1337)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "            name='Adam'\n",
    "        )\n",
    "\n",
    "# Create a function for the Tensorflow implementation of leaky_relu\n",
    "def leaky_relu(x):\n",
    "    return tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "# Shouldn't be neccessary if we use softmax\n",
    "# def normalize_adj_matrix(adj):\n",
    "#     degree = tf.reduce_sum(adj, axis=0)\n",
    "#     inv_degree = tf.math.reciprocal(degree)\n",
    "#     diag_inv_degree = tf.linalg.diag(inv_degree)\n",
    "#     norm_adj = diag_inv_degree * adj\n",
    "#     return norm_adj\n",
    "\n",
    "hidden_units = 64\n",
    "activation = leaky_relu\n",
    "do = 0\n",
    "\n",
    "# Assuming all time steps are the same size, we can just use the first item to determine input shape\n",
    "# For the time-series data\n",
    "input_seq = keras.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "    \n",
    "# Create the input layer for the data that comes from outside the graph (needs to be NxN)\n",
    "input_rel = keras.Input(shape=(adj_matrix.shape[1], adj_matrix.shape[2]))\n",
    "\n",
    "\n",
    "# Load in an already trained LSTM Model\n",
    "file_name = '2-20-21-1_LSTM_[25,25,20]_NoDropout_100Epoch_80BatchSize_1000ALPHA'\n",
    "model_path = './ignorable_data/models/[55, 25, 20]_split/'\n",
    "pre_trained_lstm = tf.keras.models.load_model(model_path + f'{file_name}', compile=False,\n",
    "                                              custom_objects={'leaky_relu': leaky_relu})\n",
    "\n",
    "# Change the names to avoid conflicts\n",
    "pre_trained_lstm.layers[0]._name = 'Original-InputLayer'\n",
    "pre_trained_lstm.layers[1]._name = 'Original-LSTM'\n",
    "pre_trained_lstm.layers[2]._name = 'Original-Dense'\n",
    "\n",
    "# # Make sure that the weights for the lstm model cannot be updated\n",
    "pre_trained_lstm.layers[0].trainable = False\n",
    "pre_trained_lstm.layers[1].trainable = False\n",
    "pre_trained_lstm.layers[2].trainable = False\n",
    "\n",
    "# This is the LSTM layer, input_seq is not carried over from the original because we don't care how it was initalized\n",
    "x = pre_trained_lstm.layers[1](input_seq)\n",
    "\n",
    "# Experimental vector multiplication\n",
    "# W = tf.Variable(tf.random.uniform(shape=[adj_matrix.shape[0], 1]))\n",
    "# W = tf.keras.layers.Variable\n",
    "# y = Ein_Multiply()([input_rel, W], \"ij, k->ik\")\n",
    "\n",
    "# This is a seperate input layer that will take in the relational matrix\n",
    "# Dimensionality: N x N x 1\n",
    "# y = tf.keras.layers.Dense(1, activation=activation)(input_rel)\n",
    "\n",
    "# These are the similarity values\n",
    "# Dimensionality: N x T x N\n",
    "\n",
    "# As a memory test, let's only take 1 time embedding and see if our computer can handle it\n",
    "x = x[:, -1, :]\n",
    "\n",
    "# w = Ein_Multiply()([w, x], \"ij, jk->ik\")\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "# w = MaskedDense(880)(x)\n",
    "e_bar = square_keep_self_loop(880)(x)\n",
    "# w = tf.matmul(w, x)\n",
    "\n",
    "# This is where we can decide to add an additional dense layer for learning or not, but we're currently not implementing this\n",
    "\n",
    "# Lastly, we want to recombine the original embeddings and with the new ones, so that both data is present for learning\n",
    "# Dimensionality: NxTxD*2\n",
    "\n",
    "# # This is the original Dense Layer\n",
    "# x = pre_trained_lstm.layers[2](x)\n",
    "\n",
    "# This is a new Dense layer we might want to experiment with\n",
    "o = Dense(1, activation=activation)(e_bar)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_seq], outputs=o)\n",
    "\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_models import rank_loss_correct_pred_rr\n",
    "\n",
    "# View what we just created\n",
    "# model.compile(loss=rank_loss_rr, optimizer=optimizer)\n",
    "model.compile(loss=rank_loss_correct_pred_rr, optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, len(model.layers)):\n",
    "#     print(model.layers[i].name)\n",
    "tf.print(model.layers[13].name)\n",
    "tf.print(model.layers[13].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "checkpoint_filepath = './tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_filepath,\n",
    "            save_weights_only=True,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    return 0.00035\n",
    "\n",
    "inputs_train = [x_train]\n",
    "train_labels = y_train\n",
    "\n",
    "inputs_val = [x_val]\n",
    "val_labels = y_val\n",
    "\n",
    "# If we're using the GCN\n",
    "inputs_train.append(adj_matrix)\n",
    "inputs_val.append(adj_matrix)\n",
    "\n",
    "# int(inputs_train.shape[0])\n",
    "\n",
    "history = model.fit(inputs_train, train_labels, batch_size=int(inputs_train[0].shape[0]),\n",
    "                              epochs=0, validation_data=(inputs_val, val_labels),\n",
    "                   callbacks=[model_checkpoint_callback,\n",
    "                             tf.keras.callbacks.LearningRateScheduler(scheduler,\n",
    "                                                                      verbose=0)])\n",
    "\n",
    "model.load_weights(checkpoint_filepath)\n",
    "\n",
    "for h in history.history['val_loss']:\n",
    "    losses.append(h)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict([x_train, DMJ.Normalized_Adjacency_Matrix], batch_size=880)\n",
    "model_save = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for h in history.history['val_loss']:\n",
    "#     losses.append(h)\n",
    "# plt.plot(losses)\n",
    "\n",
    "DMJ.Normalized_Adjacency_Matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMJ.model = model\n",
    "DMJ.model_name = \"3-29-21-1_[25,25,20]_400Epoch_NaiveWeightAlpha_1000_1.02val_loss\"\n",
    "DMJ.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_name = \"2-16-21-Seq1LSTM-F-64HU-[800,239,200]split-full_y\"\n",
    "# new_directory = './ignorable_data/prediction_results/[55, 25, 20]_splits/'\n",
    "# GP.generate_validation_prediction_json_SplitBatch_nofeat(model_name, new_directory, x_g, x_val, sliding_window=30)\n",
    "# GP.generate_validation_prediction_json_SplitBatch_close_gap(model_name, new_directory, x_g, x_val, sliding_window=30)\n",
    "model_name = '3-28-21-1_[25,25,20]_100Epoch_BrokenNaiveAlpha_1000'\n",
    "model_dir = './ignorable_data/models/[55, 25, 20]_split'\n",
    "# model_dir = 'G:\\Shared drives\\Max Huffman - ECEN 403 404 URS Research 2020 2021\\Datasets\\models'\n",
    "past = x_train\n",
    "future = x_val\n",
    "# new_dir = 'G:\\Shared drives\\Max Huffman - ECEN 403 404 URS Research 2020 2021\\Datasets\\predictions\\pc_version'\n",
    "new_dir = './ignorable_data/prediction_results/[55, 25, 20]_splits/'\n",
    "sliding_window = x_val.shape[1]\n",
    "\n",
    "window = x_train.shape[1]\n",
    "input_Adj_matrix = adj_matrix\n",
    "# GP.generate_predictions(model_name, model_dir, past, future, new_dir, window,\n",
    "#                         model_type='gcn', input_Adj_matrix=adj_matrix, batch_size=880)\n",
    "GP.generate_predictions(model_name, model_dir, past, future, new_dir, window, model_type='lstm', batch_size=880)\n",
    "# GCN_output = GP.return_embeddings(model_name, model_dir, past, future, new_dir, w, model_type='gcn')\n",
    "# embeddings = GP.return_embeddings(model_name, model_dir, past, future, new_dir, window, model_type='gcn')\n",
    "\n",
    "#     model_name = '2-20-21-1_LSTM_[25,25,20]_NoDropout_35Epoch_80BatchSize_IncreasedVariedLR_RRMSE'\n",
    "#     GP.generate_predictions(model_name, model_dir, past, future, new_dir, w)\n",
    "# GP.generate_validation_prediction_json_SplitBatch(model_name, new_dir, x_g, x_val, sliding_window=sliding_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the training set, these are the validation values that are output from the LSTM model\n",
    "print(embeddings.shape)\n",
    "\n",
    "# This is the NAM that we are using to aggregate the embedding results\n",
    "print(DMJ.Normalized_Adjacency_Matrix[6,6])\n",
    "\n",
    "# This should be the aggregated values output from using the NAM (The dimensions look fine)\n",
    "# new_embeddings = tf.einsum('ntd,nm->mtd', embeddings, DMJ.Normalized_Adjacency_Matrix)\n",
    "new_embeddings = tf.einsum('mn,ntd->mtd', DMJ.Normalized_Adjacency_Matrix, embeddings)\n",
    "print(new_embeddings.shape)\n",
    "\n",
    "print(embeddings[0, -7, 0:10])\n",
    "# print(embeddings[0, -1, 0:10])\n",
    "print('  ')\n",
    "print(new_embeddings[0, -7, 0:10])\n",
    "# print(new_embeddings[0, -1, 0:10])\n",
    "\n",
    "# print(tf.subtract(embeddings[0, -2, 0:10], embeddings[0, -1, 0:10]))\n",
    "# print(tf.subtract(new_embeddings[0, -2, 0:10], new_embeddings[0, -1, 0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above are the output embeddings of the LSTM layer\n",
    "# Below is 1 output prediction for a simple NAM Aggregate added to a pre-trained LSTM\n",
    "GCN_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_file_name = '3-28-21-1_[25,25,20]_100Epoch_BrokenNaiveAlpha_1000309win_309past_309fut'\n",
    "p_file_dir = '.\\ignorable_data\\prediction_results\\[55, 25, 20]_splits'\n",
    "# p_file_dir = 'G:\\Shared drives\\Max Huffman - ECEN 403 404 URS Research 2020 2021\\Datasets\\predictions\\pc_version'\n",
    "future = x_val\n",
    "new_dir = './ignorable_data/datablocks/[55, 25, 20]_splits/'\n",
    "close_gap = False\n",
    "\n",
    "use_argmin = False\n",
    "yesterday_pred = False\n",
    "GP.generate_prediction_results(p_file_name, p_file_dir, future, new_dir,\n",
    "                               close_gap=close_gap, use_argmin=use_argmin, yesterday_pred=yesterday_pred, rr_labels=False)\n",
    "\n",
    "for root, dirs, files in os.walk(r'C:\\Users\\Maxwell\\PycharmProjects\\TAMU-ECEN-403-IFPTSND\\ECEN_403_IFM\\TAMU-ECEN-403-IFPTSND\\ignorable_data\\datablocks\\[55, 25, 20]_splits'):\n",
    "    for filename in files:\n",
    "#         GP.generate_prediction_results(filename, p_file_dir, future, new_dir, close_gap=close_gap, use_argmin=use_argmin, yesterday_pred=yesterday_pred)\n",
    "        GP.add_daily_value_to_datablock(filename, './ignorable_data/datablocks/[55, 25, 20]_splits')\n",
    "        GP.add_daily_value_to_datablock_discontinuous(filename, './ignorable_data/datablocks/[55, 25, 20]_splits')\n",
    "        GP.add_cumulative_return_ratio_discontinuous(filename, './ignorable_data/datablocks/[55, 25, 20]_splits')\n",
    "        None\n",
    "\n",
    "\n",
    "# use_argmin = True\n",
    "# yesterday_pred = False\n",
    "# GP.generate_prediction_results(p_file_name, p_file_dir, future, new_dir, close_gap=close_gap, use_argmin=use_argmin, yesterday_pred=yesterday_pred)\n",
    "# # GP.generate_model_diagnostics_given_sets(p_file_dir + f'/{p_file_name}', future, datablock_folder=new_dir, try_all_pred=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_company(n):\n",
    "    # n = 597\n",
    "    # n = 488\n",
    "    # n = 161\n",
    "    # n = 561\n",
    "    # n = 440\n",
    "    # n = 200\n",
    "    # # Argmin\n",
    "    # n = 780\n",
    "\n",
    "    # n = 876\n",
    "    # n = 110\n",
    "    r = 1\n",
    "    # n = 100\n",
    "    # n=0\n",
    "\n",
    "    r=1\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "#     ax.set_ylim([0,1])\n",
    "    ax.set_xlim([20,80])\n",
    "\n",
    "    time = tf.concat([x_train, x_val, x_test], axis=1)\n",
    "\n",
    "    # ax = fig.add_subplot()\n",
    "    for i in range(r):\n",
    "    #     print(f'{i+n*r} ', end='')\n",
    "    #     ax.plot(time[i+n*r, :, 0])\n",
    "        ax.plot(x_val[i+n*r, :, 0], label='Closing Price', linewidth=2, color='black')\n",
    "    #     ax.plot(rr_val[i+n*r, :], label='Return Ratio')\n",
    "\n",
    "        ax.plot(A[:, i+n*r], label='LSTM-1000 ALPHA')\n",
    "    #     ax.plot(B[:, i+n*r], label='LSTM-1000 ALPHA + 1 Dense')\n",
    "    #     ax.plot(C[:, i+n*r], label='LSTM-1000 ALPHA + 1NAM')\n",
    "    #     ax.plot(D[:, i+n*r], label='LSTM-1000 ALPHA + 1NAM + 1 Dense')\n",
    "    #     ax.plot(E[:, i+n*r], label='LSTM-1000 ALPHA + 881Dense-X-Adj')\n",
    "    #     ax.plot(F[:, i+n*r], label='LSTM-1000 ALPHA + 881Dense-X-Adj + Trainable Final Layer')\n",
    "        ax.plot(G[:, i+n*r], label='LSTM-1000 ALPHA + Explict')\n",
    "        ax.plot(H[:, i+n*r], label='LSTM-1000 ALPHA + Implicit')\n",
    "        ax.plot(I[:, i+n*r], label='Naive')\n",
    "\n",
    "\n",
    "        ax.legend()\n",
    "        ax.set_xlabel('Validation Days (Time)')\n",
    "        ax.set_ylabel('Closing Price')\n",
    "        ax.set_title(f'Company {i+n*r}')\n",
    "\n",
    "    print(DMJ.entities[n])\n",
    "\n",
    "\n",
    "\n",
    "plot_company(488)\n",
    "plot_company(221)\n",
    "plot_company(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_dir = '.\\ignorable_data\\prediction_results\\[55, 25, 20]_splits/'\n",
    "pred_file = '2-20-21-1_LSTM_[25,25,20]Reloaded_1000ALPHA309win_309past_309fut'\n",
    "GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "A = GP.test_obj\n",
    "\n",
    "pred_dir = '.\\ignorable_data\\prediction_results\\[55, 25, 20]_splits/'\n",
    "pred_file = '3-12-21-1_LSTM_[25,25,20]_10Epoch_880BatchSize_TFMSE_Additional_64_Dense_Layer309win_309past_309fut'\n",
    "GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "B = GP.test_obj\n",
    "\n",
    "pred_file = '2-20-21-1_LSTM_[25,25,20]_NoDropout_100Epoch_80BatchSize_1000ALPHA_1NAMAGGREGATE309win_309past_309fut'\n",
    "GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "C = GP.test_obj\n",
    "\n",
    "pred_file = '2-20-21-1_LSTM_[25,25,20]_NoDropout_100Epoch_80BatchSize_1000ALPHA_1DenseGCN_TFMSE_FullTrain309win_309past_309fut'\n",
    "GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "D = GP.test_obj\n",
    "\n",
    "pred_file = '3-15-21-1_LSTM_[25,25,20]_650Epoch_881BatchSize_TFMSE_881Dense-X-SquishAdj309win_309past_309fut'\n",
    "GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "E = GP.test_obj\n",
    "\n",
    "pred_file = '3-15-21-1_LSTM_[25,25,20]_100Epoch_881BatchSize_TFMSE_881Dense-X-SquishAdj_TrainableFinalDense309win_309past_309fut'\n",
    "GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "F = GP.test_obj\n",
    "\n",
    "pred_file = '3-25-21-1_[25,25,20]_300Epoch_Explicit_-1_Alpha_1000309win_309past_309fut'\n",
    "GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "G = GP.test_obj\n",
    "\n",
    "pred_file = '3-25-21-1_[25,25,20]_325Epoch_Implicit_-1_Alpha_1000309win_309past_309fut'\n",
    "GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "H = GP.test_obj\n",
    "\n",
    "pred_file = '3-28-21-1_[25,25,20]_100Epoch_BrokenNaiveAlpha_1000309win_309past_309fut'\n",
    "GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "I = GP.test_obj\n",
    "\n",
    "# pred_file = '02-17-2021--07--20-1LSTM-F-0ALPHA-[55,25,20]split-[None, 1]-40Epochs-rlf-Loss-64-HU-250win_681past_309fut'\n",
    "# GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "# J = GP.test_obj\n",
    "\n",
    "# pred_file = '02-17-2021--07--20-1LSTM-F-0ALPHA-[55,25,20]split-[None, 1]-40Epochs-rlf-Loss-64-HU-500win_681past_309fut'\n",
    "# GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "# K = GP.test_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP.compare_data_blocks('.\\ignorable_data\\datablocks\\[55, 25, 20]_splits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # pred_dir = r\"G:\\Shared drives\\Max Huffman - ECEN 403 404 URS Research 2020 2021\\Datasets\\predictions/\"\n",
    "# pred_dir = r\".\\ignorable_data\\prediction_results\\[55, 25, 20]_splits/\"\n",
    "# pred_file = '3-11-21-1_LSTM_[25,25,20]_60Epoch_40BatchSize_100ALPHA_RR_Labels309win_309past_309fut_220predBatch'\n",
    "# GP.generate_model_diagnostics(pred_dir + pred_file, datablock_folder='./ignorable_data/datablocks/', rr_labels=True)\n",
    "# # GP.generate_model_diagnostics_given_sets_close_gap(pred_dir + pred_file, x_val, datablock_folder='./ignorable_data/datablocks/', try_all_pred=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Let's look at our relations_file real quick\n",
    "with open('./ignorable_data/data_sets/NASDAQ_Cleaned - Contains ZUMZ/updated_relations.json') as read_file:\n",
    "    relations_dict = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The degree vector of Adj\n",
    "degree = np.sum(Adj, axis=0)\n",
    "\n",
    "# Inverse degree vector\n",
    "inv = lambda x: x**-1\n",
    "inv_degree = inv(degree)\n",
    "\n",
    "# Convert into an inverse diagonal matrix\n",
    "diag_inv_degree = np.diag(inv_degree)\n",
    "\n",
    "# Create the negative square root version\n",
    "inv_sqrt_degree = np.sqrt(inv_degree)\n",
    "\n",
    "diag_inv_sqrt_degree = np.diag(inv_sqrt_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symetric normalization yields the correct output\n",
    "print(np.sum(np.dot(np.dot(inv_sqrt_degree, Adj), inv_sqrt_degree)))\n",
    "print(np.sum(np.matmul(np.matmul(inv_sqrt_degree, Adj), inv_sqrt_degree)))\n",
    "\n",
    "# Symetric normalization yields the correct output\n",
    "print(np.dot(np.dot(inv_sqrt_degree, Adj), inv_sqrt_degree))\n",
    "print(np.matmul(np.matmul(inv_sqrt_degree, Adj), inv_sqrt_degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last company, ZUMF was truncated in this example, so this value makes sense.\n",
    "print(np.sum(DMJ.Normalized_Adjacency_Matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard normalization yields the correct output\n",
    "print(np.sum(np.matmul(diag_inv_degree, Adj)))\n",
    "\n",
    "# Standard normalization yields the correct output\n",
    "print(np.matmul(diag_inv_degree, Adj))\n",
    "print(np.dot(diag_inv_degree, Adj))\n",
    "print(np.dot(Adj, diag_inv_degree))\n",
    "\n",
    "print(np.dot(Adj, diag_inv_degree)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_adj_matrix(adj):\n",
    "    degree = tf.reduce_sum(adj, axis=0)\n",
    "    inv_degree = tf.math.reciprocal(degree)\n",
    "    diag_inv_degree = tf.linalg.diag(inv_degree)\n",
    "    r = diag_inv_degree * adj\n",
    "    return r\n",
    "\n",
    "adf_tf = tf.constant(Adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adf_tf)\n",
    "print(tf.reduce_sum(normalize_adj_matrix(adf_tf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.einsum(\"ij, k->ik\", Adj, Adj[:,3])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.einsum(\"ij, k->ij\", Adj, Adj[:,3])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Adj[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Temporal Relational Ranking Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the relations loaded from their dataset\n",
    "rel_encoding = np.load(r'C:\\Users\\Maxwell\\Documents\\Backups\\TAMU-ECEN-403-IFPTSND\\Temporal_Relational_Stock_Ranking-master\\data\\RELATIONS\\sector_industry\\NASDAQ_industry_relation.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Shape of relational data:\\t\\t\\t\\t\\t\", rel_encoding.shape)\n",
    "print(\"Shape of relational data 1 Hidden Unit Dense Layer:\\t\\t\", tf.keras.layers.Dense(2)(tf.constant(rel_encoding)).shape)\n",
    "print(\"Shape of relational data 1 Hidden Unit Dense Layer Truncated:\\t\", tf.keras.layers.Dense(2)(rel_encoding)[:, :, -1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Do we know for sure that our relationships are still in the right order?\")\n",
    "print(\"After checking the first group, yes, those orders are correct!\")\n",
    "print(Adj.shape)\n",
    "print(Rel.shape)\n",
    "print(np.transpose(Rel).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "sum = 0\n",
    "for i in np.transpose(Rel)[0,:,0]:\n",
    "    sum = sum + i\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\", shape=[int(input_shape[-1]), self.num_outputs])\n",
    "\n",
    "    def call(self, input):\n",
    "        return tf.matmul(input, self.kernel)\n",
    "\n",
    "test_layer = MyDenseLayer(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_layer(input_seq)\n",
    "x = tf.keras.layers.Dense(12)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[input_seq], outputs=x)\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class square_weight_layer(tf.keras.layers.Layer):\n",
    "    \n",
    "#     def __init__(self, square_shape):\n",
    "#         super(square_weight_layer, self).__init__()\n",
    "#         self.square_shape = square_shape\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         self.square_kernel = self.add_weight(\"square-kernel\",\n",
    "#                                              shape=[int(self.square_shape), int(self.square_shape)], trainable=True,\n",
    "#                                             dtype=tf.float32, initializer=tf.zeros_initializer)\n",
    "#         self.square_kernel = tf.add(tf.constant(-1000, shape=[880,880], dtype=tf.float32), self.square_kernel)\n",
    "#         self.square_kernel = tf.linalg.set_diag(self.square_kernel, tf.constant(1, shape=[880], dtype=tf.float32))\n",
    "        \n",
    "#     def call(self, input):\n",
    "# #         self.square_kernel = self.square_kernel + tf.eye(num_rows=int(square_shape), num_columns=int(square_shape))\n",
    "#         self.square_kernel = tf.nn.softmax(self.square_kernel, axis=0)\n",
    "#         self.square_kernel = tf.linalg.set_diag(self.square_kernel, tf.constant(1, shape=[880], dtype=tf.float32))\n",
    "#         print(self.square_kernel)\n",
    "#         return tf.matmul(self.square_kernel, input)\n",
    "\n",
    "class square_keep_self_loop(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, N):\n",
    "        super(square_keep_self_loop, self).__init__()\n",
    "        \n",
    "        self.N = N\n",
    "        self.data_t = tf.float32\n",
    "        \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        # Create the weights, initialized with zeroes\n",
    "        self.kernel = self.add_weight(\"square-kernel\",\n",
    "                                             shape=[self.N,self.N],\n",
    "                                            dtype=self.data_t, initializer=tf.keras.initializers.identity)\n",
    "        \n",
    "#         self.square_kernel = tf.add(tf.constant(-1000, shape=[self.N, self.N], dtype=self.data_t), self.square_kernel)\n",
    "        \n",
    "#         self.square_kernel = tf.linalg.set_diag(self.square_kernel, tf.constant(1, shape=self.N, dtype=self.data_t))\n",
    "        \n",
    "    def call(self, input):\n",
    "#         self.square_kernel = self.square_kernel + tf.eye(num_rows=int(square_shape), num_columns=int(square_shape))\n",
    "\n",
    "        # Normalize the matrix - across the horizontal axis\n",
    "#         self.kernel = tf.nn.softmax(self.kernel, axis=0)\n",
    "        # Ensure that the self loops are maintained\n",
    "#         self.square_kernel = tf.linalg.set_diag(self.square_kernel, tf.constant(1, shape=self.N, dtype=self.data_t))\n",
    "        \n",
    "        return self.kernel\n",
    "\n",
    "# class square_keep_self_loop(tf.keras.layers.Dense):\n",
    "    \n",
    "#     def __init__(self, N):\n",
    "#         super(square_keep_self_loop, self).__init__(N)\n",
    "        \n",
    "#         self.N = N\n",
    "#         self.data_t = tf.float32\n",
    "        \n",
    "#         print(self.kernel)\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "        \n",
    "#         # Create the weights, initialized with zeroes\n",
    "#         self.kernel = self.add_weight(\"square-kernel\",\n",
    "#                                              shape=[self.N,self.N],\n",
    "#                                             dtype=self.data_t, initializer=tf.zeros_initializer)\n",
    "        \n",
    "# #         self.square_kernel = tf.add(tf.constant(-1000, shape=[self.N, self.N], dtype=self.data_t), self.square_kernel)\n",
    "        \n",
    "# #         self.square_kernel = tf.linalg.set_diag(self.square_kernel, tf.constant(1, shape=self.N, dtype=self.data_t))\n",
    "        \n",
    "#     def call(self, input):\n",
    "# #         self.square_kernel = self.square_kernel + tf.eye(num_rows=int(square_shape), num_columns=int(square_shape))\n",
    "\n",
    "#         # Normalize the matrix - across the horizontal axis\n",
    "#         self.kernel = tf.nn.softmax(self.kernel, axis=0)\n",
    "#         # Ensure that the self loops are maintained\n",
    "# #         self.square_kernel = tf.linalg.set_diag(self.square_kernel, tf.constant(1, shape=self.N, dtype=self.data_t))\n",
    "#         self.kernel = tf.matmul(self.kernel, input)\n",
    "        \n",
    "#         return super().call(input)\n",
    "\n",
    "\n",
    "# class square_keep_self_loop(tf.keras.layers.Layer):\n",
    "\n",
    "#   def __init__(self, units):\n",
    "#       super(square_keep_self_loop, self).__init__()\n",
    "#       self.units = units\n",
    "\n",
    "#   def build(self, input_shape):  # Create the state of the layer (weights)\n",
    "#     w_init = tf.random_normal_initializer()\n",
    "#     self.w = tf.Variable(\n",
    "#         initial_value=w_init(shape=(self.units, self.units),\n",
    "#                              dtype='float32'),\n",
    "#         trainable=True)\n",
    "#     self.w = tf.nn.softmax(self.w)\n",
    "\n",
    "#   def call(self, inputs):  # Defines the computation from inputs to outputs\n",
    "        \n",
    "#         return tf.matmul(self.w, inputs)\n",
    "\n",
    "class MaskedDense(Dense):\n",
    "    #Dense layer defined here:\n",
    "    #https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/layers/core.py#L1081-L1247\n",
    "    def __init__(self, units, *args, **kwargs):\n",
    "        super(MaskedDense, self).__init__(units, *args, **kwargs)        \n",
    "        self.units = units\n",
    "    \n",
    "    def call(self, x):\n",
    "#         self.kernel = tf.nn.softmax(self.kernel, axis=0)\n",
    "#         self.kernel = tf.linalg.set_diag(self.kernel, tf.constant(1, shape=[self.units], dtype=tf.float32))\n",
    "#         self.kernel = tf.nn.softmax(self.kernel, axis=0)\n",
    "\n",
    "        return super().call(x)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(MaskedDense, self).build(input_shape)\n",
    "        \n",
    "\n",
    "class square_keep_self_loop(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, N):\n",
    "        super(square_keep_self_loop, self).__init__(N)\n",
    "        \n",
    "        self.N = N\n",
    "        self.data_t = tf.float32\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        # Create the weights, initialized with zeroes\n",
    "        self.kernel = self.add_weight(\"square-kernel\", shape=[self.N,self.N], dtype=self.data_t,\n",
    "                                      initializer=tf.initializers.identity, trainable=True)\n",
    "        \n",
    "#         self.square_kernel = tf.add(tf.constant(-1000, shape=[self.N, self.N], dtype=self.data_t), self.square_kernel)\n",
    "        \n",
    "#         self.square_kernel = tf.linalg.set_diag(self.square_kernel, tf.constant(1, shape=self.N, dtype=self.data_t))\n",
    "        \n",
    "    def call(self, input):\n",
    "        \n",
    "        # Create a second tensor that leaves the internal kernel to be trainable\n",
    "        a_mat = tf.matmul(tf.eye(self.N, self.N), self.kernel)\n",
    "        \n",
    "        # Normalize the values\n",
    "        a_mat = tf.nn.softmax(a_mat, axis=0)\n",
    "#         a_mat = a_mat + tf.eye(self.N, self.N)\n",
    "#         a_mat = tf.nn.softmax(a_mat, axis=0)\n",
    "\n",
    "        # Ensure that the self loops are maintained\n",
    "        a_mat = tf.linalg.set_diag(a_mat, tf.constant(1, shape=[self.N], dtype=self.data_t))\n",
    "        \n",
    "        output = tf.matmul(a_mat, input)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_shape=880\n",
    "eye = tf.eye(num_rows=int(square_shape), num_columns=int(square_shape))\n",
    "\n",
    "# SWL = square_weight_layer()(eye)\n",
    "SWL = square_keep_self_loop(880)(eye)\n",
    "SWL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(-1000, shape=[None,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Matrix Through Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/test9.npy', '/test18.npy', '/test27.npy', '/test36.npy', '/test45.npy', '/test54.npy', '/test63.npy', '/test72.npy', '/test81.npy', '/test90.npy', '/test99.npy', '/test108.npy', '/test117.npy', '/test126.npy', '/test135.npy', '/test144.npy', '/testLAST.npy']\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "# !{sys.executable} -m pip install plotly\n",
    "\n",
    "path = r'G:\\Shared drives\\Max Huffman - ECEN 403 404 URS Research 2020 2021\\Datasets\\weight_matrix\\learned_implict_1_layer'\n",
    "\n",
    "files = os.listdir(path)\n",
    "files = ['/' + i for i in files if i != '.ipynb_checkpoints']\n",
    "print(files)\n",
    "\n",
    "# Get the first one\n",
    "company_strengths = np.load(path + files[0])\n",
    "# For all but the first, add the dimensions\n",
    "for f in files[1:]:\n",
    "    temp = np.load(path + f)\n",
    "    company_strengths = np.concatenate([company_strengths, temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(881, 66, 881)\n",
      "0.0011412372\n",
      "0.0011409178\n",
      "0.0011407234\n",
      "0.0011405654\n"
     ]
    }
   ],
   "source": [
    "print(company_strengths.shape)\n",
    "\n",
    "def company_time_slice(c, t, company_strengths, original):\n",
    "    original = original[c, :]\n",
    "    slice_max = np.max(original)\n",
    "    original = [idx[0] for idx, val in np.ndenumerate(original) if val==slice_max]\n",
    "    \n",
    "    relations = company_strengths[c, t, :]\n",
    "    slice_max = np.max(relations)\n",
    "    data = [idx[0] for idx, val in np.ndenumerate(relations) if val==slice_max]\n",
    "    \n",
    "    o_set = set(original)\n",
    "    n_set = set(data)\n",
    "    \n",
    "    print(o_set.intersection(n_set), end=' ')\n",
    "\n",
    "# for i in range(66):\n",
    "#     company_time_slice(220, i, company_strengths, Adj)\n",
    "\n",
    "\n",
    "def TwoD_similarity(x ,y):\n",
    "    if x.shape != y.shape:\n",
    "        print(\"SIZE ERROR\")\n",
    "        return\n",
    "    else:\n",
    "        z = np.where(x==y, 1, 0)\n",
    "        z = np.sum(z) / z.flatten().shape[0]\n",
    "        \n",
    "        return z\n",
    "\n",
    "print(np.max(company_strengths[0, 0, :]))\n",
    "print(np.max(company_strengths[0, 1, :]))\n",
    "print(np.max(company_strengths[0, 2, :]))\n",
    "print(np.max(company_strengths[0, 3, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(company_strengths.shape[1]):\n",
    "    c = np.array(company_strengths)[:, i, :]\n",
    "    unique_relationships = list(set(c.flatten()))\n",
    "    unique_relationships.sort()\n",
    "    x = list(range(0, len(unique_relationships)))\n",
    "    plt.plot(x, unique_relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "98\n",
      "95\n",
      "100\n",
      "100\n",
      "98\n",
      "100\n",
      "97\n",
      "97\n",
      "96\n",
      "104\n",
      "100\n",
      "100\n",
      "94\n",
      "94\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "95\n",
      "95\n",
      "97\n",
      "97\n",
      "98\n",
      "98\n",
      "97\n",
      "97\n",
      "98\n",
      "93\n",
      "99\n",
      "99\n",
      "96\n",
      "98\n",
      "101\n",
      "101\n",
      "93\n",
      "103\n",
      "97\n",
      "97\n",
      "98\n",
      "101\n",
      "98\n",
      "98\n",
      "96\n",
      "101\n",
      "123\n",
      "123\n",
      "103\n",
      "97\n",
      "99\n",
      "99\n",
      "101\n",
      "102\n",
      "99\n",
      "99\n",
      "103\n",
      "102\n",
      "103\n",
      "103\n",
      "101\n",
      "103\n",
      "104\n",
      "104\n",
      "108\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-490b01169eab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompany_strengths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wait'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m#     b_ind = np.argpartition(b, -15)[-15:]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#     b_ind = b[b_ind]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maxwell\\pycharmprojects\\ml-class\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             )\n\u001b[1;32m--> 860\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maxwell\\pycharmprojects\\ml-class\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "for c in range(10):\n",
    "    for i in range(company_strengths.shape[1]):\n",
    "        b = company_strengths[c, i, :]\n",
    "        print(len(set(b)))\n",
    "    input('wait')\n",
    "    #     b_ind = np.argpartition(b, -15)[-15:]\n",
    "    #     b_ind = b[b_ind]\n",
    "    #     b_ind.sort()\n",
    "    #     print(b_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_shape = 881\n",
    "eye = tf.eye(num_rows=int(square_shape), num_columns=int(square_shape))\n",
    "# eye = tf.ones(shape=[5,5])\n",
    "eye = np.array(eye)\n",
    "for i in range(5):\n",
    "    eye[1, i] = 1\n",
    "\n",
    "for i in range(2):\n",
    "    eye = eye + tf.eye(num_rows=int(square_shape), num_columns=int(square_shape))\n",
    "\n",
    "eye = tf.constant(eye)\n",
    "print(eye)\n",
    "\n",
    "eye_t = tf.transpose(eye)\n",
    "\n",
    "eye = tf.sparse.from_dense(eye)\n",
    "eye = tf.sparse.softmax(eye)\n",
    "eye = tf.sparse.to_dense(eye)\n",
    "# eye = tf.math.sqrt(eye)\n",
    "# eye = tf.math.reciprocal_no_nan(eye)\n",
    "\n",
    "eye_t = tf.sparse.from_dense(eye_t)\n",
    "eye_t = tf.sparse.softmax(eye_t)\n",
    "eye_t = tf.sparse.to_dense(eye_t)\n",
    "# eye_t = tf.math.sqrt(eye_t)\n",
    "# eye_t = tf.math.reciprocal_no_nan(eye_t)\n",
    "\n",
    "smooth = tf.math.subtract(tf.add(eye, eye_t), tf.eye(square_shape,square_shape))\n",
    "# print(tf.multiply(smooth, tf.eye(num_rows=int(square_shape), num_columns=int(square_shape))))\n",
    "print(smooth)\n",
    "\n",
    "# print(tf.linalg.set_diag(smooth, tf.constant(5, shape=square_shape, dtype=tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_mat = tf.eye(10,10)\n",
    "\n",
    "a_mat_t = tf.transpose(a_mat)\n",
    "# a_mat = tf.sparse.from_dense(a_mat)\n",
    "\n",
    "a_mat = tf.sparse.from_dense(a_mat)\n",
    "a_mat = tf.sparse.softmax(a_mat)\n",
    "a_mat = tf.sparse.to_dense(a_mat)\n",
    "\n",
    "a_mat_t = tf.sparse.from_dense(a_mat_t)\n",
    "a_mat_t = tf.sparse.softmax(a_mat_t)\n",
    "a_mat_t = tf.sparse.to_dense(a_mat_t)\n",
    "\n",
    "print(a_mat)\n",
    "boolean_mask = tf.math.greater(a_mat, 0)\n",
    "print(boolean_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zeres = tf.math.logical_not(tf.equal(eye, 0.))\n",
    "print(non_zeres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_softmax = tf.nn.softmax(tf.boolean_mask(eye, non_zeres))\n",
    "# print(tf.where(non_zeres), tf.ones(shape=non_zeres.shape))\n",
    "print(sparse_softmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_(tensor):\n",
    "\n",
    "    zeros = tf.cast(tf.equal(tensor, 0.), tf.float64)\n",
    "    cond_ = tf.reduce_sum(zeros)\n",
    "\n",
    "    def true_fn():\n",
    "        non_zeros = ~tf.equal(tensor, 0.)\n",
    "        sparse_softmax = tf.nn.softmax(tf.boolean_mask(tensor, non_zeros))\n",
    "        sparse_softmax_shape = tf.shape(sparse_softmax)[0]\n",
    "        orig_shape = tf.shape(tensor)[0]\n",
    "        shape_ = orig_shape-sparse_softmax_shape\n",
    "        zeros = tf.zeros(shape=shape_, dtype=tf.float32)\n",
    "        new_vec = tf.concat([sparse_softmax, zeros], axis=0)\n",
    "\n",
    "        return new_vec\n",
    "\n",
    "    def false_fn():\n",
    "\n",
    "        return tf.zeros(shape=tf.shape(tensor), dtype=tf.float64)\n",
    "\n",
    "    return tf.cond(tf.equal(cond_, tf.cast(tf.shape(tensor)[0], tf.float64)), false_fn, true_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sparse_softmax(time_vector):\n",
    "    non_zeros = ~tf.equal(time_vector, 0.)\n",
    "\n",
    "    sparse_softmax = tf.nn.softmax(tf.boolean_mask(time_vector, non_zeros))\n",
    "    new_time_vector = sparse_softmax * tf.cast(non_zeros, tf.float32) # won't work because dimensions are different\n",
    "    return time_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[6., 2., 0.], [0., 4., 5.]])  # of type tf.float32\n",
    "\n",
    "k = 2\n",
    "values, indices = tf.nn.top_k(x, k, sorted=False)  # indices will be [[0, 1], [1, 2]], values will be [[6., 2.], [4., 5.]]\n",
    "\n",
    "# We need to create full indices like [[0, 0], [0, 1], [1, 2], [1, 1]]\n",
    "my_range = tf.expand_dims(tf.range(0, indices.get_shape()[0]), 1)  # will be [[0], [1]]\n",
    "my_range_repeated = tf.tile(my_range, [1, k])  # will be [[0, 0], [1, 1]]\n",
    "\n",
    "# change shapes to [N, k, 1] and [N, k, 1], to concatenate into [N, k, 2]\n",
    "full_indices = tf.concat([tf.expand_dims(my_range_repeated, 2), tf.expand_dims(indices, 2)], axis=2)\n",
    "full_indices = tf.reshape(full_indices, [-1, 2])\n",
    "\n",
    "print(x)\n",
    "\n",
    "to_substract = tf.sparse.to_dense(full_indices, x.get_shape(), tf.reshape(values, [-1]))\n",
    "\n",
    "res = x - to_substract  # res should be all 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
