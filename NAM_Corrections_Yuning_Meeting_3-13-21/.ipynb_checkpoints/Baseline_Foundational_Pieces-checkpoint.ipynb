{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ignore cuDDa warning messages\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enable GPU\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# # Expands the Jupyter Notebook Output Size to fit your window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "# Load in tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Change the working directory back to the original to keep paths the same between files\n",
    "os.chdir(r'C:\\Users\\Maxwell\\PycharmProjects\\TAMU-ECEN-403-IFPTSND\\ECEN_403_IFM\\TAMU-ECEN-403-IFPTSND')\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "import sys\n",
    "from os.path import join, isfile\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "from explore_entities import Graph_Entities\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, GridBox\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allows for scrolling windows to be very large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "    IPython.OutputArea.auto_scroll_threshold = 9999\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "    IPython.OutputArea.auto_scroll_threshold = 9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import TF_models and truncate the entities to only contain 880 companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d849e1e207804cfdbedb53c0889955fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Dropdown(description='Model Types:', options=('lstm', 'lstm_gcn_1', 'lstm_gcn_2', 'lstm_gcn_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow_models import TF_Models, Ein_Multiply, leaky_relu, rank_loss_func\n",
    "DMJ = TF_Models('./ignorable_data/data_sets/NASDAQ_Cleaned - Contains ZUMZ/', './ignorable_data/models/[55, 25, 20]_split/', reload=False)\n",
    "data_splits = DMJ.split_data()\n",
    "\n",
    "DMJ.Normalized_Adjacency_Matrix = DMJ.Normalized_Adjacency_Matrix[0:880, 0:880]\n",
    "DMJ.XX_tf = DMJ.XX_tf[0:-1, :, :]\n",
    "DMJ.YY_tf = DMJ.YY_tf[0:-1, :]\n",
    "DMJ.RR_tf = DMJ.RR_tf[0:-1, :]\n",
    "DMJ.entities = DMJ.entities[0:-1]\n",
    "DMJ.entities_idx.pop('ZUMZ')\n",
    "\n",
    "model = DMJ.generate_model()\n",
    "\n",
    "from graph_predictions import Graph_Predictions\n",
    "GP = Graph_Predictions(\"./ignorable_data/models/[55, 25, 20]_split/\", \"./ignorable_data/strategies/RL_validation_strategies/\", 'x_val', DMJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if we split the data into time batches ourselves and trained them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(880, 1239, 5)\n",
      "(880, 309, 5)\n",
      "(880, 309, 5)\n",
      "tf.Tensor(0.455917, shape=(), dtype=float32)\n",
      "tf.Tensor(0.461538, shape=(), dtype=float32)\n",
      "tf.Tensor(0.012328968, shape=(), dtype=float32)\n",
      "tf.Tensor(0.425614, shape=(), dtype=float32)\n",
      "tf.Tensor(0.415741, shape=(), dtype=float32)\n",
      "tf.Tensor([0.415741], shape=(1,), dtype=float32)\n",
      "(None, 309, 5)\n"
     ]
    }
   ],
   "source": [
    "# Given a total and list of splits, evenly distributes the total amount proportional to the given list\n",
    "def split_windows(total, percentages_list):\n",
    "    # Get a sum of the initial total\n",
    "    percentage_sum = sum(percentages_list)\n",
    "\n",
    "    # Create a new list based on a percentage of the total\n",
    "    new_splits = []\n",
    "    for perc in percentages_list:\n",
    "        new_splits.append(int(total * (perc / percentage_sum)))\n",
    "    \n",
    "    # Where to shift the extra days that don't exactly divide between the values\n",
    "    if sum(new_splits) != total:\n",
    "        new_splits[-1] = new_splits[-1] + (total - sum(new_splits))\n",
    "\n",
    "    return new_splits\n",
    "\n",
    "# one_x = DMJ.XX_tf[0:2, :, :]\n",
    "# one_y = DMJ.YY_tf[0:2, :]\n",
    "one_x = DMJ.XX_tf\n",
    "print(DMJ.XX_tf.shape)\n",
    "one_y = DMJ.YY_tf\n",
    "\n",
    "# one_x = DMJ.XX_tf[0:-1, :, :]\n",
    "# one_y = DMJ.YY_tf[0:-1, :]\n",
    "\n",
    "# # Given a dataset, let's section off a fifth of the data to be used for testing purposes\n",
    "# time_split = [1000, 239,]\n",
    "# x_train, x_test = tf.split(one_x, split_windows(one_x.shape[1], time_split),\n",
    "#                                   axis=1)\n",
    "# y_train, y_test = tf.split(one_y, split_windows(one_y.shape[1], time_split),\n",
    "#                                   axis=1)\n",
    "# rr_train, rr_test = tf.split(DMJ.RR_tf, split_windows(one_y.shape[1], time_split),\n",
    "#                                      axis=1)\n",
    "\n",
    "# Given a dataset, let's section off a fifth of the data to be used for testing purposes\n",
    "time_split = [90, 710, 239, 199]\n",
    "time_split = [55, 25, 20]\n",
    "\n",
    "time_split = [30, 25, 25, 20]\n",
    "x_g, x_train, x_val, x_test = tf.split(one_x, split_windows(one_x.shape[1], time_split),\n",
    "                                  axis=1)\n",
    "y_g, y_train, y_val, y_test = tf.split(one_y, split_windows(one_y.shape[1], time_split),\n",
    "                                  axis=1)\n",
    "rr_g, rr_train, rr_val, rr_test = tf.split(DMJ.RR_tf, split_windows(one_y.shape[1], time_split),\n",
    "                                     axis=1)\n",
    "\n",
    "# y_train = y_train[:, -1]\n",
    "# y_val = y_val[:, -1]\n",
    "\n",
    "# # Once we have the data partitioned, let's split it into 8 sets of 125\n",
    "# batch_splits = [1]*8\n",
    "# # Create a list of 8 different time batches\n",
    "# x_train_batches = []\n",
    "# x_train_batches.append(tf.split(x_train, split_windows(x_train.shape[1], batch_splits), axis=1))\n",
    "# x_train_batches = [item for sublist in x_train_batches for item in sublist]\n",
    "\n",
    "# y_train_batches = []\n",
    "# y_train_batches.append(tf.split(y_train, split_windows(x_train.shape[1], batch_splits), axis=1))\n",
    "# y_train_batches = [item for sublist in y_train_batches for item in sublist]\n",
    "\n",
    "# # Lets try truncating the values for the labels to only be the final value\n",
    "# for i in range(len(y_train_batches)):\n",
    "#     y_train_batches[i] = y_train_batches[i][:, -1]\n",
    "\n",
    "# print(x_train[0, -1, 0])\n",
    "\n",
    "# print(rr_train[0, -1])\n",
    "\n",
    "# print(x_val[0, 0, 0])\n",
    "# print(y_train[0, -1])\n",
    "# for set in [x_train, x_g, x_val, x_test]:\n",
    "print(x_val.shape)\n",
    "print(x_train.shape)\n",
    "\n",
    "print(x_train[0, 0, 0])\n",
    "print(x_train[0, 1, 0])\n",
    "print(rr_train[0, 0])\n",
    "\n",
    "print(x_train[0, -1, 0])\n",
    "print(x_train[0, -2, 0])\n",
    "print(x_train[0, -2:-1, 0])\n",
    "\n",
    "print(keras.Input(shape=(x_train.shape[1], x_train.shape[2])).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create the one-hot encoded adjacency matrix to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Text(value='Loading Normalized Adjacency Matrix:', disabled=True, layout=Layout(width='auto'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Text(value='Loading Normalized Adjacency Matrix:', disabled=True, layout=Layout(width='auto'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import explore_entities\n",
    "# Load in the code\n",
    "GE = Graph_Entities('./ignorable_data/data_sets/NASDAQ_Cleaned - Contains ZUMZ - Yuning/')\n",
    "# Generate the baseline components we're wokring with\n",
    "NAM, Adj, Rel = GE.get_matrix_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the dimensionality of normalized adjacency matrix we have so far "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symetrically Normalized DMJ: (881, 881)\n",
      "Normalized\n",
      "####\n",
      "One-Hot Encoded Relationships Split by Group: (92, 881, 881)\n",
      "####\n",
      "One-Hot Encoded All Relationships: (881, 881)\n",
      "Rows Not Normalized\n",
      "Columns Not Normalized\n",
      "####\n",
      "12.5\n"
     ]
    }
   ],
   "source": [
    "# Checks to see if a matrix is normalized among it's rows and columns to 6 decimal places\n",
    "def is_normalized(m):\n",
    "    m_t = np.transpose(m)\n",
    "    r_trigger = True\n",
    "    c_trigger = True\n",
    "    for i in m:\n",
    "        if (round(np.sum(i), 6)) != 1 and r_trigger:\n",
    "            print('Rows Not Normalized')\n",
    "            r_trigger = not r_trigger\n",
    "    for i in m_t:\n",
    "        if (round(np.sum(i), 6)) != 1 and c_trigger:\n",
    "            print('Columns Not Normalized')\n",
    "            c_trigger = not c_trigger\n",
    "    \n",
    "    if r_trigger and c_trigger:\n",
    "        print('Normalized')\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Created with D^-1/2 * A * D^-1/2\n",
    "print(f\"Symetrically Normalized DMJ: {NAM.shape}\")\n",
    "is_normalized(NAM)\n",
    "print(\"####\")\n",
    "# All relationships, but still seperated by the different groups\n",
    "print(f\"One-Hot Encoded Relationships Split by Group: {Rel.shape}\")\n",
    "print(\"####\")\n",
    "# All relationships squished into one matrix\n",
    "print(f\"One-Hot Encoded All Relationships: {Adj.shape}\")\n",
    "is_normalized(Adj)\n",
    "print(\"####\")\n",
    "\n",
    "None\n",
    "\n",
    "print(np.sum(Rel[9, :, :])/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a total and list of splits, evenly distributes the total amount proportional to the given list\n",
    "def split_windows(total, percentages_list):\n",
    "    # Get a sum of the initial total\n",
    "    percentage_sum = sum(percentages_list)\n",
    "\n",
    "    # Create a new list based on a percentage of the total\n",
    "    new_splits = []\n",
    "    for perc in percentages_list:\n",
    "        new_splits.append(int(total * (perc / percentage_sum)))\n",
    "    \n",
    "    # Where to shift the extra days that don't exactly divide between the values\n",
    "    if sum(new_splits) != total:\n",
    "        new_splits[-1] = new_splits[-1] + (total - sum(new_splits))\n",
    "\n",
    "    return new_splits\n",
    "\n",
    "one_x = DMJ.XX_tf\n",
    "one_y = DMJ.YY_tf\n",
    "\n",
    "time_split = [90, 710, 239, 199]\n",
    "time_split = [55, 25, 20]\n",
    "\n",
    "time_split = [30, 25, 25, 20]\n",
    "x_g, x_train, x_val, x_test = tf.split(one_x, split_windows(one_x.shape[1], time_split),\n",
    "                                  axis=1)\n",
    "y_g, y_train, y_val, y_test = tf.split(one_y, split_windows(one_y.shape[1], time_split),\n",
    "                                  axis=1)\n",
    "rr_g, rr_train, rr_val, rr_test = tf.split(DMJ.RR_tf, split_windows(one_y.shape[1], time_split),\n",
    "                                     axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in an already trained LSTM model & Adding Topographical Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_models import mse_rr\n",
    "from tensorflow_models import rank_loss_rr\n",
    "tf.random.set_seed(1337)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "            name='Adam'\n",
    "        )\n",
    "\n",
    "# Create a function for the Tensorflow implementation of leaky_relu\n",
    "def leaky_relu(x):\n",
    "    return tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "def normalize_adj_matrix(adj):\n",
    "    degree = tf.reduce_sum(adj, axis=0)\n",
    "    inv_degree = tf.math.reciprocal(degree)\n",
    "    diag_inv_degree = tf.linalg.diag(inv_degree)\n",
    "    norm_adj = diag_inv_degree * adj\n",
    "    return norm_adj\n",
    "\n",
    "hidden_units = 64\n",
    "activation = leaky_relu\n",
    "do = 0\n",
    "\n",
    "# Assuming all time steps are the same size, we can just use the first item to determine input shape\n",
    "# For the time-series data\n",
    "input_seq = keras.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "\n",
    "\n",
    "# For the Adjacency Matrix we would like to introduce to the algorithm\n",
    "adj_matrix = Adj\n",
    "\n",
    "# Since some implementations removed the last company\n",
    "if adj_matrix.shape[0] == 881:\n",
    "    adj_matrix = adj_matrix[0:-1, 0:-1]\n",
    "\n",
    "input_rel = keras.Input(shape=(adj_matrix.shape[0]))\n",
    "\n",
    "\n",
    "# Load in an already trained LSTM Model\n",
    "file_name = '2-20-21-1_LSTM_[25,25,20]_NoDropout_100Epoch_80BatchSize_1000ALPHA'\n",
    "model_path = './ignorable_data/models/[55, 25, 20]_split/'\n",
    "pre_trained_lstm = tf.keras.models.load_model(model_path + f'{file_name}', compile=False,\n",
    "                                              custom_objects={'leaky_relu': leaky_relu})\n",
    "\n",
    "# Change the names to avoid conflicts\n",
    "pre_trained_lstm.layers[0]._name = 'Original-InputLayer'\n",
    "pre_trained_lstm.layers[1]._name = 'Original-LSTM'\n",
    "pre_trained_lstm.layers[2]._name = 'Original-Dense'\n",
    "\n",
    "# # Make sure that the weights for the lstm model cannot be updated\n",
    "pre_trained_lstm.layers[0].trainable = False\n",
    "pre_trained_lstm.layers[1].trainable = False\n",
    "pre_trained_lstm.layers[2].trainable = False\n",
    "\n",
    "# This is the LSTM layer, input_seq is not carried over from the original because we don't care how it was initalized\n",
    "x = pre_trained_lstm.layers[1](input_seq)\n",
    "\n",
    "# Experimental vector multiplication\n",
    "# W = tf.Variable(tf.random.uniform(shape=[adj_matrix.shape[0], 1]))\n",
    "# W = tf.keras.layers.Variable\n",
    "# y = Ein_Multiply()([input_rel, W], \"ij, k->ik\")\n",
    "\n",
    "# This is a seperate input layer that will take in the relational matrix\n",
    "y = tf.keras.layers.Dense(hidden_units, activation)(input_rel)\n",
    "y = normalize_adj_matrix(y)\n",
    "\n",
    "# # This is one aggregation using the NAM and accounting for the time dimension\n",
    "x = Ein_Multiply()([y, x], 'mn,ntd->mtd')\n",
    "# x = Dense(hidden_units, activation=activation)(x)\n",
    "\n",
    "# This is the original Dense Layer\n",
    "x = pre_trained_lstm.layers[2](x)\n",
    "\n",
    "# This is a new Dense layer we might want to experiment with\n",
    "# x = Dense(1, activation=activation)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_seq, input_rel], outputs=x)\n",
    "\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 880)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           56384       input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_2 (TensorFlowOp [(64,)]              0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reciprocal_2 (Tenso [(64,)]              0           tf_op_layer_Sum_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_diag_2 (TensorFlowO [(64, 64)]           0           tf_op_layer_Reciprocal_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           [(None, 309, 5)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_2 (TensorFlowOp [(64, 64)]           0           tf_op_layer_diag_2[0][0]         \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Original-LSTM (LSTM)            (None, 309, 64)      17920       input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "ein__multiply_6 (Ein_Multiply)  (64, 309, 64)        0           tf_op_layer_Mul_2[0][0]          \n",
      "                                                                 Original-LSTM[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Original-Dense (Dense)          multiple             65          ein__multiply_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 74,369\n",
      "Trainable params: 56,384\n",
      "Non-trainable params: 17,985\n",
      "__________________________________________________________________________________________________\n",
      "<tf.Variable 'Variable:0' shape=(880, 1) dtype=float32, numpy=\n",
      "array([[0.33436978],\n",
      "       [0.514704  ],\n",
      "       [0.6911713 ],\n",
      "       [0.79071164],\n",
      "       [0.69171417],\n",
      "       [0.8070296 ],\n",
      "       [0.09853482],\n",
      "       [0.15362263],\n",
      "       [0.84117436],\n",
      "       [0.7703353 ],\n",
      "       [0.17167294],\n",
      "       [0.6810354 ],\n",
      "       [0.6033895 ],\n",
      "       [0.4884671 ],\n",
      "       [0.865558  ],\n",
      "       [0.82201385],\n",
      "       [0.05294383],\n",
      "       [0.18914998],\n",
      "       [0.4899726 ],\n",
      "       [0.38476682],\n",
      "       [0.3806584 ],\n",
      "       [0.6911081 ],\n",
      "       [0.6731272 ],\n",
      "       [0.6707982 ],\n",
      "       [0.15133595],\n",
      "       [0.11396837],\n",
      "       [0.30297172],\n",
      "       [0.34670746],\n",
      "       [0.1944778 ],\n",
      "       [0.9890053 ],\n",
      "       [0.49450898],\n",
      "       [0.48231125],\n",
      "       [0.49535382],\n",
      "       [0.37302148],\n",
      "       [0.16706705],\n",
      "       [0.9284092 ],\n",
      "       [0.0600915 ],\n",
      "       [0.7854403 ],\n",
      "       [0.26803863],\n",
      "       [0.361912  ],\n",
      "       [0.8186139 ],\n",
      "       [0.6114521 ],\n",
      "       [0.2569312 ],\n",
      "       [0.43790615],\n",
      "       [0.47558892],\n",
      "       [0.9377291 ],\n",
      "       [0.703961  ],\n",
      "       [0.81710505],\n",
      "       [0.07035434],\n",
      "       [0.8093898 ],\n",
      "       [0.23248136],\n",
      "       [0.506925  ],\n",
      "       [0.76622987],\n",
      "       [0.01797128],\n",
      "       [0.01478446],\n",
      "       [0.04573298],\n",
      "       [0.97424865],\n",
      "       [0.55927837],\n",
      "       [0.51719606],\n",
      "       [0.02838552],\n",
      "       [0.23204029],\n",
      "       [0.50579226],\n",
      "       [0.8415947 ],\n",
      "       [0.14272332],\n",
      "       [0.4282391 ],\n",
      "       [0.6740693 ],\n",
      "       [0.77267146],\n",
      "       [0.19434178],\n",
      "       [0.5197824 ],\n",
      "       [0.1697644 ],\n",
      "       [0.50355756],\n",
      "       [0.7242055 ],\n",
      "       [0.7697085 ],\n",
      "       [0.13252306],\n",
      "       [0.8658874 ],\n",
      "       [0.21113443],\n",
      "       [0.7111546 ],\n",
      "       [0.11829579],\n",
      "       [0.99138856],\n",
      "       [0.6533824 ],\n",
      "       [0.23859608],\n",
      "       [0.05654621],\n",
      "       [0.9959074 ],\n",
      "       [0.65698576],\n",
      "       [0.06670439],\n",
      "       [0.4667238 ],\n",
      "       [0.1493243 ],\n",
      "       [0.3471949 ],\n",
      "       [0.15077305],\n",
      "       [0.3345523 ],\n",
      "       [0.6101433 ],\n",
      "       [0.6757612 ],\n",
      "       [0.37259948],\n",
      "       [0.632367  ],\n",
      "       [0.7114246 ],\n",
      "       [0.33786702],\n",
      "       [0.21515799],\n",
      "       [0.6310811 ],\n",
      "       [0.39692366],\n",
      "       [0.935181  ],\n",
      "       [0.7806586 ],\n",
      "       [0.06878328],\n",
      "       [0.08870602],\n",
      "       [0.7757704 ],\n",
      "       [0.6339568 ],\n",
      "       [0.57704914],\n",
      "       [0.46817863],\n",
      "       [0.00273502],\n",
      "       [0.892236  ],\n",
      "       [0.4994018 ],\n",
      "       [0.81992745],\n",
      "       [0.97292995],\n",
      "       [0.08708525],\n",
      "       [0.04083526],\n",
      "       [0.4316349 ],\n",
      "       [0.31059802],\n",
      "       [0.8755728 ],\n",
      "       [0.67221427],\n",
      "       [0.25979328],\n",
      "       [0.55697894],\n",
      "       [0.44358552],\n",
      "       [0.3188647 ],\n",
      "       [0.11600554],\n",
      "       [0.8824874 ],\n",
      "       [0.7779199 ],\n",
      "       [0.20714343],\n",
      "       [0.10901713],\n",
      "       [0.73574185],\n",
      "       [0.4261073 ],\n",
      "       [0.66994274],\n",
      "       [0.49038732],\n",
      "       [0.20027983],\n",
      "       [0.07920325],\n",
      "       [0.8200408 ],\n",
      "       [0.5213815 ],\n",
      "       [0.703485  ],\n",
      "       [0.9073305 ],\n",
      "       [0.2239238 ],\n",
      "       [0.31434417],\n",
      "       [0.07854652],\n",
      "       [0.7867439 ],\n",
      "       [0.36543489],\n",
      "       [0.3560387 ],\n",
      "       [0.06300437],\n",
      "       [0.00931799],\n",
      "       [0.47417665],\n",
      "       [0.8529695 ],\n",
      "       [0.09237766],\n",
      "       [0.5756072 ],\n",
      "       [0.30105233],\n",
      "       [0.72555184],\n",
      "       [0.51058626],\n",
      "       [0.2331419 ],\n",
      "       [0.28199685],\n",
      "       [0.7409432 ],\n",
      "       [0.20927143],\n",
      "       [0.5460812 ],\n",
      "       [0.81405807],\n",
      "       [0.5963311 ],\n",
      "       [0.00904226],\n",
      "       [0.20410013],\n",
      "       [0.07753992],\n",
      "       [0.01772273],\n",
      "       [0.7947209 ],\n",
      "       [0.95766246],\n",
      "       [0.91092265],\n",
      "       [0.2511617 ],\n",
      "       [0.8454771 ],\n",
      "       [0.15298164],\n",
      "       [0.2923318 ],\n",
      "       [0.8188609 ],\n",
      "       [0.759845  ],\n",
      "       [0.7976078 ],\n",
      "       [0.48192966],\n",
      "       [0.6224829 ],\n",
      "       [0.11602592],\n",
      "       [0.704703  ],\n",
      "       [0.49292755],\n",
      "       [0.49009287],\n",
      "       [0.2366296 ],\n",
      "       [0.5707375 ],\n",
      "       [0.9607886 ],\n",
      "       [0.52824545],\n",
      "       [0.9463186 ],\n",
      "       [0.03896713],\n",
      "       [0.9213731 ],\n",
      "       [0.53236175],\n",
      "       [0.7440611 ],\n",
      "       [0.20248806],\n",
      "       [0.497249  ],\n",
      "       [0.7300025 ],\n",
      "       [0.17815816],\n",
      "       [0.93065476],\n",
      "       [0.7482804 ],\n",
      "       [0.19016898],\n",
      "       [0.39702356],\n",
      "       [0.43462527],\n",
      "       [0.988719  ],\n",
      "       [0.0395472 ],\n",
      "       [0.65492976],\n",
      "       [0.40188003],\n",
      "       [0.1275121 ],\n",
      "       [0.32168627],\n",
      "       [0.3955387 ],\n",
      "       [0.34033906],\n",
      "       [0.4171791 ],\n",
      "       [0.5501858 ],\n",
      "       [0.619491  ],\n",
      "       [0.7493948 ],\n",
      "       [0.93620074],\n",
      "       [0.91836   ],\n",
      "       [0.4739343 ],\n",
      "       [0.7864338 ],\n",
      "       [0.20776713],\n",
      "       [0.21708417],\n",
      "       [0.35802448],\n",
      "       [0.41885424],\n",
      "       [0.20802164],\n",
      "       [0.46449316],\n",
      "       [0.7711661 ],\n",
      "       [0.89445746],\n",
      "       [0.06595922],\n",
      "       [0.5973344 ],\n",
      "       [0.23890138],\n",
      "       [0.69949126],\n",
      "       [0.08609354],\n",
      "       [0.717167  ],\n",
      "       [0.63545656],\n",
      "       [0.84730494],\n",
      "       [0.9399735 ],\n",
      "       [0.02000761],\n",
      "       [0.19443536],\n",
      "       [0.6227381 ],\n",
      "       [0.1674062 ],\n",
      "       [0.18561769],\n",
      "       [0.3620739 ],\n",
      "       [0.59135413],\n",
      "       [0.14929652],\n",
      "       [0.58828115],\n",
      "       [0.206761  ],\n",
      "       [0.7238618 ],\n",
      "       [0.33766603],\n",
      "       [0.9675491 ],\n",
      "       [0.20223475],\n",
      "       [0.6053287 ],\n",
      "       [0.18817854],\n",
      "       [0.3819343 ],\n",
      "       [0.8666526 ],\n",
      "       [0.26895344],\n",
      "       [0.35008287],\n",
      "       [0.87489307],\n",
      "       [0.45822084],\n",
      "       [0.1563487 ],\n",
      "       [0.07554579],\n",
      "       [0.9592583 ],\n",
      "       [0.57290375],\n",
      "       [0.1416539 ],\n",
      "       [0.88446903],\n",
      "       [0.5916935 ],\n",
      "       [0.60492444],\n",
      "       [0.9552556 ],\n",
      "       [0.97722185],\n",
      "       [0.7670033 ],\n",
      "       [0.30179095],\n",
      "       [0.21430564],\n",
      "       [0.31895673],\n",
      "       [0.4854988 ],\n",
      "       [0.35157466],\n",
      "       [0.05788457],\n",
      "       [0.62132466],\n",
      "       [0.49903858],\n",
      "       [0.9068532 ],\n",
      "       [0.07427251],\n",
      "       [0.89927375],\n",
      "       [0.9635577 ],\n",
      "       [0.74984515],\n",
      "       [0.16841686],\n",
      "       [0.7820697 ],\n",
      "       [0.7541524 ],\n",
      "       [0.4654088 ],\n",
      "       [0.852556  ],\n",
      "       [0.4287603 ],\n",
      "       [0.67909145],\n",
      "       [0.04256475],\n",
      "       [0.29072022],\n",
      "       [0.579458  ],\n",
      "       [0.88753295],\n",
      "       [0.01404452],\n",
      "       [0.38961053],\n",
      "       [0.00223899],\n",
      "       [0.88945067],\n",
      "       [0.95758724],\n",
      "       [0.62082803],\n",
      "       [0.26089215],\n",
      "       [0.06598401],\n",
      "       [0.48632765],\n",
      "       [0.28244352],\n",
      "       [0.32698166],\n",
      "       [0.21524179],\n",
      "       [0.05971527],\n",
      "       [0.6670791 ],\n",
      "       [0.04881966],\n",
      "       [0.9373629 ],\n",
      "       [0.5382637 ],\n",
      "       [0.07710385],\n",
      "       [0.579787  ],\n",
      "       [0.97601223],\n",
      "       [0.8707812 ],\n",
      "       [0.6716293 ],\n",
      "       [0.643896  ],\n",
      "       [0.46722388],\n",
      "       [0.01776516],\n",
      "       [0.7448139 ],\n",
      "       [0.59592307],\n",
      "       [0.24199188],\n",
      "       [0.7769736 ],\n",
      "       [0.01470244],\n",
      "       [0.7337028 ],\n",
      "       [0.23252022],\n",
      "       [0.9941757 ],\n",
      "       [0.06419599],\n",
      "       [0.8740878 ],\n",
      "       [0.94349706],\n",
      "       [0.58134115],\n",
      "       [0.87468755],\n",
      "       [0.398435  ],\n",
      "       [0.14927673],\n",
      "       [0.4094745 ],\n",
      "       [0.6197901 ],\n",
      "       [0.2978859 ],\n",
      "       [0.9395461 ],\n",
      "       [0.313264  ],\n",
      "       [0.99614716],\n",
      "       [0.1887157 ],\n",
      "       [0.39047074],\n",
      "       [0.48860538],\n",
      "       [0.17258883],\n",
      "       [0.73838365],\n",
      "       [0.13034296],\n",
      "       [0.09365106],\n",
      "       [0.42439175],\n",
      "       [0.44485664],\n",
      "       [0.94712055],\n",
      "       [0.57406974],\n",
      "       [0.7625097 ],\n",
      "       [0.51314616],\n",
      "       [0.1062007 ],\n",
      "       [0.7519413 ],\n",
      "       [0.4146278 ],\n",
      "       [0.94315577],\n",
      "       [0.7339685 ],\n",
      "       [0.0755899 ],\n",
      "       [0.8732672 ],\n",
      "       [0.46555233],\n",
      "       [0.0308094 ],\n",
      "       [0.11379826],\n",
      "       [0.64446807],\n",
      "       [0.18355227],\n",
      "       [0.05335653],\n",
      "       [0.04029322],\n",
      "       [0.48517   ],\n",
      "       [0.9206178 ],\n",
      "       [0.15713918],\n",
      "       [0.114995  ],\n",
      "       [0.28303754],\n",
      "       [0.7354988 ],\n",
      "       [0.66149807],\n",
      "       [0.40393102],\n",
      "       [0.17780721],\n",
      "       [0.26414943],\n",
      "       [0.83452153],\n",
      "       [0.28308225],\n",
      "       [0.9045721 ],\n",
      "       [0.8871745 ],\n",
      "       [0.01009548],\n",
      "       [0.18190026],\n",
      "       [0.8791394 ],\n",
      "       [0.984879  ],\n",
      "       [0.01412976],\n",
      "       [0.90905094],\n",
      "       [0.14041674],\n",
      "       [0.52836514],\n",
      "       [0.21549964],\n",
      "       [0.81428313],\n",
      "       [0.3385105 ],\n",
      "       [0.89725065],\n",
      "       [0.7597735 ],\n",
      "       [0.26321733],\n",
      "       [0.5364169 ],\n",
      "       [0.08683002],\n",
      "       [0.38155663],\n",
      "       [0.22963941],\n",
      "       [0.11937737],\n",
      "       [0.460685  ],\n",
      "       [0.190063  ],\n",
      "       [0.5519061 ],\n",
      "       [0.7090535 ],\n",
      "       [0.7003579 ],\n",
      "       [0.5546346 ],\n",
      "       [0.36948764],\n",
      "       [0.8373184 ],\n",
      "       [0.22922051],\n",
      "       [0.168504  ],\n",
      "       [0.06413674],\n",
      "       [0.82698214],\n",
      "       [0.62178886],\n",
      "       [0.63709664],\n",
      "       [0.5574868 ],\n",
      "       [0.40088844],\n",
      "       [0.542887  ],\n",
      "       [0.2755469 ],\n",
      "       [0.05303812],\n",
      "       [0.35606873],\n",
      "       [0.24802697],\n",
      "       [0.07136345],\n",
      "       [0.35504687],\n",
      "       [0.47343636],\n",
      "       [0.11587107],\n",
      "       [0.95734525],\n",
      "       [0.5454329 ],\n",
      "       [0.91033363],\n",
      "       [0.94252086],\n",
      "       [0.1468631 ],\n",
      "       [0.8786603 ],\n",
      "       [0.32996833],\n",
      "       [0.4349624 ],\n",
      "       [0.4192958 ],\n",
      "       [0.93909764],\n",
      "       [0.19383657],\n",
      "       [0.39429796],\n",
      "       [0.02100158],\n",
      "       [0.55460715],\n",
      "       [0.69183946],\n",
      "       [0.8581599 ],\n",
      "       [0.86202204],\n",
      "       [0.06739461],\n",
      "       [0.2262075 ],\n",
      "       [0.78147507],\n",
      "       [0.8719233 ],\n",
      "       [0.767087  ],\n",
      "       [0.35736096],\n",
      "       [0.6217575 ],\n",
      "       [0.6873405 ],\n",
      "       [0.08520329],\n",
      "       [0.5600579 ],\n",
      "       [0.6144339 ],\n",
      "       [0.74826074],\n",
      "       [0.8018317 ],\n",
      "       [0.13952303],\n",
      "       [0.2758087 ],\n",
      "       [0.7474823 ],\n",
      "       [0.72314644],\n",
      "       [0.6186731 ],\n",
      "       [0.1935271 ],\n",
      "       [0.665004  ],\n",
      "       [0.92620754],\n",
      "       [0.9890804 ],\n",
      "       [0.19695127],\n",
      "       [0.43886638],\n",
      "       [0.30242372],\n",
      "       [0.6075965 ],\n",
      "       [0.7853955 ],\n",
      "       [0.38864076],\n",
      "       [0.6004237 ],\n",
      "       [0.06715083],\n",
      "       [0.28800547],\n",
      "       [0.24176598],\n",
      "       [0.6048132 ],\n",
      "       [0.9513979 ],\n",
      "       [0.7548708 ],\n",
      "       [0.6420963 ],\n",
      "       [0.31701958],\n",
      "       [0.98634887],\n",
      "       [0.6407496 ],\n",
      "       [0.92162   ],\n",
      "       [0.18718302],\n",
      "       [0.615288  ],\n",
      "       [0.58072054],\n",
      "       [0.68490887],\n",
      "       [0.99607635],\n",
      "       [0.66307485],\n",
      "       [0.5642308 ],\n",
      "       [0.7954736 ],\n",
      "       [0.8710797 ],\n",
      "       [0.9699969 ],\n",
      "       [0.40470278],\n",
      "       [0.79902816],\n",
      "       [0.04890668],\n",
      "       [0.2378366 ],\n",
      "       [0.8845215 ],\n",
      "       [0.2699448 ],\n",
      "       [0.10311127],\n",
      "       [0.33606017],\n",
      "       [0.28759074],\n",
      "       [0.9155768 ],\n",
      "       [0.5895692 ],\n",
      "       [0.4099977 ],\n",
      "       [0.07561779],\n",
      "       [0.00534642],\n",
      "       [0.12450993],\n",
      "       [0.31122875],\n",
      "       [0.58465695],\n",
      "       [0.15152037],\n",
      "       [0.07742059],\n",
      "       [0.26469457],\n",
      "       [0.03947449],\n",
      "       [0.863395  ],\n",
      "       [0.7953291 ],\n",
      "       [0.5427147 ],\n",
      "       [0.1866107 ],\n",
      "       [0.46477127],\n",
      "       [0.17051125],\n",
      "       [0.7545235 ],\n",
      "       [0.6659175 ],\n",
      "       [0.7379172 ],\n",
      "       [0.2132721 ],\n",
      "       [0.8454704 ],\n",
      "       [0.2631495 ],\n",
      "       [0.6847662 ],\n",
      "       [0.32269228],\n",
      "       [0.66943467],\n",
      "       [0.461421  ],\n",
      "       [0.5620276 ],\n",
      "       [0.04804516],\n",
      "       [0.33053553],\n",
      "       [0.7108309 ],\n",
      "       [0.7809036 ],\n",
      "       [0.3746717 ],\n",
      "       [0.22445905],\n",
      "       [0.7038945 ],\n",
      "       [0.8179766 ],\n",
      "       [0.65872884],\n",
      "       [0.5608344 ],\n",
      "       [0.57133055],\n",
      "       [0.77842987],\n",
      "       [0.68846416],\n",
      "       [0.7191659 ],\n",
      "       [0.20921195],\n",
      "       [0.26843655],\n",
      "       [0.72726655],\n",
      "       [0.80825996],\n",
      "       [0.63422775],\n",
      "       [0.02177525],\n",
      "       [0.53936553],\n",
      "       [0.56067276],\n",
      "       [0.81749296],\n",
      "       [0.47377288],\n",
      "       [0.2440213 ],\n",
      "       [0.7352097 ],\n",
      "       [0.38218403],\n",
      "       [0.9682838 ],\n",
      "       [0.1462493 ],\n",
      "       [0.10874963],\n",
      "       [0.73805296],\n",
      "       [0.20761395],\n",
      "       [0.41598225],\n",
      "       [0.8528366 ],\n",
      "       [0.27821124],\n",
      "       [0.24058068],\n",
      "       [0.02018714],\n",
      "       [0.25070524],\n",
      "       [0.4826579 ],\n",
      "       [0.6314211 ],\n",
      "       [0.1459738 ],\n",
      "       [0.06602943],\n",
      "       [0.12450433],\n",
      "       [0.2087686 ],\n",
      "       [0.04611123],\n",
      "       [0.96820164],\n",
      "       [0.8671919 ],\n",
      "       [0.9784305 ],\n",
      "       [0.00275612],\n",
      "       [0.72316945],\n",
      "       [0.40632367],\n",
      "       [0.7010436 ],\n",
      "       [0.53242254],\n",
      "       [0.92179596],\n",
      "       [0.90726244],\n",
      "       [0.2774868 ],\n",
      "       [0.17456901],\n",
      "       [0.63032436],\n",
      "       [0.2852124 ],\n",
      "       [0.288033  ],\n",
      "       [0.18232548],\n",
      "       [0.6961913 ],\n",
      "       [0.9822662 ],\n",
      "       [0.37166512],\n",
      "       [0.6470336 ],\n",
      "       [0.41417158],\n",
      "       [0.26399982],\n",
      "       [0.17984152],\n",
      "       [0.93360794],\n",
      "       [0.01576769],\n",
      "       [0.9286798 ],\n",
      "       [0.598153  ],\n",
      "       [0.31206322],\n",
      "       [0.90264845],\n",
      "       [0.7373657 ],\n",
      "       [0.7948891 ],\n",
      "       [0.70638967],\n",
      "       [0.03826773],\n",
      "       [0.6423472 ],\n",
      "       [0.5099448 ],\n",
      "       [0.7992935 ],\n",
      "       [0.73647606],\n",
      "       [0.40905142],\n",
      "       [0.73112893],\n",
      "       [0.16000855],\n",
      "       [0.85087836],\n",
      "       [0.5422014 ],\n",
      "       [0.21180737],\n",
      "       [0.21995199],\n",
      "       [0.06969464],\n",
      "       [0.6585753 ],\n",
      "       [0.80152965],\n",
      "       [0.670293  ],\n",
      "       [0.43730867],\n",
      "       [0.05242991],\n",
      "       [0.1013099 ],\n",
      "       [0.02129912],\n",
      "       [0.3286494 ],\n",
      "       [0.8863013 ],\n",
      "       [0.5645945 ],\n",
      "       [0.02567744],\n",
      "       [0.17804718],\n",
      "       [0.9660604 ],\n",
      "       [0.20464206],\n",
      "       [0.05851805],\n",
      "       [0.60719347],\n",
      "       [0.91522837],\n",
      "       [0.9377363 ],\n",
      "       [0.9790802 ],\n",
      "       [0.7198591 ],\n",
      "       [0.29273486],\n",
      "       [0.35582376],\n",
      "       [0.95107603],\n",
      "       [0.6035831 ],\n",
      "       [0.40175617],\n",
      "       [0.9143976 ],\n",
      "       [0.353575  ],\n",
      "       [0.6378883 ],\n",
      "       [0.13297594],\n",
      "       [0.06990933],\n",
      "       [0.64816177],\n",
      "       [0.06283677],\n",
      "       [0.31121504],\n",
      "       [0.44781148],\n",
      "       [0.8545196 ],\n",
      "       [0.38181746],\n",
      "       [0.18424225],\n",
      "       [0.74014044],\n",
      "       [0.14418292],\n",
      "       [0.6796726 ],\n",
      "       [0.3882681 ],\n",
      "       [0.14561367],\n",
      "       [0.32915676],\n",
      "       [0.3726225 ],\n",
      "       [0.8070674 ],\n",
      "       [0.48333526],\n",
      "       [0.7020054 ],\n",
      "       [0.15686858],\n",
      "       [0.15834236],\n",
      "       [0.7503046 ],\n",
      "       [0.00927103],\n",
      "       [0.89321053],\n",
      "       [0.18736017],\n",
      "       [0.4671992 ],\n",
      "       [0.38345098],\n",
      "       [0.02677786],\n",
      "       [0.62091255],\n",
      "       [0.79494333],\n",
      "       [0.5488695 ],\n",
      "       [0.08920336],\n",
      "       [0.7955574 ],\n",
      "       [0.6900972 ],\n",
      "       [0.94307244],\n",
      "       [0.07174826],\n",
      "       [0.6797539 ],\n",
      "       [0.6875725 ],\n",
      "       [0.8371388 ],\n",
      "       [0.8908254 ],\n",
      "       [0.08828163],\n",
      "       [0.56902707],\n",
      "       [0.42423368],\n",
      "       [0.22153616],\n",
      "       [0.6363425 ],\n",
      "       [0.19896305],\n",
      "       [0.15679455],\n",
      "       [0.6396164 ],\n",
      "       [0.83350766],\n",
      "       [0.04250371],\n",
      "       [0.6813687 ],\n",
      "       [0.5801661 ],\n",
      "       [0.6063256 ],\n",
      "       [0.37150764],\n",
      "       [0.98314047],\n",
      "       [0.35523796],\n",
      "       [0.6777159 ],\n",
      "       [0.7454057 ],\n",
      "       [0.2723074 ],\n",
      "       [0.98901606],\n",
      "       [0.17606556],\n",
      "       [0.9345089 ],\n",
      "       [0.5940714 ],\n",
      "       [0.6543914 ],\n",
      "       [0.72110665],\n",
      "       [0.04376698],\n",
      "       [0.1440512 ],\n",
      "       [0.3008088 ],\n",
      "       [0.762256  ],\n",
      "       [0.87949836],\n",
      "       [0.04347777],\n",
      "       [0.6225109 ],\n",
      "       [0.3136171 ],\n",
      "       [0.23272514],\n",
      "       [0.8388485 ],\n",
      "       [0.9637519 ],\n",
      "       [0.87550676],\n",
      "       [0.2052052 ],\n",
      "       [0.78073335],\n",
      "       [0.82878447],\n",
      "       [0.59439254],\n",
      "       [0.539878  ],\n",
      "       [0.02096093],\n",
      "       [0.70853865],\n",
      "       [0.06743228],\n",
      "       [0.3162372 ],\n",
      "       [0.73124313],\n",
      "       [0.4988321 ],\n",
      "       [0.26745522],\n",
      "       [0.64496076],\n",
      "       [0.5021522 ],\n",
      "       [0.5802846 ],\n",
      "       [0.6224785 ],\n",
      "       [0.03581297],\n",
      "       [0.84511566],\n",
      "       [0.24625397],\n",
      "       [0.8207617 ],\n",
      "       [0.05231166],\n",
      "       [0.28620625],\n",
      "       [0.64320874],\n",
      "       [0.80765116],\n",
      "       [0.9741218 ],\n",
      "       [0.0733943 ],\n",
      "       [0.23446083],\n",
      "       [0.23649597],\n",
      "       [0.18535173],\n",
      "       [0.25749958],\n",
      "       [0.60335803],\n",
      "       [0.76026666],\n",
      "       [0.62076104],\n",
      "       [0.5238991 ],\n",
      "       [0.62820077],\n",
      "       [0.46485293],\n",
      "       [0.9161252 ],\n",
      "       [0.3761412 ],\n",
      "       [0.4654876 ],\n",
      "       [0.89042926],\n",
      "       [0.9300872 ],\n",
      "       [0.14004326],\n",
      "       [0.1046443 ],\n",
      "       [0.19760013],\n",
      "       [0.9421207 ],\n",
      "       [0.8845204 ],\n",
      "       [0.92176366],\n",
      "       [0.05630624],\n",
      "       [0.21986735],\n",
      "       [0.7277162 ],\n",
      "       [0.1909703 ],\n",
      "       [0.13392341],\n",
      "       [0.91630614],\n",
      "       [0.74444854],\n",
      "       [0.65159535],\n",
      "       [0.7755512 ],\n",
      "       [0.3206823 ],\n",
      "       [0.55100286],\n",
      "       [0.01344573],\n",
      "       [0.25937796],\n",
      "       [0.8346671 ],\n",
      "       [0.733194  ],\n",
      "       [0.74802196],\n",
      "       [0.77529824],\n",
      "       [0.11506057],\n",
      "       [0.0843308 ],\n",
      "       [0.59102607],\n",
      "       [0.06377637],\n",
      "       [0.5964768 ],\n",
      "       [0.23155355],\n",
      "       [0.96251047],\n",
      "       [0.7522248 ],\n",
      "       [0.5849234 ],\n",
      "       [0.2712016 ],\n",
      "       [0.99700534],\n",
      "       [0.8719671 ],\n",
      "       [0.70161366],\n",
      "       [0.6083362 ],\n",
      "       [0.8096173 ],\n",
      "       [0.05185223],\n",
      "       [0.9414456 ],\n",
      "       [0.7096832 ],\n",
      "       [0.9433174 ],\n",
      "       [0.5079491 ],\n",
      "       [0.88440275],\n",
      "       [0.22924662],\n",
      "       [0.48180664],\n",
      "       [0.7103009 ],\n",
      "       [0.20594275],\n",
      "       [0.45715368],\n",
      "       [0.97268915],\n",
      "       [0.5034269 ],\n",
      "       [0.4196334 ],\n",
      "       [0.01895714],\n",
      "       [0.9714097 ],\n",
      "       [0.56684947],\n",
      "       [0.9035561 ],\n",
      "       [0.72563326],\n",
      "       [0.5427853 ],\n",
      "       [0.5072684 ],\n",
      "       [0.65152526],\n",
      "       [0.5927522 ],\n",
      "       [0.73744917],\n",
      "       [0.2680974 ],\n",
      "       [0.04176509],\n",
      "       [0.23840702],\n",
      "       [0.3397988 ],\n",
      "       [0.5378355 ],\n",
      "       [0.51594734],\n",
      "       [0.12749588],\n",
      "       [0.43044317],\n",
      "       [0.6097692 ],\n",
      "       [0.45660293],\n",
      "       [0.17310631],\n",
      "       [0.3780347 ],\n",
      "       [0.6183337 ],\n",
      "       [0.76388   ],\n",
      "       [0.118577  ],\n",
      "       [0.15409994],\n",
      "       [0.7921879 ],\n",
      "       [0.9572755 ],\n",
      "       [0.43647885],\n",
      "       [0.7244142 ],\n",
      "       [0.24733782],\n",
      "       [0.11069191],\n",
      "       [0.7105006 ],\n",
      "       [0.48974335],\n",
      "       [0.19479406],\n",
      "       [0.5507457 ],\n",
      "       [0.6309477 ],\n",
      "       [0.44720256],\n",
      "       [0.559955  ],\n",
      "       [0.45011342],\n",
      "       [0.19236696],\n",
      "       [0.01507246],\n",
      "       [0.19851136],\n",
      "       [0.22597742],\n",
      "       [0.88940966],\n",
      "       [0.6559721 ],\n",
      "       [0.9541091 ],\n",
      "       [0.9591582 ],\n",
      "       [0.2718042 ],\n",
      "       [0.32915473],\n",
      "       [0.15159059],\n",
      "       [0.50465095],\n",
      "       [0.72431326],\n",
      "       [0.2346437 ],\n",
      "       [0.26201248],\n",
      "       [0.7999532 ],\n",
      "       [0.9817165 ],\n",
      "       [0.30570996],\n",
      "       [0.95364034],\n",
      "       [0.39958668],\n",
      "       [0.6063937 ],\n",
      "       [0.32276404],\n",
      "       [0.1383847 ],\n",
      "       [0.8890526 ],\n",
      "       [0.79736197],\n",
      "       [0.68806636],\n",
      "       [0.054299  ],\n",
      "       [0.21911538],\n",
      "       [0.8804339 ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# View what we just created\n",
    "# model.compile(loss=rank_loss_rr, optimizer=optimizer)\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "model.summary()\n",
    "\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, len(model.layers)):\n",
    "#     print(model.layers[i].name)\n",
    "# tf.print(model.layers[5].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.4257 - val_loss: 0.4299\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.4247 - val_loss: 0.4292\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.4236 - val_loss: 0.4284\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.4223 - val_loss: 0.4276\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.4212 - val_loss: 0.4268\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.4200 - val_loss: 0.4260\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.4187 - val_loss: 0.4251\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.4177 - val_loss: 0.4242\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.4163 - val_loss: 0.4232\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.4150 - val_loss: 0.4222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25508dfc430>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "checkpoint_filepath = './tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_filepath,\n",
    "            save_weights_only=True,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    return 0.001\n",
    "\n",
    "inputs_train = [x_train]\n",
    "train_labels = y_train\n",
    "\n",
    "inputs_val = [x_val]\n",
    "val_labels = y_val\n",
    "\n",
    "# If we're using the GCN\n",
    "inputs_train.append(adj_matrix)\n",
    "inputs_val.append(adj_matrix)\n",
    "\n",
    "# int(inputs_train.shape[0])\n",
    "\n",
    "history = model.fit(inputs_train, train_labels, batch_size=int(inputs_train[0].shape[0]),\n",
    "                              epochs=10, validation_data=(inputs_val, val_labels),\n",
    "                   callbacks=[model_checkpoint_callback,\n",
    "                             tf.keras.callbacks.LearningRateScheduler(scheduler,\n",
    "                                                                      verbose=0)])\n",
    "\n",
    "model.load_weights(checkpoint_filepath)\n",
    "\n",
    "for h in history.history['val_loss']:\n",
    "    losses.append(h)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict([x_train, DMJ.Normalized_Adjacency_Matrix], batch_size=880)\n",
    "model_save = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for h in history.history['val_loss']:\n",
    "#     losses.append(h)\n",
    "# plt.plot(losses)\n",
    "\n",
    "DMJ.Normalized_Adjacency_Matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMJ.model = model\n",
    "DMJ.model_name = \"3-15-21-1_LSTM_[25,25,20]_100Epoch_881BatchSize_TFMSE_881Dense-X-SquishAdj_TrainableFinalDense\"\n",
    "DMJ.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_name = \"2-16-21-Seq1LSTM-F-64HU-[800,239,200]split-full_y\"\n",
    "# new_directory = './ignorable_data/prediction_results/[55, 25, 20]_splits/'\n",
    "# GP.generate_validation_prediction_json_SplitBatch_nofeat(model_name, new_directory, x_g, x_val, sliding_window=30)\n",
    "# GP.generate_validation_prediction_json_SplitBatch_close_gap(model_name, new_directory, x_g, x_val, sliding_window=30)\n",
    "model_name = '3-15-21-1_LSTM_[25,25,20]_100Epoch_881BatchSize_TFMSE_881Dense-X-SquishAdj_TrainableFinalDense'\n",
    "model_dir = './ignorable_data/models/[55, 25, 20]_split'\n",
    "# model_dir = 'G:\\Shared drives\\Max Huffman - ECEN 403 404 URS Research 2020 2021\\Datasets\\models'\n",
    "past = x_train\n",
    "future = x_val\n",
    "# new_dir = 'G:\\Shared drives\\Max Huffman - ECEN 403 404 URS Research 2020 2021\\Datasets\\predictions\\pc_version'\n",
    "new_dir = './ignorable_data/prediction_results/[55, 25, 20]_splits/'\n",
    "sliding_window = x_val.shape[1]\n",
    "\n",
    "window = x_train.shape[1]\n",
    "\n",
    "GP.generate_predictions(model_name, model_dir, past, future, new_dir, window, model_type='gcn', batch_size=881)\n",
    "# GP.generate_predictions(model_name, model_dir, past, future, new_dir, window, model_type='lstm', batch_size=880)\n",
    "# GCN_output = GP.return_embeddings(model_name, model_dir, past, future, new_dir, w, model_type='gcn')\n",
    "# embeddings = GP.return_embeddings(model_name, model_dir, past, future, new_dir, window, model_type='gcn')\n",
    "\n",
    "#     model_name = '2-20-21-1_LSTM_[25,25,20]_NoDropout_35Epoch_80BatchSize_IncreasedVariedLR_RRMSE'\n",
    "#     GP.generate_predictions(model_name, model_dir, past, future, new_dir, w)\n",
    "# GP.generate_validation_prediction_json_SplitBatch(model_name, new_dir, x_g, x_val, sliding_window=sliding_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the training set, these are the validation values that are output from the LSTM model\n",
    "print(embeddings.shape)\n",
    "\n",
    "# This is the NAM that we are using to aggregate the embedding results\n",
    "print(DMJ.Normalized_Adjacency_Matrix[6,6])\n",
    "\n",
    "# This should be the aggregated values output from using the NAM (The dimensions look fine)\n",
    "# new_embeddings = tf.einsum('ntd,nm->mtd', embeddings, DMJ.Normalized_Adjacency_Matrix)\n",
    "new_embeddings = tf.einsum('mn,ntd->mtd', DMJ.Normalized_Adjacency_Matrix, embeddings)\n",
    "print(new_embeddings.shape)\n",
    "\n",
    "print(embeddings[0, -7, 0:10])\n",
    "# print(embeddings[0, -1, 0:10])\n",
    "print('  ')\n",
    "print(new_embeddings[0, -7, 0:10])\n",
    "# print(new_embeddings[0, -1, 0:10])\n",
    "\n",
    "# print(tf.subtract(embeddings[0, -2, 0:10], embeddings[0, -1, 0:10]))\n",
    "# print(tf.subtract(new_embeddings[0, -2, 0:10], new_embeddings[0, -1, 0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above are the output embeddings of the LSTM layer\n",
    "# Below is 1 output prediction for a simple NAM Aggregate added to a pre-trained LSTM\n",
    "GCN_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_file_name = '3-15-21-1_LSTM_[25,25,20]_100Epoch_881BatchSize_TFMSE_881Dense-X-SquishAdj_TrainableFinalDense309win_309past_309fut'\n",
    "p_file_dir = '.\\ignorable_data\\prediction_results\\[55, 25, 20]_splits'\n",
    "# p_file_dir = 'G:\\Shared drives\\Max Huffman - ECEN 403 404 URS Research 2020 2021\\Datasets\\predictions\\pc_version'\n",
    "future = x_val\n",
    "new_dir = './ignorable_data/datablocks/[55, 25, 20]_splits/'\n",
    "close_gap = False\n",
    "\n",
    "use_argmin = False\n",
    "yesterday_pred = False\n",
    "GP.generate_prediction_results(p_file_name, p_file_dir, future, new_dir, close_gap=close_gap, use_argmin=use_argmin, yesterday_pred=yesterday_pred, rr_labels=True)\n",
    "\n",
    "for root, dirs, files in os.walk(r'C:\\Users\\Maxwell\\PycharmProjects\\TAMU-ECEN-403-IFPTSND\\ECEN_403_IFM\\TAMU-ECEN-403-IFPTSND\\ignorable_data\\datablocks\\[55, 25, 20]_splits'):\n",
    "    for filename in files:\n",
    "#         GP.generate_prediction_results(filename, p_file_dir, future, new_dir, close_gap=close_gap, use_argmin=use_argmin, yesterday_pred=yesterday_pred)\n",
    "        GP.add_daily_value_to_datablock(filename, './ignorable_data/datablocks/[55, 25, 20]_splits')\n",
    "        GP.add_daily_value_to_datablock_discontinuous(filename, './ignorable_data/datablocks/[55, 25, 20]_splits')\n",
    "        GP.add_cumulative_return_ratio_discontinuous(filename, './ignorable_data/datablocks/[55, 25, 20]_splits')\n",
    "        None\n",
    "\n",
    "\n",
    "# use_argmin = True\n",
    "# yesterday_pred = False\n",
    "# GP.generate_prediction_results(p_file_name, p_file_dir, future, new_dir, close_gap=close_gap, use_argmin=use_argmin, yesterday_pred=yesterday_pred)\n",
    "# # GP.generate_model_diagnostics_given_sets(p_file_dir + f'/{p_file_name}', future, datablock_folder=new_dir, try_all_pred=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 597\n",
    "# n = 488\n",
    "# n = 161\n",
    "# n = 561\n",
    "# n = 440\n",
    "n = 200\n",
    "# # Argmin\n",
    "# n = 780\n",
    "\n",
    "# n = 876\n",
    "# n = 110\n",
    "r = 1\n",
    "# n = 100\n",
    "# n=0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "# ax.set_ylim([0,1])\n",
    "\n",
    "time = tf.concat([x_train, x_val, x_test], axis=1)\n",
    "\n",
    "# ax = fig.add_subplot()\n",
    "for i in range(r):\n",
    "#     print(f'{i+n*r} ', end='')\n",
    "#     ax.plot(time[i+n*r, :, 0])\n",
    "    ax.plot(x_val[i+n*r, :, 0], label='Closing Price')\n",
    "#     ax.plot(rr_val[i+n*r, :], label='Return Ratio')\n",
    "    \n",
    "    ax.plot(A[:, i+n*r], label='LSTM-1000 ALPHA')\n",
    "    ax.plot(B[:, i+n*r], label='LSTM-1000 ALPHA + 1 Dense')\n",
    "    ax.plot(C[:, i+n*r], label='LSTM-1000 ALPHA + 1NAM')\n",
    "    ax.plot(D[:, i+n*r], label='LSTM-1000 ALPHA + 1NAM + 1 Dense')\n",
    "    ax.plot(E[:, i+n*r], label='LSTM-1000 ALPHA + 881Dense-X-Adj')\n",
    "    ax.plot(F[:, i+n*r], label='LSTM-1000 ALPHA + 881Dense-X-Adj + Trainable Final Layer')\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Validation Days (Time)')\n",
    "    ax.set_ylabel('Closing Price')\n",
    "    ax.set_title(f'Company {i+n*r}')\n",
    "# Orange\n",
    "# Green\n",
    "# Red\n",
    "# Purple\n",
    "# Brown\n",
    "\n",
    "print(DMJ.entities[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_dir = '.\\ignorable_data\\prediction_results\\[55, 25, 20]_splits/'\n",
    "pred_file = '2-20-21-1_LSTM_[25,25,20]Reloaded_1000ALPHA309win_309past_309fut'\n",
    "GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "A = GP.test_obj\n",
    "\n",
    "pred_dir = '.\\ignorable_data\\prediction_results\\[55, 25, 20]_splits/'\n",
    "pred_file = '3-12-21-1_LSTM_[25,25,20]_10Epoch_880BatchSize_TFMSE_Additional_64_Dense_Layer309win_309past_309fut'\n",
    "GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "B = GP.test_obj\n",
    "\n",
    "pred_file = '2-20-21-1_LSTM_[25,25,20]_NoDropout_100Epoch_80BatchSize_1000ALPHA_1NAMAGGREGATE309win_309past_309fut'\n",
    "GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "C = GP.test_obj\n",
    "\n",
    "pred_file = '2-20-21-1_LSTM_[25,25,20]_NoDropout_100Epoch_80BatchSize_1000ALPHA_1DenseGCN_TFMSE_FullTrain309win_309past_309fut'\n",
    "GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "D = GP.test_obj\n",
    "\n",
    "pred_file = '3-15-21-1_LSTM_[25,25,20]_650Epoch_881BatchSize_TFMSE_881Dense-X-SquishAdj309win_309past_309fut'\n",
    "GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "E = GP.test_obj\n",
    "\n",
    "pred_file = '3-15-21-1_LSTM_[25,25,20]_100Epoch_881BatchSize_TFMSE_881Dense-X-SquishAdj_TrainableFinalDense309win_309past_309fut'\n",
    "GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "F = GP.test_obj\n",
    "\n",
    "# pred_file = '02-17-2021--07--20-1LSTM-F-0ALPHA-[55,25,20]split-[None, 1]-40Epochs-rlf-Loss-64-HU-30win_681past_309fut'\n",
    "# GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "# G = GP.test_obj\n",
    "\n",
    "# pred_file = '02-17-2021--07--20-1LSTM-F-0ALPHA-[55,25,20]split-[None, 1]-40Epochs-rlf-Loss-64-HU-60win_681past_309fut'\n",
    "# GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "# H = GP.test_obj\n",
    "\n",
    "# pred_file = '02-17-2021--07--20-1LSTM-F-0ALPHA-[55,25,20]split-[None, 1]-40Epochs-rlf-Loss-64-HU-125win_681past_309fut'\n",
    "# GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "# I = GP.test_obj\n",
    "\n",
    "# pred_file = '02-17-2021--07--20-1LSTM-F-0ALPHA-[55,25,20]split-[None, 1]-40Epochs-rlf-Loss-64-HU-250win_681past_309fut'\n",
    "# GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "# J = GP.test_obj\n",
    "\n",
    "# pred_file = '02-17-2021--07--20-1LSTM-F-0ALPHA-[55,25,20]split-[None, 1]-40Epochs-rlf-Loss-64-HU-500win_681past_309fut'\n",
    "# GP.graph_model_prediction_given_sets(pred_dir + pred_file, x_val)\n",
    "# K = GP.test_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP.compare_data_blocks('.\\ignorable_data\\datablocks\\[55, 25, 20]_splits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # pred_dir = r\"G:\\Shared drives\\Max Huffman - ECEN 403 404 URS Research 2020 2021\\Datasets\\predictions/\"\n",
    "# pred_dir = r\".\\ignorable_data\\prediction_results\\[55, 25, 20]_splits/\"\n",
    "# pred_file = '3-11-21-1_LSTM_[25,25,20]_60Epoch_40BatchSize_100ALPHA_RR_Labels309win_309past_309fut_220predBatch'\n",
    "# GP.generate_model_diagnostics(pred_dir + pred_file, datablock_folder='./ignorable_data/datablocks/', rr_labels=True)\n",
    "# # GP.generate_model_diagnostics_given_sets_close_gap(pred_dir + pred_file, x_val, datablock_folder='./ignorable_data/datablocks/', try_all_pred=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Let's look at our relations_file real quick\n",
    "with open('./ignorable_data/data_sets/NASDAQ_Cleaned - Contains ZUMZ/updated_relations.json') as read_file:\n",
    "    relations_dict = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The degree vector of Adj\n",
    "degree = np.sum(Adj, axis=0)\n",
    "\n",
    "# Inverse degree vector\n",
    "inv = lambda x: x**-1\n",
    "inv_degree = inv(degree)\n",
    "\n",
    "# Convert into an inverse diagonal matrix\n",
    "diag_inv_degree = np.diag(inv_degree)\n",
    "\n",
    "# Create the negative square root version\n",
    "inv_sqrt_degree = np.sqrt(inv_degree)\n",
    "\n",
    "diag_inv_sqrt_degree = np.diag(inv_sqrt_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symetric normalization yields the correct output\n",
    "print(np.sum(np.dot(np.dot(inv_sqrt_degree, Adj), inv_sqrt_degree)))\n",
    "print(np.sum(np.matmul(np.matmul(inv_sqrt_degree, Adj), inv_sqrt_degree)))\n",
    "\n",
    "# Symetric normalization yields the correct output\n",
    "print(np.dot(np.dot(inv_sqrt_degree, Adj), inv_sqrt_degree))\n",
    "print(np.matmul(np.matmul(inv_sqrt_degree, Adj), inv_sqrt_degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last company, ZUMF was truncated in this example, so this value makes sense.\n",
    "print(np.sum(DMJ.Normalized_Adjacency_Matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard normalization yields the correct output\n",
    "print(np.sum(np.matmul(diag_inv_degree, Adj)))\n",
    "\n",
    "# Standard normalization yields the correct output\n",
    "print(np.matmul(diag_inv_degree, Adj))\n",
    "print(np.dot(diag_inv_degree, Adj))\n",
    "print(np.dot(Adj, diag_inv_degree))\n",
    "\n",
    "print(np.dot(Adj, diag_inv_degree)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_adj_matrix(adj):\n",
    "    degree = tf.reduce_sum(adj, axis=0)\n",
    "    inv_degree = tf.math.reciprocal(degree)\n",
    "    diag_inv_degree = tf.linalg.diag(inv_degree)\n",
    "    r = diag_inv_degree * adj\n",
    "    return r\n",
    "\n",
    "adf_tf = tf.constant(Adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adf_tf)\n",
    "print(tf.reduce_sum(normalize_adj_matrix(adf_tf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.einsum(\"ij, k->ik\", Adj, Adj[:,3])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.einsum(\"ij, k->ij\", Adj, Adj[:,3])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Adj[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_encoding = np.load(r'C:\\Users\\Maxwell\\Documents\\Backups\\TAMU-ECEN-403-IFPTSND\\Temporal_Relational_Stock_Ranking-master\\data\\RELATIONS\\sector_industry\\NASDAQ_industry_relation.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1026, 1026, 97)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1026, 1026, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tf.keras.layers.Dense(1)(rel_encoding)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1026, 1026])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:, :, -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
