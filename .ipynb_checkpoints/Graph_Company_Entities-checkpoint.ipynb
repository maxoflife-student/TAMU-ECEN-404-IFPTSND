{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from bqplot import (\n",
    "    OrdinalScale, LinearScale, Bars, Lines, Axis, Figure, PanZoom, Toolbar\n",
    ")\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "\n",
    "# Given an item and a list, if that item is in the list, returns the appropriate index\n",
    "def return_idx(item, l):\n",
    "    i = 0\n",
    "    for thing in l:\n",
    "        if item == thing:\n",
    "            return i\n",
    "        else:\n",
    "            i += 1\n",
    "    # If it's not in the list, then it's failed\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_Strategies():\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.path_strat = path + '\\strategy_results'\n",
    "\n",
    "        # If there isn't a strategy_results folder yet, make one\n",
    "        try:\n",
    "            os.mkdir(self.path_strat)\n",
    "        except:\n",
    "            None\n",
    "        \n",
    "        # Load the names of each strategy\n",
    "        p_files = self.generate_p_files()\n",
    "        # Load the values of each strategy \n",
    "        values = self.values_from_p(p_files)\n",
    "        # Combine them into a dictionary\n",
    "        self.strat_dict = {p_files[i]:values[i] for i in range(len(values))}\n",
    "        \n",
    "        # Used when you want to graph everything\n",
    "        self.all_black = False\n",
    "        \n",
    "    def generate_p_files(self):\n",
    "        files  = [f for f in listdir(self.path_strat) if isfile(join(self.path_strat, f))]\n",
    "        files  = [f for f in files if f.endswith('.p')]\n",
    "        files.sort()\n",
    "        return(files)\n",
    "    \n",
    "    '''Takes in a list of files, returns a list of list of values'''\n",
    "    def values_from_p(self, file):\n",
    "        file_l= []\n",
    "        for f in file:\n",
    "            with open(self.path_strat + '\\\\' + f, 'rb') as read:\n",
    "                file_l.append(pickle.load(read))\n",
    "        return file_l\n",
    "    \n",
    "    def strat_graph(self, strat_sel):\n",
    "        # Create a class variable for the selected feature\n",
    "        self.strat_sel = strat_sel\n",
    "        \n",
    "        colors_list = ['f30000', 'f38c00', 'edf300', '7af300', '00f3ce', '0076f3', '9700f3', 'f300c3', '990000', 'd08800', '05aa00', '00a0aa', '7600aa']\n",
    "        colors_list = [f'#{i}' for i in colors_list]\n",
    "        \n",
    "        if self.all_black:\n",
    "            colors_list = []\n",
    "            colors_list.append('#f30000')\n",
    "            for i in range(100):\n",
    "                colors_list.append('#000000')\n",
    "        \n",
    "        self.max_l = 0\n",
    "        for key in strat_sel:\n",
    "            value = len(self.strat_dict[key])\n",
    "            if value > self.max_l:\n",
    "                self.max_l = value\n",
    "        \n",
    "        x_data = list(range(self.max_l))\n",
    "        y_data = [self.strat_dict[key] for key in strat_sel]\n",
    "        \n",
    "            \n",
    "        x_scale = LinearScale()\n",
    "        y_scale = LinearScale()\n",
    "\n",
    "        ax_x = Axis(scale=x_scale, label='Trading Days', grid_lines='solid')\n",
    "        ax_y = Axis(scale=y_scale, label='Portfolio Total (USD)', orientation='vertical', label_offset='50px', )\n",
    "\n",
    "        line = [Lines(labels=[strat_sel[i]], x=x_data, y=y_data[i], scales={'x': x_scale, 'y': y_scale}, colors=[colors_list[i]], display_legend=True) for i in range(len(strat_sel))]\n",
    "\n",
    "        panzoom = PanZoom(scales={'x': [x_scale], 'y': [y_scale]})\n",
    "\n",
    "        fig = Figure(marks=line, axes=[ax_x, ax_y], title='Comparing Trading Strategies Over the Same Test Set', colors=['red'], legend_location='top-left', legend_text={'font-size':12})\n",
    "        fig.layout.height = '950px'\n",
    "\n",
    "        toolbar = Toolbar(figure = fig)\n",
    "\n",
    "        display(fig, toolbar)\n",
    "        \n",
    "    def display_graph(self):\n",
    "        \n",
    "        strat_sel = widgets.SelectMultiple(\n",
    "            options=self.strat_dict.keys(),\n",
    "            rows=10,\n",
    "            description='Strategies',\n",
    "            disabled=False,\n",
    "            layout=Layout(width='40%')\n",
    "        )\n",
    "\n",
    "        widgets.interact(self.strat_graph, strat_sel = strat_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fbf29ff6ce4150a0fe943ecd74ae04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='Strategies', layout=Layout(width='40%'), options=('0_Averageâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GS = Graph_Strategies(path=r'G:\\Shared drives\\Max Huffman - ECEN 403 404 URS Research 2020 2021\\Datasets')\n",
    "GS.display_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Given a folder with entities, graphs all the files'''\n",
    "class Graph_Time_Series_Data():\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        # The directory where all the entities time_series CSV are stored\n",
    "        self.path = path\n",
    "        self.entities, self.entities_idx = self.generate_list_of_entities()\n",
    "        self.relations = self.generate_relations()\n",
    "        self.Normalized_Adjacency_Matrix = self.generate_normalized_ajacency_matrix()\n",
    "    \n",
    "    '''Returns the list of entities and declares the relationship file if its in the directory'''\n",
    "    def generate_list_of_entities(self):\n",
    "        files  = [f for f in listdir(self.path) if isfile(join(self.path, f))]\n",
    "        ents = [i.replace('.csv','') for i in files if i.endswith('.csv')]\n",
    "        ents.sort()\n",
    "        ents_idx = {item:idx for idx, item in enumerate(ents)}\n",
    "    \n",
    "        return ents, ents_idx\n",
    "    \n",
    "    def generate_relations(self):\n",
    "        files  = [f for f in listdir(self.path) if isfile(join(self.path, f))]\n",
    "        relation_file = [i for i in files if i.endswith('.json')]\n",
    "        \n",
    "        if len(relation_file) == 1:\n",
    "            # Load the relationship dictionary\n",
    "            with open(self.path + '\\\\' + relation_file[0]) as read_file:\n",
    "                relations_dict = json.load(read_file)\n",
    "            \n",
    "            self.relations_dict = relations_dict\n",
    "            \n",
    "        elif len(relation_file) == 0:\n",
    "            print('Directory does not contain an entity relationship .json file')\n",
    "            \n",
    "        else:\n",
    "            sys.exit('There are multiple .json files in the directory, remove all or leave 1')\n",
    "    \n",
    "    '''Given a list of entities, return a list of their values averaged over the time-period'''\n",
    "    '''Will be useful in detecting when a Neighboring Group moves NOT in accordance with the average'''\n",
    "    def generate_average_entity(self, entities):\n",
    "        None\n",
    "            \n",
    "    \n",
    "    '''Generates the normalized adjacency matrix from the relations file'''\n",
    "    def generate_normalized_ajacency_matrix(self):  \n",
    "        companies = self.entities\n",
    "        new_industry_relations = self.relations_dict\n",
    "\n",
    "        # Iterate through each company ticker and replace it with a tuple that contains its index and ticker\n",
    "        for key, value in new_industry_relations.items():\n",
    "            new_value = []\n",
    "            for v in value:\n",
    "                new_value.append((return_idx(v, companies), v))\n",
    "            new_industry_relations[key] = new_value\n",
    "\n",
    "        # Iterate through each industry relationship and create an N x N adjacency matrix\n",
    "        # Combine them all to create the final adjacency matrix in the same format as Paper #2\n",
    "        RR_t = []\n",
    "        for sector in new_industry_relations.keys():\n",
    "            # Create an empty relationship matrix\n",
    "            all_zeroes = tf.zeros([len(companies), len(companies)])\n",
    "            relation_slice = all_zeroes.numpy()\n",
    "\n",
    "            # Gather all the companies that exist in this sector\n",
    "            siblings = new_industry_relations[sector]\n",
    "            for i in siblings:\n",
    "                for j in siblings:\n",
    "                    relation_slice[i[0], j[0]] = 1\n",
    "                    relation_slice[j[0], i[0]] = 1\n",
    "            RR_t.append(relation_slice)\n",
    "            \n",
    "        RR_tf = tf.constant(RR_t)\n",
    "        RR_tf = tf.transpose(RR_tf)\n",
    "        relation_encoding = RR_tf.numpy()\n",
    "        rel_shape = [relation_encoding.shape[0], relation_encoding.shape[1]]\n",
    "        mask_flags = np.equal(np.zeros(rel_shape, dtype=int), np.sum(relation_encoding, axis=2))\n",
    "\n",
    "        ajacent = np.where(mask_flags, np.zeros(rel_shape, dtype=float), np.ones(rel_shape, dtype=float))\n",
    "\n",
    "        degree = np.sum(ajacent, axis=0)\n",
    "        for i in range(len(degree)):\n",
    "            degree[i] = 1.0 / degree[i]\n",
    "        np.sqrt(degree, degree)\n",
    "        deg_neg_half_power = np.diag(degree)\n",
    "\n",
    "        GCN_mat = np.dot(np.dot(deg_neg_half_power, ajacent), deg_neg_half_power)\n",
    "        \n",
    "        GCN_mat = np.nan_to_num(GCN_mat)\n",
    "        GCN_mat = tf.constant(GCN_mat) \n",
    "        \n",
    "        return GCN_mat\n",
    "    \n",
    "    '''Returns a list of neighboring entities given an entity, includes the given entity'''\n",
    "    def return_neighbors(self, ent):\n",
    "        # List containing the idx of all entities that are neighbors to the given entity\n",
    "        neighbors = [self.entities[idx] for idx, item in enumerate(self.Normalized_Adjacency_Matrix[self.entities_idx[ent]]) if item > 0]\n",
    "        return neighbors\n",
    "    \n",
    "    \n",
    "    def clean_csv_files(self):\n",
    "        \n",
    "        data_folder = Path(self.path)\n",
    "        list_of_data_csv_files = [f for f in listdir(data_folder) if isfile(join(data_folder, f))]\n",
    "\n",
    "        clean_names = [i[7:].replace('_1','') for i in list_of_data_csv_files]\n",
    "\n",
    "        # Number of companies\n",
    "        N = len(list_of_data_csv_files)\n",
    "\n",
    "        # In this example we're cleaning up the csv files that are being read.\n",
    "        # We don't need the first column or the last row of the provided data set\n",
    "        df = pd.read_csv(data_folder / list_of_data_csv_files[0], header=None, usecols=[1, 2, 3, 4, 5])\n",
    "        df.columns = ['Close', '5D MA', '10D MA', '20D MA', '30D MA']\n",
    "\n",
    "        # Removethe bottom 5 rows and top 1 row to avoid -1234 empty spaces\n",
    "        df = df[1:-5]\n",
    "\n",
    "        # Number of sequences\n",
    "        S = (len(df.index))\n",
    "\n",
    "        # Number of features (columns)\n",
    "        D = len(df.columns)\n",
    "\n",
    "        for stock in range(0, N):\n",
    "            # Read its CSV values, skipping the index column and the last row which has -1234 as a value\n",
    "            df = pd.read_csv(data_folder / list_of_data_csv_files[stock], header=None, usecols=[1, 2, 3, 4, 5], engine='python')\n",
    "            df.columns = ['Close', '5D MA', '10D MA', '20D MA', '30D MA']\n",
    "\n",
    "            # Removethe bottom 5 rows and top 1 row to avoid -1234 empty spaces\n",
    "            df = df[1:-5]\n",
    "            \n",
    "            df.to_csv(data_folder / clean_names[stock], index=False)\n",
    "            \n",
    "        \n",
    "    def entity_graph(self, sel_feature, x_range, n_range, show_rel):\n",
    "        # Create a class variable for the selected feature\n",
    "        self.sel_feature = sel_feature\n",
    "        self.x_range = x_range\n",
    "        self.show_rel = show_rel\n",
    "        self.n_range = n_range\n",
    "        \n",
    "        # Create some colors for the graphed lines to cycle through\n",
    "        colors_list = [hex(0x8A0808 - i *0xB0D0) for i in range(50)]\n",
    "        colors_list = [str(i) for i in colors_list]\n",
    "        colors_list = ['#' + i[2:] for i in colors_list]\n",
    "        shuffle(colors_list)\n",
    "        colors_list.insert(0, '#f30000')\n",
    "        \n",
    "        # There will always be one entity selected, so it sets the X-axis\n",
    "        ent_df = pd.read_csv(self.path + '\\\\' + self.sel_ent + \".csv\")\n",
    "        x_data = list(range(len(ent_df[ent_df.columns[self.feature_key[self.sel_feature]]].values)))[x_range[0]:x_range[1]]\n",
    "        \n",
    "        if not self.show_rel:\n",
    "            y_data = ent_df[ent_df.columns[self.feature_key[self.sel_feature]]].values\n",
    "        else:\n",
    "            # Key names for the legned\n",
    "            keys = self.return_neighbors(self.sel_ent)\n",
    "            # List of DataFrames containing all the entities related to each other\n",
    "            list_of_dfs = [pd.read_csv(self.path + '\\\\' + entity + \".csv\") for entity in keys]\n",
    "            # List of values from those DataFrames\n",
    "            values = [df[df.columns[self.feature_key[self.sel_feature]]].values for df in list_of_dfs]\n",
    "            \n",
    "        x_scale = LinearScale()\n",
    "        y_scale = LinearScale()\n",
    "\n",
    "        ax_x = Axis(scale=x_scale, label='Time Steps', grid_lines='solid')\n",
    "        ax_y = Axis(scale=y_scale, label='Value', orientation='vertical', label_offset='50px', )\n",
    "\n",
    "        if not self.show_rel:\n",
    "            line = [Lines(labels=[self.sel_ent], x=x_data, y=y_data, scales={'x': x_scale, 'y': y_scale}, display_legend=True)]\n",
    "        else:\n",
    "            n_range_of_entities = list(range(len(values)))[n_range[0]:n_range[1]]\n",
    "            n_range_of_entities.insert(0,0)\n",
    "            line = [Lines(labels=[keys[i]], x=x_data, y=values[i], scales={'x': x_scale, 'y': y_scale}, colors=[colors_list[i]], display_legend=True) for i in n_range_of_entities]\n",
    "\n",
    "        panzoom = PanZoom(scales={'x': [x_scale], 'y': [y_scale]})\n",
    "        \n",
    "\n",
    "        fig = Figure(marks=line, axes=[ax_x, ax_y], title='Value of Entity(s) Over Time', colors=['red'], legend_location='top-left')\n",
    "        fig.layout.height = '850px'\n",
    "\n",
    "        toolbar = Toolbar(figure = fig)\n",
    "\n",
    "        display(fig, toolbar)\n",
    "        \n",
    "    def display_graph(self):\n",
    "        \n",
    "        \n",
    "        # Create a dropdown menu to select which entity you would like to view\n",
    "        ent_drop = widgets.Dropdown(\n",
    "            options = self.entities,\n",
    "            description = 'Entities: ',\n",
    "            layout=Layout(justify_content='flex-start')\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        def sel_feature(sel_ent):\n",
    "            # Declare as a class variables\n",
    "            self.sel_ent = sel_ent\n",
    "            \n",
    "            # Load in the data for the selected entity\n",
    "            ent_df = pd.read_csv(self.path + '\\\\' + self.sel_ent + \".csv\")\n",
    "            # Create a dropdown menu to select which feature you would like to view\n",
    "            ent_features = [f'{i}' for i in ent_df.columns]\n",
    "            \n",
    "            self.feature_key = {name:i for i, name in enumerate(ent_df.columns)}\n",
    "            \n",
    "            feat_drop = widgets.Dropdown(\n",
    "                options = ent_features,\n",
    "                description = 'Features: ',\n",
    "                layout=Layout(justify_content='flex-end')\n",
    "                \n",
    "            )\n",
    "            \n",
    "            # Changes the default slider values to be the previous iteration if the main entity is changed\n",
    "            try:\n",
    "                start = self.x_range[0]\n",
    "                end = self.x_range[1]\n",
    "            except:\n",
    "                start = 0\n",
    "                end = 300\n",
    "            \n",
    "            x_range = widgets.IntRangeSlider(\n",
    "                value=[start, end],\n",
    "                min=0,\n",
    "                max=ent_df.shape[0],\n",
    "                step=10,\n",
    "                description='Time Range:',\n",
    "                continuous_update=False,\n",
    "                orientation='horizontal',\n",
    "                readout=True,\n",
    "                readout_format='d',\n",
    "                layout=Layout(width='100%', align_items='stretch')\n",
    "            )\n",
    "            \n",
    "            \n",
    "            n_range = widgets.IntRangeSlider(\n",
    "                value=[0, 5],\n",
    "                min=1,\n",
    "                max=len(self.return_neighbors(sel_ent)),\n",
    "                step=1,\n",
    "                description='Neighbors:',\n",
    "                continuous_update=False,\n",
    "                orientation='horizontal',\n",
    "                readout=True,\n",
    "                readout_format='d',\n",
    "                layout=Layout(width='40%', align_items='stretch')\n",
    "            )\n",
    "            \n",
    "            # Create a checkbox boolean\n",
    "            show_rel = widgets.Checkbox(\n",
    "                value=False,\n",
    "                description = 'Show Neighbors',\n",
    "                disabled=False,\n",
    "            )\n",
    "            \n",
    "            widgets.interact(self.entity_graph, sel_feature = feat_drop, x_range = x_range, n_range = n_range, show_rel = show_rel)\n",
    "               \n",
    "        widgets.interact(sel_feature, sel_ent = ent_drop)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-249-c885f39cbc5a>:81: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  degree[i] = 1.0 / degree[i]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a78193656d40d1a1b605643c438de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Entities: ', layout=Layout(justify_content='flex-start'), options=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = Graph_Time_Series_Data(path=r'C:\\Users\\Maxwell\\PycharmProjects\\TAMU-ECEN-403-IFPTSND\\Temporal_Relational_Stock_Ranking-master\\data\\2013-01-01 - NASDAQ - Demo')\n",
    "test.display_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03125 0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.03125 0.      0.      0.03125\n",
      " 0.      0.      0.03125 0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.03125 0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.03125 0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.03125 0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.03125 0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.03125 0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.03125 0.\n",
      " 0.      0.      0.      0.      0.      0.      0.03125 0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.03125 0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.03125 0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.03125 0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.03125 0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.03125 0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.03125\n",
      " 0.      0.03125 0.      0.      0.      0.      0.      0.      0.03125\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.03125 0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.03125 0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.03125 0.      0.      0.03125 0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.03125 0.      0.      0.03125 0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.03125 0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.03125\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.03125 0.03125 0.03125 0.\n",
      " 0.03125 0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.03125 0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      " 0.      0.      0.      0.      0.      0.      0.      0.     ]\n"
     ]
    }
   ],
   "source": [
    "GCN = test.Normalized_Adjacency_Matrix.numpy()\n",
    "GCN_t = np.transpose(GCN)\n",
    "\n",
    "# for i in range(100):\n",
    "#     sumf = 0\n",
    "#     for n in GCN[i]:\n",
    "#         sumf = sumf + n\n",
    "#     print(sumf)\n",
    "\n",
    "print(GCN_t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
